{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zj/anaconda3/envs/finrl/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)\n",
    "e_train_gym_conservative.value_history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -72.8      |\n",
      "|    reward             | 0.19451597 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.68       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 68         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -0.115     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -1.4624771 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -167     |\n",
      "|    reward             | 5.02583  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    reward             | 5.606354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | -7.546301 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.0793    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 145       |\n",
      "|    reward             | 0.4507672 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -0.0998    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | -2.1521304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0.00557     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.80710465 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 70.3        |\n",
      "|    reward             | -0.11950674 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | -4.1389766 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -245     |\n",
      "|    reward             | 6.363784 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -63.1      |\n",
      "|    reward             | 0.07753525 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -0.000831 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 48.9      |\n",
      "|    reward             | -4.088032 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 179       |\n",
      "|    reward             | 2.0626597 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | 4.8591986 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 85.1       |\n",
      "|    reward             | 0.85958314 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -141     |\n",
      "|    reward             | 5.65319  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | 1.1973313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | 0.36287376 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | -0.0091     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -83.6       |\n",
      "|    reward             | -0.30971453 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 204       |\n",
      "|    reward             | 1.7650424 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | -7.5710273 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -2.04e+03  |\n",
      "|    reward             | -14.886115 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3e+03      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.0559524 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -46.7     |\n",
      "|    reward             | -0.434364 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    reward             | 4.8586307 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -0.4118847 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    reward             | 1.0554261 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 66.3      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.88      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 2.3091433 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -20.7      |\n",
      "|    reward             | 0.38583377 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 43.7       |\n",
      "|    reward             | -0.3664559 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -38.8      |\n",
      "|    reward             | -0.4616701 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | 0.11014476 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -3.93     |\n",
      "|    reward             | 2.1390972 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 76.4       |\n",
      "|    reward             | 0.16336557 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -85.2     |\n",
      "|    reward             | 1.0221922 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | 1.1701288 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 33.2      |\n",
      "|    reward             | 2.4472284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.2081411 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -0.481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -5.13     |\n",
      "|    reward             | 1.3224076 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2         |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.25540048 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.000881  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 1.3826902 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -64       |\n",
      "|    reward             | 3.9822705 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 63.9       |\n",
      "|    reward             | 0.95108056 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | -2.1539907 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    reward             | 4.8509326 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.00948     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -105        |\n",
      "|    reward             | -0.22313617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -104        |\n",
      "|    reward             | -0.99914765 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 353        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | 0.20132123 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -7.57e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 46.2       |\n",
      "|    reward             | 0.26696855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -83.4      |\n",
      "|    reward             | -1.8360271 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | 3.2874866 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 92.2      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161472.69\n",
      "total_reward: 2161472.69\n",
      "total_cost: 19221.41\n",
      "total_trades: 41334\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.54     |\n",
      "|    reward             | 0.2828299 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.19252001 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 2.0577734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.6       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -46.9       |\n",
      "|    reward             | -0.06746031 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.00117    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | 0.18157594 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0.0166    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | 0.6473793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.22656512 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 59.9       |\n",
      "|    reward             | -0.8028962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 439        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7693416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 446         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | -0.10761352 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 454      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 203      |\n",
      "|    reward             | 3.869458 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -0.0428   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 110       |\n",
      "|    reward             | 1.2343621 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -2.028344 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.33169752 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.98       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -869     |\n",
      "|    reward             | -8.09732 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 536      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.56556416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | -2.9329143 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 88.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 504        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 72.3       |\n",
      "|    reward             | 0.22214015 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -0.6425189 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -360        |\n",
      "|    reward             | -0.22756429 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 80.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -430        |\n",
      "|    reward             | -0.44158605 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 131         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 404        |\n",
      "|    reward             | -5.8487034 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -14.82644 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 832       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 548       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | 1.4826734 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.0473    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | 0.34629944 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -42       |\n",
      "|    reward             | -2.415951 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.0485888 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 42.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -207       |\n",
      "|    reward             | -3.2154734 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 56.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 5.370093  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | 0.03019213 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 118        |\n",
      "|    reward             | -1.1561224 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -214        |\n",
      "|    reward             | -0.94865924 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 30.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 613       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 1.1797212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 41.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 411        |\n",
      "|    reward             | -22.785406 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 627       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | 3.2164123 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 87          |\n",
      "|    reward             | -0.17441794 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 262         |\n",
      "|    reward             | -0.85795397 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 48.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 72.7       |\n",
      "|    reward             | -2.2230675 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 22.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -49.2     |\n",
      "|    reward             | 2.6728501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -238     |\n",
      "|    reward             | 8.656925 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0.000219    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.62001467 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 1.1713017 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 1.3898315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -52.5     |\n",
      "|    reward             | -6.044222 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    reward             | 1.8213228 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 706      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 177      |\n",
      "|    reward             | 8.957433 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.26523116 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | -0.00926   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | -0.6623605 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_1\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 124       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.5073655 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3946387.70\n",
      "total_reward: 2946387.70\n",
      "total_cost: 357438.48\n",
      "total_trades: 81024\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015788507 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00723     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 0.3435485   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375185 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -1.1157341  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016662188 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00193    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.2809894   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017038994 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00886    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | 3.2505164   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01701039 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0063     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 1.8685282  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486872 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0142    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    reward               | 0.39857626 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020911664 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0215     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 1.3883617   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7870/2360990771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_ppo = agent.train_model(model=model_ppo, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=3000000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             )\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_total_asset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_total_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m_get_date\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m         \"\"\"\n\u001b[0;32m-> 2039\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_hashtable_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_hashtable_algo\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_object_for_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mhtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_check_object_for_strings\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# including nulls because that is the only difference between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# StringHashTable and ObjectHashtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "Logging to ppo/8_9\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 118       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 17        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.7735156 |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017141536 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.000815   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.97        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    reward               | 0.87238264  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020700062 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.000377    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | -1.1141158  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016944326 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00404     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 3.4031198   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 83.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020287305 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.00815     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.5         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    reward               | 3.0896044   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033340376 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.0199     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | 1.9651109   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020314064 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.00831    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 1.699519    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146674365 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.5        |\n",
      "|    explained_variance   | -0.00934     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    reward               | 0.111564256  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024441488 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0108     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | 0.29339638  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017688043 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0.0157      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.18420015  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017259847 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 1.7608775   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020796824 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.0324     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.29        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | -0.19528693 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2924221.42\n",
      "total_reward: 1924221.42\n",
      "total_cost: 316090.63\n",
      "total_trades: 78547\n",
      "Sharpe: 0.603\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 236         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021577362 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -0.19596574 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018078584 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.00569     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | -0.2126098  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015789794 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.0042      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 2.821724    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019838762 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0039      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | 0.25532323  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017993968 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.011       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 0.36551204  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018817777 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.00123     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.28822002 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 66.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015669467 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | -0.0164     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | -0.43828735 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024833087 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.00435     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -0.6084556  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 65.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021173522 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.00846     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -6.164447   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023324816 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.0294      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 3.5745618   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019209854 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.0179      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 1.1091183   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015902992 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | 8.084099    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 82.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023505282 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.67081445  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022522267 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.52        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 0.44640502  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2979893.84\n",
      "total_reward: 1979893.84\n",
      "total_cost: 304117.90\n",
      "total_trades: 75542\n",
      "Sharpe: 0.611\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028918099 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0315      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | 0.78273934  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028139807 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.00281     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -1.7846901  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020997021 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -0.65063566 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021115076 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.013      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    reward               | 0.82026684  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 564        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03619449 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.7      |\n",
      "|    explained_variance   | -0.00422   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.5       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    reward               | 1.6597645  |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 69.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 582         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021115389 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -0.0691202  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 600         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034333196 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.0167     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -0.42431706 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 618         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028198242 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0132      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.7097938   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 636         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017183341 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0104      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.32940608  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036352538 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0795      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.86        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -3.5115843  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 672        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03722957 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.1      |\n",
      "|    explained_variance   | -0.0135    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.2       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    reward               | -0.471461  |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 83.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 689         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029276181 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | -7.926272   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 708         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026813192 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.00367     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -2.1111271  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 726         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025919914 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0163      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    reward               | -0.5322937  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4249712.52\n",
      "total_reward: 3249712.52\n",
      "total_cost: 276871.12\n",
      "total_trades: 73191\n",
      "Sharpe: 0.806\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025633162 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0173      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    reward               | 0.37491745  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 75.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 763         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015614071 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.00234     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -0.47437537 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 98          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025923848 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 0.5865171   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 800         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025465146 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | 0.0292      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | 0.049281813 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 819         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037976407 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | -0.00834    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 0.6560085   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 837        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03643445 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.76       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    reward               | -4.8664193 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 855         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022490459 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | -0.00281    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 1.7491857   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 873         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020182345 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.00173     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 8.845829    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 95.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 892         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033218548 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | -0.53720194 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 91.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 910        |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02107561 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.7      |\n",
      "|    explained_variance   | 0.0436     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    reward               | -1.3682231 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 24         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 928         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.05380343  |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.1        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | 0.00274     |\n",
      "|    reward               | -0.20329031 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 946         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031677667 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | -0.00533    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.5        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -3.9148052  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 79          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 965        |\n",
      "|    total_timesteps      | 108544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03202444 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0335     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14         |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.00693   |\n",
      "|    reward               | 2.387834   |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 984         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023762926 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0242      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 1.0669519   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 1003       |\n",
      "|    total_timesteps      | 112640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03972151 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.00347    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41         |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.00499   |\n",
      "|    reward               | 3.435828   |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3570862.79\n",
      "total_reward: 2570862.79\n",
      "total_cost: 306409.05\n",
      "total_trades: 75089\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1021        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035938546 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | 1.7780644   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1040        |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028091999 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0142      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | -0.23198897 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 83.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 1059       |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02546818 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.2      |\n",
      "|    explained_variance   | 0.0497     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.7       |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    reward               | 0.80017054 |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 86.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1077        |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025758453 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | 1.7044668   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 83.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1096        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036357824 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | -0.0528     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.25        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | -0.31707385 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 1114       |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02223364 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | -0.0205    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.5       |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.00805   |\n",
      "|    reward               | 1.4213164  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 63.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1133        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026972776 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0341      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | 6.9173956   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 1152       |\n",
      "|    total_timesteps      | 129024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03190663 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.00629    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | 0.0012     |\n",
      "|    reward               | 2.5060806  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 41         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1170        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020936247 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.000342    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | -0.62420255 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 1188       |\n",
      "|    total_timesteps      | 133120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02300477 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0252     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 52.4       |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.00851   |\n",
      "|    reward               | -1.3957038 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 87.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1207        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029090386 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.00419     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 2.9160311   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 78.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1225        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038564004 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.91        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.6711551  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 1242       |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03589365 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.7      |\n",
      "|    explained_variance   | 0.00982    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.5       |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    reward               | 0.15574928 |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 80.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 1261       |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03380338 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.0336     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.5       |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.00765   |\n",
      "|    reward               | -1.4849764 |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 57.2       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2379698.66\n",
      "total_reward: 1379698.66\n",
      "total_cost: 320884.13\n",
      "total_trades: 74399\n",
      "Sharpe: 0.502\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1279        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034138143 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.00357     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.13994366 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041191295 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.0242      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 0.46123987  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 1316       |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03725774 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.9      |\n",
      "|    explained_variance   | 0.0347     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.00916   |\n",
      "|    reward               | -10.48139  |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 33.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1334        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030024504 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.0754      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.96        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.15518944  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1353        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031111183 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0676      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -1.6350302  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1371        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028059416 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | 1.6677893   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1389        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031865187 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 1.0664654   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 1407       |\n",
      "|    total_timesteps      | 157696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03048024 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.2      |\n",
      "|    explained_variance   | 0.0247     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.76       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.00767   |\n",
      "|    reward               | 0.668053   |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 23         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1425        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026014931 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 2.9155831   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1443        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033617236 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.0441      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.8570205   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1462        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034880266 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0623      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | 0.41041178  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1480        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018330593 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0745      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -0.7125414  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 61          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1498        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02592865  |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0252      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -0.78827435 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1516        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016443225 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.0883      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 0.18193682  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2101249.17\n",
      "total_reward: 1101249.17\n",
      "total_cost: 296553.45\n",
      "total_trades: 73227\n",
      "Sharpe: 0.430\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1535        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025809696 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0718      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.37        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.109500386 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1554        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043682545 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0613      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 0.04759277  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1572        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026798338 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.0707      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 1.21795     |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1590        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032214858 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | -0.0533     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.98        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | 2.0559952   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1608        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037605006 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.0481      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    reward               | -2.7534072  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1626        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046755914 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.046       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | -0.14969285 |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1645        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034558363 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | 0.41635886  |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 85.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1663        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03602113  |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0787      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | -0.30180758 |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1681        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032300938 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | -1.8817426  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 82          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 1700       |\n",
      "|    total_timesteps      | 190464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02596085 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.9      |\n",
      "|    explained_variance   | 0.0475     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37         |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | -0.00432   |\n",
      "|    reward               | -1.9646126 |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 63.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1718        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030015927 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.9       |\n",
      "|    explained_variance   | 0.0203      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    reward               | -0.21284465 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1736        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023712363 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46         |\n",
      "|    explained_variance   | 0.0753      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -1.2827721  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 1754       |\n",
      "|    total_timesteps      | 196608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02584888 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46        |\n",
      "|    explained_variance   | 0.0368     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20         |\n",
      "|    n_updates            | 950        |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    reward               | 1.0346544  |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 49         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 1772       |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04209498 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.1      |\n",
      "|    explained_variance   | 0.0154     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.2       |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -2.89e-05  |\n",
      "|    reward               | 1.3648102  |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 32.6       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3269150.60\n",
      "total_reward: 2269150.60\n",
      "total_cost: 308039.47\n",
      "total_trades: 73664\n",
      "Sharpe: 0.647\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1791        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026362693 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.0414      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.05192206 |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1809        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031854957 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.0264      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | -1.9262127  |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 61.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 1828       |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01837058 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.3      |\n",
      "|    explained_variance   | 0.0395     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42         |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | -2.215527  |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 71.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 1846       |\n",
      "|    total_timesteps      | 206848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03489563 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.3      |\n",
      "|    explained_variance   | 0.0582     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | -0.00426   |\n",
      "|    reward               | -1.4860654 |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 30.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1864        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022246547 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.052       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -1.1628128  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1883        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022189435 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.4       |\n",
      "|    explained_variance   | 0.076       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.3170328   |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 1901       |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07056843 |\n",
      "|    clip_fraction        | 0.459      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.4      |\n",
      "|    explained_variance   | -0.0294    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.3       |\n",
      "|    n_updates            | 1030       |\n",
      "|    policy_gradient_loss | 0.00466    |\n",
      "|    reward               | 1.8688803  |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 35.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 1920       |\n",
      "|    total_timesteps      | 215040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03801911 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | 0.0331     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.6       |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    reward               | -3.8192868 |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 73.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1938        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029156595 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | 0.00464     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -0.7974007  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 1956        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033777457 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | -0.58811873 |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 85.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 1974       |\n",
      "|    total_timesteps      | 221184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03755711 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.7      |\n",
      "|    explained_variance   | 0.0127     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.1       |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.00551   |\n",
      "|    reward               | -0.5629523 |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 19.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 1992        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029648822 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | 0.01889198  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 77.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 2010        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036853645 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 2.0519753   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 2028       |\n",
      "|    total_timesteps      | 227328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04037764 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.8      |\n",
      "|    explained_variance   | 0.121      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | -0.00468   |\n",
      "|    reward               | 8.067288   |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 32.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3060597.80\n",
      "total_reward: 2060597.80\n",
      "total_cost: 312772.04\n",
      "total_trades: 73302\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 2046        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055083513 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.00795     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.000717   |\n",
      "|    reward               | -1.3186854  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 72.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 2065        |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039092332 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.000787    |\n",
      "|    reward               | -7.958382   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 2082        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025432106 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.0133      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | 0.6753651   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 2101       |\n",
      "|    total_timesteps      | 235520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04004226 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.1      |\n",
      "|    explained_variance   | -0.0109    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.34       |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | -0.00737   |\n",
      "|    reward               | -1.3312051 |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 23.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2119        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035415027 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | -1.9154272  |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 2137        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039939985 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | 0.66159767  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 89.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 2155        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021973774 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | -0.0453     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 1.5485333   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2173        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056727253 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | 1.295892    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 75.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 2192        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037325047 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.00824     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    reward               | -2.8354487  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 2210        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029608816 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.0142      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | -1.1001923  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 2228       |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03347399 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.5      |\n",
      "|    explained_variance   | 0.0323     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.8       |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    reward               | 0.9244238  |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 61.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 2248        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032108575 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | -0.00531    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | 2.4747186   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 73.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 2266        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045089602 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.4        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | 0.00208     |\n",
      "|    reward               | 0.49525937  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 2285        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031792104 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.0297      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | 0.58421737  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2591748.10\n",
      "total_reward: 1591748.10\n",
      "total_cost: 316695.06\n",
      "total_trades: 73234\n",
      "Sharpe: 0.551\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 2303        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03806799  |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.0721      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -0.50203294 |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 127        |\n",
      "|    time_elapsed         | 2322       |\n",
      "|    total_timesteps      | 260096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03355003 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.7      |\n",
      "|    explained_variance   | 0.045      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | -4.345476  |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 41.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 2340        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043959346 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.0274      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | 2.4246864   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 2358        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035177626 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.0401      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.5397375  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 96.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 2376         |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.030366     |\n",
      "|    clip_fraction        | 0.228        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.9        |\n",
      "|    explained_variance   | 0.0473       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.3         |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | -0.009661776 |\n",
      "|    std                  | 1.26         |\n",
      "|    value_loss           | 68.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 2395        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034079004 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -2.154451   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 2413        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024818372 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | -0.00929    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.23        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 2.200253    |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 2432        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026647452 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0614      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.2        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | 2.5231245   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 2450        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030210657 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.00385     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | 1.6365374   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 135        |\n",
      "|    time_elapsed         | 2468       |\n",
      "|    total_timesteps      | 276480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04981225 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.1      |\n",
      "|    explained_variance   | 0.0359     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.8       |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | -0.00458   |\n",
      "|    reward               | -0.6846704 |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 28         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 2486        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044216875 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0361      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.2840182   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 2504       |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03171958 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.2      |\n",
      "|    explained_variance   | 0.0405     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.4       |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | -0.000186  |\n",
      "|    reward               | 0.58534944 |\n",
      "|    std                  | 1.28       |\n",
      "|    value_loss           | 69.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 2522        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057284974 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.00533     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | 0.5000605   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 62.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2541        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034738064 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | 0.00149     |\n",
      "|    reward               | -1.1758231  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2214069.28\n",
      "total_reward: 1214069.28\n",
      "total_cost: 300799.85\n",
      "total_trades: 70594\n",
      "Sharpe: 0.462\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 2559        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034739185 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0941      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 1.4788734   |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 2577        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031326257 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.0591      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    reward               | 1.981997    |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 142        |\n",
      "|    time_elapsed         | 2595       |\n",
      "|    total_timesteps      | 290816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04392592 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.4      |\n",
      "|    explained_variance   | -0.00524   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.2       |\n",
      "|    n_updates            | 1410       |\n",
      "|    policy_gradient_loss | 0.00591    |\n",
      "|    reward               | -1.4454795 |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 43.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 2613        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026809175 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.0237      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | 0.09530249  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 2631        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017105293 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | 2.6790931   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 65.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 2649        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025218481 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    reward               | -0.5438303  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 2667        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029606137 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.0747      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | 0.00146     |\n",
      "|    reward               | 2.6956565   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 2685        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025099467 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    reward               | -0.48297706 |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 2704        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018931337 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.00341     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | -1.1235477  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 72.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 2723        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024988405 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    reward               | 1.362331    |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 2741        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032403484 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.000904   |\n",
      "|    reward               | 2.342346    |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 2760        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025373865 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 0.5864475   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 2778       |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03080684 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.8      |\n",
      "|    explained_variance   | 0.0751     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.2       |\n",
      "|    n_updates            | 1510       |\n",
      "|    policy_gradient_loss | -0.00434   |\n",
      "|    reward               | -2.3893394 |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 42.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 2797        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037149288 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.0403      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | 0.48574856  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2904473.81\n",
      "total_reward: 1904473.81\n",
      "total_cost: 266961.13\n",
      "total_trades: 66302\n",
      "Sharpe: 0.573\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 2817        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055502504 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.027       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | 0.000427    |\n",
      "|    reward               | -0.43030277 |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 68.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 2835        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026547706 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.0537      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    reward               | -1.2576237  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2854        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018500011 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.0318      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    reward               | -2.0538547  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 157        |\n",
      "|    time_elapsed         | 2873       |\n",
      "|    total_timesteps      | 321536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04179831 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49        |\n",
      "|    explained_variance   | 0.0487     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.1       |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | 0.00406    |\n",
      "|    reward               | -1.7558986 |\n",
      "|    std                  | 1.31       |\n",
      "|    value_loss           | 60.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 2892        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015529856 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.0418      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | 0.000727    |\n",
      "|    reward               | -10.18451   |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 159       |\n",
      "|    time_elapsed         | 2911      |\n",
      "|    total_timesteps      | 325632    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0437954 |\n",
      "|    clip_fraction        | 0.255     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -49       |\n",
      "|    explained_variance   | 0.0371    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 14.7      |\n",
      "|    n_updates            | 1580      |\n",
      "|    policy_gradient_loss | -0.00179  |\n",
      "|    reward               | -3.905565 |\n",
      "|    std                  | 1.31      |\n",
      "|    value_loss           | 42.2      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 2930       |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03349519 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49        |\n",
      "|    explained_variance   | 0.0489     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.5       |\n",
      "|    n_updates            | 1590       |\n",
      "|    policy_gradient_loss | -0.0074    |\n",
      "|    reward               | 1.574649   |\n",
      "|    std                  | 1.31       |\n",
      "|    value_loss           | 60.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 2949        |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029283913 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.0531      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 25.39506    |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 91.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 2968        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033657663 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | -6.210414   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 64.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 2987        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037012283 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.0678      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | -1.0166824  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 3007        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025681986 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 0.32372862  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 3025        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040096693 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.0203      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | 0.00195     |\n",
      "|    reward               | 6.1463747   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 91.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 3044        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033594407 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.0636      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | 0.000736    |\n",
      "|    reward               | 1.3079853   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 3062        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027868733 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.061       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    reward               | -1.7931044  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 75.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 3080        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035672333 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | -0.0069     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.2        |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 0.60106355  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4357086.48\n",
      "total_reward: 3357086.48\n",
      "total_cost: 271850.18\n",
      "total_trades: 68828\n",
      "Sharpe: 0.760\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 3100        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020668797 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.0543      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | -3.8916647  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 3118        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039897703 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.0468      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67          |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | -3.4323425  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 78.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 3136        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040384248 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.0877      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.8        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | -0.81400305 |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3156        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026845686 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.0771      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.8        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | 1.0792603   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 3174        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040012784 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.011       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | 0.00773     |\n",
      "|    reward               | -1.2346132  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 3193        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034862928 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.0699      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | 0.2805814   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 74.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 3213        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031797115 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.0308      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 0.15997936  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 76.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 3231        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024291415 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.0886      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 4.2300177   |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 3250       |\n",
      "|    total_timesteps      | 362496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04648768 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50        |\n",
      "|    explained_variance   | 0.042      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.4       |\n",
      "|    n_updates            | 1760       |\n",
      "|    policy_gradient_loss | -0.00727   |\n",
      "|    reward               | -0.1563233 |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 53         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 3268        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036828883 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.035       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | -0.9417338  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 76.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 179        |\n",
      "|    time_elapsed         | 3287       |\n",
      "|    total_timesteps      | 366592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03598076 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.1      |\n",
      "|    explained_variance   | 0.0723     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.5       |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | -0.00145   |\n",
      "|    reward               | 0.65677637 |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 89         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 180        |\n",
      "|    time_elapsed         | 3305       |\n",
      "|    total_timesteps      | 368640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04495021 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.2      |\n",
      "|    explained_variance   | 0.0172     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 1790       |\n",
      "|    policy_gradient_loss | -0.00642   |\n",
      "|    reward               | -0.8445355 |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 26.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 3323        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027348638 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | 0.29679897  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 182        |\n",
      "|    time_elapsed         | 3342       |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03649335 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.3      |\n",
      "|    explained_variance   | 0.0382     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.1       |\n",
      "|    n_updates            | 1810       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | -2.3807662 |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 83.5       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4514048.76\n",
      "total_reward: 3514048.76\n",
      "total_cost: 255097.01\n",
      "total_trades: 68896\n",
      "Sharpe: 0.795\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3360        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046545934 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.00388     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | 0.00221     |\n",
      "|    reward               | -1.2405423  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 3378        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042772286 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    reward               | -3.2137396  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 3397       |\n",
      "|    total_timesteps      | 378880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03954544 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.4      |\n",
      "|    explained_variance   | -0.0135    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.6       |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.00607   |\n",
      "|    reward               | 6.6393104  |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 86.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 186        |\n",
      "|    time_elapsed         | 3417       |\n",
      "|    total_timesteps      | 380928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02765704 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.4      |\n",
      "|    explained_variance   | 0.0492     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 1850       |\n",
      "|    policy_gradient_loss | -0.00467   |\n",
      "|    reward               | -1.999837  |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 38         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 3438        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022586733 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.0599      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | 1.5005095   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 3456        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024499524 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | 0.13451092  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 3475        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014311701 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.0695      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -3.2405438  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 71.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 3493        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026225539 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | 5.0992384   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 3511        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032933734 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | 1.3700595   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 3530        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022707649 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.0248      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | 0.00154     |\n",
      "|    reward               | 11.248374   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 68.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 3548        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026567714 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | 0.000846    |\n",
      "|    reward               | 1.3353199   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 74.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 3567        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028277826 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.00556     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | 1.4409869   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 78          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 3587        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031392485 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0144      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.7        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 0.5525496   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 3605        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022271274 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.00048     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | 4.381329    |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 84.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3827576.98\n",
      "total_reward: 2827576.98\n",
      "total_cost: 261112.92\n",
      "total_trades: 68951\n",
      "Sharpe: 0.716\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 197        |\n",
      "|    time_elapsed         | 3624       |\n",
      "|    total_timesteps      | 403456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06811935 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.7      |\n",
      "|    explained_variance   | -0.102     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.9       |\n",
      "|    n_updates            | 1960       |\n",
      "|    policy_gradient_loss | 0.00654    |\n",
      "|    reward               | 2.2076535  |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 29.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 3643        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024925033 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.0888      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 0.7787595   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 3662        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027173558 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 3.3147423   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 3681        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027933665 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | -0.00548    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    reward               | -0.29796806 |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 201        |\n",
      "|    time_elapsed         | 3700       |\n",
      "|    total_timesteps      | 411648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03019631 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.9      |\n",
      "|    explained_variance   | 0.023      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 103        |\n",
      "|    n_updates            | 2000       |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | -0.9415544 |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 169        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 3719        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021279432 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.0989      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | -12.903487  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 85.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 203        |\n",
      "|    time_elapsed         | 3737       |\n",
      "|    total_timesteps      | 415744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04074882 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.9      |\n",
      "|    explained_variance   | -0.00177   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.9       |\n",
      "|    n_updates            | 2020       |\n",
      "|    policy_gradient_loss | -0.00376   |\n",
      "|    reward               | -0.605495  |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 132        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 3756        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053067558 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    reward               | -0.5918857  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 3774        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024166632 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.039       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.5        |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    reward               | 4.3735642   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 3793        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019171119 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.0957      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | -2.628235   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 89.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 3811       |\n",
      "|    total_timesteps      | 423936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03400559 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.1      |\n",
      "|    explained_variance   | 0.141      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 2060       |\n",
      "|    policy_gradient_loss | -0.00229   |\n",
      "|    reward               | -1.0944915 |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 33.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 208        |\n",
      "|    time_elapsed         | 3830       |\n",
      "|    total_timesteps      | 425984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03244125 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.1      |\n",
      "|    explained_variance   | 0.0943     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.2       |\n",
      "|    n_updates            | 2070       |\n",
      "|    policy_gradient_loss | 5.3e-05    |\n",
      "|    reward               | -3.3447323 |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 79.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 3849        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020476447 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | 0.000416    |\n",
      "|    reward               | 3.483122    |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 3868        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02914698  |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | 0.00115     |\n",
      "|    reward               | -0.42127857 |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3975805.79\n",
      "total_reward: 2975805.79\n",
      "total_cost: 182631.11\n",
      "total_trades: 63183\n",
      "Sharpe: 0.637\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 3886        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020298976 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89          |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | 0.17150198  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 3905        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04287182  |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.0964      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | 0.00184     |\n",
      "|    reward               | 0.025520394 |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 3924        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015765587 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.0695      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | 0.00196     |\n",
      "|    reward               | 1.0781876   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 3943        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026695598 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | -0.4882914  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 3962        |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044223785 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.0903      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | 0.00593     |\n",
      "|    reward               | 0.51758426  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 3981       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01623801 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.4      |\n",
      "|    explained_variance   | 0.212      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.2       |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | 0.56883615 |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 50.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 3999        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019304289 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.091       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 0.6950503   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 218        |\n",
      "|    time_elapsed         | 4019       |\n",
      "|    total_timesteps      | 446464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02129961 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.4      |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.6       |\n",
      "|    n_updates            | 2170       |\n",
      "|    policy_gradient_loss | -0.009     |\n",
      "|    reward               | 0.9147229  |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 38.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 4038        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017857704 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 175         |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    reward               | -0.7913772  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 220        |\n",
      "|    time_elapsed         | 4057       |\n",
      "|    total_timesteps      | 450560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03166035 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.4      |\n",
      "|    explained_variance   | 0.0495     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.4       |\n",
      "|    n_updates            | 2190       |\n",
      "|    policy_gradient_loss | -0.00658   |\n",
      "|    reward               | 2.3598015  |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 65.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 221        |\n",
      "|    time_elapsed         | 4076       |\n",
      "|    total_timesteps      | 452608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06258549 |\n",
      "|    clip_fraction        | 0.43       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.5      |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.1       |\n",
      "|    n_updates            | 2200       |\n",
      "|    policy_gradient_loss | 0.00333    |\n",
      "|    reward               | -1.3290033 |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 38         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 4094        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04064931  |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | 0.00364     |\n",
      "|    reward               | -0.40548903 |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 4113        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030168211 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.031       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.1        |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | 1.8924731   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 224        |\n",
      "|    time_elapsed         | 4133       |\n",
      "|    total_timesteps      | 458752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02766427 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.7      |\n",
      "|    explained_variance   | 0.145      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 2230       |\n",
      "|    policy_gradient_loss | 0.00183    |\n",
      "|    reward               | 1.1347402  |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 37.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4207480.97\n",
      "total_reward: 3207480.97\n",
      "total_cost: 195821.30\n",
      "total_trades: 64231\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 4151       |\n",
      "|    total_timesteps      | 460800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04245798 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.8      |\n",
      "|    explained_variance   | 0.203      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.8       |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | -0.00698   |\n",
      "|    reward               | 2.17302    |\n",
      "|    std                  | 1.45       |\n",
      "|    value_loss           | 49.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 4170        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033370607 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 3.6091092   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 4188         |\n",
      "|    total_timesteps      | 464896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140926475 |\n",
      "|    clip_fraction        | 0.216        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51.8        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 2260         |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | 0.58846885   |\n",
      "|    std                  | 1.45         |\n",
      "|    value_loss           | 92.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 4207        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046132587 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | 2.1199582   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 4226        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031207182 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | -0.41952056 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 4245        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058991626 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    reward               | 0.08174828  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 4263        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034460645 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.068       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | -4.525917   |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 4282        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021536909 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -0.69008905 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 233        |\n",
      "|    time_elapsed         | 4301       |\n",
      "|    total_timesteps      | 477184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02996294 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.1      |\n",
      "|    explained_variance   | 0.181      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.1       |\n",
      "|    n_updates            | 2320       |\n",
      "|    policy_gradient_loss | -0.00724   |\n",
      "|    reward               | 3.059269   |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 76.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 4319        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037649143 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    reward               | 0.40295863  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 4337        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030728944 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | -1.6487919  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 4355        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031787906 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | 1.9967308   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 4373        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020584667 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 0.85697603  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 69.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 4392        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01872522  |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | -0.000663   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.08        |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -0.50708526 |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3605262.14\n",
      "total_reward: 2605262.14\n",
      "total_cost: 210530.76\n",
      "total_trades: 63882\n",
      "Sharpe: 0.689\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 4410        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030348688 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    reward               | 3.546947    |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 87.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 240        |\n",
      "|    time_elapsed         | 4428       |\n",
      "|    total_timesteps      | 491520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04063562 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.3      |\n",
      "|    explained_variance   | 0.365      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28         |\n",
      "|    n_updates            | 2390       |\n",
      "|    policy_gradient_loss | 0.00454    |\n",
      "|    reward               | -1.5100704 |\n",
      "|    std                  | 1.47       |\n",
      "|    value_loss           | 57.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 4446        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031783544 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | 0.000241    |\n",
      "|    reward               | -2.7520666  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 242        |\n",
      "|    time_elapsed         | 4464       |\n",
      "|    total_timesteps      | 495616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03189831 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.4      |\n",
      "|    explained_variance   | 0.0904     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 2410       |\n",
      "|    policy_gradient_loss | -0.00132   |\n",
      "|    reward               | 0.8623813  |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 86.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 4482        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019094551 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -0.06118005 |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 4501        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020532047 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.0243      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 0.7827793   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 94.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 4519        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036305763 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 1.9580595   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 4538        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050901763 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.0866      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    reward               | 1.1619132   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 4556        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030666932 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.0706      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | 0.000851    |\n",
      "|    reward               | 2.9244611   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 4575        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031878132 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | -1.8371812  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 249        |\n",
      "|    time_elapsed         | 4593       |\n",
      "|    total_timesteps      | 509952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03604231 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.8      |\n",
      "|    explained_variance   | 0.0935     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 2480       |\n",
      "|    policy_gradient_loss | -0.0069    |\n",
      "|    reward               | 2.135564   |\n",
      "|    std                  | 1.5        |\n",
      "|    value_loss           | 93.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 250        |\n",
      "|    time_elapsed         | 4611       |\n",
      "|    total_timesteps      | 512000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03950123 |\n",
      "|    clip_fraction        | 0.386      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.8      |\n",
      "|    explained_variance   | 0.119      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 2490       |\n",
      "|    policy_gradient_loss | 0.00369    |\n",
      "|    reward               | -8.346969  |\n",
      "|    std                  | 1.5        |\n",
      "|    value_loss           | 75.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 4630        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018695634 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.0929      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.000667   |\n",
      "|    reward               | -0.25060782 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 4648        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029340664 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | -3.4087725  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4470969.72\n",
      "total_reward: 3470969.72\n",
      "total_cost: 152484.72\n",
      "total_trades: 60264\n",
      "Sharpe: 0.751\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 4666        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035234954 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | 0.00259     |\n",
      "|    reward               | -0.23262791 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 4684        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042807497 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | 0.00196     |\n",
      "|    reward               | -1.6728044  |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 4703        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033635914 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.066       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    reward               | 6.968975    |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 256        |\n",
      "|    time_elapsed         | 4721       |\n",
      "|    total_timesteps      | 524288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02491846 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53        |\n",
      "|    explained_variance   | -0.000674  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 2550       |\n",
      "|    policy_gradient_loss | 6.51e-05   |\n",
      "|    reward               | 7.159239   |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 154        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 4739        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025778322 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.2        |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    reward               | -0.7693047  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 4758        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045261793 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | 3.0577292   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 4776        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020715404 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.6        |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.7469997   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 92.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 260        |\n",
      "|    time_elapsed         | 4795       |\n",
      "|    total_timesteps      | 532480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0267283  |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.1      |\n",
      "|    explained_variance   | 0.0921     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 115        |\n",
      "|    n_updates            | 2590       |\n",
      "|    policy_gradient_loss | -0.00431   |\n",
      "|    reward               | -0.6905554 |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 123        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 4813        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034945432 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | 0.001       |\n",
      "|    reward               | 0.75377154  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 4831       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04033746 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.2      |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | 0.00357    |\n",
      "|    reward               | -0.9614772 |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 33.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 263        |\n",
      "|    time_elapsed         | 4850       |\n",
      "|    total_timesteps      | 538624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03352321 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.3      |\n",
      "|    explained_variance   | 0.0854     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.7       |\n",
      "|    n_updates            | 2620       |\n",
      "|    policy_gradient_loss | -0.00753   |\n",
      "|    reward               | 0.31045777 |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 99.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 264        |\n",
      "|    time_elapsed         | 4870       |\n",
      "|    total_timesteps      | 540672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03553    |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.3      |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.8       |\n",
      "|    n_updates            | 2630       |\n",
      "|    policy_gradient_loss | -0.00135   |\n",
      "|    reward               | -2.0556023 |\n",
      "|    std                  | 1.53       |\n",
      "|    value_loss           | 99.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 4888        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027729424 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    reward               | -1.4083409  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 4906        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028938806 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | -2.2958858  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4541250.90\n",
      "total_reward: 3541250.90\n",
      "total_cost: 179868.30\n",
      "total_trades: 62670\n",
      "Sharpe: 0.738\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 4924        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027891165 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | 0.00116     |\n",
      "|    reward               | -1.1870106  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 94.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 4942       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.034312   |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.5      |\n",
      "|    explained_variance   | 0.0483     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.6       |\n",
      "|    n_updates            | 2670       |\n",
      "|    policy_gradient_loss | 0.00394    |\n",
      "|    reward               | -1.0160537 |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 149        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 4961        |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033217996 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | 1.0373503   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 4979        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019452872 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.023       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | 2.299138    |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 271        |\n",
      "|    time_elapsed         | 4998       |\n",
      "|    total_timesteps      | 555008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02954385 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.6      |\n",
      "|    explained_variance   | 0.025      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.7       |\n",
      "|    n_updates            | 2700       |\n",
      "|    policy_gradient_loss | -0.00943   |\n",
      "|    reward               | 5.2565303  |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 83         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 272        |\n",
      "|    time_elapsed         | 5018       |\n",
      "|    total_timesteps      | 557056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01739832 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.6      |\n",
      "|    explained_variance   | 0.149      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.7       |\n",
      "|    n_updates            | 2710       |\n",
      "|    policy_gradient_loss | -0.00282   |\n",
      "|    reward               | 1.1657046  |\n",
      "|    std                  | 1.54       |\n",
      "|    value_loss           | 37         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 5036        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028527219 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.69364196 |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 5055        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025815796 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | -11.4183235 |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 5073        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035491608 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | 0.488082    |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 276        |\n",
      "|    time_elapsed         | 5092       |\n",
      "|    total_timesteps      | 565248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03953238 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.8      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.7       |\n",
      "|    n_updates            | 2750       |\n",
      "|    policy_gradient_loss | 0.0031     |\n",
      "|    reward               | 0.29556128 |\n",
      "|    std                  | 1.55       |\n",
      "|    value_loss           | 40.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 5110        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039749376 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    reward               | -0.8342538  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 278        |\n",
      "|    time_elapsed         | 5129       |\n",
      "|    total_timesteps      | 569344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05023318 |\n",
      "|    clip_fraction        | 0.456      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.8      |\n",
      "|    explained_variance   | 0.0994     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.2       |\n",
      "|    n_updates            | 2770       |\n",
      "|    policy_gradient_loss | 0.0162     |\n",
      "|    reward               | 1.613694   |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 44.8       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 279       |\n",
      "|    time_elapsed         | 5147      |\n",
      "|    total_timesteps      | 571392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0346853 |\n",
      "|    clip_fraction        | 0.313     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -53.9     |\n",
      "|    explained_variance   | 0.0345    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 15.3      |\n",
      "|    n_updates            | 2780      |\n",
      "|    policy_gradient_loss | -0.000185 |\n",
      "|    reward               | 1.310486  |\n",
      "|    std                  | 1.56      |\n",
      "|    value_loss           | 28.9      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 5165        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030997852 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 3.4400527   |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 281        |\n",
      "|    time_elapsed         | 5183       |\n",
      "|    total_timesteps      | 575488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02395872 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.1      |\n",
      "|    explained_variance   | 0.222      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.7       |\n",
      "|    n_updates            | 2800       |\n",
      "|    policy_gradient_loss | -0.00838   |\n",
      "|    reward               | 1.6259757  |\n",
      "|    std                  | 1.57       |\n",
      "|    value_loss           | 64.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2802617.00\n",
      "total_reward: 1802617.00\n",
      "total_cost: 306100.20\n",
      "total_trades: 68902\n",
      "Sharpe: 0.548\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 5202        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04233699  |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.0211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -0.31805918 |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 283        |\n",
      "|    time_elapsed         | 5220       |\n",
      "|    total_timesteps      | 579584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05511018 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.2      |\n",
      "|    explained_variance   | 0.0804     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.5       |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | -0.00311   |\n",
      "|    reward               | 1.0639102  |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 50.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 5239        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039810367 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.9        |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 3.4752002   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 5259        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043727566 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.0563      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | 0.00342     |\n",
      "|    reward               | 3.2391293   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 5277        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044030458 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.0581      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | 0.0055      |\n",
      "|    reward               | -0.46432832 |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 5296        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027399084 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.0867      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 0.16020422  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 5314        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020501837 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | 0.00033     |\n",
      "|    reward               | 1.4613699   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 89.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 289        |\n",
      "|    time_elapsed         | 5333       |\n",
      "|    total_timesteps      | 591872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04693868 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.5      |\n",
      "|    explained_variance   | 0.193      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 2880       |\n",
      "|    policy_gradient_loss | -0.00684   |\n",
      "|    reward               | 6.1571274  |\n",
      "|    std                  | 1.59       |\n",
      "|    value_loss           | 28.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 5352        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031678673 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.0973      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.13021755 |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 291        |\n",
      "|    time_elapsed         | 5371       |\n",
      "|    total_timesteps      | 595968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03266429 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.5      |\n",
      "|    explained_variance   | 0.0379     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.8       |\n",
      "|    n_updates            | 2900       |\n",
      "|    policy_gradient_loss | -0.00833   |\n",
      "|    reward               | 0.07731365 |\n",
      "|    std                  | 1.59       |\n",
      "|    value_loss           | 122        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 292        |\n",
      "|    time_elapsed         | 5389       |\n",
      "|    total_timesteps      | 598016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04261682 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.6      |\n",
      "|    explained_variance   | -0.0162    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.9       |\n",
      "|    n_updates            | 2910       |\n",
      "|    policy_gradient_loss | -0.00619   |\n",
      "|    reward               | -3.975085  |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 124        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 5408        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033721957 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | -0.36662    |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 294        |\n",
      "|    time_elapsed         | 5427       |\n",
      "|    total_timesteps      | 602112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02493428 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.7      |\n",
      "|    explained_variance   | 0.0931     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.6       |\n",
      "|    n_updates            | 2930       |\n",
      "|    policy_gradient_loss | -0.0034    |\n",
      "|    reward               | 0.1498409  |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 81         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 5446        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025569797 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.067       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.6        |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | -1.7678574  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 91.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2871762.55\n",
      "total_reward: 1871762.55\n",
      "total_cost: 321711.83\n",
      "total_trades: 71430\n",
      "Sharpe: 0.537\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5465        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036132865 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.00674     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    reward               | -0.1928787  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 297        |\n",
      "|    time_elapsed         | 5483       |\n",
      "|    total_timesteps      | 608256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03836105 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.7      |\n",
      "|    explained_variance   | 0.14       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.6       |\n",
      "|    n_updates            | 2960       |\n",
      "|    policy_gradient_loss | -0.0017    |\n",
      "|    reward               | -3.2751951 |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 77         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 5501        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023487609 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -9.4e-05    |\n",
      "|    reward               | -3.7255805  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 94.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 5519        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016307402 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | -0.0103     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | -0.52200025 |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 62.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 300        |\n",
      "|    time_elapsed         | 5538       |\n",
      "|    total_timesteps      | 614400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02902387 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.8      |\n",
      "|    explained_variance   | 0.141      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 44.9       |\n",
      "|    n_updates            | 2990       |\n",
      "|    policy_gradient_loss | -0.0059    |\n",
      "|    reward               | 1.2792208  |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 66.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 5556        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023334187 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | 0.53057337  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 5574        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030169342 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.0917      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.000317   |\n",
      "|    reward               | -10.716422  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 5592        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030679595 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | -0.0837     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | -3.9860096  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 5611        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029251318 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.0913      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -3.8509934  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 91.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 5629        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026201395 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    reward               | -1.3295481  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 5648        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034159236 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.03        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -0.19783832 |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 307       |\n",
      "|    time_elapsed         | 5666      |\n",
      "|    total_timesteps      | 628736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0245497 |\n",
      "|    clip_fraction        | 0.241     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -54.9     |\n",
      "|    explained_variance   | 0.0945    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 37.4      |\n",
      "|    n_updates            | 3060      |\n",
      "|    policy_gradient_loss | -0.00589  |\n",
      "|    reward               | 3.211209  |\n",
      "|    std                  | 1.62      |\n",
      "|    value_loss           | 71.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 5684        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027096491 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 0.23926677  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 5702        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010830532 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 0.3200957   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 91.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3077806.03\n",
      "total_reward: 2077806.03\n",
      "total_cost: 276652.87\n",
      "total_trades: 67363\n",
      "Sharpe: 0.540\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 5721        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018953484 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.0822      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | -0.1844909  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 311        |\n",
      "|    time_elapsed         | 5740       |\n",
      "|    total_timesteps      | 636928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03086758 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.1      |\n",
      "|    explained_variance   | 0.0812     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.6       |\n",
      "|    n_updates            | 3100       |\n",
      "|    policy_gradient_loss | -0.00399   |\n",
      "|    reward               | 1.0268507  |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 106        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 5758        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040455192 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | 1.127901    |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 93.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 313        |\n",
      "|    time_elapsed         | 5776       |\n",
      "|    total_timesteps      | 641024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05719942 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.1      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.2       |\n",
      "|    n_updates            | 3120       |\n",
      "|    policy_gradient_loss | 0.00765    |\n",
      "|    reward               | -7.2864423 |\n",
      "|    std                  | 1.63       |\n",
      "|    value_loss           | 38.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 5794        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025162086 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -4.14e-06   |\n",
      "|    reward               | -2.1023521  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 72.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 5812        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028542124 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | 2.6397474   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 97.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 5831        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042010803 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.0766      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.2        |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | 2.9285233   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 5849        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022789843 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | 0.049483355 |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 318        |\n",
      "|    time_elapsed         | 5868       |\n",
      "|    total_timesteps      | 651264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02823139 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.3      |\n",
      "|    explained_variance   | 0.107      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.1       |\n",
      "|    n_updates            | 3170       |\n",
      "|    policy_gradient_loss | -0.00879   |\n",
      "|    reward               | 6.1775584  |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 92.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 319        |\n",
      "|    time_elapsed         | 5887       |\n",
      "|    total_timesteps      | 653312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03594237 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.4      |\n",
      "|    explained_variance   | 0.0604     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.5       |\n",
      "|    n_updates            | 3180       |\n",
      "|    policy_gradient_loss | -0.00435   |\n",
      "|    reward               | -3.3915753 |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 96.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 320        |\n",
      "|    time_elapsed         | 5905       |\n",
      "|    total_timesteps      | 655360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02700719 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.5      |\n",
      "|    explained_variance   | -0.0555    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 3190       |\n",
      "|    policy_gradient_loss | -0.00665   |\n",
      "|    reward               | -3.1248221 |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 57.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 5924        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033945706 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.0885      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | -2.3087401  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 5942        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025723716 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.2        |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | 0.28379574  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 5960        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021130312 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.0505      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | -0.5725116  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4759288.90\n",
      "total_reward: 3759288.90\n",
      "total_cost: 315902.33\n",
      "total_trades: 69802\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 5979        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02919218  |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.2        |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -0.18797868 |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 94.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 5997        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020211354 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.0792      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.839455    |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 6014        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035229653 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.0683      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 1.8889773   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 6032        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042131647 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.081       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | 0.6066223   |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 6051        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024264269 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.0723      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.5        |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | -0.243727   |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 6069        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033951744 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.0972      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | -2.570653   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 6087        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027464148 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.0685      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | -4.468609   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 73          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 6106        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034965675 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.0793      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 0.015906088 |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 99.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 332        |\n",
      "|    time_elapsed         | 6124       |\n",
      "|    total_timesteps      | 679936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03171266 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.3      |\n",
      "|    explained_variance   | 0.0354     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.7       |\n",
      "|    n_updates            | 3310       |\n",
      "|    policy_gradient_loss | -0.00543   |\n",
      "|    reward               | 0.19608717 |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 89.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 6142        |\n",
      "|    total_timesteps      | 681984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025988942 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.0585      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.2        |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | -0.35409924 |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 6161        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04245395  |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9           |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | -0.40965986 |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 335        |\n",
      "|    time_elapsed         | 6179       |\n",
      "|    total_timesteps      | 686080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02449084 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.4      |\n",
      "|    explained_variance   | 0.268      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.3       |\n",
      "|    n_updates            | 3340       |\n",
      "|    policy_gradient_loss | -0.0067    |\n",
      "|    reward               | -1.7105517 |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 72.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 6197        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010191676 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 1.9312241   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 337        |\n",
      "|    time_elapsed         | 6215       |\n",
      "|    total_timesteps      | 690176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01828455 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.4      |\n",
      "|    explained_variance   | 0.0514     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.3       |\n",
      "|    n_updates            | 3360       |\n",
      "|    policy_gradient_loss | -0.00621   |\n",
      "|    reward               | 1.4462173  |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 71.2       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3429962.13\n",
      "total_reward: 2429962.13\n",
      "total_cost: 297826.97\n",
      "total_trades: 68951\n",
      "Sharpe: 0.630\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 6233        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034083568 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | -0.74736017 |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 6251        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017554034 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | 4.7032113   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 92.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 6269       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03210054 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.6      |\n",
      "|    explained_variance   | 0.174      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.3       |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | -0.00561   |\n",
      "|    reward               | 0.2853135  |\n",
      "|    std                  | 1.71       |\n",
      "|    value_loss           | 78.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 341        |\n",
      "|    time_elapsed         | 6287       |\n",
      "|    total_timesteps      | 698368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04314439 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.6      |\n",
      "|    explained_variance   | -0.00158   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.3       |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | -0.003     |\n",
      "|    reward               | -1.3302468 |\n",
      "|    std                  | 1.72       |\n",
      "|    value_loss           | 33         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 6306        |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024565525 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | 0.99869037  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 6323        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031855464 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    reward               | 1.5962154   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 6341        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029920733 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | -0.0216     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.000674   |\n",
      "|    reward               | 2.1464467   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 6359        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023708662 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | 1.6420608   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 6376        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030515743 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -0.35128465 |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 69.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 6394        |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028538022 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | 0.0039      |\n",
      "|    reward               | -1.4146535  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 6412        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019626018 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    reward               | -0.85251206 |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 349        |\n",
      "|    time_elapsed         | 6430       |\n",
      "|    total_timesteps      | 714752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02343483 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57        |\n",
      "|    explained_variance   | 0.199      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.5       |\n",
      "|    n_updates            | 3480       |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    reward               | 0.9085971  |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 64.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 350        |\n",
      "|    time_elapsed         | 6449       |\n",
      "|    total_timesteps      | 716800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01509025 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57        |\n",
      "|    explained_variance   | 0.235      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.1       |\n",
      "|    n_updates            | 3490       |\n",
      "|    policy_gradient_loss | -0.00485   |\n",
      "|    reward               | -1.938037  |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 65.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 6467        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037009038 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 1.9262776   |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3122841.81\n",
      "total_reward: 2122841.81\n",
      "total_cost: 270189.50\n",
      "total_trades: 67068\n",
      "Sharpe: 0.599\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 6486        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020868931 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | -1.0434924  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 6504        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023036327 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | -2.2152083  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 6523        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028172476 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.0253      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -3.3786075  |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 355        |\n",
      "|    time_elapsed         | 6541       |\n",
      "|    total_timesteps      | 727040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03140064 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.2      |\n",
      "|    explained_variance   | 0.114      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.4       |\n",
      "|    n_updates            | 3540       |\n",
      "|    policy_gradient_loss | -0.0078    |\n",
      "|    reward               | 0.7685537  |\n",
      "|    std                  | 1.75       |\n",
      "|    value_loss           | 58.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 6560        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01601028  |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | -0.15121838 |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 82          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 6578        |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011081829 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    reward               | -0.36860538 |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 71.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 358        |\n",
      "|    time_elapsed         | 6597       |\n",
      "|    total_timesteps      | 733184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03198814 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.3      |\n",
      "|    explained_variance   | 0.15       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 3570       |\n",
      "|    policy_gradient_loss | -0.00654   |\n",
      "|    reward               | -0.2001014 |\n",
      "|    std                  | 1.75       |\n",
      "|    value_loss           | 31         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 6615        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020010661 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | -1.5911767  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 84          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 6633        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016452933 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | 0.14828776  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 83.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 361        |\n",
      "|    time_elapsed         | 6651       |\n",
      "|    total_timesteps      | 739328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0218542  |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.4      |\n",
      "|    explained_variance   | -0.0406    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.5       |\n",
      "|    n_updates            | 3600       |\n",
      "|    policy_gradient_loss | -0.00145   |\n",
      "|    reward               | 0.34257373 |\n",
      "|    std                  | 1.76       |\n",
      "|    value_loss           | 45.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 362        |\n",
      "|    time_elapsed         | 6669       |\n",
      "|    total_timesteps      | 741376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02671516 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.5      |\n",
      "|    explained_variance   | 0.0469     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 62.7       |\n",
      "|    n_updates            | 3610       |\n",
      "|    policy_gradient_loss | 0.00338    |\n",
      "|    reward               | 0.14885867 |\n",
      "|    std                  | 1.76       |\n",
      "|    value_loss           | 77         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 6687        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015928859 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | 0.093       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.1        |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | 0.000851    |\n",
      "|    reward               | -23.774567  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 364        |\n",
      "|    time_elapsed         | 6710       |\n",
      "|    total_timesteps      | 745472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02195884 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.5      |\n",
      "|    explained_variance   | 0.349      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.5       |\n",
      "|    n_updates            | 3630       |\n",
      "|    policy_gradient_loss | 0.00147    |\n",
      "|    reward               | -0.7032989 |\n",
      "|    std                  | 1.77       |\n",
      "|    value_loss           | 81.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 6728        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031877108 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.000807   |\n",
      "|    reward               | 1.312156    |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2851889.32\n",
      "total_reward: 1851889.32\n",
      "total_cost: 246289.99\n",
      "total_trades: 64584\n",
      "Sharpe: 0.516\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 366        |\n",
      "|    time_elapsed         | 6745       |\n",
      "|    total_timesteps      | 749568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03150133 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.6      |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 32.5       |\n",
      "|    n_updates            | 3650       |\n",
      "|    policy_gradient_loss | -0.00524   |\n",
      "|    reward               | 2.235701   |\n",
      "|    std                  | 1.77       |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 367       |\n",
      "|    time_elapsed         | 6764      |\n",
      "|    total_timesteps      | 751616    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0271758 |\n",
      "|    clip_fraction        | 0.304     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -57.6     |\n",
      "|    explained_variance   | 0.106     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 49.4      |\n",
      "|    n_updates            | 3660      |\n",
      "|    policy_gradient_loss | -0.00182  |\n",
      "|    reward               | 3.7855525 |\n",
      "|    std                  | 1.77      |\n",
      "|    value_loss           | 89.9      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 6783        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026578514 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    reward               | -0.66497165 |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 6802        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032295328 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    reward               | -1.0874652  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 6821        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029381037 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.0762      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    reward               | 0.46291927  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 91.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 6840        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028915346 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | 0.000538    |\n",
      "|    reward               | -2.6638935  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 6858        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024265243 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | 2.353075    |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 6878        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019480303 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | -1.2153118  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 78.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 6897        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022033643 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    reward               | 0.60760075  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 6916        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02907953  |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    reward               | -0.18636718 |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 6935        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031121003 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | 0.8246296   |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 6954        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013860901 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | 0.029353397 |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 65          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 378        |\n",
      "|    time_elapsed         | 6972       |\n",
      "|    total_timesteps      | 774144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02680111 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.1      |\n",
      "|    explained_variance   | -0.0262    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.1       |\n",
      "|    n_updates            | 3770       |\n",
      "|    policy_gradient_loss | -0.00265   |\n",
      "|    reward               | 4.1527143  |\n",
      "|    std                  | 1.8        |\n",
      "|    value_loss           | 44.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 6989        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028048612 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | -1.8612006  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2583567.75\n",
      "total_reward: 1583567.75\n",
      "total_cost: 231443.33\n",
      "total_trades: 61908\n",
      "Sharpe: 0.504\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 380        |\n",
      "|    time_elapsed         | 7008       |\n",
      "|    total_timesteps      | 778240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0256555  |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.1      |\n",
      "|    explained_variance   | 0.175      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.1       |\n",
      "|    n_updates            | 3790       |\n",
      "|    policy_gradient_loss | -0.00958   |\n",
      "|    reward               | 0.45139074 |\n",
      "|    std                  | 1.81       |\n",
      "|    value_loss           | 67.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 7026        |\n",
      "|    total_timesteps      | 780288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022683974 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    reward               | -1.4463786  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 7045        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050277345 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | 0.0159      |\n",
      "|    reward               | 0.5999365   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 7063        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029047895 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 1.6349273   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 7082        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015927352 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 3.3289413   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 88.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 7101        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034649312 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | -1.3433512  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 7119        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028604938 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -0.32858008 |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 7138        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019196287 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.873605    |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 388        |\n",
      "|    time_elapsed         | 7157       |\n",
      "|    total_timesteps      | 794624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03646642 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.4      |\n",
      "|    explained_variance   | 0.232      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 3870       |\n",
      "|    policy_gradient_loss | -0.00147   |\n",
      "|    reward               | 1.1308734  |\n",
      "|    std                  | 1.82       |\n",
      "|    value_loss           | 50.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 389        |\n",
      "|    time_elapsed         | 7176       |\n",
      "|    total_timesteps      | 796672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01353113 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.4      |\n",
      "|    explained_variance   | 0.224      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.9       |\n",
      "|    n_updates            | 3880       |\n",
      "|    policy_gradient_loss | -0.00923   |\n",
      "|    reward               | 3.5783968  |\n",
      "|    std                  | 1.82       |\n",
      "|    value_loss           | 64.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 7195        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024835693 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | 0.00734     |\n",
      "|    reward               | 2.5943441   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 91.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 7214        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012966809 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    reward               | 1.3513498   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 74.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 392        |\n",
      "|    time_elapsed         | 7233       |\n",
      "|    total_timesteps      | 802816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01909386 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.5      |\n",
      "|    explained_variance   | 0.252      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 3910       |\n",
      "|    policy_gradient_loss | -0.00848   |\n",
      "|    reward               | -3.15981   |\n",
      "|    std                  | 1.83       |\n",
      "|    value_loss           | 33.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 7251        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018937444 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | -1.3426716  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7270        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017479513 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.000338   |\n",
      "|    reward               | 0.56780434  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 79.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4036223.15\n",
      "total_reward: 3036223.15\n",
      "total_cost: 265284.61\n",
      "total_trades: 65126\n",
      "Sharpe: 0.699\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 7289        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015375495 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | 2.2396212   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 396        |\n",
      "|    time_elapsed         | 7308       |\n",
      "|    total_timesteps      | 811008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02080523 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.5      |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.9       |\n",
      "|    n_updates            | 3950       |\n",
      "|    policy_gradient_loss | -0.00506   |\n",
      "|    reward               | 1.8822169  |\n",
      "|    std                  | 1.83       |\n",
      "|    value_loss           | 54.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 7326        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027785532 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | -1.550504   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 398        |\n",
      "|    time_elapsed         | 7345       |\n",
      "|    total_timesteps      | 815104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01824509 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.6      |\n",
      "|    explained_variance   | 0.208      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.5       |\n",
      "|    n_updates            | 3970       |\n",
      "|    policy_gradient_loss | -0.00823   |\n",
      "|    reward               | -5.7245183 |\n",
      "|    std                  | 1.83       |\n",
      "|    value_loss           | 54.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 7363        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028078204 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -8.947292   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 7381        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034978207 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | -0.83032316 |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 7400        |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029907987 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | -4.625639   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 7419        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031873267 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.044       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | 0.6297286   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 7437        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035701297 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    reward               | -0.72633404 |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 7455        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015692689 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | -0.21218047 |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 7474        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025186438 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    reward               | 2.5545332   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 7492        |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030045718 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | 1.5068493   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 7511        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024983156 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 4.009402    |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 76.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 7529        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024849113 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | 0.000457    |\n",
      "|    reward               | 4.4546537   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4712757.12\n",
      "total_reward: 3712757.12\n",
      "total_cost: 317335.84\n",
      "total_trades: 71829\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 7548       |\n",
      "|    total_timesteps      | 837632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03502951 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.9      |\n",
      "|    explained_variance   | 0.312      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | 0.00216    |\n",
      "|    reward               | -5.5838385 |\n",
      "|    std                  | 1.85       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 410        |\n",
      "|    time_elapsed         | 7566       |\n",
      "|    total_timesteps      | 839680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02944881 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59        |\n",
      "|    explained_variance   | 0.135      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 88         |\n",
      "|    n_updates            | 4090       |\n",
      "|    policy_gradient_loss | -0.0056    |\n",
      "|    reward               | 2.574395   |\n",
      "|    std                  | 1.86       |\n",
      "|    value_loss           | 174        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 7584        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023387194 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.2        |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | 1.4053744   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 7603        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026997613 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | -0.52443165 |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 7621        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026790753 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | -2.6863258  |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 7640        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060495935 |\n",
      "|    clip_fraction        | 0.439       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | 0.00432     |\n",
      "|    reward               | -1.4561974  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 7659        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051026322 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.2        |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | 0.00618     |\n",
      "|    reward               | 2.0943546   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 7678        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037768424 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.0312      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    reward               | 0.47083503  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 7697        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031552106 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -0.5558162  |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 7716        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031346068 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | -0.27818078 |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 7735        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039814964 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.0873      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.000987   |\n",
      "|    reward               | 0.4084934   |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 7754        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027324105 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -0.3272057  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 7773        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01953172  |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -0.73165125 |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 7791        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026297152 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.0904      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 0.17528236  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4902346.36\n",
      "total_reward: 3902346.36\n",
      "total_cost: 257974.84\n",
      "total_trades: 65997\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 7811        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032301515 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 1.8407924   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 7830        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022014473 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    reward               | -3.3257773  |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 98.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 7848        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014959803 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | -13.259384  |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 7867        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023545908 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 3.2200625   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 59.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 7886        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023548145 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -0.43758565 |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 428       |\n",
      "|    time_elapsed         | 7905      |\n",
      "|    total_timesteps      | 876544    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0173795 |\n",
      "|    clip_fraction        | 0.192     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -59.8     |\n",
      "|    explained_variance   | 0.0594    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 55.9      |\n",
      "|    n_updates            | 4270      |\n",
      "|    policy_gradient_loss | -0.00869  |\n",
      "|    reward               | -9.843496 |\n",
      "|    std                  | 1.91      |\n",
      "|    value_loss           | 91.7      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 7924        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018382397 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.64581096 |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 68.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 430           |\n",
      "|    time_elapsed         | 7943          |\n",
      "|    total_timesteps      | 880640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.042038128   |\n",
      "|    clip_fraction        | 0.365         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -59.9         |\n",
      "|    explained_variance   | 0.109         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.06          |\n",
      "|    n_updates            | 4290          |\n",
      "|    policy_gradient_loss | -0.00496      |\n",
      "|    reward               | -0.0017407241 |\n",
      "|    std                  | 1.92          |\n",
      "|    value_loss           | 18.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 7961        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032008156 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | -3.6346097  |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 7979        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033145025 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.0859      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.00085    |\n",
      "|    reward               | -0.43517882 |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 7997        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040170968 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | -0.00335    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.64        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | -2.8373342  |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 8015        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027019229 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 2.4685767   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 63.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 8033        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032924365 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.75        |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | -0.38440156 |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 8052        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022113996 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.0945      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.19        |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | 3.7438452   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3267724.17\n",
      "total_reward: 2267724.17\n",
      "total_cost: 338916.76\n",
      "total_trades: 71723\n",
      "Sharpe: 0.632\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 8070        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020227222 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | -1.1684191  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 8089        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024351656 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    reward               | 1.1715024   |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 8107        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022597872 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.000416   |\n",
      "|    reward               | 2.7943752   |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 8126        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032585345 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -0.38122666 |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 8145        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018308314 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.7762689  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 8164        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035512254 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | 3.794493    |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 8182        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028725587 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 2.9284844   |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 8200        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027636722 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.0995      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.2        |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | -0.23330498 |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 75.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 8219        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019210365 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | -0.8984307  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 446        |\n",
      "|    time_elapsed         | 8237       |\n",
      "|    total_timesteps      | 913408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252584 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.6      |\n",
      "|    explained_variance   | 0.105      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.1       |\n",
      "|    n_updates            | 4450       |\n",
      "|    policy_gradient_loss | -0.00574   |\n",
      "|    reward               | 1.5056537  |\n",
      "|    std                  | 1.97       |\n",
      "|    value_loss           | 65         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 8257        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023804147 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.67        |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | -1.1889532  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 8275        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031696826 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.0905      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 0.95004535  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 8293        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015242007 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.8        |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | 3.8336673   |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 76          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 8312        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028407566 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.97        |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    reward               | -0.36095446 |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3794873.11\n",
      "total_reward: 2794873.11\n",
      "total_cost: 250070.03\n",
      "total_trades: 65596\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 8331        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026271967 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    reward               | -0.4361394  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 8349        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014775302 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | 0.00634     |\n",
      "|    reward               | -4.5286336  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 8367        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029660836 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.0909      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | 1.5574592   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 454        |\n",
      "|    time_elapsed         | 8386       |\n",
      "|    total_timesteps      | 929792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03255268 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61        |\n",
      "|    explained_variance   | -0.0462    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 4530       |\n",
      "|    policy_gradient_loss | -0.00544   |\n",
      "|    reward               | 1.2351536  |\n",
      "|    std                  | 1.99       |\n",
      "|    value_loss           | 24.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 455         |\n",
      "|    time_elapsed         | 8404        |\n",
      "|    total_timesteps      | 931840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027317438 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.000309   |\n",
      "|    reward               | 1.7210759   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 8422        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018226989 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -12.006969  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 8440        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028712394 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.43        |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -4.201249   |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 8458        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033054657 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    reward               | -6.3982625  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 8477        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023028534 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.8        |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | 0.61720127  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 460        |\n",
      "|    time_elapsed         | 8495       |\n",
      "|    total_timesteps      | 942080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02981636 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.3      |\n",
      "|    explained_variance   | 0.142      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 4590       |\n",
      "|    policy_gradient_loss | -0.000412  |\n",
      "|    reward               | -3.4093776 |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 24         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 8514        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027989421 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -0.84011817 |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 8533        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0277307   |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.0944      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.052300613 |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 92          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 8552        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036157288 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.0737      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | -0.7972301  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 8570        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027484499 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | -0.00235    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | -1.031608   |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2682786.86\n",
      "total_reward: 1682786.86\n",
      "total_cost: 290404.14\n",
      "total_trades: 69317\n",
      "Sharpe: 0.562\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 465        |\n",
      "|    time_elapsed         | 8589       |\n",
      "|    total_timesteps      | 952320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01823538 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.5      |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.8       |\n",
      "|    n_updates            | 4640       |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    reward               | 0.76834023 |\n",
      "|    std                  | 2.03       |\n",
      "|    value_loss           | 58.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 8607        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022452611 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | 0.000844    |\n",
      "|    reward               | -3.8751068  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 8625        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031490758 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.000765   |\n",
      "|    reward               | 0.50924194  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 8643        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017648563 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 0.4632201   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 8660        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016358184 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -0.772326   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 8678        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013563978 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | -1.8070624  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 8696        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02917632  |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.0674      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.3         |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | -0.25215757 |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 8714        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027618617 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    reward               | -0.4363336  |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 473        |\n",
      "|    time_elapsed         | 8732       |\n",
      "|    total_timesteps      | 968704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02122899 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.9      |\n",
      "|    explained_variance   | 0.11       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.8       |\n",
      "|    n_updates            | 4720       |\n",
      "|    policy_gradient_loss | -0.00829   |\n",
      "|    reward               | 2.2800734  |\n",
      "|    std                  | 2.06       |\n",
      "|    value_loss           | 65         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 474        |\n",
      "|    time_elapsed         | 8750       |\n",
      "|    total_timesteps      | 970752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02859968 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.9      |\n",
      "|    explained_variance   | -0.0558    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 4730       |\n",
      "|    policy_gradient_loss | -0.00791   |\n",
      "|    reward               | 2.0250986  |\n",
      "|    std                  | 2.06       |\n",
      "|    value_loss           | 29.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 8768        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023892147 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.0491      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.4081719  |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 476       |\n",
      "|    time_elapsed         | 8786      |\n",
      "|    total_timesteps      | 974848    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0278689 |\n",
      "|    clip_fraction        | 0.22      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -62       |\n",
      "|    explained_variance   | 0.0722    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 48.3      |\n",
      "|    n_updates            | 4750      |\n",
      "|    policy_gradient_loss | -0.0066   |\n",
      "|    reward               | 4.027925  |\n",
      "|    std                  | 2.07      |\n",
      "|    value_loss           | 74        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 8805        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01563486  |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.0507      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.00051    |\n",
      "|    reward               | -0.87650496 |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 8823        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023061235 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.0638      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 2.2792203   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 89.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3235412.57\n",
      "total_reward: 2235412.57\n",
      "total_cost: 274531.47\n",
      "total_trades: 68001\n",
      "Sharpe: 0.580\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 479        |\n",
      "|    time_elapsed         | 8841       |\n",
      "|    total_timesteps      | 980992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01892    |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.1      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 156        |\n",
      "|    n_updates            | 4780       |\n",
      "|    policy_gradient_loss | -0.00719   |\n",
      "|    reward               | -2.9604156 |\n",
      "|    std                  | 2.07       |\n",
      "|    value_loss           | 115        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 8860        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017031237 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | -5.1646643  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 481        |\n",
      "|    time_elapsed         | 8879       |\n",
      "|    total_timesteps      | 985088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02179037 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.3      |\n",
      "|    explained_variance   | 0.0553     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.3       |\n",
      "|    n_updates            | 4800       |\n",
      "|    policy_gradient_loss | -0.0058    |\n",
      "|    reward               | 2.939811   |\n",
      "|    std                  | 2.08       |\n",
      "|    value_loss           | 25.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 8897        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019846968 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.0393      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -1.5903729  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 483        |\n",
      "|    time_elapsed         | 8915       |\n",
      "|    total_timesteps      | 989184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01824034 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.4      |\n",
      "|    explained_variance   | 0.0628     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.6       |\n",
      "|    n_updates            | 4820       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    reward               | -9.448567  |\n",
      "|    std                  | 2.09       |\n",
      "|    value_loss           | 92.3       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 484       |\n",
      "|    time_elapsed         | 8933      |\n",
      "|    total_timesteps      | 991232    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0187421 |\n",
      "|    clip_fraction        | 0.243     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -62.4     |\n",
      "|    explained_variance   | 0.0413    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 17.7      |\n",
      "|    n_updates            | 4830      |\n",
      "|    policy_gradient_loss | 0.00116   |\n",
      "|    reward               | 0.7009245 |\n",
      "|    std                  | 2.09      |\n",
      "|    value_loss           | 33.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 8958        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022378478 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.0435      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -1.8695011  |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 8976        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019870892 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 1.6199098   |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 94.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 487          |\n",
      "|    time_elapsed         | 8994         |\n",
      "|    total_timesteps      | 997376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.019940892  |\n",
      "|    clip_fraction        | 0.218        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.5        |\n",
      "|    explained_variance   | 0.0299       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.7         |\n",
      "|    n_updates            | 4860         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | 0.0045359964 |\n",
      "|    std                  | 2.1          |\n",
      "|    value_loss           | 99.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 9013        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025822194 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.000644    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.61        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | -0.44822752 |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 489        |\n",
      "|    time_elapsed         | 9032       |\n",
      "|    total_timesteps      | 1001472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01721515 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.6      |\n",
      "|    explained_variance   | 0.0266     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 83.9       |\n",
      "|    n_updates            | 4880       |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    reward               | -0.7689673 |\n",
      "|    std                  | 2.11       |\n",
      "|    value_loss           | 129        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 9050        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020671256 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.0472      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.2        |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 0.09272721  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 9069        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025733847 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.0629      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 2.9490118   |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 9088        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019645337 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.0647      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46          |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    reward               | 2.484359    |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3279710.51\n",
      "total_reward: 2279710.51\n",
      "total_cost: 336546.03\n",
      "total_trades: 71348\n",
      "Sharpe: 0.582\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 493          |\n",
      "|    time_elapsed         | 9106         |\n",
      "|    total_timesteps      | 1009664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.029817313  |\n",
      "|    clip_fraction        | 0.241        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.8        |\n",
      "|    explained_variance   | 0.000549     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 4920         |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    reward               | 0.0070061283 |\n",
      "|    std                  | 2.13         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 494         |\n",
      "|    time_elapsed         | 9124        |\n",
      "|    total_timesteps      | 1011712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020565722 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | -0.015      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.7        |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    reward               | -0.3115352  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 9143        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026273662 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.0282      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.52        |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | -0.16562386 |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 9162        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022924803 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.0116      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 0.1634442   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 9182        |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020971999 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.0338      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.9        |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 1.670013    |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 9200        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017032461 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.0862      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | -0.3828946  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 9218        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017608961 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.1        |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | -1.6252968  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 9237        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014187057 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.0833      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.3        |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | -1.7609577  |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 9256        |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035500005 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | -0.0264     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.42835733 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 9275        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013542179 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | -0.32183704 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 503        |\n",
      "|    time_elapsed         | 9293       |\n",
      "|    total_timesteps      | 1030144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01910022 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.1      |\n",
      "|    explained_variance   | 0.0832     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.5       |\n",
      "|    n_updates            | 5020       |\n",
      "|    policy_gradient_loss | -0.00542   |\n",
      "|    reward               | 0.72698784 |\n",
      "|    std                  | 2.14       |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 9313        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021549238 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.0872      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.5        |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | -4.921739   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 505        |\n",
      "|    time_elapsed         | 9331       |\n",
      "|    total_timesteps      | 1034240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03631886 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.1      |\n",
      "|    explained_variance   | -0.0539    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 5040       |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | -1.8883448 |\n",
      "|    std                  | 2.15       |\n",
      "|    value_loss           | 23.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 9349        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028088514 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.0389      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.5        |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | 0.8037093   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 9368        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026690315 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | -0.000934   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    reward               | 3.6617208   |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5437688.95\n",
      "total_reward: 4437688.95\n",
      "total_cost: 294868.73\n",
      "total_trades: 68517\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 9387        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022211054 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.0782      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    reward               | -0.48323184 |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 68.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 509        |\n",
      "|    time_elapsed         | 9405       |\n",
      "|    total_timesteps      | 1042432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01272849 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.3      |\n",
      "|    explained_variance   | 0.106      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 57.3       |\n",
      "|    n_updates            | 5080       |\n",
      "|    policy_gradient_loss | -0.00874   |\n",
      "|    reward               | 0.37096748 |\n",
      "|    std                  | 2.16       |\n",
      "|    value_loss           | 144        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 9424        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019860424 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.7        |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.21088941  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 9443        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02857007  |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.0763      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -0.06295163 |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 83.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 9461        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020047333 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | -1.6188908  |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 9480        |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022306232 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.0802      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.7        |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.33492684  |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 9499        |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026306583 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.0771      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | -0.000319   |\n",
      "|    reward               | 4.937097    |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 9518        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023388699 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | -0.0697     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | -1.9318117  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 9536        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014992132 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.0692      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | -3.088668   |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 9555        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023196936 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    reward               | 3.2911327   |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 95.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 9573        |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021777932 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.00124     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | 0.7398236   |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 9591        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037720483 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | -0.0164     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.57        |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | -0.31313258 |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 9609        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020088483 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.33        |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.5230917  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 63.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 9628        |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017657533 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -0.3139328  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3644264.84\n",
      "total_reward: 2644264.84\n",
      "total_cost: 339375.06\n",
      "total_trades: 70820\n",
      "Sharpe: 0.760\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 9646        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027196951 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.00663     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | 0.82027894  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 9664        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022247855 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.0241      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 2.6944234   |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 9682        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019859135 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | 0.06756452  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 57.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 9701        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03278009  |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.0874      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | -0.000889   |\n",
      "|    reward               | -0.21738473 |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 526        |\n",
      "|    time_elapsed         | 9719       |\n",
      "|    total_timesteps      | 1077248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02953938 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.3      |\n",
      "|    explained_variance   | 0.242      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 5250       |\n",
      "|    policy_gradient_loss | -0.00889   |\n",
      "|    reward               | 0.17532893 |\n",
      "|    std                  | 2.23       |\n",
      "|    value_loss           | 32.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 9737        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017393528 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.1         |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | -1.2546349  |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 528        |\n",
      "|    time_elapsed         | 9755       |\n",
      "|    total_timesteps      | 1081344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01834287 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.4      |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.16       |\n",
      "|    n_updates            | 5270       |\n",
      "|    policy_gradient_loss | -0.00705   |\n",
      "|    reward               | 1.2723587  |\n",
      "|    std                  | 2.24       |\n",
      "|    value_loss           | 31.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 9773        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026337655 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.39        |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | 0.4450056   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 110            |\n",
      "|    iterations           | 530            |\n",
      "|    time_elapsed         | 9791           |\n",
      "|    total_timesteps      | 1085440        |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.020214176    |\n",
      "|    clip_fraction        | 0.204          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -64.5          |\n",
      "|    explained_variance   | 0.23           |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 25.6           |\n",
      "|    n_updates            | 5290           |\n",
      "|    policy_gradient_loss | -0.0091        |\n",
      "|    reward               | -0.00045649515 |\n",
      "|    std                  | 2.25           |\n",
      "|    value_loss           | 55.9           |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 9809        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019199286 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | 4.289969    |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 9827        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023462877 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | 1.0223888   |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 533        |\n",
      "|    time_elapsed         | 9845       |\n",
      "|    total_timesteps      | 1091584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0218177  |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.6      |\n",
      "|    explained_variance   | 0.33       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 5320       |\n",
      "|    policy_gradient_loss | -0.00845   |\n",
      "|    reward               | -1.3571397 |\n",
      "|    std                  | 2.26       |\n",
      "|    value_loss           | 25.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 9864        |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02290715  |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | -0.15448189 |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 9881        |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020793634 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | 1.2172502   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3137157.75\n",
      "total_reward: 2137157.75\n",
      "total_cost: 223332.12\n",
      "total_trades: 64423\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 536        |\n",
      "|    time_elapsed         | 9899       |\n",
      "|    total_timesteps      | 1097728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01306935 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.7      |\n",
      "|    explained_variance   | 0.351      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.19       |\n",
      "|    n_updates            | 5350       |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    reward               | 0.3980591  |\n",
      "|    std                  | 2.27       |\n",
      "|    value_loss           | 12.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 9918        |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019813204 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    reward               | -0.9749445  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 9936        |\n",
      "|    total_timesteps      | 1101824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010223748 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.79        |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | -1.7757245  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 9955         |\n",
      "|    total_timesteps      | 1103872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148538165 |\n",
      "|    clip_fraction        | 0.224        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.8        |\n",
      "|    explained_variance   | 0.0862       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.99         |\n",
      "|    n_updates            | 5380         |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | 1.1564343    |\n",
      "|    std                  | 2.27         |\n",
      "|    value_loss           | 20.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 540          |\n",
      "|    time_elapsed         | 9974         |\n",
      "|    total_timesteps      | 1105920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01811593   |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.8        |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.9          |\n",
      "|    n_updates            | 5390         |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | -0.012924464 |\n",
      "|    std                  | 2.27         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 9993        |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018276334 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | -8.400662   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 542         |\n",
      "|    time_elapsed         | 10012       |\n",
      "|    total_timesteps      | 1110016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017912738 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.0736      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | 3.9455137   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 10030       |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023457661 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.19        |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 1.887857    |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 10049       |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019045431 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | -0.32958576 |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 545         |\n",
      "|    time_elapsed         | 10068       |\n",
      "|    total_timesteps      | 1116160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017061945 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | 1.1018472   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 10086       |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019512108 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.87        |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.000666   |\n",
      "|    reward               | -0.37751266 |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 547         |\n",
      "|    time_elapsed         | 10104       |\n",
      "|    total_timesteps      | 1120256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024562757 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 5460        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 2.1193857   |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 10123       |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017333811 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -1.8153145  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 10141       |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016341645 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.81        |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | 0.96780616  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3166279.73\n",
      "total_reward: 2166279.73\n",
      "total_cost: 252067.93\n",
      "total_trades: 65537\n",
      "Sharpe: 0.705\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 10160       |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020580415 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | -0.5031307  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 10178       |\n",
      "|    total_timesteps      | 1128448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013731824 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | -0.38851726 |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 552         |\n",
      "|    time_elapsed         | 10196       |\n",
      "|    total_timesteps      | 1130496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023962818 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    reward               | 1.4651124   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 553        |\n",
      "|    time_elapsed         | 10215      |\n",
      "|    total_timesteps      | 1132544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02575899 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.5      |\n",
      "|    explained_variance   | 0.355      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.2        |\n",
      "|    n_updates            | 5520       |\n",
      "|    policy_gradient_loss | -0.00683   |\n",
      "|    reward               | 0.09885061 |\n",
      "|    std                  | 2.33       |\n",
      "|    value_loss           | 14.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 10233       |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029029477 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 0.83743393  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 10252       |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014197941 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | 1.2305717   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 10271       |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012649046 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -2.3935602  |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 557        |\n",
      "|    time_elapsed         | 10289      |\n",
      "|    total_timesteps      | 1140736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01575594 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.7      |\n",
      "|    explained_variance   | 0.254      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.52       |\n",
      "|    n_updates            | 5560       |\n",
      "|    policy_gradient_loss | -0.00916   |\n",
      "|    reward               | -1.348519  |\n",
      "|    std                  | 2.35       |\n",
      "|    value_loss           | 20.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 10307       |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014945128 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.14297749 |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 10325       |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023822706 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | -0.00378    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 0.18523242  |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 10344       |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016336296 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.0855      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.87        |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | 0.43160093  |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 10362       |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017310826 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.3496218  |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 562        |\n",
      "|    time_elapsed         | 10380      |\n",
      "|    total_timesteps      | 1150976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01899434 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66        |\n",
      "|    explained_variance   | 0.00965    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 104        |\n",
      "|    n_updates            | 5610       |\n",
      "|    policy_gradient_loss | -0.00574   |\n",
      "|    reward               | -2.1588912 |\n",
      "|    std                  | 2.37       |\n",
      "|    value_loss           | 137        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 10398       |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01821942  |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -0.85076696 |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3135970.27\n",
      "total_reward: 2135970.27\n",
      "total_cost: 276835.78\n",
      "total_trades: 65957\n",
      "Sharpe: 0.701\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 564        |\n",
      "|    time_elapsed         | 10417      |\n",
      "|    total_timesteps      | 1155072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01645254 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.1      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 5630       |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | 0.87372506 |\n",
      "|    std                  | 2.38       |\n",
      "|    value_loss           | 43.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 10435       |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016836021 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -10.744328  |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 566        |\n",
      "|    time_elapsed         | 10453      |\n",
      "|    total_timesteps      | 1159168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0313176  |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.3      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.78       |\n",
      "|    n_updates            | 5650       |\n",
      "|    policy_gradient_loss | 0.000984   |\n",
      "|    reward               | 0.11484637 |\n",
      "|    std                  | 2.39       |\n",
      "|    value_loss           | 19.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 567        |\n",
      "|    time_elapsed         | 10471      |\n",
      "|    total_timesteps      | 1161216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02301641 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.3      |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.13       |\n",
      "|    n_updates            | 5660       |\n",
      "|    policy_gradient_loss | -0.00839   |\n",
      "|    reward               | -5.398886  |\n",
      "|    std                  | 2.4        |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 568          |\n",
      "|    time_elapsed         | 10490        |\n",
      "|    total_timesteps      | 1163264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020915762  |\n",
      "|    clip_fraction        | 0.208        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.4        |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 5670         |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    reward               | -0.032625202 |\n",
      "|    std                  | 2.41         |\n",
      "|    value_loss           | 39.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 10509       |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014676569 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.74        |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | -7.079654   |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 10527       |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018035978 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 2.148056    |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 10546       |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021111552 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.46145838  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 572         |\n",
      "|    time_elapsed         | 10564       |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017356157 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | 0.46370265  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 10583       |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017201323 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.0677      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.29        |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | 1.03836     |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 10601       |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016370703 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -0.28673244 |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 10620       |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018129189 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | 0.47136563  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 10638       |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024671333 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.0448      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | -1.2667346  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 10657       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017122997 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | -0.0891     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.88        |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.052860588 |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3050450.35\n",
      "total_reward: 2050450.35\n",
      "total_cost: 326021.36\n",
      "total_trades: 67400\n",
      "Sharpe: 0.678\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 10674       |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016225487 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.0363      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -0.86926347 |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 76.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 10693       |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021111961 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.0679      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | 1.5638329   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 61.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 580        |\n",
      "|    time_elapsed         | 10711      |\n",
      "|    total_timesteps      | 1187840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02049566 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.1      |\n",
      "|    explained_variance   | 0.0728     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.33       |\n",
      "|    n_updates            | 5790       |\n",
      "|    policy_gradient_loss | -0.0091    |\n",
      "|    reward               | 0.47817227 |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 23.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 10729       |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016163856 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 1.7815086   |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 582         |\n",
      "|    time_elapsed         | 10747       |\n",
      "|    total_timesteps      | 1191936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015346967 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.0952      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | -0.14848354 |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 10765       |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022872906 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.36995077 |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 54.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 10783       |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023633337 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.34        |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.12231411 |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 110           |\n",
      "|    iterations           | 585           |\n",
      "|    time_elapsed         | 10802         |\n",
      "|    total_timesteps      | 1198080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.014267134   |\n",
      "|    clip_fraction        | 0.146         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -67.4         |\n",
      "|    explained_variance   | 0.112         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 41.5          |\n",
      "|    n_updates            | 5840          |\n",
      "|    policy_gradient_loss | -0.00992      |\n",
      "|    reward               | -0.0017713727 |\n",
      "|    std                  | 2.49          |\n",
      "|    value_loss           | 49.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 586         |\n",
      "|    time_elapsed         | 10821       |\n",
      "|    total_timesteps      | 1200128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017907493 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.0692      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | -4.9986005  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 587        |\n",
      "|    time_elapsed         | 10840      |\n",
      "|    total_timesteps      | 1202176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02423659 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.5      |\n",
      "|    explained_variance   | 0.00399    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.6       |\n",
      "|    n_updates            | 5860       |\n",
      "|    policy_gradient_loss | -0.00524   |\n",
      "|    reward               | 1.168626   |\n",
      "|    std                  | 2.5        |\n",
      "|    value_loss           | 33.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 10859       |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023450255 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.0158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -0.5755158  |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 10878       |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018520359 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.0722      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | -2.8735301  |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 10896       |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026438348 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | -0.0631     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    reward               | 3.2895825   |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 591         |\n",
      "|    time_elapsed         | 10915       |\n",
      "|    total_timesteps      | 1210368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029275132 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.0902      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | 0.00475     |\n",
      "|    reward               | -1.1599169  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3540493.84\n",
      "total_reward: 2540493.84\n",
      "total_cost: 316371.92\n",
      "total_trades: 67113\n",
      "Sharpe: 0.643\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 10934       |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025746252 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.0464      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | 0.00337     |\n",
      "|    reward               | 0.23048139  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 10953       |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017376631 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.0922      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    reward               | 0.45332354  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 10971       |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023871725 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | -2.6895056  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 10990       |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014939243 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.096       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | -2.9708996  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 87.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 11009       |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017114278 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.0684      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -5.7290072  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 86.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 11029       |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019442424 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | -0.0181     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.000226   |\n",
      "|    reward               | -1.0937023  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 11049       |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020154037 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 0.22061989  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 599         |\n",
      "|    time_elapsed         | 11067       |\n",
      "|    total_timesteps      | 1226752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015269848 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | 0.000409    |\n",
      "|    reward               | 1.3378278   |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 11085       |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019086968 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.3        |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 1.705154    |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 11104       |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027060576 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | -0.0188     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | -0.9448019  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 602        |\n",
      "|    time_elapsed         | 11123      |\n",
      "|    total_timesteps      | 1232896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01537412 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.1      |\n",
      "|    explained_variance   | 0.261      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.9       |\n",
      "|    n_updates            | 6010       |\n",
      "|    policy_gradient_loss | 0.00137    |\n",
      "|    reward               | 2.3309815  |\n",
      "|    std                  | 2.55       |\n",
      "|    value_loss           | 89.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 11141       |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019984175 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    reward               | 1.1955798   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 604          |\n",
      "|    time_elapsed         | 11160        |\n",
      "|    total_timesteps      | 1236992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101088025 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.2        |\n",
      "|    explained_variance   | 0.0118       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 6030         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 7.3496637    |\n",
      "|    std                  | 2.55         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 11178       |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010683958 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.0936      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | -1.1079736  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 93          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 606          |\n",
      "|    time_elapsed         | 11196        |\n",
      "|    total_timesteps      | 1241088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075863358 |\n",
      "|    clip_fraction        | 0.0633       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.2        |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.3         |\n",
      "|    n_updates            | 6050         |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | 5.3607078    |\n",
      "|    std                  | 2.56         |\n",
      "|    value_loss           | 97.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3708162.20\n",
      "total_reward: 2708162.20\n",
      "total_cost: 301108.45\n",
      "total_trades: 65804\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 11215       |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014099382 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.6        |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | 0.22193179  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 92          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 11233       |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022395179 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.0524      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | 0.659461    |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 11252       |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014473556 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | -1.3628705  |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 610         |\n",
      "|    time_elapsed         | 11270       |\n",
      "|    total_timesteps      | 1249280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017932266 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 6090        |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | 2.96685     |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 11288       |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017500883 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | -0.181      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | 1.5703245   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 11306       |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024856115 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    reward               | 5.1067095   |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 67.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 11325       |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012843304 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | 3.0709238   |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 614        |\n",
      "|    time_elapsed         | 11344      |\n",
      "|    total_timesteps      | 1257472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01618741 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.5      |\n",
      "|    explained_variance   | 0.298      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31         |\n",
      "|    n_updates            | 6130       |\n",
      "|    policy_gradient_loss | -0.00248   |\n",
      "|    reward               | 0.01951176 |\n",
      "|    std                  | 2.58       |\n",
      "|    value_loss           | 55.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 11364       |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017486388 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    reward               | 1.5138241   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 75.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 11383       |\n",
      "|    total_timesteps      | 1261568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012713576 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    reward               | 0.714788    |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 92.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 617        |\n",
      "|    time_elapsed         | 11401      |\n",
      "|    total_timesteps      | 1263616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02211284 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.6      |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 42.3       |\n",
      "|    n_updates            | 6160       |\n",
      "|    policy_gradient_loss | -0.0044    |\n",
      "|    reward               | 2.2338524  |\n",
      "|    std                  | 2.6        |\n",
      "|    value_loss           | 83.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 11420       |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024060184 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | -0.0878     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.83        |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | -1.5939714  |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 11438       |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018123835 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -0.7080911  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 61.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 11457       |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013938839 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | -0.24652302 |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 82.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2687920.03\n",
      "total_reward: 1687920.03\n",
      "total_cost: 337043.34\n",
      "total_trades: 68272\n",
      "Sharpe: 0.552\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 11475       |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012935718 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | -0.47545487 |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 11494       |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02676659  |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -0.23327594 |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 11512       |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015940383 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | 0.62626183  |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 79.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 11530       |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008293679 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | 0.8972766   |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 625          |\n",
      "|    time_elapsed         | 11549        |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022381518  |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.9        |\n",
      "|    explained_variance   | -0.012       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.49         |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -0.095859565 |\n",
      "|    std                  | 2.62         |\n",
      "|    value_loss           | 20.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 11567       |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012888586 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.037845045 |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 11585        |\n",
      "|    total_timesteps      | 1284096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117209945 |\n",
      "|    clip_fraction        | 0.0786       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -69          |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 6260         |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | 0.76928866   |\n",
      "|    std                  | 2.63         |\n",
      "|    value_loss           | 72.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 11603       |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026732812 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 1.0851427   |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 11621       |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015007739 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | -0.36572465 |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 11639       |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009915078 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    reward               | 8.535329    |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 11657       |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031847954 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | 0.06749918  |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 11675       |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028321706 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.0721      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.96        |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | -0.16023254 |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 11694       |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024811286 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.10292903  |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 36.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 11719       |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022662245 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.00328     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.9        |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | -2.2342606  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3475745.82\n",
      "total_reward: 2475745.82\n",
      "total_cost: 350662.76\n",
      "total_trades: 68002\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 635         |\n",
      "|    time_elapsed         | 11737       |\n",
      "|    total_timesteps      | 1300480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024824051 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.0552      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.49        |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 2.9582956   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 11755       |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018046709 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.0238      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | 0.52016693  |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 11773       |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021792207 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.00682     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    reward               | -0.58999336 |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 11791       |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021425566 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.017       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.59        |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | 3.6052465   |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 11809       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020509018 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.0529      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.95        |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -0.07114582 |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 110       |\n",
      "|    iterations           | 640       |\n",
      "|    time_elapsed         | 11827     |\n",
      "|    total_timesteps      | 1310720   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0230151 |\n",
      "|    clip_fraction        | 0.242     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -69.9     |\n",
      "|    explained_variance   | 0.0288    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 34.9      |\n",
      "|    n_updates            | 6390      |\n",
      "|    policy_gradient_loss | -0.0107   |\n",
      "|    reward               | 0.9815997 |\n",
      "|    std                  | 2.72      |\n",
      "|    value_loss           | 55.7      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 11845       |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022792533 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | -1.92734    |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 11864       |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019798705 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.0472      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.87        |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 1.9918389   |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 11883       |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018171163 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 0.62883246  |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 11900       |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021190941 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.0292      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 2.8305597   |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 11918       |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019212835 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.35        |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | 0.006       |\n",
      "|    reward               | -3.0329223  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 11937       |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021025836 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.0295      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.13726762 |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 11956       |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018226888 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.0717      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    reward               | 1.7111216   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 11974       |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017772669 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.0585      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | 1.5176588   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3518962.66\n",
      "total_reward: 2518962.66\n",
      "total_cost: 345508.53\n",
      "total_trades: 67770\n",
      "Sharpe: 0.773\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 11993       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024552498 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | -0.0112     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.28        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | -2.7823617  |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 650        |\n",
      "|    time_elapsed         | 12011      |\n",
      "|    total_timesteps      | 1331200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02061506 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.6      |\n",
      "|    explained_variance   | -0.00644   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.8       |\n",
      "|    n_updates            | 6490       |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    reward               | 0.8712691  |\n",
      "|    std                  | 2.79       |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 12029       |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018201977 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.0779      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 6500        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.5306555   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 652        |\n",
      "|    time_elapsed         | 12047      |\n",
      "|    total_timesteps      | 1335296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01541344 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.7      |\n",
      "|    explained_variance   | -0.0357    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10         |\n",
      "|    n_updates            | 6510       |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    reward               | 1.8379     |\n",
      "|    std                  | 2.8        |\n",
      "|    value_loss           | 20.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 653        |\n",
      "|    time_elapsed         | 12066      |\n",
      "|    total_timesteps      | 1337344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01581534 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.8      |\n",
      "|    explained_variance   | 0.0501     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35         |\n",
      "|    n_updates            | 6520       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    reward               | 2.0118945  |\n",
      "|    std                  | 2.8        |\n",
      "|    value_loss           | 52.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 12084       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014521178 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.0779      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | 8.440798    |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 12103       |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019515991 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 0.081989184 |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 12122       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016675219 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.44665906  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 12140       |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011079698 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.0835      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    reward               | 0.24962337  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 12158       |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022390895 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.0653      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    reward               | -0.09700606 |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 12177       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020509379 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | -8.14e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.63        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | -2.516987   |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 12196       |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016611073 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -0.41201028 |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 12214       |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013901392 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.0607      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.8851334  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 64.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 12232       |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014382675 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | 0.4992917   |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2473295.02\n",
      "total_reward: 1473295.02\n",
      "total_cost: 317736.41\n",
      "total_trades: 66440\n",
      "Sharpe: 0.572\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 12251       |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01656099  |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.51408756 |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 664        |\n",
      "|    time_elapsed         | 12270      |\n",
      "|    total_timesteps      | 1359872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01288446 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.2      |\n",
      "|    explained_variance   | 0.365      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 6630       |\n",
      "|    policy_gradient_loss | -0.00685   |\n",
      "|    reward               | 0.6100661  |\n",
      "|    std                  | 2.84       |\n",
      "|    value_loss           | 21.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 12289       |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020141412 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 0.7007653   |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 12308       |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025001366 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.00435     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.07        |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.06866208  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 12326       |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014320854 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.0747      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -0.05658077 |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 12345       |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011403245 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 6670        |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | 0.5913016   |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 12364       |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019185565 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.0975      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 0.41880003  |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 670        |\n",
      "|    time_elapsed         | 12382      |\n",
      "|    total_timesteps      | 1372160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01689215 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.5      |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.8        |\n",
      "|    n_updates            | 6690       |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    reward               | 1.2076591  |\n",
      "|    std                  | 2.87       |\n",
      "|    value_loss           | 22.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 12401       |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016451381 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.000739    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -0.43411013 |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 12420       |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021591488 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | -0.0289     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 0.05404963  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 12438       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018706087 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | -0.30470368 |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 12456       |\n",
      "|    total_timesteps      | 1380352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017167121 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.75        |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 1.5317943   |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 12474       |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015799591 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | 0.34014463  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 12492       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024658771 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.0433      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.89        |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | -1.6790445  |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2995843.75\n",
      "total_reward: 1995843.75\n",
      "total_cost: 315586.62\n",
      "total_trades: 67136\n",
      "Sharpe: 0.673\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 12510       |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023435848 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.0281      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 6760        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | -0.5298893  |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 12528       |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018145945 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 3.6208248   |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 12547       |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01248397  |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | -0.92612106 |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 12565       |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019727323 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    reward               | -3.6743295  |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 12584       |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017061811 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.0387      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 1.4581414   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 12602       |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013179883 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.0494      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 1.7075449   |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 12621       |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026235566 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.57        |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | 2.2015307   |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 12639       |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017388161 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | 0.5273962   |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 685        |\n",
      "|    time_elapsed         | 12657      |\n",
      "|    total_timesteps      | 1402880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01463976 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.1      |\n",
      "|    explained_variance   | 0.0445     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.3       |\n",
      "|    n_updates            | 6840       |\n",
      "|    policy_gradient_loss | -0.00632   |\n",
      "|    reward               | -1.863146  |\n",
      "|    std                  | 2.93       |\n",
      "|    value_loss           | 50.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 12675       |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016863404 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.00377     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | 1.2742279   |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 12693       |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014110835 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.0559      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | -0.0365812  |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 12712       |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011422016 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 2.4997845   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 12730       |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01966504  |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.0296      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | -0.26517433 |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 12748       |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024285372 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.0856      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -0.1672335  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3343574.40\n",
      "total_reward: 2343574.40\n",
      "total_cost: 302808.17\n",
      "total_trades: 65597\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 12767       |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015673434 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.0445      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -0.04124689 |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 692        |\n",
      "|    time_elapsed         | 12785      |\n",
      "|    total_timesteps      | 1417216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01978492 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.4      |\n",
      "|    explained_variance   | 0.215      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 6910       |\n",
      "|    policy_gradient_loss | 0.00173    |\n",
      "|    reward               | 2.373154   |\n",
      "|    std                  | 2.96       |\n",
      "|    value_loss           | 41.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 12804       |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016084809 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.0801      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    reward               | 1.0732112   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 12823       |\n",
      "|    total_timesteps      | 1421312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012661813 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    reward               | -0.900092   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 12841       |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024671195 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.00994     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    reward               | 0.016761603 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 12859       |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015307425 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.0242      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | -1.4547024  |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 12877       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019777836 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.0616      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21        |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 0.873801    |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 12895       |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012742488 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.0402      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 1.1684908   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 699          |\n",
      "|    time_elapsed         | 12913        |\n",
      "|    total_timesteps      | 1431552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020161983  |\n",
      "|    clip_fraction        | 0.178        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -72.8        |\n",
      "|    explained_variance   | 0.054        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 6980         |\n",
      "|    policy_gradient_loss | -0.00996     |\n",
      "|    reward               | -0.061255183 |\n",
      "|    std                  | 3            |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 12931       |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018550372 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.00651     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | -1.1630603  |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 701        |\n",
      "|    time_elapsed         | 12949      |\n",
      "|    total_timesteps      | 1435648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01788453 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.9      |\n",
      "|    explained_variance   | 0.0965     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.8       |\n",
      "|    n_updates            | 7000       |\n",
      "|    policy_gradient_loss | -0.00489   |\n",
      "|    reward               | -4.8301616 |\n",
      "|    std                  | 3.01       |\n",
      "|    value_loss           | 29.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 12967       |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024487842 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.0759      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    reward               | 0.6322521   |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 12985       |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018807527 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.0484      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | -0.55184454 |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 13003       |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022017725 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | -2.0392504  |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4061680.69\n",
      "total_reward: 3061680.69\n",
      "total_cost: 319572.33\n",
      "total_trades: 67310\n",
      "Sharpe: 0.848\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 13021       |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021245454 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.0937      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.45112562  |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 706        |\n",
      "|    time_elapsed         | 13039      |\n",
      "|    total_timesteps      | 1445888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02259425 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73        |\n",
      "|    explained_variance   | 0.0652     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.1       |\n",
      "|    n_updates            | 7050       |\n",
      "|    policy_gradient_loss | -0.00742   |\n",
      "|    reward               | 1.4813617  |\n",
      "|    std                  | 3.03       |\n",
      "|    value_loss           | 50.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 13057       |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022495829 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.13        |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    reward               | 0.25063273  |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 13074       |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016619679 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.0696      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | 0.05231973  |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 13092       |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018931035 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    reward               | 1.0268773   |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 13110       |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018178806 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | -0.0386     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.07        |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    reward               | -0.31438577 |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 13127       |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01927964  |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.0245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | -0.53908813 |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 13146        |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114920065 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.5        |\n",
      "|    explained_variance   | 0.0928       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 7110         |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    reward               | -0.51201123  |\n",
      "|    std                  | 3.08         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 713         |\n",
      "|    time_elapsed         | 13164       |\n",
      "|    total_timesteps      | 1460224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020394007 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -0.109993   |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 13182       |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020543817 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | -0.0421     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.78        |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    reward               | -0.78788245 |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 110          |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 13201        |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.019839384  |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.7        |\n",
      "|    explained_variance   | 0.0659       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 7140         |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    reward               | -0.049849838 |\n",
      "|    std                  | 3.11         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 13219       |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014505421 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.8       |\n",
      "|    explained_variance   | 0.0293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | -3.387367   |\n",
      "|    std                  | 3.12        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 13237       |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017020613 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.00233     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | 0.75787485  |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 13255       |\n",
      "|    total_timesteps      | 1470464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022345401 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.00884     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.6582732  |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 13273       |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012400283 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.0742      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 5.980978    |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3178123.19\n",
      "total_reward: 2178123.19\n",
      "total_cost: 310092.05\n",
      "total_trades: 67355\n",
      "Sharpe: 0.641\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 13291       |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015267898 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.0241      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.2814947   |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 13309       |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014907492 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.067       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.46        |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 1.5353926   |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 13327       |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011666665 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | -1.7002071  |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 64.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 723         |\n",
      "|    time_elapsed         | 13346       |\n",
      "|    total_timesteps      | 1480704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013167683 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | -2.758136   |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 13364       |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017093584 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.0693      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.62        |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | 3.3916962   |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 13382       |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017580044 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.0473      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | 1.965866    |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 13400       |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021160003 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 7250        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 0.6054624   |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 727        |\n",
      "|    time_elapsed         | 13418      |\n",
      "|    total_timesteps      | 1488896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02316001 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.3      |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.8       |\n",
      "|    n_updates            | 7260       |\n",
      "|    policy_gradient_loss | 0.00285    |\n",
      "|    reward               | 0.68483025 |\n",
      "|    std                  | 3.17       |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 13437       |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023750793 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | 1.2596241   |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 729        |\n",
      "|    time_elapsed         | 13456      |\n",
      "|    total_timesteps      | 1492992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01899842 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.4      |\n",
      "|    explained_variance   | 0.0168     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.1       |\n",
      "|    n_updates            | 7280       |\n",
      "|    policy_gradient_loss | -0.00799   |\n",
      "|    reward               | -1.6890813 |\n",
      "|    std                  | 3.18       |\n",
      "|    value_loss           | 85.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 13475       |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013268931 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.21515635  |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 76.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 13494       |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014938957 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.00163     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.62        |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 1.325906    |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 13513       |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019382339 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.0384      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.29147592 |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 56.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 110        |\n",
      "|    iterations           | 733        |\n",
      "|    time_elapsed         | 13531      |\n",
      "|    total_timesteps      | 1501184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01875979 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.6      |\n",
      "|    explained_variance   | 0.0218     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.5       |\n",
      "|    n_updates            | 7320       |\n",
      "|    policy_gradient_loss | -0.00202   |\n",
      "|    reward               | -1.2863653 |\n",
      "|    std                  | 3.2        |\n",
      "|    value_loss           | 105        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3162902.58\n",
      "total_reward: 2162902.58\n",
      "total_cost: 275956.84\n",
      "total_trades: 65401\n",
      "Sharpe: 0.708\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 13549       |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009977615 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.48        |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | -4.1268744  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 13567       |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017524866 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.0377      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    reward               | -1.1058042  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 13586       |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019579135 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    reward               | -0.5840185  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 13604       |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014761425 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 1.3425435   |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 13623       |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015630625 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.00409     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.182116   |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 13642       |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013875778 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.0924      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | -0.17488503 |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 740         |\n",
      "|    time_elapsed         | 13659       |\n",
      "|    total_timesteps      | 1515520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016726004 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 7390        |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | 0.81908125  |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 13677       |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017060941 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.037       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.07        |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | 0.27819932  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 13695       |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012532221 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.59        |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | 0.4456694   |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 13713       |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014397863 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | -5.009799   |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 13732       |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017601982 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | -0.0151     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | 0.33987808  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 13749       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012206972 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.24        |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    reward               | -0.6885892  |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 13767       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007090022 |\n",
      "|    clip_fraction        | 0.0362      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    reward               | -0.30099592 |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 13785       |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012893457 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 0.6032472   |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3535847.60\n",
      "total_reward: 2535847.60\n",
      "total_cost: 246091.87\n",
      "total_trades: 64771\n",
      "Sharpe: 0.761\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 13804       |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012962306 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.47        |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -0.78334105 |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 13822       |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014059457 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.0805      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -3.6430633  |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 13840       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013695195 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.0815      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | 3.8532777   |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 13858       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018661313 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | -0.00347    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | -0.5846827  |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 752         |\n",
      "|    time_elapsed         | 13876       |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011433324 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    reward               | 0.41449067  |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 13893       |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009627332 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | 0.3912235   |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 13911       |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011372271 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | -0.0465     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 1.8207339   |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 755          |\n",
      "|    time_elapsed         | 13929        |\n",
      "|    total_timesteps      | 1546240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014165944  |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.6        |\n",
      "|    explained_variance   | 0.0408       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.72         |\n",
      "|    n_updates            | 7540         |\n",
      "|    policy_gradient_loss | -0.00977     |\n",
      "|    reward               | -0.049267106 |\n",
      "|    std                  | 3.31         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 13947       |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013949573 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | -0.64840925 |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 13966       |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020962682 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.0684      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.9133773   |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 13984       |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018787399 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | -0.0209     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.29        |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -0.5258428  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 14002       |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014600577 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.0403      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 0.43143147  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 760          |\n",
      "|    time_elapsed         | 14020        |\n",
      "|    total_timesteps      | 1556480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0144323865 |\n",
      "|    clip_fraction        | 0.209        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76          |\n",
      "|    explained_variance   | 0.0594       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 7590         |\n",
      "|    policy_gradient_loss | -0.00973     |\n",
      "|    reward               | 0.8354309    |\n",
      "|    std                  | 3.36         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 14039       |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011980135 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.0147      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -1.2022357  |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3401502.13\n",
      "total_reward: 2401502.13\n",
      "total_cost: 228058.67\n",
      "total_trades: 63106\n",
      "Sharpe: 0.719\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 14057       |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012257984 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.0993      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.88        |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 2.7611659   |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 9.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 14075       |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013593468 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | -2.409417   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 14094       |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010035403 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | 0.00521     |\n",
      "|    reward               | 0.98506945  |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 14112       |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020804483 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.56        |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    reward               | -1.0243503  |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 14129       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011570593 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 0.5626456   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 62.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 767         |\n",
      "|    time_elapsed         | 14148       |\n",
      "|    total_timesteps      | 1570816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015971607 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 7660        |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 11.764448   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 14166       |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018668726 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 2.4152043   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 14185       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015317826 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.0832      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.36        |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.58512086  |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 14202       |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013960834 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | -0.29099873 |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 14220       |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012668569 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | -3.3532364  |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 14237       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016421517 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | 0.6992664   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 773          |\n",
      "|    time_elapsed         | 14256        |\n",
      "|    total_timesteps      | 1583104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146709755 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.4        |\n",
      "|    explained_variance   | 0.0632       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 7720         |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    reward               | -0.6433158   |\n",
      "|    std                  | 3.4          |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 14274       |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010120313 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.0417      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 1.7305377   |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 14291       |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0175572   |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | -0.0066     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -0.06946047 |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3544936.80\n",
      "total_reward: 2544936.80\n",
      "total_cost: 236442.69\n",
      "total_trades: 63831\n",
      "Sharpe: 0.786\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 14309       |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014414265 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | 0.5963398   |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 777         |\n",
      "|    time_elapsed         | 14326       |\n",
      "|    total_timesteps      | 1591296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013832919 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 0.9807223   |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 14344       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011848279 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | 1.6573395   |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 14362       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012787009 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | -0.000354   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.62        |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | -1.1652205  |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 780          |\n",
      "|    time_elapsed         | 14380        |\n",
      "|    total_timesteps      | 1597440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125749875 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.6        |\n",
      "|    explained_variance   | 0.201        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 7790         |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | 0.5338961    |\n",
      "|    std                  | 3.43         |\n",
      "|    value_loss           | 48.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 14398       |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009768875 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | -1.3950647  |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 782        |\n",
      "|    time_elapsed         | 14416      |\n",
      "|    total_timesteps      | 1601536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00892528 |\n",
      "|    clip_fraction        | 0.0862     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.7      |\n",
      "|    explained_variance   | -0.0145    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.7       |\n",
      "|    n_updates            | 7810       |\n",
      "|    policy_gradient_loss | -0.0046    |\n",
      "|    reward               | -16.589222 |\n",
      "|    std                  | 3.43       |\n",
      "|    value_loss           | 42.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 14434       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018375237 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | -0.0114     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | -0.22517489 |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 784        |\n",
      "|    time_elapsed         | 14452      |\n",
      "|    total_timesteps      | 1605632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01023039 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.7      |\n",
      "|    explained_variance   | 0.0666     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 7830       |\n",
      "|    policy_gradient_loss | -0.00779   |\n",
      "|    reward               | 0.86117625 |\n",
      "|    std                  | 3.44       |\n",
      "|    value_loss           | 43.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 14471       |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008027371 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.0499      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | -1.3971066  |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 14489       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015929237 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.09        |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 1.6286446   |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 787         |\n",
      "|    time_elapsed         | 14508       |\n",
      "|    total_timesteps      | 1611776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011336323 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.0727      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -1.3701395  |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 14526       |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013025382 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.0612      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    reward               | -2.496452   |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 14544       |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014195787 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.0498      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.9998666  |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3649133.69\n",
      "total_reward: 2649133.69\n",
      "total_cost: 103908.22\n",
      "total_trades: 55533\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 14563       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016356535 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | 1.4261539   |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 14581       |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010738831 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | 1.5757631   |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 792         |\n",
      "|    time_elapsed         | 14600       |\n",
      "|    total_timesteps      | 1622016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013390782 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | 4.5211987   |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 14618       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016761258 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.22        |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | -1.0911981  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 14636       |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013100314 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | 0.32753345  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 14655       |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007358086 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | 3.9837074   |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 796         |\n",
      "|    time_elapsed         | 14673       |\n",
      "|    total_timesteps      | 1630208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012289313 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.072       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 0.06876773  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 797          |\n",
      "|    time_elapsed         | 14691        |\n",
      "|    total_timesteps      | 1632256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016931016  |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77          |\n",
      "|    explained_variance   | 0.0937       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 7960         |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | -0.106308006 |\n",
      "|    std                  | 3.47         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 798          |\n",
      "|    time_elapsed         | 14710        |\n",
      "|    total_timesteps      | 1634304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083734095 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77          |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 7970         |\n",
      "|    policy_gradient_loss | 0.000242     |\n",
      "|    reward               | 0.3574679    |\n",
      "|    std                  | 3.48         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 14729       |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011320383 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 0.022145174 |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 800          |\n",
      "|    time_elapsed         | 14748        |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105256755 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.1        |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 7990         |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    reward               | 0.9674002    |\n",
      "|    std                  | 3.48         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 14767       |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015508935 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -1.9688131  |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 802          |\n",
      "|    time_elapsed         | 14786        |\n",
      "|    total_timesteps      | 1642496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060019726 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.1        |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 8010         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 1.5983789    |\n",
      "|    std                  | 3.48         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 803        |\n",
      "|    time_elapsed         | 14805      |\n",
      "|    total_timesteps      | 1644544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02357646 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.1      |\n",
      "|    explained_variance   | 0.293      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.53       |\n",
      "|    n_updates            | 8020       |\n",
      "|    policy_gradient_loss | -0.00812   |\n",
      "|    reward               | 0.8732907  |\n",
      "|    std                  | 3.49       |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3672974.91\n",
      "total_reward: 2672974.91\n",
      "total_cost: 110377.58\n",
      "total_trades: 56798\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 14824       |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009210639 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 1.5193064   |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 14843       |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012295656 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.0936      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -0.4030169  |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 14861       |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011450462 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 2.1757116   |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 14879       |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015520927 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | -1.9288552  |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 14897       |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015120629 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    reward               | 1.0721622   |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 809         |\n",
      "|    time_elapsed         | 14916       |\n",
      "|    total_timesteps      | 1656832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014342947 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 0.51274675  |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 14934       |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010194249 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.61        |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 0.23849857  |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 14952       |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008351074 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | 0.031394206 |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 812          |\n",
      "|    time_elapsed         | 14970        |\n",
      "|    total_timesteps      | 1662976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049913717 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.4        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 8110         |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | 4.1246247    |\n",
      "|    std                  | 3.52         |\n",
      "|    value_loss           | 52.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 14989       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007621865 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.061       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | 0.24518724  |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 814          |\n",
      "|    time_elapsed         | 15007        |\n",
      "|    total_timesteps      | 1667072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076454086 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.4        |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 8130         |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    reward               | 2.2676034    |\n",
      "|    std                  | 3.53         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 815        |\n",
      "|    time_elapsed         | 15025      |\n",
      "|    total_timesteps      | 1669120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01467752 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.5      |\n",
      "|    explained_variance   | 0.149      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.3       |\n",
      "|    n_updates            | 8140       |\n",
      "|    policy_gradient_loss | -0.00795   |\n",
      "|    reward               | -1.3814341 |\n",
      "|    std                  | 3.53       |\n",
      "|    value_loss           | 49.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 816        |\n",
      "|    time_elapsed         | 15043      |\n",
      "|    total_timesteps      | 1671168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00911234 |\n",
      "|    clip_fraction        | 0.0749     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.5      |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.2       |\n",
      "|    n_updates            | 8150       |\n",
      "|    policy_gradient_loss | -0.00481   |\n",
      "|    reward               | 2.3104942  |\n",
      "|    std                  | 3.54       |\n",
      "|    value_loss           | 42.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 15061       |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012907216 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 0.5090463   |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4418589.82\n",
      "total_reward: 3418589.82\n",
      "total_cost: 165569.55\n",
      "total_trades: 61513\n",
      "Sharpe: 0.805\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 15079       |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018214047 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 0.79778296  |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 15097       |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010917533 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | -0.49203348 |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 69.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 15115       |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017691508 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 8190        |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | 0.034264293 |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 821          |\n",
      "|    time_elapsed         | 15133        |\n",
      "|    total_timesteps      | 1681408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022471704  |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.5        |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 8200         |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    reward               | -0.056733195 |\n",
      "|    std                  | 3.54         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 15151       |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014701039 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.0615      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | 1.8530867   |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 15169       |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014696717 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.0942      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 8220        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | -0.14077024 |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 15197       |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016165713 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.69        |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | -1.0137267  |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 15216       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009779734 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -2.0859957  |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 826         |\n",
      "|    time_elapsed         | 15234       |\n",
      "|    total_timesteps      | 1691648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008986267 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | 1.4797239   |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 15252       |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012883805 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.2         |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | -3.2727273  |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 828        |\n",
      "|    time_elapsed         | 15270      |\n",
      "|    total_timesteps      | 1695744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837735 |\n",
      "|    clip_fraction        | 0.0439     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.7      |\n",
      "|    explained_variance   | 0.178      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.2       |\n",
      "|    n_updates            | 8270       |\n",
      "|    policy_gradient_loss | -0.00495   |\n",
      "|    reward               | 0.05600541 |\n",
      "|    std                  | 3.56       |\n",
      "|    value_loss           | 41.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 15289       |\n",
      "|    total_timesteps      | 1697792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011061585 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    reward               | 6.717879    |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 15307       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014773245 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.0938      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | -1.727681   |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 831         |\n",
      "|    time_elapsed         | 15325       |\n",
      "|    total_timesteps      | 1701888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012809603 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 1.1021419   |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 15342       |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009964991 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | 2.1112423   |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3275141.61\n",
      "total_reward: 2275141.61\n",
      "total_cost: 85495.13\n",
      "total_trades: 55707\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 833         |\n",
      "|    time_elapsed         | 15361       |\n",
      "|    total_timesteps      | 1705984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011467652 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -1.5732641  |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 15379       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015010222 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -4.4973183  |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 835         |\n",
      "|    time_elapsed         | 15396       |\n",
      "|    total_timesteps      | 1710080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009997055 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    reward               | 0.6836312   |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 15414       |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012724057 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.0654      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | -1.1608223  |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 15432       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025121719 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.095       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | -1.6190546  |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 15450       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006416953 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | 2.0395508   |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 15467       |\n",
      "|    total_timesteps      | 1718272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010239206 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 8380        |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    reward               | 0.5880089   |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 15485       |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015262989 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | 0.4408606   |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 15503       |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015860204 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.27        |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | -0.42172292 |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 842        |\n",
      "|    time_elapsed         | 15521      |\n",
      "|    total_timesteps      | 1724416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0121812  |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.1      |\n",
      "|    explained_variance   | 0.283      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 8410       |\n",
      "|    policy_gradient_loss | -0.00921   |\n",
      "|    reward               | -2.4235275 |\n",
      "|    std                  | 3.61       |\n",
      "|    value_loss           | 38.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 15539       |\n",
      "|    total_timesteps      | 1726464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007268643 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 8420        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | -5.623631   |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 15557       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016031075 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.81        |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    reward               | 0.4443723   |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 15575       |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010710491 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | -0.27094978 |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 15593       |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017626833 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    reward               | 0.012192575 |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3576780.95\n",
      "total_reward: 2576780.95\n",
      "total_cost: 123823.86\n",
      "total_trades: 59721\n",
      "Sharpe: 0.692\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 15611       |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012033333 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.0671      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 2.3038254   |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 15628       |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023435615 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.63        |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | 2.1691217   |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 849        |\n",
      "|    time_elapsed         | 15647      |\n",
      "|    total_timesteps      | 1738752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00912722 |\n",
      "|    clip_fraction        | 0.0822     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.3      |\n",
      "|    explained_variance   | 0.162      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.4       |\n",
      "|    n_updates            | 8480       |\n",
      "|    policy_gradient_loss | -0.0071    |\n",
      "|    reward               | -2.3654954 |\n",
      "|    std                  | 3.63       |\n",
      "|    value_loss           | 48         |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 850           |\n",
      "|    time_elapsed         | 15664         |\n",
      "|    total_timesteps      | 1740800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007209657   |\n",
      "|    clip_fraction        | 0.0579        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -78.3         |\n",
      "|    explained_variance   | 0.0604        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.5          |\n",
      "|    n_updates            | 8490          |\n",
      "|    policy_gradient_loss | -0.00743      |\n",
      "|    reward               | -0.0048624845 |\n",
      "|    std                  | 3.63          |\n",
      "|    value_loss           | 39.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 15682       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023491513 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | -1.3814927  |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 15699       |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006568653 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | -1.7585759  |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 15717       |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009566374 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | 2.157976    |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 15735       |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014821081 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.0618      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | 0.020641077 |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 15753       |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017908182 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | 0.23571034  |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 15771       |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024024306 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 0.92393124  |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 15789       |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009319296 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 4.3118744   |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 15807       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015563069 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    reward               | 1.4082536   |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 15825       |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018199285 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.0802      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | -0.9560169  |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 860        |\n",
      "|    time_elapsed         | 15843      |\n",
      "|    total_timesteps      | 1761280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01203999 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.9      |\n",
      "|    explained_variance   | 0.204      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.7       |\n",
      "|    n_updates            | 8590       |\n",
      "|    policy_gradient_loss | -0.00463   |\n",
      "|    reward               | 2.2587483  |\n",
      "|    std                  | 3.7        |\n",
      "|    value_loss           | 38.8       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3905467.27\n",
      "total_reward: 2905467.27\n",
      "total_cost: 267161.57\n",
      "total_trades: 67167\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 15861       |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017444693 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.09        |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | 0.3562349   |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 15879       |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018616168 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.03        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -2.5252886  |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 15897       |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01780034  |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | -0.66917837 |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 864         |\n",
      "|    time_elapsed         | 15915       |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015390892 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | -0.00312    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 8630        |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | 0.952122    |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 15933       |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014908248 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    reward               | -1.5478415  |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 78.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 15951       |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019953704 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.0791      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.4        |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | 1.0609546   |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 96.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 867        |\n",
      "|    time_elapsed         | 15969      |\n",
      "|    total_timesteps      | 1775616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01803793 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.3      |\n",
      "|    explained_variance   | 0.032      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 41.7       |\n",
      "|    n_updates            | 8660       |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    reward               | 2.194168   |\n",
      "|    std                  | 3.76       |\n",
      "|    value_loss           | 86.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 15987       |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018882943 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.06        |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -1.2439941  |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 16005       |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010456987 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | 0.020906946 |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 70          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 870         |\n",
      "|    time_elapsed         | 16023       |\n",
      "|    total_timesteps      | 1781760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011630878 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 8690        |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | 0.022317894 |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 16041       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018506829 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.93        |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 2.589612    |\n",
      "|    std                  | 3.78        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 16059       |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015553476 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 1.1134653   |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 16077       |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008942012 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 8720        |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | -1.7474731  |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 16094       |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011381753 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.0964      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 1.4288589   |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4410778.88\n",
      "total_reward: 3410778.88\n",
      "total_cost: 229168.69\n",
      "total_trades: 64013\n",
      "Sharpe: 0.807\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 16112       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012450816 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.0862      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.06        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -2.0232635  |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 16131       |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009612504 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 2.0058706   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 877         |\n",
      "|    time_elapsed         | 16149       |\n",
      "|    total_timesteps      | 1796096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013501691 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | -0.16756582 |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 16167       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013766547 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | -3.9046438  |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 879         |\n",
      "|    time_elapsed         | 16186       |\n",
      "|    total_timesteps      | 1800192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015317168 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.20066653  |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 880        |\n",
      "|    time_elapsed         | 16205      |\n",
      "|    total_timesteps      | 1802240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01258495 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.8      |\n",
      "|    explained_variance   | 0.0154     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.4       |\n",
      "|    n_updates            | 8790       |\n",
      "|    policy_gradient_loss | -0.00838   |\n",
      "|    reward               | 5.4235024  |\n",
      "|    std                  | 3.83       |\n",
      "|    value_loss           | 102        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 16224       |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015626835 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | -0.0194     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | -2.6815865  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 16242       |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013244289 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.44        |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | -1.4065284  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 68.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 16262       |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013766376 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0536      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | 0.73432595  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 884         |\n",
      "|    time_elapsed         | 16281       |\n",
      "|    total_timesteps      | 1810432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010921279 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 4.874191    |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 76.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 16299       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013827309 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 1.9767255   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 16318       |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019194705 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.0535      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.5560392  |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 16337       |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015630536 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.0339      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 4.90285     |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 90.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 16355       |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014128216 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 1.5199777   |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3133839.33\n",
      "total_reward: 2133839.33\n",
      "total_cost: 301378.29\n",
      "total_trades: 66990\n",
      "Sharpe: 0.627\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 889         |\n",
      "|    time_elapsed         | 16374       |\n",
      "|    total_timesteps      | 1820672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011149126 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.30483186  |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 62.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 16394       |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011878239 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.40955916 |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 16413       |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010338683 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 8900        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -1.1523653  |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 892        |\n",
      "|    time_elapsed         | 16431      |\n",
      "|    total_timesteps      | 1826816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01883651 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.2      |\n",
      "|    explained_variance   | 0.0699     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 8910       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    reward               | 1.805524   |\n",
      "|    std                  | 3.88       |\n",
      "|    value_loss           | 22.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 16450       |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014927683 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.06        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | -0.7680041  |\n",
      "|    std                  | 3.89        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 894         |\n",
      "|    time_elapsed         | 16469       |\n",
      "|    total_timesteps      | 1830912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014384408 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | -0.00991    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.9        |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | 3.100383    |\n",
      "|    std                  | 3.9         |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 16488       |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021632908 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | -0.0112     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | -1.7378838  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 896         |\n",
      "|    time_elapsed         | 16506       |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017464153 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | -0.00222    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.1        |\n",
      "|    n_updates            | 8950        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | -1.5448745  |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 897        |\n",
      "|    time_elapsed         | 16524      |\n",
      "|    total_timesteps      | 1837056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01649902 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.6      |\n",
      "|    explained_variance   | 0.053      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 63.3       |\n",
      "|    n_updates            | 8960       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    reward               | -17.540634 |\n",
      "|    std                  | 3.93       |\n",
      "|    value_loss           | 93.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 16542       |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019182414 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | -0.0447     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | 1.3584212   |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 899        |\n",
      "|    time_elapsed         | 16560      |\n",
      "|    total_timesteps      | 1841152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01617198 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.7      |\n",
      "|    explained_variance   | 0.167      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.32       |\n",
      "|    n_updates            | 8980       |\n",
      "|    policy_gradient_loss | -0.00659   |\n",
      "|    reward               | -1.6036855 |\n",
      "|    std                  | 3.94       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 16579       |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016019756 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.0565      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | 1.6729826   |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 78.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 901        |\n",
      "|    time_elapsed         | 16598      |\n",
      "|    total_timesteps      | 1845248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0170142  |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.7      |\n",
      "|    explained_variance   | 0.0138     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 56.6       |\n",
      "|    n_updates            | 9000       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | -0.1791014 |\n",
      "|    std                  | 3.95       |\n",
      "|    value_loss           | 103        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 16617       |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014384947 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.0117      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 0.2583109   |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5195196.74\n",
      "total_reward: 4195196.74\n",
      "total_cost: 288597.78\n",
      "total_trades: 65318\n",
      "Sharpe: 0.786\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 16635       |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013316071 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.0591      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.9156325  |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 82.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 904        |\n",
      "|    time_elapsed         | 16654      |\n",
      "|    total_timesteps      | 1851392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0147308  |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.9      |\n",
      "|    explained_variance   | 0.0362     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 57.2       |\n",
      "|    n_updates            | 9030       |\n",
      "|    policy_gradient_loss | -0.00639   |\n",
      "|    reward               | 0.29507777 |\n",
      "|    std                  | 3.98       |\n",
      "|    value_loss           | 125        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 16673       |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016114973 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | -0.0817     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 0.13590509  |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 16693       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009747736 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.0951      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    reward               | 2.0233612   |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 907          |\n",
      "|    time_elapsed         | 16710        |\n",
      "|    total_timesteps      | 1857536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015618954  |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.1        |\n",
      "|    explained_variance   | 0.0688       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 9060         |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | -0.025020385 |\n",
      "|    std                  | 4.01         |\n",
      "|    value_loss           | 57           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 16729       |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012700755 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.0288      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | 2.3221328   |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 909         |\n",
      "|    time_elapsed         | 16747       |\n",
      "|    total_timesteps      | 1861632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016877694 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0547      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.6         |\n",
      "|    n_updates            | 9080        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -2.6938999  |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 910        |\n",
      "|    time_elapsed         | 16766      |\n",
      "|    total_timesteps      | 1863680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01350411 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.3      |\n",
      "|    explained_variance   | 0.048      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.1       |\n",
      "|    n_updates            | 9090       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | -0.8716914 |\n",
      "|    std                  | 4.02       |\n",
      "|    value_loss           | 69.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 16784       |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008903202 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -3.4675715  |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 16803       |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015780289 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0512      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | 0.97869116  |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 16821       |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010960039 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0518      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.2        |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 1.7556578   |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 914         |\n",
      "|    time_elapsed         | 16839       |\n",
      "|    total_timesteps      | 1871872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010570116 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.0342      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 9130        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.9824764   |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 16857        |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059908656 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.4        |\n",
      "|    explained_variance   | 0.0225       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.7         |\n",
      "|    n_updates            | 9140         |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 1.9485571    |\n",
      "|    std                  | 4.04         |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 916        |\n",
      "|    time_elapsed         | 16875      |\n",
      "|    total_timesteps      | 1875968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01194861 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.5      |\n",
      "|    explained_variance   | 0.0556     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 9150       |\n",
      "|    policy_gradient_loss | -0.00826   |\n",
      "|    reward               | 2.3301096  |\n",
      "|    std                  | 4.05       |\n",
      "|    value_loss           | 38         |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5452682.97\n",
      "total_reward: 4452682.97\n",
      "total_cost: 294700.13\n",
      "total_trades: 66027\n",
      "Sharpe: 0.728\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 917         |\n",
      "|    time_elapsed         | 16893       |\n",
      "|    total_timesteps      | 1878016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009266557 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.0317      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 9160        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | 0.5754749   |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 918         |\n",
      "|    time_elapsed         | 16912       |\n",
      "|    total_timesteps      | 1880064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012339048 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | -0.00435    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.5        |\n",
      "|    n_updates            | 9170        |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | 5.2263074   |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 919        |\n",
      "|    time_elapsed         | 16931      |\n",
      "|    total_timesteps      | 1882112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01418335 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.5      |\n",
      "|    explained_variance   | 0.0112     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.4       |\n",
      "|    n_updates            | 9180       |\n",
      "|    policy_gradient_loss | -0.0068    |\n",
      "|    reward               | -0.9825216 |\n",
      "|    std                  | 4.06       |\n",
      "|    value_loss           | 68.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 16949       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013231534 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.014421955 |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 921       |\n",
      "|    time_elapsed         | 16967     |\n",
      "|    total_timesteps      | 1886208   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0082525 |\n",
      "|    clip_fraction        | 0.0498    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -81.6     |\n",
      "|    explained_variance   | 0.0627    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 84.9      |\n",
      "|    n_updates            | 9200      |\n",
      "|    policy_gradient_loss | -0.00915  |\n",
      "|    reward               | -2.018185 |\n",
      "|    std                  | 4.07      |\n",
      "|    value_loss           | 214       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 16985       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009558732 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.4        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | 3.8683627   |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 93          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 923         |\n",
      "|    time_elapsed         | 17004       |\n",
      "|    total_timesteps      | 1890304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015183542 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.00573     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.52768946 |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 17022       |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012761526 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60          |\n",
      "|    n_updates            | 9230        |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | -0.9700071  |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 17040       |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012146145 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.065       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | 3.9767613   |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 73          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 17058       |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018855546 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    reward               | 1.7410463   |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 17076       |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011331344 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.0522      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 2.1069489   |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 928         |\n",
      "|    time_elapsed         | 17093       |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009742651 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | 0.15633729  |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 17111       |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014446618 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 5.042845    |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 17129       |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010622144 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 7.1941495   |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5279603.97\n",
      "total_reward: 4279603.97\n",
      "total_cost: 216972.36\n",
      "total_trades: 60766\n",
      "Sharpe: 0.727\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 931         |\n",
      "|    time_elapsed         | 17147       |\n",
      "|    total_timesteps      | 1906688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017569873 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | -0.9775793  |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 932         |\n",
      "|    time_elapsed         | 17165       |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014657041 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.0827      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 1.0784048   |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 933        |\n",
      "|    time_elapsed         | 17183      |\n",
      "|    total_timesteps      | 1910784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01498719 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82        |\n",
      "|    explained_variance   | 0.265      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.1       |\n",
      "|    n_updates            | 9320       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    reward               | -2.1495106 |\n",
      "|    std                  | 4.12       |\n",
      "|    value_loss           | 36.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 17201       |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011510648 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 0.4197068   |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 935        |\n",
      "|    time_elapsed         | 17219      |\n",
      "|    total_timesteps      | 1914880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01305628 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.1      |\n",
      "|    explained_variance   | 0.0846     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.9       |\n",
      "|    n_updates            | 9340       |\n",
      "|    policy_gradient_loss | -0.00933   |\n",
      "|    reward               | 13.859026  |\n",
      "|    std                  | 4.14       |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 17237       |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008142116 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.0118      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.1        |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | -6.677428   |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 17256       |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008742956 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.0673      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.7        |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 0.31098405  |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 938          |\n",
      "|    time_elapsed         | 17274        |\n",
      "|    total_timesteps      | 1921024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008526358  |\n",
      "|    clip_fraction        | 0.0579       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.2        |\n",
      "|    explained_variance   | 0.113        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.4         |\n",
      "|    n_updates            | 9370         |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    reward               | -0.122205496 |\n",
      "|    std                  | 4.15         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 17293       |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008177371 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.0282      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.2        |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 0.061773073 |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 17311       |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012740029 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | 5.85257     |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 44.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 17329       |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016707696 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.091       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | -0.4446194  |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 17347       |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013340579 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.0681      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.6        |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -0.3455071  |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 17365       |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011954982 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.0943      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | -1.2128502  |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 17383       |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013403544 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 9430        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -1.1120664  |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 945         |\n",
      "|    time_elapsed         | 17401       |\n",
      "|    total_timesteps      | 1935360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008495243 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0784      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.5        |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 2.188875    |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6114902.98\n",
      "total_reward: 5114902.98\n",
      "total_cost: 174522.59\n",
      "total_trades: 58271\n",
      "Sharpe: 0.836\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 17420       |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009030195 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    reward               | -1.2900618  |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 17438       |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017605556 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -1.509761   |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 948         |\n",
      "|    time_elapsed         | 17456       |\n",
      "|    total_timesteps      | 1941504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007457698 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 0.997978    |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 949          |\n",
      "|    time_elapsed         | 17474        |\n",
      "|    total_timesteps      | 1943552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045026136 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.6        |\n",
      "|    explained_variance   | 0.0297       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.8         |\n",
      "|    n_updates            | 9480         |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 4.44199      |\n",
      "|    std                  | 4.21         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 17492       |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810343 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | 1.3146285   |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 17510       |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011187443 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 9500        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.9179184   |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 17528       |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010226218 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.0584      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 9510        |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    reward               | 4.7392654   |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 17547       |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008194426 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.0682      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | -0.86742526 |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 17565       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009280981 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.0674      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.7        |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 1.3623581   |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 955          |\n",
      "|    time_elapsed         | 17584        |\n",
      "|    total_timesteps      | 1955840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068384814 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.8        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 9540         |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    reward               | 0.58148956   |\n",
      "|    std                  | 4.24         |\n",
      "|    value_loss           | 238          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 17602       |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006212815 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    reward               | 1.8409307   |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 17620       |\n",
      "|    total_timesteps      | 1959936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016044717 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 9560        |\n",
      "|    policy_gradient_loss | 0.0024      |\n",
      "|    reward               | -0.5512902  |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 83.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 958        |\n",
      "|    time_elapsed         | 17639      |\n",
      "|    total_timesteps      | 1961984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01399684 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.8      |\n",
      "|    explained_variance   | 0.118      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 193        |\n",
      "|    n_updates            | 9570       |\n",
      "|    policy_gradient_loss | -0.00725   |\n",
      "|    reward               | -0.6788511 |\n",
      "|    std                  | 4.25       |\n",
      "|    value_loss           | 355        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 17657       |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004877948 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 9580        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    reward               | -3.0279934  |\n",
      "|    std                  | 4.25        |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6813028.26\n",
      "total_reward: 5813028.26\n",
      "total_cost: 187311.60\n",
      "total_trades: 59669\n",
      "Sharpe: 0.799\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 17675       |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016073588 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.3        |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    reward               | 10.932894   |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 17693       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007570647 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | 0.33014414  |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 962          |\n",
      "|    time_elapsed         | 17712        |\n",
      "|    total_timesteps      | 1970176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071751485 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83          |\n",
      "|    explained_variance   | 0.0998       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 231          |\n",
      "|    n_updates            | 9610         |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    reward               | -1.1133249   |\n",
      "|    std                  | 4.26         |\n",
      "|    value_loss           | 316          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 963        |\n",
      "|    time_elapsed         | 17730      |\n",
      "|    total_timesteps      | 1972224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00926374 |\n",
      "|    clip_fraction        | 0.091      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83        |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 172        |\n",
      "|    n_updates            | 9620       |\n",
      "|    policy_gradient_loss | -0.00983   |\n",
      "|    reward               | 2.4242249  |\n",
      "|    std                  | 4.26       |\n",
      "|    value_loss           | 371        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 17748       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010639437 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | 0.56399083  |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 965          |\n",
      "|    time_elapsed         | 17766        |\n",
      "|    total_timesteps      | 1976320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032249351 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83          |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 298          |\n",
      "|    n_updates            | 9640         |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | 0.40098926   |\n",
      "|    std                  | 4.27         |\n",
      "|    value_loss           | 247          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 17785       |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00798805  |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | 0.016688958 |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 967        |\n",
      "|    time_elapsed         | 17803      |\n",
      "|    total_timesteps      | 1980416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00910399 |\n",
      "|    clip_fraction        | 0.0381     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.1      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.2       |\n",
      "|    n_updates            | 9660       |\n",
      "|    policy_gradient_loss | -0.00484   |\n",
      "|    reward               | -3.9006894 |\n",
      "|    std                  | 4.29       |\n",
      "|    value_loss           | 125        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 968          |\n",
      "|    time_elapsed         | 17822        |\n",
      "|    total_timesteps      | 1982464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100322785 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.2        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 253          |\n",
      "|    n_updates            | 9670         |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 1.0322306    |\n",
      "|    std                  | 4.29         |\n",
      "|    value_loss           | 314          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 969          |\n",
      "|    time_elapsed         | 17840        |\n",
      "|    total_timesteps      | 1984512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099269375 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.2        |\n",
      "|    explained_variance   | 0.0766       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 9680         |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | -10.9336815  |\n",
      "|    std                  | 4.3          |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 970         |\n",
      "|    time_elapsed         | 17859       |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015705355 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 9690        |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    reward               | -4.1930637  |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 17877       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013041505 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | -1.0087167  |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 17896       |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013175436 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86          |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 1.3247347   |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 973        |\n",
      "|    time_elapsed         | 17914      |\n",
      "|    total_timesteps      | 1992704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01251816 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.3      |\n",
      "|    explained_variance   | 0.303      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 121        |\n",
      "|    n_updates            | 9720       |\n",
      "|    policy_gradient_loss | -0.0056    |\n",
      "|    reward               | -15.429724 |\n",
      "|    std                  | 4.31       |\n",
      "|    value_loss           | 183        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6629770.22\n",
      "total_reward: 5629770.22\n",
      "total_cost: 143168.87\n",
      "total_trades: 56091\n",
      "Sharpe: 0.834\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 17933       |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018952593 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | -0.9469467  |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 975        |\n",
      "|    time_elapsed         | 17951      |\n",
      "|    total_timesteps      | 1996800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01694934 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.3      |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.2       |\n",
      "|    n_updates            | 9740       |\n",
      "|    policy_gradient_loss | -0.00567   |\n",
      "|    reward               | 1.9675252  |\n",
      "|    std                  | 4.32       |\n",
      "|    value_loss           | 158        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 17969       |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008881392 |\n",
      "|    clip_fraction        | 0.048       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | -4.213166   |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 977         |\n",
      "|    time_elapsed         | 17988       |\n",
      "|    total_timesteps      | 2000896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013045641 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 0.84391814  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 978         |\n",
      "|    time_elapsed         | 18006       |\n",
      "|    total_timesteps      | 2002944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011976232 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | 0.099010915 |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 18024       |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012045678 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | -0.6440144  |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 980          |\n",
      "|    time_elapsed         | 18043        |\n",
      "|    total_timesteps      | 2007040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122549655 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.6        |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 9790         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | -0.71608734  |\n",
      "|    std                  | 4.36         |\n",
      "|    value_loss           | 98.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 18061       |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015739255 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 9800        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.84641445  |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 982         |\n",
      "|    time_elapsed         | 18078       |\n",
      "|    total_timesteps      | 2011136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007972408 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | -0.09610465 |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 94.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 18096       |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007890733 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | -0.68667376 |\n",
      "|    std                  | 4.37        |\n",
      "|    value_loss           | 91.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 18114       |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013973948 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 0.7520781   |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 18132       |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016216448 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -1.2762002  |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 71          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 986          |\n",
      "|    time_elapsed         | 18150        |\n",
      "|    total_timesteps      | 2019328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061719297 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.7        |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.3         |\n",
      "|    n_updates            | 9850         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 0.14098692   |\n",
      "|    std                  | 4.38         |\n",
      "|    value_loss           | 98.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 987         |\n",
      "|    time_elapsed         | 18168       |\n",
      "|    total_timesteps      | 2021376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009985706 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 9860        |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | 0.5597212   |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5301990.06\n",
      "total_reward: 4301990.06\n",
      "total_cost: 98473.62\n",
      "total_trades: 53112\n",
      "Sharpe: 0.815\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 18187       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015181427 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 2.0747712   |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 989        |\n",
      "|    time_elapsed         | 18206      |\n",
      "|    total_timesteps      | 2025472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00770116 |\n",
      "|    clip_fraction        | 0.0812     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.8      |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28         |\n",
      "|    n_updates            | 9880       |\n",
      "|    policy_gradient_loss | -0.00529   |\n",
      "|    reward               | 1.0114721  |\n",
      "|    std                  | 4.39       |\n",
      "|    value_loss           | 80.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 18224       |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002310874 |\n",
      "|    clip_fraction        | 0.00698     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    reward               | -0.42582875 |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 79.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 991          |\n",
      "|    time_elapsed         | 18242        |\n",
      "|    total_timesteps      | 2029568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130452085 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.8        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 9900         |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 0.10299124   |\n",
      "|    std                  | 4.39         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 992         |\n",
      "|    time_elapsed         | 18261       |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012881739 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | -2.6060097  |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 993          |\n",
      "|    time_elapsed         | 18280        |\n",
      "|    total_timesteps      | 2033664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027019721 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.9        |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 9920         |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 4.4654503    |\n",
      "|    std                  | 4.4          |\n",
      "|    value_loss           | 87           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 994        |\n",
      "|    time_elapsed         | 18299      |\n",
      "|    total_timesteps      | 2035712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00929364 |\n",
      "|    clip_fraction        | 0.0609     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.9      |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.3       |\n",
      "|    n_updates            | 9930       |\n",
      "|    policy_gradient_loss | -0.00426   |\n",
      "|    reward               | -0.5928793 |\n",
      "|    std                  | 4.41       |\n",
      "|    value_loss           | 56.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 18317       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012674536 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | 0.12605512  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 18334       |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011904167 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 1.5672333   |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 997         |\n",
      "|    time_elapsed         | 18353       |\n",
      "|    total_timesteps      | 2041856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008023746 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | -17.192139  |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 82.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 18371       |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015797075 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    reward               | -4.2618504  |\n",
      "|    std                  | 4.42        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 18389       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005932698 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | -0.5905464  |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 18407       |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009352624 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | 2.3279302   |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1001        |\n",
      "|    time_elapsed         | 18425       |\n",
      "|    total_timesteps      | 2050048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007725413 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | 0.055741373 |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3967105.53\n",
      "total_reward: 2967105.53\n",
      "total_cost: 111178.58\n",
      "total_trades: 53930\n",
      "Sharpe: 0.696\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1002       |\n",
      "|    time_elapsed         | 18443      |\n",
      "|    total_timesteps      | 2052096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01332579 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.1      |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 10010      |\n",
      "|    policy_gradient_loss | -0.0083    |\n",
      "|    reward               | -0.681181  |\n",
      "|    std                  | 4.43       |\n",
      "|    value_loss           | 44.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1003         |\n",
      "|    time_elapsed         | 18461        |\n",
      "|    total_timesteps      | 2054144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053226887 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.1        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 10020        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -1.2976749   |\n",
      "|    std                  | 4.43         |\n",
      "|    value_loss           | 51.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1004         |\n",
      "|    time_elapsed         | 18480        |\n",
      "|    total_timesteps      | 2056192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048245024 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.1        |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 10030        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | -0.28484312  |\n",
      "|    std                  | 4.44         |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 18498       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020705532 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.36        |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -0.19590864 |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1006         |\n",
      "|    time_elapsed         | 18517        |\n",
      "|    total_timesteps      | 2060288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059025264 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.2        |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 10050        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | -2.4718454   |\n",
      "|    std                  | 4.46         |\n",
      "|    value_loss           | 53           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 18535        |\n",
      "|    total_timesteps      | 2062336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071311044 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 10060        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    reward               | 10.598577    |\n",
      "|    std                  | 4.46         |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 18553       |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012838563 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    reward               | -0.8953303  |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 72.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1009        |\n",
      "|    time_elapsed         | 18572       |\n",
      "|    total_timesteps      | 2066432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015029561 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.8        |\n",
      "|    n_updates            | 10080       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | 0.005784547 |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 18590       |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007736372 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | 5.339448    |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1011        |\n",
      "|    time_elapsed         | 18608       |\n",
      "|    total_timesteps      | 2070528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007205842 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 0.6904922   |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 18627       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015716558 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -1.4392829  |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 18645       |\n",
      "|    total_timesteps      | 2074624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007520583 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 10120       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -1.5776637  |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 77.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1014         |\n",
      "|    time_elapsed         | 18664        |\n",
      "|    total_timesteps      | 2076672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076312115 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.5        |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.6         |\n",
      "|    n_updates            | 10130        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -0.6616675   |\n",
      "|    std                  | 4.5          |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 18681       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015340259 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | 1.8705612   |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4186859.95\n",
      "total_reward: 3186859.95\n",
      "total_cost: 125965.84\n",
      "total_trades: 54963\n",
      "Sharpe: 0.661\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1016        |\n",
      "|    time_elapsed         | 18699       |\n",
      "|    total_timesteps      | 2080768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007204625 |\n",
      "|    clip_fraction        | 0.0298      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | 0.025405042 |\n",
      "|    std                  | 4.5         |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1017        |\n",
      "|    time_elapsed         | 18717       |\n",
      "|    total_timesteps      | 2082816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010532707 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 10160       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -13.140909  |\n",
      "|    std                  | 4.51        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1018        |\n",
      "|    time_elapsed         | 18735       |\n",
      "|    total_timesteps      | 2084864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010666957 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.0708      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 10170       |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | -0.8930575  |\n",
      "|    std                  | 4.51        |\n",
      "|    value_loss           | 94.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 18753       |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012181743 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 1.2902192   |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 89.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 18771       |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009355418 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -0.74565417 |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1021        |\n",
      "|    time_elapsed         | 18789       |\n",
      "|    total_timesteps      | 2091008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012515787 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57          |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 0.57913154  |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 18807       |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014687618 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 1.0674142   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 18825       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004096719 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | 0.4178384   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 93.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1024          |\n",
      "|    time_elapsed         | 18843         |\n",
      "|    total_timesteps      | 2097152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092251424 |\n",
      "|    clip_fraction        | 0.002         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -84.7         |\n",
      "|    explained_variance   | 0.456         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 38.8          |\n",
      "|    n_updates            | 10230         |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | -9.233736     |\n",
      "|    std                  | 4.53          |\n",
      "|    value_loss           | 116           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1025         |\n",
      "|    time_elapsed         | 18861        |\n",
      "|    total_timesteps      | 2099200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063866386 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.8        |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 10240        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 5.340083     |\n",
      "|    std                  | 4.54         |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1026        |\n",
      "|    time_elapsed         | 18879       |\n",
      "|    total_timesteps      | 2101248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011988232 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.7475139   |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 18897       |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007471041 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.7        |\n",
      "|    n_updates            | 10260       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | 1.1530248   |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1028        |\n",
      "|    time_elapsed         | 18915       |\n",
      "|    total_timesteps      | 2105344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012283564 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    reward               | 0.6348534   |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 18933       |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011783913 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.9       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | -0.23674461 |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3763414.19\n",
      "total_reward: 2763414.19\n",
      "total_cost: 126639.63\n",
      "total_trades: 54794\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1030         |\n",
      "|    time_elapsed         | 18951        |\n",
      "|    total_timesteps      | 2109440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059148343 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85          |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 10290        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | -2.5301924   |\n",
      "|    std                  | 4.57         |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1031       |\n",
      "|    time_elapsed         | 18970      |\n",
      "|    total_timesteps      | 2111488    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00542463 |\n",
      "|    clip_fraction        | 0.0219     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85        |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.6       |\n",
      "|    n_updates            | 10300      |\n",
      "|    policy_gradient_loss | -0.00433   |\n",
      "|    reward               | -1.3480847 |\n",
      "|    std                  | 4.58       |\n",
      "|    value_loss           | 44.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1032        |\n",
      "|    time_elapsed         | 18989       |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016137028 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | 0.35944942  |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1033         |\n",
      "|    time_elapsed         | 19007        |\n",
      "|    total_timesteps      | 2115584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103988275 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.1        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 10320        |\n",
      "|    policy_gradient_loss | -0.00829     |\n",
      "|    reward               | 1.6804845    |\n",
      "|    std                  | 4.59         |\n",
      "|    value_loss           | 51.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 19025       |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006561868 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | 1.779807    |\n",
      "|    std                  | 4.59        |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 19043       |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007539163 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | -0.524093   |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1036        |\n",
      "|    time_elapsed         | 19061       |\n",
      "|    total_timesteps      | 2121728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013126357 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    reward               | 0.06391695  |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1037         |\n",
      "|    time_elapsed         | 19079        |\n",
      "|    total_timesteps      | 2123776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035131911 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.2        |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 10360        |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    reward               | 1.5921296    |\n",
      "|    std                  | 4.61         |\n",
      "|    value_loss           | 57.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 19097       |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009710487 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.6        |\n",
      "|    n_updates            | 10370       |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -2.4090767  |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 94.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1039       |\n",
      "|    time_elapsed         | 19115      |\n",
      "|    total_timesteps      | 2127872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01458404 |\n",
      "|    clip_fraction        | 0.0645     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.2      |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.8       |\n",
      "|    n_updates            | 10380      |\n",
      "|    policy_gradient_loss | -0.00511   |\n",
      "|    reward               | 0.58573854 |\n",
      "|    std                  | 4.61       |\n",
      "|    value_loss           | 31.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 19133       |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008178801 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | -2.0301712  |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1041         |\n",
      "|    time_elapsed         | 19151        |\n",
      "|    total_timesteps      | 2131968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063020834 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.3        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 10400        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | 5.318648     |\n",
      "|    std                  | 4.62         |\n",
      "|    value_loss           | 66           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 19169       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011559001 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | 0.065832496 |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 19187       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014435941 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | 0.21880484  |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3373489.34\n",
      "total_reward: 2373489.34\n",
      "total_cost: 112885.77\n",
      "total_trades: 54508\n",
      "Sharpe: 0.612\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1044         |\n",
      "|    time_elapsed         | 19204        |\n",
      "|    total_timesteps      | 2138112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073811756 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.4        |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 10430        |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    reward               | 2.0220563    |\n",
      "|    std                  | 4.64         |\n",
      "|    value_loss           | 56.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1045        |\n",
      "|    time_elapsed         | 19222       |\n",
      "|    total_timesteps      | 2140160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007861104 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    reward               | -0.37701046 |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 19240       |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022360992 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | -0.8384232  |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1047        |\n",
      "|    time_elapsed         | 19258       |\n",
      "|    total_timesteps      | 2144256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009673923 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | -2.4262402  |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 19276       |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006472961 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | 0.78166455  |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 61          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 19294       |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014840616 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.000708   |\n",
      "|    reward               | -1.5750409  |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1050        |\n",
      "|    time_elapsed         | 19312       |\n",
      "|    total_timesteps      | 2150400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010909403 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.81310177 |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 19330       |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010477335 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | 0.41170475  |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 19349       |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006175098 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | 1.9460702   |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 19367       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012402913 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | 1.3691946   |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 19386       |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008387824 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | 0.13305685  |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1055        |\n",
      "|    time_elapsed         | 19404       |\n",
      "|    total_timesteps      | 2160640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008325465 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | 2.1870804   |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 19435       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011448001 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | -2.6548834  |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1057         |\n",
      "|    time_elapsed         | 19454        |\n",
      "|    total_timesteps      | 2164736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009418899  |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.8        |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 10560        |\n",
      "|    policy_gradient_loss | -0.00865     |\n",
      "|    reward               | -0.026714236 |\n",
      "|    std                  | 4.69         |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1058       |\n",
      "|    time_elapsed         | 19472      |\n",
      "|    total_timesteps      | 2166784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00996732 |\n",
      "|    clip_fraction        | 0.0881     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.8      |\n",
      "|    explained_variance   | 0.433      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.3       |\n",
      "|    n_updates            | 10570      |\n",
      "|    policy_gradient_loss | -0.00516   |\n",
      "|    reward               | -5.505482  |\n",
      "|    std                  | 4.7        |\n",
      "|    value_loss           | 51.8       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3778026.89\n",
      "total_reward: 2778026.89\n",
      "total_cost: 156769.15\n",
      "total_trades: 57086\n",
      "Sharpe: 0.701\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 19490       |\n",
      "|    total_timesteps      | 2168832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012964925 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 10580       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 0.28839567  |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1060       |\n",
      "|    time_elapsed         | 19508      |\n",
      "|    total_timesteps      | 2170880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01744311 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.9      |\n",
      "|    explained_variance   | 0.257      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.9       |\n",
      "|    n_updates            | 10590      |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    reward               | 0.81555    |\n",
      "|    std                  | 4.71       |\n",
      "|    value_loss           | 29.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 19526       |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012800425 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | 0.08065076  |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 19544       |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009471664 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.9       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.000924   |\n",
      "|    reward               | -1.6832328  |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1063       |\n",
      "|    time_elapsed         | 19562      |\n",
      "|    total_timesteps      | 2177024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01407579 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86        |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 10620      |\n",
      "|    policy_gradient_loss | -0.00781   |\n",
      "|    reward               | -1.2082613 |\n",
      "|    std                  | 4.73       |\n",
      "|    value_loss           | 25.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 19580       |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012394712 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | 1.6741443   |\n",
      "|    std                  | 4.74        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1065       |\n",
      "|    time_elapsed         | 19598      |\n",
      "|    total_timesteps      | 2181120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01030938 |\n",
      "|    clip_fraction        | 0.0806     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.1      |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.3       |\n",
      "|    n_updates            | 10640      |\n",
      "|    policy_gradient_loss | -0.00506   |\n",
      "|    reward               | -1.7244301 |\n",
      "|    std                  | 4.75       |\n",
      "|    value_loss           | 60.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1066        |\n",
      "|    time_elapsed         | 19616       |\n",
      "|    total_timesteps      | 2183168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016528301 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | -1.3186014  |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 19634       |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013749834 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    reward               | -0.27320576 |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1068        |\n",
      "|    time_elapsed         | 19652       |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014810086 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 10670       |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | -2.8848374  |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 19670       |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012993609 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    reward               | 1.8197033   |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1070        |\n",
      "|    time_elapsed         | 19688       |\n",
      "|    total_timesteps      | 2191360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015088645 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.32        |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.1666594   |\n",
      "|    std                  | 4.79        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 19706       |\n",
      "|    total_timesteps      | 2193408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011335121 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 10700       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | -0.92258716 |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1072       |\n",
      "|    time_elapsed         | 19724      |\n",
      "|    total_timesteps      | 2195456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00576076 |\n",
      "|    clip_fraction        | 0.0292     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.4      |\n",
      "|    explained_variance   | 0.291      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.5       |\n",
      "|    n_updates            | 10710      |\n",
      "|    policy_gradient_loss | -0.00446   |\n",
      "|    reward               | 1.6793691  |\n",
      "|    std                  | 4.8        |\n",
      "|    value_loss           | 67.8       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3937864.69\n",
      "total_reward: 2937864.69\n",
      "total_cost: 153633.93\n",
      "total_trades: 56869\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 19742       |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011573964 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | 1.1097258   |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1074         |\n",
      "|    time_elapsed         | 19760        |\n",
      "|    total_timesteps      | 2199552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141001735 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.5        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 10730        |\n",
      "|    policy_gradient_loss | -0.00871     |\n",
      "|    reward               | 0.8291656    |\n",
      "|    std                  | 4.81         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1075         |\n",
      "|    time_elapsed         | 19778        |\n",
      "|    total_timesteps      | 2201600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072247703 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.5        |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 10740        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | 0.4710348    |\n",
      "|    std                  | 4.81         |\n",
      "|    value_loss           | 57.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 19796       |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009716965 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -0.28674933 |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 19814       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017629659 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.2806233   |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1078       |\n",
      "|    time_elapsed         | 19834      |\n",
      "|    total_timesteps      | 2207744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00691946 |\n",
      "|    clip_fraction        | 0.0331     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.5      |\n",
      "|    explained_variance   | 0.435      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.8       |\n",
      "|    n_updates            | 10770      |\n",
      "|    policy_gradient_loss | -0.00477   |\n",
      "|    reward               | 1.377126   |\n",
      "|    std                  | 4.82       |\n",
      "|    value_loss           | 56.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1079        |\n",
      "|    time_elapsed         | 19853       |\n",
      "|    total_timesteps      | 2209792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007340014 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 10780       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | -0.51571655 |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 19871       |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018557513 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | -0.87407464 |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1081       |\n",
      "|    time_elapsed         | 19888      |\n",
      "|    total_timesteps      | 2213888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01246354 |\n",
      "|    clip_fraction        | 0.094      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.7      |\n",
      "|    explained_variance   | 0.462      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.6       |\n",
      "|    n_updates            | 10800      |\n",
      "|    policy_gradient_loss | -0.00947   |\n",
      "|    reward               | -1.6450301 |\n",
      "|    std                  | 4.85       |\n",
      "|    value_loss           | 40.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 19906       |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008106804 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 5.449543    |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 19925       |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011554539 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -2.1512332  |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1084        |\n",
      "|    time_elapsed         | 19943       |\n",
      "|    total_timesteps      | 2220032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013421388 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | 0.23560187  |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 19962       |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009677736 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | -1.2946838  |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 56.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 19980       |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009632159 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -4.4791913  |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4264086.54\n",
      "total_reward: 3264086.54\n",
      "total_cost: 202142.10\n",
      "total_trades: 59899\n",
      "Sharpe: 0.752\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 19999       |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015109751 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    reward               | 1.2991338   |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 20017       |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009824709 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | -1.528294   |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1089        |\n",
      "|    time_elapsed         | 20035       |\n",
      "|    total_timesteps      | 2230272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011997702 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.028018493 |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 20054       |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010874875 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    reward               | 1.088189    |\n",
      "|    std                  | 4.88        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 20073       |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012088904 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.92        |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.15906146  |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 20091       |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012694439 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | -2.417532   |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 20109       |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008525131 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 10920       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | -4.470757   |\n",
      "|    std                  | 4.9         |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1094       |\n",
      "|    time_elapsed         | 20127      |\n",
      "|    total_timesteps      | 2240512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01365409 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87        |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.65       |\n",
      "|    n_updates            | 10930      |\n",
      "|    policy_gradient_loss | -0.00812   |\n",
      "|    reward               | 0.3873827  |\n",
      "|    std                  | 4.9        |\n",
      "|    value_loss           | 28.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 20145       |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006002961 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 0.4309534   |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1096        |\n",
      "|    time_elapsed         | 20163       |\n",
      "|    total_timesteps      | 2244608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009260526 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 10950       |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    reward               | 0.8950555   |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1097        |\n",
      "|    time_elapsed         | 20182       |\n",
      "|    total_timesteps      | 2246656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013091452 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 0.50415045  |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 20200       |\n",
      "|    total_timesteps      | 2248704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014390519 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 10970       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -2.2439153  |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1099       |\n",
      "|    time_elapsed         | 20219      |\n",
      "|    total_timesteps      | 2250752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00744623 |\n",
      "|    clip_fraction        | 0.0457     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.2      |\n",
      "|    explained_variance   | 0.54       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.5       |\n",
      "|    n_updates            | 10980      |\n",
      "|    policy_gradient_loss | -0.00712   |\n",
      "|    reward               | 3.6226013  |\n",
      "|    std                  | 4.93       |\n",
      "|    value_loss           | 45.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1100         |\n",
      "|    time_elapsed         | 20237        |\n",
      "|    total_timesteps      | 2252800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067915823 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.2        |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 10990        |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    reward               | 1.790546     |\n",
      "|    std                  | 4.93         |\n",
      "|    value_loss           | 56.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3750847.86\n",
      "total_reward: 2750847.86\n",
      "total_cost: 171180.57\n",
      "total_trades: 58138\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 20256       |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014346028 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.56        |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | 5.193883    |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 20274       |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010362175 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 1.3569227   |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 20293       |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010529753 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | 1.8328414   |\n",
      "|    std                  | 4.97        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 20311       |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014380463 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 4.6491976   |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 20329       |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009959468 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -3.7698426  |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1106         |\n",
      "|    time_elapsed         | 20348        |\n",
      "|    total_timesteps      | 2265088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073415926 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.5        |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 11050        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 0.061261576  |\n",
      "|    std                  | 4.99         |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 20367       |\n",
      "|    total_timesteps      | 2267136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008496786 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | -2.684096   |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1108        |\n",
      "|    time_elapsed         | 20385       |\n",
      "|    total_timesteps      | 2269184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015377548 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.08        |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.124731064 |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1109        |\n",
      "|    time_elapsed         | 20402       |\n",
      "|    total_timesteps      | 2271232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010568081 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | -0.50859314 |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1110        |\n",
      "|    time_elapsed         | 20420       |\n",
      "|    total_timesteps      | 2273280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013233826 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 11090       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 1.2693129   |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 20438       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014956851 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.29        |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | -0.95160526 |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1112         |\n",
      "|    time_elapsed         | 20456        |\n",
      "|    total_timesteps      | 2277376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124367215 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.7        |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 11110        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    reward               | 0.7110281    |\n",
      "|    std                  | 5.03         |\n",
      "|    value_loss           | 39           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1113        |\n",
      "|    time_elapsed         | 20474       |\n",
      "|    total_timesteps      | 2279424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012340484 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 4.3022213   |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 20492       |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01489529  |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | -0.46916756 |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3727894.55\n",
      "total_reward: 2727894.55\n",
      "total_cost: 140170.56\n",
      "total_trades: 58066\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 20509       |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014430286 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.34626803 |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1116        |\n",
      "|    time_elapsed         | 20527       |\n",
      "|    total_timesteps      | 2285568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423977 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 3.699021    |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1117         |\n",
      "|    time_elapsed         | 20545        |\n",
      "|    total_timesteps      | 2287616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065796496 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88          |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 11160        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | -0.7953118   |\n",
      "|    std                  | 5.07         |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 20562       |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011140398 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | 0.5909219   |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1119         |\n",
      "|    time_elapsed         | 20580        |\n",
      "|    total_timesteps      | 2291712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050338134 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88          |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 11180        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | 1.3344666    |\n",
      "|    std                  | 5.07         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 20598       |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008145917 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    reward               | 2.0063066   |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1121       |\n",
      "|    time_elapsed         | 20617      |\n",
      "|    total_timesteps      | 2295808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01281839 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88        |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 11200      |\n",
      "|    policy_gradient_loss | -0.006     |\n",
      "|    reward               | -3.427121  |\n",
      "|    std                  | 5.08       |\n",
      "|    value_loss           | 33.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 20634       |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010847343 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | -0.661955   |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 20652       |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009750092 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | 0.32511127  |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1124        |\n",
      "|    time_elapsed         | 20670       |\n",
      "|    total_timesteps      | 2301952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008400173 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -1.6312015  |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1125       |\n",
      "|    time_elapsed         | 20689      |\n",
      "|    total_timesteps      | 2304000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01624261 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.1      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.22       |\n",
      "|    n_updates            | 11240      |\n",
      "|    policy_gradient_loss | -0.00599   |\n",
      "|    reward               | 0.3806602  |\n",
      "|    std                  | 5.09       |\n",
      "|    value_loss           | 20.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 20707       |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007293698 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 0.8640223   |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1127        |\n",
      "|    time_elapsed         | 20725       |\n",
      "|    total_timesteps      | 2308096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011850216 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    reward               | -3.3684652  |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 20743       |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008975837 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.75        |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | 1.7112813   |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4022086.12\n",
      "total_reward: 3022086.12\n",
      "total_cost: 105579.34\n",
      "total_trades: 55864\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1129        |\n",
      "|    time_elapsed         | 20761       |\n",
      "|    total_timesteps      | 2312192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013293028 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    reward               | -2.9787607  |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1130         |\n",
      "|    time_elapsed         | 20779        |\n",
      "|    total_timesteps      | 2314240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073843636 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.4        |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 11290        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -2.4794395   |\n",
      "|    std                  | 5.13         |\n",
      "|    value_loss           | 66.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1131        |\n",
      "|    time_elapsed         | 20797       |\n",
      "|    total_timesteps      | 2316288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010941383 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | 1.7583225   |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1132       |\n",
      "|    time_elapsed         | 20815      |\n",
      "|    total_timesteps      | 2318336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01221956 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.3      |\n",
      "|    explained_variance   | 0.541      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.48       |\n",
      "|    n_updates            | 11310      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | 0.77852994 |\n",
      "|    std                  | 5.14       |\n",
      "|    value_loss           | 22.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1133         |\n",
      "|    time_elapsed         | 20833        |\n",
      "|    total_timesteps      | 2320384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066426047 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.4        |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 11320        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -0.93504924  |\n",
      "|    std                  | 5.14         |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1134        |\n",
      "|    time_elapsed         | 20851       |\n",
      "|    total_timesteps      | 2322432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010357785 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    reward               | -2.4361598  |\n",
      "|    std                  | 5.14        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 20869       |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013314922 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.4       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | -0.4073025  |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1136        |\n",
      "|    time_elapsed         | 20886       |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008602148 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 11350       |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    reward               | 0.13784342  |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1137         |\n",
      "|    time_elapsed         | 20904        |\n",
      "|    total_timesteps      | 2328576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039067604 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.5        |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 11360        |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    reward               | -2.8029017   |\n",
      "|    std                  | 5.16         |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1138        |\n",
      "|    time_elapsed         | 20922       |\n",
      "|    total_timesteps      | 2330624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011772016 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    reward               | 2.109872    |\n",
      "|    std                  | 5.17        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1139         |\n",
      "|    time_elapsed         | 20940        |\n",
      "|    total_timesteps      | 2332672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076835547 |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.5        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 11380        |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    reward               | -0.7623139   |\n",
      "|    std                  | 5.16         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 20957       |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006914965 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.5       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | -3.688157   |\n",
      "|    std                  | 5.17        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1141         |\n",
      "|    time_elapsed         | 20976        |\n",
      "|    total_timesteps      | 2336768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043377536 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.6        |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 11400        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 1.6321931    |\n",
      "|    std                  | 5.18         |\n",
      "|    value_loss           | 52.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 20994       |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016302258 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | -3.1285193  |\n",
      "|    std                  | 5.18        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3653487.46\n",
      "total_reward: 2653487.46\n",
      "total_cost: 85193.50\n",
      "total_trades: 54650\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1143        |\n",
      "|    time_elapsed         | 21012       |\n",
      "|    total_timesteps      | 2340864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006170987 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.58        |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | 0.04745867  |\n",
      "|    std                  | 5.18        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1144       |\n",
      "|    time_elapsed         | 21030      |\n",
      "|    total_timesteps      | 2342912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00352573 |\n",
      "|    clip_fraction        | 0.00659    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.6      |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.5       |\n",
      "|    n_updates            | 11430      |\n",
      "|    policy_gradient_loss | -0.00439   |\n",
      "|    reward               | -2.9789507 |\n",
      "|    std                  | 5.18       |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 21047       |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009684302 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | -0.84227943 |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1146         |\n",
      "|    time_elapsed         | 21065        |\n",
      "|    total_timesteps      | 2347008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099628735 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.7        |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 11450        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | 0.20745496   |\n",
      "|    std                  | 5.2          |\n",
      "|    value_loss           | 35.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1147       |\n",
      "|    time_elapsed         | 21082      |\n",
      "|    total_timesteps      | 2349056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00555118 |\n",
      "|    clip_fraction        | 0.0303     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.7      |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.8       |\n",
      "|    n_updates            | 11460      |\n",
      "|    policy_gradient_loss | -0.00233   |\n",
      "|    reward               | 16.431679  |\n",
      "|    std                  | 5.2        |\n",
      "|    value_loss           | 43.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1148       |\n",
      "|    time_elapsed         | 21100      |\n",
      "|    total_timesteps      | 2351104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00344188 |\n",
      "|    clip_fraction        | 0.00508    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.7      |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.1       |\n",
      "|    n_updates            | 11470      |\n",
      "|    policy_gradient_loss | -0.00474   |\n",
      "|    reward               | 1.1432538  |\n",
      "|    std                  | 5.2        |\n",
      "|    value_loss           | 47.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 21118       |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010269792 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 3.6912007   |\n",
      "|    std                  | 5.21        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1150       |\n",
      "|    time_elapsed         | 21136      |\n",
      "|    total_timesteps      | 2355200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00634423 |\n",
      "|    clip_fraction        | 0.0453     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.8      |\n",
      "|    explained_variance   | 0.479      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.2       |\n",
      "|    n_updates            | 11490      |\n",
      "|    policy_gradient_loss | -0.00393   |\n",
      "|    reward               | 0.488436   |\n",
      "|    std                  | 5.21       |\n",
      "|    value_loss           | 41.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1151        |\n",
      "|    time_elapsed         | 21153       |\n",
      "|    total_timesteps      | 2357248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008966073 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | -1.9893909  |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 21171       |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014803936 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 6.4263654   |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1153         |\n",
      "|    time_elapsed         | 21189        |\n",
      "|    total_timesteps      | 2361344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076007945 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.9        |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 11520        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | -5.244737    |\n",
      "|    std                  | 5.22         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 21206       |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013464276 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 11530       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 0.23963289  |\n",
      "|    std                  | 5.23        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1155       |\n",
      "|    time_elapsed         | 21224      |\n",
      "|    total_timesteps      | 2365440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01430146 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.9      |\n",
      "|    explained_variance   | 0.162      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 11540      |\n",
      "|    policy_gradient_loss | -0.00254   |\n",
      "|    reward               | -1.1783623 |\n",
      "|    std                  | 5.23       |\n",
      "|    value_loss           | 33.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 21242       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011476342 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    reward               | -0.13189045 |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3380324.42\n",
      "total_reward: 2380324.42\n",
      "total_cost: 69343.32\n",
      "total_trades: 53550\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1157        |\n",
      "|    time_elapsed         | 21260       |\n",
      "|    total_timesteps      | 2369536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006107266 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | 1.6415795   |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1158        |\n",
      "|    time_elapsed         | 21278       |\n",
      "|    total_timesteps      | 2371584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012284206 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | 3.5053508   |\n",
      "|    std                  | 5.26        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 21296       |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013341574 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -1.2363733  |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 21314       |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009116132 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    reward               | 1.0738367   |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 21332       |\n",
      "|    total_timesteps      | 2377728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006373237 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 11600       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    reward               | 0.05031822  |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 21350       |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009385927 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 3.794388    |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1163         |\n",
      "|    time_elapsed         | 21368        |\n",
      "|    total_timesteps      | 2381824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075610816 |\n",
      "|    clip_fraction        | 0.0602       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.3        |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 11620        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | 0.23834285   |\n",
      "|    std                  | 5.3          |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1164       |\n",
      "|    time_elapsed         | 21386      |\n",
      "|    total_timesteps      | 2383872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00570134 |\n",
      "|    clip_fraction        | 0.0401     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.3      |\n",
      "|    explained_variance   | 0.474      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 11630      |\n",
      "|    policy_gradient_loss | -0.00531   |\n",
      "|    reward               | -0.7585684 |\n",
      "|    std                  | 5.31       |\n",
      "|    value_loss           | 32.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 21404       |\n",
      "|    total_timesteps      | 2385920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007171134 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | 1.5716894   |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 21423       |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013863213 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.04        |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | -1.635694   |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1167        |\n",
      "|    time_elapsed         | 21441       |\n",
      "|    total_timesteps      | 2390016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014355186 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 0.20858373  |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 21459       |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005179182 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    reward               | 2.7045176   |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 21477       |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009171559 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | 1.9997993   |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1170        |\n",
      "|    time_elapsed         | 21495       |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010827914 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | 0.9349552   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 21512       |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011205326 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | -5.4501452  |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4013654.26\n",
      "total_reward: 3013654.26\n",
      "total_cost: 80311.40\n",
      "total_trades: 54250\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1172        |\n",
      "|    time_elapsed         | 21531       |\n",
      "|    total_timesteps      | 2400256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008350095 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | 1.3398982   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 21548       |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016535638 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.55        |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 1.4887695   |\n",
      "|    std                  | 5.35        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 21567       |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010073679 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | 0.16950841  |\n",
      "|    std                  | 5.35        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 21586       |\n",
      "|    total_timesteps      | 2406400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009151701 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 11740       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -7.2462893  |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 44.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1176        |\n",
      "|    time_elapsed         | 21604       |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011477076 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.13        |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 0.40409842  |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1177        |\n",
      "|    time_elapsed         | 21623       |\n",
      "|    total_timesteps      | 2410496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011495996 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 11760       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | 0.10784222  |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 21640        |\n",
      "|    total_timesteps      | 2412544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054525062 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.7        |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 11770        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -5.3968487   |\n",
      "|    std                  | 5.38         |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 21658       |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012655051 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | 2.9288125   |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 21676       |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009567134 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.4         |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    reward               | 1.5917101   |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 21694       |\n",
      "|    total_timesteps      | 2418688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008534609 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | 0.26019236  |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1182        |\n",
      "|    time_elapsed         | 21712       |\n",
      "|    total_timesteps      | 2420736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010182293 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 11810       |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | -0.87167895 |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 21730       |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009799993 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.12        |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | -1.3480989  |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1184        |\n",
      "|    time_elapsed         | 21748       |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013298493 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 11830       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -0.26476038 |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 21765       |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008623869 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | -0.33248606 |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3457979.03\n",
      "total_reward: 2457979.03\n",
      "total_cost: 95286.20\n",
      "total_trades: 54076\n",
      "Sharpe: 0.683\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1186        |\n",
      "|    time_elapsed         | 21783       |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007689056 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -3.91e-05   |\n",
      "|    reward               | -2.6533883  |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1187        |\n",
      "|    time_elapsed         | 21801       |\n",
      "|    total_timesteps      | 2430976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009300971 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.22        |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -0.82972676 |\n",
      "|    std                  | 5.43        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 21819       |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005102879 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | 0.000315    |\n",
      "|    reward               | -1.0477611  |\n",
      "|    std                  | 5.43        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1189       |\n",
      "|    time_elapsed         | 21837      |\n",
      "|    total_timesteps      | 2435072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00953336 |\n",
      "|    clip_fraction        | 0.0625     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90        |\n",
      "|    explained_variance   | 0.289      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.2       |\n",
      "|    n_updates            | 11880      |\n",
      "|    policy_gradient_loss | -0.00302   |\n",
      "|    reward               | 4.038245   |\n",
      "|    std                  | 5.43       |\n",
      "|    value_loss           | 57.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 21855       |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014306484 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.8         |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | 1.266248    |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1191         |\n",
      "|    time_elapsed         | 21873        |\n",
      "|    total_timesteps      | 2439168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031569772 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.1        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 11900        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -2.085757    |\n",
      "|    std                  | 5.44         |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1192        |\n",
      "|    time_elapsed         | 21891       |\n",
      "|    total_timesteps      | 2441216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005877046 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -0.1661242  |\n",
      "|    std                  | 5.45        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1193        |\n",
      "|    time_elapsed         | 21908       |\n",
      "|    total_timesteps      | 2443264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013753347 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 11920       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 0.96038866  |\n",
      "|    std                  | 5.47        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1194        |\n",
      "|    time_elapsed         | 21926       |\n",
      "|    total_timesteps      | 2445312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013322504 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 11930       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | -3.6028929  |\n",
      "|    std                  | 5.48        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1195         |\n",
      "|    time_elapsed         | 21944        |\n",
      "|    total_timesteps      | 2447360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035852115 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.3        |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 11940        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 1.5537485    |\n",
      "|    std                  | 5.49         |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1196         |\n",
      "|    time_elapsed         | 21962        |\n",
      "|    total_timesteps      | 2449408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008796258  |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.3        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 11950        |\n",
      "|    policy_gradient_loss | -0.00897     |\n",
      "|    reward               | -0.023500552 |\n",
      "|    std                  | 5.49         |\n",
      "|    value_loss           | 38.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 21980       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013061524 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    reward               | 0.13546063  |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 21998       |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011461262 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | -1.3884401  |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1199         |\n",
      "|    time_elapsed         | 22016        |\n",
      "|    total_timesteps      | 2455552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043694805 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.3        |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 11980        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -16.88639    |\n",
      "|    std                  | 5.49         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3423039.90\n",
      "total_reward: 2423039.90\n",
      "total_cost: 144912.98\n",
      "total_trades: 57372\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1200       |\n",
      "|    time_elapsed         | 22034      |\n",
      "|    total_timesteps      | 2457600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0161689  |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.3      |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.23       |\n",
      "|    n_updates            | 11990      |\n",
      "|    policy_gradient_loss | -0.00647   |\n",
      "|    reward               | 0.47224745 |\n",
      "|    std                  | 5.51       |\n",
      "|    value_loss           | 20.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 22051       |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006898019 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    reward               | 1.5006123   |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1202        |\n",
      "|    time_elapsed         | 22069       |\n",
      "|    total_timesteps      | 2461696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013297741 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -0.47931418 |\n",
      "|    std                  | 5.52        |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 22087       |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011188519 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | 4.908449    |\n",
      "|    std                  | 5.52        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1204        |\n",
      "|    time_elapsed         | 22105       |\n",
      "|    total_timesteps      | 2465792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009905186 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.92        |\n",
      "|    n_updates            | 12030       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 0.9403594   |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 22123       |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006389304 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 0.18600254  |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 22141       |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008532329 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.9        |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -0.54523295 |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1207        |\n",
      "|    time_elapsed         | 22160       |\n",
      "|    total_timesteps      | 2471936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010038232 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.21        |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    reward               | 3.7606049   |\n",
      "|    std                  | 5.55        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 22178       |\n",
      "|    total_timesteps      | 2473984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008160659 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | -0.6108233  |\n",
      "|    std                  | 5.56        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 22196       |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010477948 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | -5.1354256  |\n",
      "|    std                  | 5.56        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 22214       |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010503785 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | -5.242717   |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 22232       |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013022235 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 0.502184    |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1212        |\n",
      "|    time_elapsed         | 22250       |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007666041 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | 1.4641746   |\n",
      "|    std                  | 5.59        |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 22268       |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008760779 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | -1.7703485  |\n",
      "|    std                  | 5.59        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3420380.90\n",
      "total_reward: 2420380.90\n",
      "total_cost: 93659.82\n",
      "total_trades: 54435\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 22286       |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016271912 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.51        |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 2.4839368   |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1215         |\n",
      "|    time_elapsed         | 22304        |\n",
      "|    total_timesteps      | 2488320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062460825 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.9        |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 12140        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -0.24659432  |\n",
      "|    std                  | 5.61         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 22321       |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008698141 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | 0.9182505   |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 22339       |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010280704 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.87        |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | 0.9376038   |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 22357       |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005121922 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | 3.2605572   |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 22374       |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010730348 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | -0.67716753 |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 22392       |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011446917 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | -0.23760398 |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 22410       |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009671155 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    reward               | -0.23299637 |\n",
      "|    std                  | 5.64        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 22428       |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006694661 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | -0.21517743 |\n",
      "|    std                  | 5.64        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 22446       |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00853442  |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 12220       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -0.28367406 |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1224        |\n",
      "|    time_elapsed         | 22463       |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013140789 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -1.7995639  |\n",
      "|    std                  | 5.67        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1225         |\n",
      "|    time_elapsed         | 22481        |\n",
      "|    total_timesteps      | 2508800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011738072  |\n",
      "|    clip_fraction        | 0.0852       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.2        |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 12240        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | -0.067460105 |\n",
      "|    std                  | 5.67         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1226       |\n",
      "|    time_elapsed         | 22499      |\n",
      "|    total_timesteps      | 2510848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00760289 |\n",
      "|    clip_fraction        | 0.0383     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.2      |\n",
      "|    explained_variance   | 0.524      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 12250      |\n",
      "|    policy_gradient_loss | -0.00582   |\n",
      "|    reward               | -15.755463 |\n",
      "|    std                  | 5.68       |\n",
      "|    value_loss           | 48.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1227        |\n",
      "|    time_elapsed         | 22517       |\n",
      "|    total_timesteps      | 2512896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009438881 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 12260       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 1.272457    |\n",
      "|    std                  | 5.68        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3621468.52\n",
      "total_reward: 2621468.52\n",
      "total_cost: 133044.01\n",
      "total_trades: 57058\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 22535       |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011186078 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 12270       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 1.7090799   |\n",
      "|    std                  | 5.69        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1229        |\n",
      "|    time_elapsed         | 22553       |\n",
      "|    total_timesteps      | 2516992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010901097 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 12280       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -0.28258517 |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1230        |\n",
      "|    time_elapsed         | 22570       |\n",
      "|    total_timesteps      | 2519040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008559468 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    reward               | 0.35088748  |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1231        |\n",
      "|    time_elapsed         | 22588       |\n",
      "|    total_timesteps      | 2521088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013969762 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.33        |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 3.9152424   |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 22606       |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006086437 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    reward               | 0.22371563  |\n",
      "|    std                  | 5.72        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1233         |\n",
      "|    time_elapsed         | 22624        |\n",
      "|    total_timesteps      | 2525184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074833203 |\n",
      "|    clip_fraction        | 0.0374       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.5        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 12320        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    reward               | 4.2388525    |\n",
      "|    std                  | 5.72         |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1234        |\n",
      "|    time_elapsed         | 22643       |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007944852 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 12330       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | 1.1700265   |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1235         |\n",
      "|    time_elapsed         | 22661        |\n",
      "|    total_timesteps      | 2529280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011080992  |\n",
      "|    clip_fraction        | 0.0705       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.6        |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.47         |\n",
      "|    n_updates            | 12340        |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | -0.115236685 |\n",
      "|    std                  | 5.75         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1236         |\n",
      "|    time_elapsed         | 22679        |\n",
      "|    total_timesteps      | 2531328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060636923 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.6        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 12350        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | -1.7709097   |\n",
      "|    std                  | 5.75         |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1237       |\n",
      "|    time_elapsed         | 22698      |\n",
      "|    total_timesteps      | 2533376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00480834 |\n",
      "|    clip_fraction        | 0.0104     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.6      |\n",
      "|    explained_variance   | 0.53       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.2       |\n",
      "|    n_updates            | 12360      |\n",
      "|    policy_gradient_loss | -0.00451   |\n",
      "|    reward               | 1.1527668  |\n",
      "|    std                  | 5.75       |\n",
      "|    value_loss           | 48.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 22716       |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009341804 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 12370       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | -0.339441   |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 22734       |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007816964 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | 0.21405585  |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1240        |\n",
      "|    time_elapsed         | 22751       |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008918928 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | -3.9862783  |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1241         |\n",
      "|    time_elapsed         | 22769        |\n",
      "|    total_timesteps      | 2541568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094148265 |\n",
      "|    clip_fraction        | 0.0751       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.7        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 12400        |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    reward               | 1.7988255    |\n",
      "|    std                  | 5.77         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3483953.13\n",
      "total_reward: 2483953.13\n",
      "total_cost: 99435.68\n",
      "total_trades: 54991\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1242         |\n",
      "|    time_elapsed         | 22787        |\n",
      "|    total_timesteps      | 2543616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066022556 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.7        |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 12410        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | 4.241649     |\n",
      "|    std                  | 5.77         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1243        |\n",
      "|    time_elapsed         | 22805       |\n",
      "|    total_timesteps      | 2545664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014495604 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    reward               | -23.93171   |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 22823       |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008679322 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    reward               | 0.018378492 |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 22841       |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009981876 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    reward               | 0.9953719   |\n",
      "|    std                  | 5.81        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1246         |\n",
      "|    time_elapsed         | 22860        |\n",
      "|    total_timesteps      | 2551808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094206035 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92          |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 12450        |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    reward               | -1.1268414   |\n",
      "|    std                  | 5.82         |\n",
      "|    value_loss           | 50.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 22879       |\n",
      "|    total_timesteps      | 2553856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008410695 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 12460       |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | -2.582964   |\n",
      "|    std                  | 5.82        |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 22897       |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009130029 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | 2.3362472   |\n",
      "|    std                  | 5.83        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1249         |\n",
      "|    time_elapsed         | 22916        |\n",
      "|    total_timesteps      | 2557952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069785602 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92          |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 12480        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | -0.29979536  |\n",
      "|    std                  | 5.84         |\n",
      "|    value_loss           | 39.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1250        |\n",
      "|    time_elapsed         | 22934       |\n",
      "|    total_timesteps      | 2560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010826466 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 12490       |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    reward               | 3.7511723   |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1251         |\n",
      "|    time_elapsed         | 22952        |\n",
      "|    total_timesteps      | 2562048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119300755 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.1        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 12500        |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | 5.4368334    |\n",
      "|    std                  | 5.86         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1252       |\n",
      "|    time_elapsed         | 22971      |\n",
      "|    total_timesteps      | 2564096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00912587 |\n",
      "|    clip_fraction        | 0.0343     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.2      |\n",
      "|    explained_variance   | 0.537      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.62       |\n",
      "|    n_updates            | 12510      |\n",
      "|    policy_gradient_loss | -0.00684   |\n",
      "|    reward               | 2.8475456  |\n",
      "|    std                  | 5.86       |\n",
      "|    value_loss           | 27.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1253         |\n",
      "|    time_elapsed         | 22990        |\n",
      "|    total_timesteps      | 2566144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055033374 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.2        |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 12520        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | -0.86772645  |\n",
      "|    std                  | 5.87         |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1254         |\n",
      "|    time_elapsed         | 23009        |\n",
      "|    total_timesteps      | 2568192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050574206 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.2        |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 12530        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    reward               | -0.10733672  |\n",
      "|    std                  | 5.87         |\n",
      "|    value_loss           | 53.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 23028       |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008760653 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.36        |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | 0.08172566  |\n",
      "|    std                  | 5.88        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4132313.93\n",
      "total_reward: 3132313.93\n",
      "total_cost: 88050.86\n",
      "total_trades: 54070\n",
      "Sharpe: 0.780\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1256         |\n",
      "|    time_elapsed         | 23047        |\n",
      "|    total_timesteps      | 2572288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054950295 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.3        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 12550        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    reward               | 2.49394      |\n",
      "|    std                  | 5.88         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1257         |\n",
      "|    time_elapsed         | 23066        |\n",
      "|    total_timesteps      | 2574336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050531467 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.3        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 12560        |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    reward               | -0.5526072   |\n",
      "|    std                  | 5.89         |\n",
      "|    value_loss           | 56.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1258         |\n",
      "|    time_elapsed         | 23085        |\n",
      "|    total_timesteps      | 2576384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060097855 |\n",
      "|    clip_fraction        | 0.0579       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.3        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 12570        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | 0.27203557   |\n",
      "|    std                  | 5.89         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 23103       |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010230077 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | -0.27801389 |\n",
      "|    std                  | 5.89        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1260        |\n",
      "|    time_elapsed         | 23121       |\n",
      "|    total_timesteps      | 2580480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010258839 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 12590       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | 25.472898   |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 23139       |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003876668 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | -1.5875437  |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 23158       |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008290831 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | 3.5413556   |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1263         |\n",
      "|    time_elapsed         | 23177        |\n",
      "|    total_timesteps      | 2586624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121555105 |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.4        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 12620        |\n",
      "|    policy_gradient_loss | -0.00801     |\n",
      "|    reward               | 0.18625179   |\n",
      "|    std                  | 5.91         |\n",
      "|    value_loss           | 47           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1264         |\n",
      "|    time_elapsed         | 23195        |\n",
      "|    total_timesteps      | 2588672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076946896 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.4        |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 12630        |\n",
      "|    policy_gradient_loss | -0.00941     |\n",
      "|    reward               | -7.3046827   |\n",
      "|    std                  | 5.91         |\n",
      "|    value_loss           | 60           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1265        |\n",
      "|    time_elapsed         | 23214       |\n",
      "|    total_timesteps      | 2590720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010651307 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | -0.40627202 |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 23233       |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014462759 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 12650       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | 1.4729418   |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 23251       |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009635579 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | -3.6159241  |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1268         |\n",
      "|    time_elapsed         | 23270        |\n",
      "|    total_timesteps      | 2596864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072533335 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.6        |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 12670        |\n",
      "|    policy_gradient_loss | -0.00753     |\n",
      "|    reward               | -1.081973    |\n",
      "|    std                  | 5.94         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1269        |\n",
      "|    time_elapsed         | 23287       |\n",
      "|    total_timesteps      | 2598912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013187054 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | -0.7556323  |\n",
      "|    std                  | 5.94        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3696645.01\n",
      "total_reward: 2696645.01\n",
      "total_cost: 62386.69\n",
      "total_trades: 51660\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1270        |\n",
      "|    time_elapsed         | 23305       |\n",
      "|    total_timesteps      | 2600960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008169981 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 12690       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 2.4578376   |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1271         |\n",
      "|    time_elapsed         | 23323        |\n",
      "|    total_timesteps      | 2603008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061572385 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.7        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 12700        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | 1.3254898    |\n",
      "|    std                  | 5.96         |\n",
      "|    value_loss           | 55.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 23342       |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012018784 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.58        |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    reward               | 0.050500166 |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 23360       |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008376965 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    reward               | 0.6225109   |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1274         |\n",
      "|    time_elapsed         | 23378        |\n",
      "|    total_timesteps      | 2609152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056589367 |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.7        |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.6         |\n",
      "|    n_updates            | 12730        |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    reward               | 0.89371526   |\n",
      "|    std                  | 5.97         |\n",
      "|    value_loss           | 57.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1275         |\n",
      "|    time_elapsed         | 23396        |\n",
      "|    total_timesteps      | 2611200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046350723 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.7        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 12740        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 1.7985222    |\n",
      "|    std                  | 5.97         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 23414       |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005017261 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | 1.9591143   |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1277       |\n",
      "|    time_elapsed         | 23431      |\n",
      "|    total_timesteps      | 2615296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00459035 |\n",
      "|    clip_fraction        | 0.014      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.7      |\n",
      "|    explained_variance   | 0.538      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.4       |\n",
      "|    n_updates            | 12760      |\n",
      "|    policy_gradient_loss | -0.00388   |\n",
      "|    reward               | 1.1576678  |\n",
      "|    std                  | 5.97       |\n",
      "|    value_loss           | 52.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1278         |\n",
      "|    time_elapsed         | 23449        |\n",
      "|    total_timesteps      | 2617344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068270527 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.7        |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 12770        |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    reward               | -0.3846544   |\n",
      "|    std                  | 5.97         |\n",
      "|    value_loss           | 54.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 23467       |\n",
      "|    total_timesteps      | 2619392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010437096 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 1.1391476   |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1280        |\n",
      "|    time_elapsed         | 23484       |\n",
      "|    total_timesteps      | 2621440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014588998 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 12790       |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | -0.07433533 |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1281        |\n",
      "|    time_elapsed         | 23502       |\n",
      "|    total_timesteps      | 2623488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005175334 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 12800       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | -1.4920498  |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1282        |\n",
      "|    time_elapsed         | 23520       |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010872755 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 0.30963254  |\n",
      "|    std                  | 5.98        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1283        |\n",
      "|    time_elapsed         | 23538       |\n",
      "|    total_timesteps      | 2627584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008353688 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 12820       |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -1.4970095  |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1284         |\n",
      "|    time_elapsed         | 23556        |\n",
      "|    total_timesteps      | 2629632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059888214 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.8        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 12830        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -4.3210273   |\n",
      "|    std                  | 5.99         |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3935700.50\n",
      "total_reward: 2935700.50\n",
      "total_cost: 52934.62\n",
      "total_trades: 50662\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1285         |\n",
      "|    time_elapsed         | 23575        |\n",
      "|    total_timesteps      | 2631680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029979711 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.8        |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.1         |\n",
      "|    n_updates            | 12840        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 2.3634636    |\n",
      "|    std                  | 5.99         |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 111       |\n",
      "|    iterations           | 1286      |\n",
      "|    time_elapsed         | 23593     |\n",
      "|    total_timesteps      | 2633728   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0084204 |\n",
      "|    clip_fraction        | 0.085     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -92.8     |\n",
      "|    explained_variance   | 0.624     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 8.54      |\n",
      "|    n_updates            | 12850     |\n",
      "|    policy_gradient_loss | -0.00246  |\n",
      "|    reward               | 1.5512177 |\n",
      "|    std                  | 6         |\n",
      "|    value_loss           | 23.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1287        |\n",
      "|    time_elapsed         | 23611       |\n",
      "|    total_timesteps      | 2635776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007807863 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -0.42735147 |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1288         |\n",
      "|    time_elapsed         | 23628        |\n",
      "|    total_timesteps      | 2637824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035131061 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.9        |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 12870        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | 5.365149     |\n",
      "|    std                  | 6.01         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 23646       |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012969331 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 2.8031924   |\n",
      "|    std                  | 6.03        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1290         |\n",
      "|    time_elapsed         | 23664        |\n",
      "|    total_timesteps      | 2641920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073247096 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93          |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 12890        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | -0.85220873  |\n",
      "|    std                  | 6.03         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1291         |\n",
      "|    time_elapsed         | 23682        |\n",
      "|    total_timesteps      | 2643968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029374282 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93          |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.4         |\n",
      "|    n_updates            | 12900        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 5.837388     |\n",
      "|    std                  | 6.03         |\n",
      "|    value_loss           | 50.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1292         |\n",
      "|    time_elapsed         | 23700        |\n",
      "|    total_timesteps      | 2646016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032971804 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93          |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 12910        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 1.9764447    |\n",
      "|    std                  | 6.03         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 23718       |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013473449 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    reward               | -1.6560719  |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1294        |\n",
      "|    time_elapsed         | 23735       |\n",
      "|    total_timesteps      | 2650112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007680273 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 0.32317755  |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1295         |\n",
      "|    time_elapsed         | 23754        |\n",
      "|    total_timesteps      | 2652160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065621953 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.1        |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 12940        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | -1.185897    |\n",
      "|    std                  | 6.04         |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 23772       |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011620408 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | 0.70785546  |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 23790       |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005255009 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 2.3170152   |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 23807       |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006578613 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 12970       |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 0.011598083 |\n",
      "|    std                  | 6.06        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3739249.51\n",
      "total_reward: 2739249.51\n",
      "total_cost: 58380.18\n",
      "total_trades: 51437\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1299        |\n",
      "|    time_elapsed         | 23825       |\n",
      "|    total_timesteps      | 2660352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001229529 |\n",
      "|    clip_fraction        | 0.00264     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 12980       |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    reward               | 0.93487734  |\n",
      "|    std                  | 6.06        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1300         |\n",
      "|    time_elapsed         | 23843        |\n",
      "|    total_timesteps      | 2662400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009208838  |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.2        |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 12990        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | -0.086425625 |\n",
      "|    std                  | 6.07         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 23861       |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008724698 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 13000       |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    reward               | -8.816198   |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1302        |\n",
      "|    time_elapsed         | 23879       |\n",
      "|    total_timesteps      | 2666496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009074097 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | 1.205921    |\n",
      "|    std                  | 6.08        |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 23897       |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011563325 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.7         |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | -1.8204539  |\n",
      "|    std                  | 6.09        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1304         |\n",
      "|    time_elapsed         | 23915        |\n",
      "|    total_timesteps      | 2670592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056076543 |\n",
      "|    clip_fraction        | 0.0533       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.3        |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.51         |\n",
      "|    n_updates            | 13030        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | -1.2956578   |\n",
      "|    std                  | 6.1          |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1305         |\n",
      "|    time_elapsed         | 23932        |\n",
      "|    total_timesteps      | 2672640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042357263 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.3        |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 13040        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | -3.764406    |\n",
      "|    std                  | 6.1          |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 23950       |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099241 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 13050       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -2.9627798  |\n",
      "|    std                  | 6.09        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 23969       |\n",
      "|    total_timesteps      | 2676736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008118121 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | 1.7449224   |\n",
      "|    std                  | 6.1         |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1308       |\n",
      "|    time_elapsed         | 23988      |\n",
      "|    total_timesteps      | 2678784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00388094 |\n",
      "|    clip_fraction        | 0.0102     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.3      |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16         |\n",
      "|    n_updates            | 13070      |\n",
      "|    policy_gradient_loss | -0.00345   |\n",
      "|    reward               | -0.9737224 |\n",
      "|    std                  | 6.1        |\n",
      "|    value_loss           | 44.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 24006       |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006109963 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -0.1938777  |\n",
      "|    std                  | 6.1         |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 24024       |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009629511 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.75590473  |\n",
      "|    std                  | 6.1         |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1311         |\n",
      "|    time_elapsed         | 24042        |\n",
      "|    total_timesteps      | 2684928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018998368 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 13100        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -0.63715905  |\n",
      "|    std                  | 6.11         |\n",
      "|    value_loss           | 57.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1312         |\n",
      "|    time_elapsed         | 24061        |\n",
      "|    total_timesteps      | 2686976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017278667 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 13110        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 1.9903109    |\n",
      "|    std                  | 6.11         |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3646435.06\n",
      "total_reward: 2646435.06\n",
      "total_cost: 62692.62\n",
      "total_trades: 52234\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1313         |\n",
      "|    time_elapsed         | 24079        |\n",
      "|    total_timesteps      | 2689024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069871666 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.7          |\n",
      "|    n_updates            | 13120        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 0.20315392   |\n",
      "|    std                  | 6.12         |\n",
      "|    value_loss           | 19.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1314         |\n",
      "|    time_elapsed         | 24097        |\n",
      "|    total_timesteps      | 2691072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0144567955 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.4        |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 13130        |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    reward               | 1.0028299    |\n",
      "|    std                  | 6.12         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 24115        |\n",
      "|    total_timesteps      | 2693120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013440899 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 13140        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | -1.7777741   |\n",
      "|    std                  | 6.13         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1316         |\n",
      "|    time_elapsed         | 24133        |\n",
      "|    total_timesteps      | 2695168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019562747 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 13150        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -8.876949    |\n",
      "|    std                  | 6.13         |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 24151       |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010226728 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    reward               | 0.2462132   |\n",
      "|    std                  | 6.13        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 24169       |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008456044 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | -0.9097202  |\n",
      "|    std                  | 6.14        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1319         |\n",
      "|    time_elapsed         | 24188        |\n",
      "|    total_timesteps      | 2701312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012002116 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 13180        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | -2.6094275   |\n",
      "|    std                  | 6.14         |\n",
      "|    value_loss           | 53.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1320         |\n",
      "|    time_elapsed         | 24206        |\n",
      "|    total_timesteps      | 2703360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069644637 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.66         |\n",
      "|    n_updates            | 13190        |\n",
      "|    policy_gradient_loss | -0.00729     |\n",
      "|    reward               | -1.3309503   |\n",
      "|    std                  | 6.14         |\n",
      "|    value_loss           | 20.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1321         |\n",
      "|    time_elapsed         | 24223        |\n",
      "|    total_timesteps      | 2705408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113482475 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.6        |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 13200        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 0.8523504    |\n",
      "|    std                  | 6.15         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1322         |\n",
      "|    time_elapsed         | 24242        |\n",
      "|    total_timesteps      | 2707456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022140471 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.6        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.9         |\n",
      "|    n_updates            | 13210        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | -0.45626497  |\n",
      "|    std                  | 6.16         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1323        |\n",
      "|    time_elapsed         | 24260       |\n",
      "|    total_timesteps      | 2709504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00523145  |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | -0.48876265 |\n",
      "|    std                  | 6.17        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 24278       |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005863079 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | -0.4681737  |\n",
      "|    std                  | 6.17        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1325         |\n",
      "|    time_elapsed         | 24296        |\n",
      "|    total_timesteps      | 2713600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059134243 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.7        |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 13240        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -0.030626277 |\n",
      "|    std                  | 6.17         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1326         |\n",
      "|    time_elapsed         | 24314        |\n",
      "|    total_timesteps      | 2715648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029248218 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.7        |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 13250        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | 1.5322795    |\n",
      "|    std                  | 6.18         |\n",
      "|    value_loss           | 49.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3788573.48\n",
      "total_reward: 2788573.48\n",
      "total_cost: 59582.48\n",
      "total_trades: 52166\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 24333       |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009608468 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | -1.9514685  |\n",
      "|    std                  | 6.19        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 24351       |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009413278 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    reward               | 1.3658053   |\n",
      "|    std                  | 6.19        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1329         |\n",
      "|    time_elapsed         | 24369        |\n",
      "|    total_timesteps      | 2721792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012439056 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.8        |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 13280        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 3.4308105    |\n",
      "|    std                  | 6.19         |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1330         |\n",
      "|    time_elapsed         | 24387        |\n",
      "|    total_timesteps      | 2723840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069865817 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.8        |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 13290        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | -1.4038291   |\n",
      "|    std                  | 6.2          |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 24405       |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010014799 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | 1.0241694   |\n",
      "|    std                  | 6.21        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1332         |\n",
      "|    time_elapsed         | 24423        |\n",
      "|    total_timesteps      | 2727936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042570513 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 13310        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 1.4376454    |\n",
      "|    std                  | 6.21         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1333         |\n",
      "|    time_elapsed         | 24442        |\n",
      "|    total_timesteps      | 2729984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066473326 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 13320        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 2.4954593    |\n",
      "|    std                  | 6.21         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 24460       |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009091288 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.52        |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | 1.2756823   |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1335        |\n",
      "|    time_elapsed         | 24477       |\n",
      "|    total_timesteps      | 2734080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009886169 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 0.2749204   |\n",
      "|    std                  | 6.23        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1336         |\n",
      "|    time_elapsed         | 24495        |\n",
      "|    total_timesteps      | 2736128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032172399 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94          |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 13350        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -0.5583813   |\n",
      "|    std                  | 6.23         |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 24513       |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008252187 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.69        |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    reward               | 0.021534361 |\n",
      "|    std                  | 6.24        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1338        |\n",
      "|    time_elapsed         | 24531       |\n",
      "|    total_timesteps      | 2740224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009762333 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 13370       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | -1.0153308  |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1339        |\n",
      "|    time_elapsed         | 24549       |\n",
      "|    total_timesteps      | 2742272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005460503 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | 0.21244603  |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1340         |\n",
      "|    time_elapsed         | 24567        |\n",
      "|    total_timesteps      | 2744320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027830345 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 13390        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 1.7551788    |\n",
      "|    std                  | 6.26         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3569304.10\n",
      "total_reward: 2569304.10\n",
      "total_cost: 67711.99\n",
      "total_trades: 51909\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1341         |\n",
      "|    time_elapsed         | 24585        |\n",
      "|    total_timesteps      | 2746368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102923075 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.06         |\n",
      "|    n_updates            | 13400        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | 0.8351158    |\n",
      "|    std                  | 6.26         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1342         |\n",
      "|    time_elapsed         | 24603        |\n",
      "|    total_timesteps      | 2748416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035601286 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 13410        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | 0.16816022   |\n",
      "|    std                  | 6.26         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1343         |\n",
      "|    time_elapsed         | 24620        |\n",
      "|    total_timesteps      | 2750464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027859774 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 13420        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | -1.4802978   |\n",
      "|    std                  | 6.26         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 24639       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011070657 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.46        |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.09065032  |\n",
      "|    std                  | 6.26        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1345         |\n",
      "|    time_elapsed         | 24657        |\n",
      "|    total_timesteps      | 2754560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101349875 |\n",
      "|    clip_fraction        | 0.0948       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | -0.00803     |\n",
      "|    reward               | 0.7619668    |\n",
      "|    std                  | 6.27         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1346         |\n",
      "|    time_elapsed         | 24691        |\n",
      "|    total_timesteps      | 2756608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071572983 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 13450        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | -3.6324234   |\n",
      "|    std                  | 6.27         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1347         |\n",
      "|    time_elapsed         | 24709        |\n",
      "|    total_timesteps      | 2758656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067907926 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.1        |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.44         |\n",
      "|    n_updates            | 13460        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 0.46923137   |\n",
      "|    std                  | 6.27         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1348         |\n",
      "|    time_elapsed         | 24726        |\n",
      "|    total_timesteps      | 2760704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112285055 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 13470        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -0.44391575  |\n",
      "|    std                  | 6.28         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1349        |\n",
      "|    time_elapsed         | 24744       |\n",
      "|    total_timesteps      | 2762752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008039815 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | -6.1254983  |\n",
      "|    std                  | 6.29        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1350         |\n",
      "|    time_elapsed         | 24762        |\n",
      "|    total_timesteps      | 2764800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032783651 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 13490        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -1.080049    |\n",
      "|    std                  | 6.29         |\n",
      "|    value_loss           | 37.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1351        |\n",
      "|    time_elapsed         | 24780       |\n",
      "|    total_timesteps      | 2766848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008574653 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.62        |\n",
      "|    n_updates            | 13500       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | 0.060828842 |\n",
      "|    std                  | 6.29        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1352         |\n",
      "|    time_elapsed         | 24798        |\n",
      "|    total_timesteps      | 2768896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016134832 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.02         |\n",
      "|    n_updates            | 13510        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | 0.43802243   |\n",
      "|    std                  | 6.29         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1353         |\n",
      "|    time_elapsed         | 24817        |\n",
      "|    total_timesteps      | 2770944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020841858 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.2        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 13520        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 1.4087903    |\n",
      "|    std                  | 6.3          |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 24835       |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016710458 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -1.0571368  |\n",
      "|    std                  | 6.31        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3477720.32\n",
      "total_reward: 2477720.32\n",
      "total_cost: 52905.05\n",
      "total_trades: 51124\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1355        |\n",
      "|    time_elapsed         | 24852       |\n",
      "|    total_timesteps      | 2775040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006272119 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 13540       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | 1.0869203   |\n",
      "|    std                  | 6.31        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 24870       |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011506181 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | -5.879616   |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1357         |\n",
      "|    time_elapsed         | 24888        |\n",
      "|    total_timesteps      | 2779136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014202608 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.4        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 13560        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    reward               | -0.54432625  |\n",
      "|    std                  | 6.33         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1358         |\n",
      "|    time_elapsed         | 24906        |\n",
      "|    total_timesteps      | 2781184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066150855 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.4        |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.19         |\n",
      "|    n_updates            | 13570        |\n",
      "|    policy_gradient_loss | -0.00685     |\n",
      "|    reward               | 0.45208445   |\n",
      "|    std                  | 6.34         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 24923       |\n",
      "|    total_timesteps      | 2783232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012177234 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 13580       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | 0.5478927   |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1360        |\n",
      "|    time_elapsed         | 24941       |\n",
      "|    total_timesteps      | 2785280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004757954 |\n",
      "|    clip_fraction        | 0.00845     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 13590       |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    reward               | -0.2521422  |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 24958       |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010707129 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.83        |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -1.7108811  |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 16.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1362         |\n",
      "|    time_elapsed         | 24976        |\n",
      "|    total_timesteps      | 2789376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070834737 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.5        |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 13610        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | 1.2969398    |\n",
      "|    std                  | 6.35         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1363         |\n",
      "|    time_elapsed         | 24994        |\n",
      "|    total_timesteps      | 2791424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015636974 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.5        |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 13620        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -0.7889174   |\n",
      "|    std                  | 6.35         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1364         |\n",
      "|    time_elapsed         | 25012        |\n",
      "|    total_timesteps      | 2793472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066870926 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.5        |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 13630        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 0.9268435    |\n",
      "|    std                  | 6.35         |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 25030       |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010746323 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 13640       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | 1.0865339   |\n",
      "|    std                  | 6.36        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1366         |\n",
      "|    time_elapsed         | 25048        |\n",
      "|    total_timesteps      | 2797568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043382454 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.5        |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 13650        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -0.22294511  |\n",
      "|    std                  | 6.36         |\n",
      "|    value_loss           | 35.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1367        |\n",
      "|    time_elapsed         | 25067       |\n",
      "|    total_timesteps      | 2799616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005701921 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 13660       |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | 1.5433486   |\n",
      "|    std                  | 6.37        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1368         |\n",
      "|    time_elapsed         | 25085        |\n",
      "|    total_timesteps      | 2801664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095751975 |\n",
      "|    clip_fraction        | 0.0786       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.6        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.47         |\n",
      "|    n_updates            | 13670        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -1.4478959   |\n",
      "|    std                  | 6.39         |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3353329.14\n",
      "total_reward: 2353329.14\n",
      "total_cost: 48677.42\n",
      "total_trades: 51803\n",
      "Sharpe: 0.691\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 25103       |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009878561 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 0.065397255 |\n",
      "|    std                  | 6.41        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1370         |\n",
      "|    time_elapsed         | 25122        |\n",
      "|    total_timesteps      | 2805760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016718807 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.8        |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 13690        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 1.1477023    |\n",
      "|    std                  | 6.41         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 25140       |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006697579 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -1.0540946  |\n",
      "|    std                  | 6.42        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1372        |\n",
      "|    time_elapsed         | 25158       |\n",
      "|    total_timesteps      | 2809856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009853305 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    reward               | -0.8467415  |\n",
      "|    std                  | 6.42        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1373        |\n",
      "|    time_elapsed         | 25176       |\n",
      "|    total_timesteps      | 2811904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005380056 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 13720       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | -1.5562116  |\n",
      "|    std                  | 6.42        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1374         |\n",
      "|    time_elapsed         | 25195        |\n",
      "|    total_timesteps      | 2813952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040593944 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.8        |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 13730        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 1.2838353    |\n",
      "|    std                  | 6.42         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 25213       |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020019488 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.97        |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    reward               | -0.6873654  |\n",
      "|    std                  | 6.44        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1376       |\n",
      "|    time_elapsed         | 25231      |\n",
      "|    total_timesteps      | 2818048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01319644 |\n",
      "|    clip_fraction        | 0.0913     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.9      |\n",
      "|    explained_variance   | 0.647      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.59       |\n",
      "|    n_updates            | 13750      |\n",
      "|    policy_gradient_loss | -0.00574   |\n",
      "|    reward               | 0.55711293 |\n",
      "|    std                  | 6.45       |\n",
      "|    value_loss           | 35.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1377         |\n",
      "|    time_elapsed         | 25249        |\n",
      "|    total_timesteps      | 2820096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018996702 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95          |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 13760        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -4.699601    |\n",
      "|    std                  | 6.46         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 25267       |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008164952 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.2         |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | -0.6381333  |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 25284       |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006785823 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.35        |\n",
      "|    n_updates            | 13780       |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | -1.6740971  |\n",
      "|    std                  | 6.48        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1380        |\n",
      "|    time_elapsed         | 25302       |\n",
      "|    total_timesteps      | 2826240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003034328 |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | 0.75868535  |\n",
      "|    std                  | 6.49        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 25320       |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002058797 |\n",
      "|    clip_fraction        | 0.00176     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 13800       |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | -0.3913462  |\n",
      "|    std                  | 6.49        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1382        |\n",
      "|    time_elapsed         | 25338       |\n",
      "|    total_timesteps      | 2830336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008123955 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.34        |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | -0.6405816  |\n",
      "|    std                  | 6.5         |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3580924.83\n",
      "total_reward: 2580924.83\n",
      "total_cost: 57193.99\n",
      "total_trades: 52704\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1383        |\n",
      "|    time_elapsed         | 25356       |\n",
      "|    total_timesteps      | 2832384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010648379 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 13820       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | 0.39002633  |\n",
      "|    std                  | 6.5         |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1384         |\n",
      "|    time_elapsed         | 25374        |\n",
      "|    total_timesteps      | 2834432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017033175 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.2        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 13830        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 3.605641     |\n",
      "|    std                  | 6.5          |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1385         |\n",
      "|    time_elapsed         | 25391        |\n",
      "|    total_timesteps      | 2836480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107997395 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.2        |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.33         |\n",
      "|    n_updates            | 13840        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | -1.8580923   |\n",
      "|    std                  | 6.51         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1386         |\n",
      "|    time_elapsed         | 25409        |\n",
      "|    total_timesteps      | 2838528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101202745 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.2        |\n",
      "|    explained_variance   | 0.763        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 13850        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | -0.34319153  |\n",
      "|    std                  | 6.52         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1387        |\n",
      "|    time_elapsed         | 25427       |\n",
      "|    total_timesteps      | 2840576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008017611 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 13860       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | -1.0313256  |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 25445       |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013708228 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | -0.4560585  |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1389       |\n",
      "|    time_elapsed         | 25463      |\n",
      "|    total_timesteps      | 2844672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.011325   |\n",
      "|    clip_fraction        | 0.0592     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.3      |\n",
      "|    explained_variance   | 0.74       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 13880      |\n",
      "|    policy_gradient_loss | -0.00424   |\n",
      "|    reward               | 0.88964945 |\n",
      "|    std                  | 6.53       |\n",
      "|    value_loss           | 20         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1390         |\n",
      "|    time_elapsed         | 25480        |\n",
      "|    total_timesteps      | 2846720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064605325 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.3        |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 13890        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | -0.49080127  |\n",
      "|    std                  | 6.54         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 25499       |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004060515 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 13900       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | -0.22607131 |\n",
      "|    std                  | 6.54        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 25517       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008246775 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 13910       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | 0.7086781   |\n",
      "|    std                  | 6.55        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1393         |\n",
      "|    time_elapsed         | 25535        |\n",
      "|    total_timesteps      | 2852864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090139685 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.4        |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 13920        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | 0.9678       |\n",
      "|    std                  | 6.55         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1394        |\n",
      "|    time_elapsed         | 25553       |\n",
      "|    total_timesteps      | 2854912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007865879 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 13930       |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 0.17500207  |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1395        |\n",
      "|    time_elapsed         | 25571       |\n",
      "|    total_timesteps      | 2856960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005414146 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 13940       |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | 2.964107    |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1396         |\n",
      "|    time_elapsed         | 25590        |\n",
      "|    total_timesteps      | 2859008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119513795 |\n",
      "|    clip_fraction        | 0.073        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.5        |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.39         |\n",
      "|    n_updates            | 13950        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | -1.4436883   |\n",
      "|    std                  | 6.56         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1397         |\n",
      "|    time_elapsed         | 25609        |\n",
      "|    total_timesteps      | 2861056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019714013 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.5        |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 13960        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | -0.05795124  |\n",
      "|    std                  | 6.56         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3873985.23\n",
      "total_reward: 2873985.23\n",
      "total_cost: 40377.74\n",
      "total_trades: 50957\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 25627       |\n",
      "|    total_timesteps      | 2863104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004413464 |\n",
      "|    clip_fraction        | 0.024       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 13970       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 2.054829    |\n",
      "|    std                  | 6.57        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1399         |\n",
      "|    time_elapsed         | 25645        |\n",
      "|    total_timesteps      | 2865152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049360474 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.5        |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.57         |\n",
      "|    n_updates            | 13980        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | 2.3322353    |\n",
      "|    std                  | 6.58         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 25663       |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006047649 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | 1.3388528   |\n",
      "|    std                  | 6.58        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1401        |\n",
      "|    time_elapsed         | 25680       |\n",
      "|    total_timesteps      | 2869248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003977076 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 14000       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | -10.296498  |\n",
      "|    std                  | 6.58        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1402        |\n",
      "|    time_elapsed         | 25698       |\n",
      "|    total_timesteps      | 2871296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009426238 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    reward               | -1.2677298  |\n",
      "|    std                  | 6.59        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 25716       |\n",
      "|    total_timesteps      | 2873344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010360166 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 14020       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -0.7729224  |\n",
      "|    std                  | 6.61        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1404        |\n",
      "|    time_elapsed         | 25734       |\n",
      "|    total_timesteps      | 2875392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009746332 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 14030       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | -4.0425844  |\n",
      "|    std                  | 6.62        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1405         |\n",
      "|    time_elapsed         | 25752        |\n",
      "|    total_timesteps      | 2877440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037202158 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.7        |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 14040        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 2.8241587    |\n",
      "|    std                  | 6.63         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1406        |\n",
      "|    time_elapsed         | 25770       |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011066239 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 14050       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 1.0418841   |\n",
      "|    std                  | 6.63        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1407        |\n",
      "|    time_elapsed         | 25788       |\n",
      "|    total_timesteps      | 2881536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009415352 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 14060       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 0.10730541  |\n",
      "|    std                  | 6.64        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1408         |\n",
      "|    time_elapsed         | 25807        |\n",
      "|    total_timesteps      | 2883584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073835845 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.8        |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 14070        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -0.116827734 |\n",
      "|    std                  | 6.64         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1409       |\n",
      "|    time_elapsed         | 25825      |\n",
      "|    total_timesteps      | 2885632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01452823 |\n",
      "|    clip_fraction        | 0.0628     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.8      |\n",
      "|    explained_variance   | 0.476      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.97       |\n",
      "|    n_updates            | 14080      |\n",
      "|    policy_gradient_loss | -0.00704   |\n",
      "|    reward               | 1.5651857  |\n",
      "|    std                  | 6.64       |\n",
      "|    value_loss           | 14.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 25843       |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00810591  |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 14090       |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    reward               | -0.66098124 |\n",
      "|    std                  | 6.65        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1411        |\n",
      "|    time_elapsed         | 25860       |\n",
      "|    total_timesteps      | 2889728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01071238  |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 14100       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    reward               | 0.049484182 |\n",
      "|    std                  | 6.66        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3558674.47\n",
      "total_reward: 2558674.47\n",
      "total_cost: 51603.92\n",
      "total_trades: 51879\n",
      "Sharpe: 0.744\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1412         |\n",
      "|    time_elapsed         | 25878        |\n",
      "|    total_timesteps      | 2891776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069172066 |\n",
      "|    clip_fraction        | 0.0665       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 14110        |\n",
      "|    policy_gradient_loss | -0.00751     |\n",
      "|    reward               | -1.0906132   |\n",
      "|    std                  | 6.67         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1413         |\n",
      "|    time_elapsed         | 25897        |\n",
      "|    total_timesteps      | 2893824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046897605 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.14         |\n",
      "|    n_updates            | 14120        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | -0.23850377  |\n",
      "|    std                  | 6.67         |\n",
      "|    value_loss           | 16.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1414         |\n",
      "|    time_elapsed         | 25914        |\n",
      "|    total_timesteps      | 2895872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040690494 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.9        |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 14130        |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | 2.538047     |\n",
      "|    std                  | 6.67         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1415         |\n",
      "|    time_elapsed         | 25932        |\n",
      "|    total_timesteps      | 2897920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046039745 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96          |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 14140        |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | -0.8747422   |\n",
      "|    std                  | 6.68         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 25950       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010509651 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.65        |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | -0.10788973 |\n",
      "|    std                  | 6.69        |\n",
      "|    value_loss           | 9.7         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1417         |\n",
      "|    time_elapsed         | 25968        |\n",
      "|    total_timesteps      | 2902016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073453356 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96          |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.81         |\n",
      "|    n_updates            | 14160        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    reward               | -3.5169322   |\n",
      "|    std                  | 6.69         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1418         |\n",
      "|    time_elapsed         | 25985        |\n",
      "|    total_timesteps      | 2904064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015344687 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96          |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.51         |\n",
      "|    n_updates            | 14170        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -0.40245134  |\n",
      "|    std                  | 6.7          |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1419        |\n",
      "|    time_elapsed         | 26004       |\n",
      "|    total_timesteps      | 2906112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008854571 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.35        |\n",
      "|    n_updates            | 14180       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | 1.3372023   |\n",
      "|    std                  | 6.71        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 26022       |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009080884 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | 0.3250807   |\n",
      "|    std                  | 6.72        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1421         |\n",
      "|    time_elapsed         | 26040        |\n",
      "|    total_timesteps      | 2910208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044573387 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.1        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 14200        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 0.1416852    |\n",
      "|    std                  | 6.72         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1422         |\n",
      "|    time_elapsed         | 26057        |\n",
      "|    total_timesteps      | 2912256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043498166 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.2        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 14210        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | 3.1274388    |\n",
      "|    std                  | 6.72         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 26074       |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008786827 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 14220       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | 0.9324987   |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 26093       |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008013605 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | 2.1682389   |\n",
      "|    std                  | 6.74        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1425         |\n",
      "|    time_elapsed         | 26111        |\n",
      "|    total_timesteps      | 2918400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015985611 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.2        |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 14240        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | -0.8954381   |\n",
      "|    std                  | 6.74         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3358106.94\n",
      "total_reward: 2358106.94\n",
      "total_cost: 55682.23\n",
      "total_trades: 51730\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1426        |\n",
      "|    time_elapsed         | 26130       |\n",
      "|    total_timesteps      | 2920448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025414212 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.34        |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | -0.000925   |\n",
      "|    reward               | -1.0501001  |\n",
      "|    std                  | 6.74        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1427         |\n",
      "|    time_elapsed         | 26147        |\n",
      "|    total_timesteps      | 2922496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075657526 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 14260        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 0.2655774    |\n",
      "|    std                  | 6.74         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1428         |\n",
      "|    time_elapsed         | 26165        |\n",
      "|    total_timesteps      | 2924544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069263275 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 14270        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | 2.7022948    |\n",
      "|    std                  | 6.75         |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1429        |\n",
      "|    time_elapsed         | 26183       |\n",
      "|    total_timesteps      | 2926592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004750693 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 14280       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | -3.1605875  |\n",
      "|    std                  | 6.75        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 26201       |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006833331 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 0.6117834   |\n",
      "|    std                  | 6.76        |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1431        |\n",
      "|    time_elapsed         | 26219       |\n",
      "|    total_timesteps      | 2930688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012023679 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | 0.07431662  |\n",
      "|    std                  | 6.76        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1432         |\n",
      "|    time_elapsed         | 26237        |\n",
      "|    total_timesteps      | 2932736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021394296 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.3        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 14310        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 0.66457003   |\n",
      "|    std                  | 6.76         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 26255       |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007843139 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.3         |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | 2.8643346   |\n",
      "|    std                  | 6.77        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 26273       |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006104172 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | 0.368787    |\n",
      "|    std                  | 6.78        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1435         |\n",
      "|    time_elapsed         | 26291        |\n",
      "|    total_timesteps      | 2938880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022838372 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.4        |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 14340        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -1.0806963   |\n",
      "|    std                  | 6.78         |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1436         |\n",
      "|    time_elapsed         | 26309        |\n",
      "|    total_timesteps      | 2940928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109499255 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.4        |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 14350        |\n",
      "|    policy_gradient_loss | 0.000844     |\n",
      "|    reward               | 2.4779477    |\n",
      "|    std                  | 6.79         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1437         |\n",
      "|    time_elapsed         | 26327        |\n",
      "|    total_timesteps      | 2942976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007926708  |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.5        |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.39         |\n",
      "|    n_updates            | 14360        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -0.016666006 |\n",
      "|    std                  | 6.79         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1438        |\n",
      "|    time_elapsed         | 26345       |\n",
      "|    total_timesteps      | 2945024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007140029 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 14370       |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | -5.387853   |\n",
      "|    std                  | 6.79        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1439         |\n",
      "|    time_elapsed         | 26363        |\n",
      "|    total_timesteps      | 2947072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019772216 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.5        |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 14380        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | -0.2985969   |\n",
      "|    std                  | 6.79         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3982973.02\n",
      "total_reward: 2982973.02\n",
      "total_cost: 47751.73\n",
      "total_trades: 50698\n",
      "Sharpe: 0.771\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 26382       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007995545 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | 1.4151007   |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1441        |\n",
      "|    time_elapsed         | 26400       |\n",
      "|    total_timesteps      | 2951168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017217673 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | 0.32339495  |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1442         |\n",
      "|    time_elapsed         | 26418        |\n",
      "|    total_timesteps      | 2953216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058500767 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.5        |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 14410        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -2.952454    |\n",
      "|    std                  | 6.81         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1443       |\n",
      "|    time_elapsed         | 26436      |\n",
      "|    total_timesteps      | 2955264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00213212 |\n",
      "|    clip_fraction        | 0.00186    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.5      |\n",
      "|    explained_variance   | 0.537      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.71       |\n",
      "|    n_updates            | 14420      |\n",
      "|    policy_gradient_loss | -0.00326   |\n",
      "|    reward               | -1.7187709 |\n",
      "|    std                  | 6.81       |\n",
      "|    value_loss           | 24.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 26454       |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009104971 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | 0.8213442   |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1445        |\n",
      "|    time_elapsed         | 26472       |\n",
      "|    total_timesteps      | 2959360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003587483 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 14440       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | 5.312411    |\n",
      "|    std                  | 6.81        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1446        |\n",
      "|    time_elapsed         | 26490       |\n",
      "|    total_timesteps      | 2961408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001094434 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 14450       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | -0.09386385 |\n",
      "|    std                  | 6.81        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 26508       |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012383833 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.09        |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    reward               | 1.4468868   |\n",
      "|    std                  | 6.82        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 26526       |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009379055 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | 0.47813636  |\n",
      "|    std                  | 6.83        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1449         |\n",
      "|    time_elapsed         | 26544        |\n",
      "|    total_timesteps      | 2967552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016271338 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.6        |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 14480        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | -0.800012    |\n",
      "|    std                  | 6.83         |\n",
      "|    value_loss           | 60           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1450        |\n",
      "|    time_elapsed         | 26562       |\n",
      "|    total_timesteps      | 2969600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009939348 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7           |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    reward               | 3.0905108   |\n",
      "|    std                  | 6.83        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 26580       |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009863564 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    reward               | 1.0060674   |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1452         |\n",
      "|    time_elapsed         | 26598        |\n",
      "|    total_timesteps      | 2973696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049291593 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 14510        |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    reward               | -1.0957434   |\n",
      "|    std                  | 6.84         |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1453         |\n",
      "|    time_elapsed         | 26616        |\n",
      "|    total_timesteps      | 2975744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020754354 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 14520        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 2.7131937    |\n",
      "|    std                  | 6.84         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3820527.97\n",
      "total_reward: 2820527.97\n",
      "total_cost: 60800.77\n",
      "total_trades: 51874\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1454        |\n",
      "|    time_elapsed         | 26634       |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008122925 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 14530       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | -1.0837551  |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1455         |\n",
      "|    time_elapsed         | 26651        |\n",
      "|    total_timesteps      | 2979840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025165873 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 14540        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 1.3638988    |\n",
      "|    std                  | 6.85         |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1456        |\n",
      "|    time_elapsed         | 26669       |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005647603 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 14550       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | 1.6890781   |\n",
      "|    std                  | 6.85        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 26687       |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498787 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.77        |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 0.1551282   |\n",
      "|    std                  | 6.86        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1458         |\n",
      "|    time_elapsed         | 26705        |\n",
      "|    total_timesteps      | 2985984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062409965 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.8        |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 14570        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | 1.5496477    |\n",
      "|    std                  | 6.87         |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 26723       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007233553 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 0.83716255  |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1460        |\n",
      "|    time_elapsed         | 26740       |\n",
      "|    total_timesteps      | 2990080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005889933 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 14590       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | -2.8396802  |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 26758       |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008015616 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.82        |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 0.357982    |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1462         |\n",
      "|    time_elapsed         | 26777        |\n",
      "|    total_timesteps      | 2994176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030596862 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 14610        |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | 14.350044    |\n",
      "|    std                  | 6.89         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1463         |\n",
      "|    time_elapsed         | 26796        |\n",
      "|    total_timesteps      | 2996224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025901934 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 14620        |\n",
      "|    policy_gradient_loss | 0.00022      |\n",
      "|    reward               | 2.7851129    |\n",
      "|    std                  | 6.89         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1464        |\n",
      "|    time_elapsed         | 26814       |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123298 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.94        |\n",
      "|    n_updates            | 14630       |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 1.301772    |\n",
      "|    std                  | 6.9         |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1465         |\n",
      "|    time_elapsed         | 26831        |\n",
      "|    total_timesteps      | 3000320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052595222 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 14640        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | 1.2478539    |\n",
      "|    std                  | 6.9          |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1466         |\n",
      "|    time_elapsed         | 26850        |\n",
      "|    total_timesteps      | 3002368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052723074 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.9        |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 14650        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | 9.555949     |\n",
      "|    std                  | 6.9          |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1467        |\n",
      "|    time_elapsed         | 26868       |\n",
      "|    total_timesteps      | 3004416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008253225 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 14660       |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    reward               | -1.2808247  |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3469149.49\n",
      "total_reward: 2469149.49\n",
      "total_cost: 46735.02\n",
      "total_trades: 50191\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1468        |\n",
      "|    time_elapsed         | 26886       |\n",
      "|    total_timesteps      | 3006464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010776429 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | -0.22210144 |\n",
      "|    std                  | 6.92        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1469         |\n",
      "|    time_elapsed         | 26903        |\n",
      "|    total_timesteps      | 3008512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076787854 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97          |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 14680        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    reward               | 0.3075922    |\n",
      "|    std                  | 6.92         |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1470        |\n",
      "|    time_elapsed         | 26921       |\n",
      "|    total_timesteps      | 3010560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004632945 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 14690       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | -1.6545413  |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 26939       |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008762726 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -0.30194235 |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1472        |\n",
      "|    time_elapsed         | 26958       |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007497604 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 14710       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 0.7402304   |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1473         |\n",
      "|    time_elapsed         | 26976        |\n",
      "|    total_timesteps      | 3016704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017839922 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.1        |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 14720        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | -0.63933915  |\n",
      "|    std                  | 6.93         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1474         |\n",
      "|    time_elapsed         | 26994        |\n",
      "|    total_timesteps      | 3018752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075687575 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.1        |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.51         |\n",
      "|    n_updates            | 14730        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | -0.8903203   |\n",
      "|    std                  | 6.94         |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1475       |\n",
      "|    time_elapsed         | 27011      |\n",
      "|    total_timesteps      | 3020800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01195363 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.1      |\n",
      "|    explained_variance   | 0.655      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.1       |\n",
      "|    n_updates            | 14740      |\n",
      "|    policy_gradient_loss | -0.00647   |\n",
      "|    reward               | -0.6230996 |\n",
      "|    std                  | 6.95       |\n",
      "|    value_loss           | 35         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1476        |\n",
      "|    time_elapsed         | 27029       |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006456687 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 14750       |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    reward               | 3.7954407   |\n",
      "|    std                  | 6.94        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1477         |\n",
      "|    time_elapsed         | 27047        |\n",
      "|    total_timesteps      | 3024896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043084193 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.1        |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 14760        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -0.79629844  |\n",
      "|    std                  | 6.95         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1478        |\n",
      "|    time_elapsed         | 27065       |\n",
      "|    total_timesteps      | 3026944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013820667 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.52        |\n",
      "|    n_updates            | 14770       |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | -1.7866881  |\n",
      "|    std                  | 6.96        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1479        |\n",
      "|    time_elapsed         | 27083       |\n",
      "|    total_timesteps      | 3028992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007669008 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 14780       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    reward               | 0.24406323  |\n",
      "|    std                  | 6.95        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1480         |\n",
      "|    time_elapsed         | 27101        |\n",
      "|    total_timesteps      | 3031040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046177255 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.1        |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 14790        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | -0.87949276  |\n",
      "|    std                  | 6.95         |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 27119       |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011644983 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.25        |\n",
      "|    n_updates            | 14800       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | -1.520102   |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3718854.55\n",
      "total_reward: 2718854.55\n",
      "total_cost: 48393.97\n",
      "total_trades: 50644\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1482       |\n",
      "|    time_elapsed         | 27138      |\n",
      "|    total_timesteps      | 3035136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01313868 |\n",
      "|    clip_fraction        | 0.0944     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.2      |\n",
      "|    explained_variance   | 0.707      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.1       |\n",
      "|    n_updates            | 14810      |\n",
      "|    policy_gradient_loss | -0.00706   |\n",
      "|    reward               | 3.4713347  |\n",
      "|    std                  | 6.98       |\n",
      "|    value_loss           | 24.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1483         |\n",
      "|    time_elapsed         | 27157        |\n",
      "|    total_timesteps      | 3037184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040896493 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 14820        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 1.3976605    |\n",
      "|    std                  | 6.98         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1484        |\n",
      "|    time_elapsed         | 27175       |\n",
      "|    total_timesteps      | 3039232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010535382 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 14830       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -0.5512594  |\n",
      "|    std                  | 6.98        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1485        |\n",
      "|    time_elapsed         | 27194       |\n",
      "|    total_timesteps      | 3041280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010230067 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 14840       |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | 0.31777596  |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1486       |\n",
      "|    time_elapsed         | 27211      |\n",
      "|    total_timesteps      | 3043328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00290535 |\n",
      "|    clip_fraction        | 0.00269    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.2      |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.96       |\n",
      "|    n_updates            | 14850      |\n",
      "|    policy_gradient_loss | -0.00366   |\n",
      "|    reward               | 1.9997014  |\n",
      "|    std                  | 6.98       |\n",
      "|    value_loss           | 38.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1487         |\n",
      "|    time_elapsed         | 27229        |\n",
      "|    total_timesteps      | 3045376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065321145 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 14860        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -0.8793999   |\n",
      "|    std                  | 6.99         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1488         |\n",
      "|    time_elapsed         | 27247        |\n",
      "|    total_timesteps      | 3047424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055707023 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.27         |\n",
      "|    n_updates            | 14870        |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    reward               | 1.3971099    |\n",
      "|    std                  | 6.99         |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1489        |\n",
      "|    time_elapsed         | 27265       |\n",
      "|    total_timesteps      | 3049472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001379165 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | 0.21308266  |\n",
      "|    std                  | 7           |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1490         |\n",
      "|    time_elapsed         | 27283        |\n",
      "|    total_timesteps      | 3051520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070037385 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 14890        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | -6.2940173   |\n",
      "|    std                  | 7            |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1491         |\n",
      "|    time_elapsed         | 27301        |\n",
      "|    total_timesteps      | 3053568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063206838 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.4        |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.48         |\n",
      "|    n_updates            | 14900        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | -1.6325463   |\n",
      "|    std                  | 7            |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1492        |\n",
      "|    time_elapsed         | 27319       |\n",
      "|    total_timesteps      | 3055616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009943346 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 14910       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | -0.74861175 |\n",
      "|    std                  | 7.01        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1493         |\n",
      "|    time_elapsed         | 27337        |\n",
      "|    total_timesteps      | 3057664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012258753 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.4        |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 14920        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 2.3147836    |\n",
      "|    std                  | 7.01         |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1494         |\n",
      "|    time_elapsed         | 27355        |\n",
      "|    total_timesteps      | 3059712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030754572 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.4        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.48         |\n",
      "|    n_updates            | 14930        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 0.71100545   |\n",
      "|    std                  | 7.02         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1495        |\n",
      "|    time_elapsed         | 27373       |\n",
      "|    total_timesteps      | 3061760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002529366 |\n",
      "|    clip_fraction        | 0.00825     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.98        |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | -1.5493276  |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3627529.23\n",
      "total_reward: 2627529.23\n",
      "total_cost: 41829.61\n",
      "total_trades: 50250\n",
      "Sharpe: 0.759\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1496         |\n",
      "|    time_elapsed         | 27391        |\n",
      "|    total_timesteps      | 3063808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006512215  |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 14950        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -0.028386896 |\n",
      "|    std                  | 7.03         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1497         |\n",
      "|    time_elapsed         | 27409        |\n",
      "|    total_timesteps      | 3065856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032383527 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 14960        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | -0.15100811  |\n",
      "|    std                  | 7.03         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 27427       |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004495807 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.06        |\n",
      "|    n_updates            | 14970       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | 1.2473595   |\n",
      "|    std                  | 7.03        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 27445       |\n",
      "|    total_timesteps      | 3069952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008471807 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 14980       |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | -0.90404546 |\n",
      "|    std                  | 7.04        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1500        |\n",
      "|    time_elapsed         | 27463       |\n",
      "|    total_timesteps      | 3072000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018882388 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 14990       |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    reward               | 2.5587106   |\n",
      "|    std                  | 7.04        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1501         |\n",
      "|    time_elapsed         | 27481        |\n",
      "|    total_timesteps      | 3074048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009331777 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 15000        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | -4.2849283   |\n",
      "|    std                  | 7.04         |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1502        |\n",
      "|    time_elapsed         | 27498       |\n",
      "|    total_timesteps      | 3076096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004093278 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.31        |\n",
      "|    n_updates            | 15010       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | 0.10181865  |\n",
      "|    std                  | 7.04        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1503        |\n",
      "|    time_elapsed         | 27516       |\n",
      "|    total_timesteps      | 3078144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011945316 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 15020       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    reward               | 1.7166667   |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1504        |\n",
      "|    time_elapsed         | 27534       |\n",
      "|    total_timesteps      | 3080192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008018067 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 15030       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 1.6887641   |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1505       |\n",
      "|    time_elapsed         | 27552      |\n",
      "|    total_timesteps      | 3082240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01050006 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.6      |\n",
      "|    explained_variance   | 0.487      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.41       |\n",
      "|    n_updates            | 15040      |\n",
      "|    policy_gradient_loss | -0.00642   |\n",
      "|    reward               | -0.2119917 |\n",
      "|    std                  | 7.05       |\n",
      "|    value_loss           | 14.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1506         |\n",
      "|    time_elapsed         | 27571        |\n",
      "|    total_timesteps      | 3084288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058109397 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.6        |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 15050        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | -0.22099574  |\n",
      "|    std                  | 7.07         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1507         |\n",
      "|    time_elapsed         | 27589        |\n",
      "|    total_timesteps      | 3086336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018158676 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.6        |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.7         |\n",
      "|    n_updates            | 15060        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | -4.4506245   |\n",
      "|    std                  | 7.07         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1508         |\n",
      "|    time_elapsed         | 27606        |\n",
      "|    total_timesteps      | 3088384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049233288 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.7        |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.59         |\n",
      "|    n_updates            | 15070        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | -5.648028    |\n",
      "|    std                  | 7.08         |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1509        |\n",
      "|    time_elapsed         | 27624       |\n",
      "|    total_timesteps      | 3090432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008036105 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 15080       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | 0.98387223  |\n",
      "|    std                  | 7.09        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 27641       |\n",
      "|    total_timesteps      | 3092480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008928918 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 15090       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 0.121562436 |\n",
      "|    std                  | 7.1         |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3732869.73\n",
      "total_reward: 2732869.73\n",
      "total_cost: 46603.85\n",
      "total_trades: 50299\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1511         |\n",
      "|    time_elapsed         | 27659        |\n",
      "|    total_timesteps      | 3094528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027464505 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.8        |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 15100        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | 0.9806505    |\n",
      "|    std                  | 7.1          |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1512        |\n",
      "|    time_elapsed         | 27678       |\n",
      "|    total_timesteps      | 3096576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009159695 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.57        |\n",
      "|    n_updates            | 15110       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 1.1164052   |\n",
      "|    std                  | 7.11        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1513        |\n",
      "|    time_elapsed         | 27696       |\n",
      "|    total_timesteps      | 3098624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007902976 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 15120       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | 0.041366354 |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1514        |\n",
      "|    time_elapsed         | 27714       |\n",
      "|    total_timesteps      | 3100672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001964634 |\n",
      "|    clip_fraction        | 0.00107     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.85        |\n",
      "|    n_updates            | 15130       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | 0.7299682   |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1515        |\n",
      "|    time_elapsed         | 27732       |\n",
      "|    total_timesteps      | 3102720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008347383 |\n",
      "|    clip_fraction        | 0.0671      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 15140       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 1.1743599   |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1516         |\n",
      "|    time_elapsed         | 27750        |\n",
      "|    total_timesteps      | 3104768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035289582 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.9        |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 15150        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 2.283786     |\n",
      "|    std                  | 7.13         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1517        |\n",
      "|    time_elapsed         | 27768       |\n",
      "|    total_timesteps      | 3106816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008294332 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 15160       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | 5.2440352   |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1518        |\n",
      "|    time_elapsed         | 27786       |\n",
      "|    total_timesteps      | 3108864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011988884 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 15170       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -2.5104556  |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1519        |\n",
      "|    time_elapsed         | 27804       |\n",
      "|    total_timesteps      | 3110912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011176015 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.45        |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | 0.76369697  |\n",
      "|    std                  | 7.14        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 27821       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006089908 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 15190       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | -0.18254124 |\n",
      "|    std                  | 7.14        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1521         |\n",
      "|    time_elapsed         | 27839        |\n",
      "|    total_timesteps      | 3115008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029042314 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.9        |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 15200        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 1.6771666    |\n",
      "|    std                  | 7.15         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 27857       |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006788139 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.04        |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 7.15        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1523        |\n",
      "|    time_elapsed         | 27875       |\n",
      "|    total_timesteps      | 3119104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009155666 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 15220       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | -0.04067359 |\n",
      "|    std                  | 7.16        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1524         |\n",
      "|    time_elapsed         | 27893        |\n",
      "|    total_timesteps      | 3121152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054622134 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 15230        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | -0.6109285   |\n",
      "|    std                  | 7.17         |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3878700.84\n",
      "total_reward: 2878700.84\n",
      "total_cost: 40816.11\n",
      "total_trades: 49979\n",
      "Sharpe: 0.776\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1525         |\n",
      "|    time_elapsed         | 27911        |\n",
      "|    total_timesteps      | 3123200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025810574 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 15240        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 1.5851086    |\n",
      "|    std                  | 7.17         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1526        |\n",
      "|    time_elapsed         | 27929       |\n",
      "|    total_timesteps      | 3125248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009257928 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.03        |\n",
      "|    n_updates            | 15250       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | 0.07877317  |\n",
      "|    std                  | 7.17        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1527        |\n",
      "|    time_elapsed         | 27947       |\n",
      "|    total_timesteps      | 3127296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004126833 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 15260       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 3.1287518   |\n",
      "|    std                  | 7.18        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1528         |\n",
      "|    time_elapsed         | 27965        |\n",
      "|    total_timesteps      | 3129344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007718005 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.1        |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 15270        |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    reward               | -2.058176    |\n",
      "|    std                  | 7.19         |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1529        |\n",
      "|    time_elapsed         | 27983       |\n",
      "|    total_timesteps      | 3131392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013106112 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.98        |\n",
      "|    n_updates            | 15280       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -1.4549444  |\n",
      "|    std                  | 7.19        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1530        |\n",
      "|    time_elapsed         | 28000       |\n",
      "|    total_timesteps      | 3133440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010552404 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 15290       |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    reward               | 1.320045    |\n",
      "|    std                  | 7.19        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1531         |\n",
      "|    time_elapsed         | 28018        |\n",
      "|    total_timesteps      | 3135488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052230926 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.1        |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 15300        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 4.3073897    |\n",
      "|    std                  | 7.2          |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1532        |\n",
      "|    time_elapsed         | 28036       |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007864549 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.13        |\n",
      "|    n_updates            | 15310       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | -3.6629884  |\n",
      "|    std                  | 7.2         |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1533        |\n",
      "|    time_elapsed         | 28054       |\n",
      "|    total_timesteps      | 3139584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006328076 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 15320       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | -0.11151386 |\n",
      "|    std                  | 7.2         |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1534         |\n",
      "|    time_elapsed         | 28072        |\n",
      "|    total_timesteps      | 3141632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054660495 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 15330        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | -2.3678527   |\n",
      "|    std                  | 7.21         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1535        |\n",
      "|    time_elapsed         | 28089       |\n",
      "|    total_timesteps      | 3143680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006794029 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 15340       |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | -4.470697   |\n",
      "|    std                  | 7.21        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1536        |\n",
      "|    time_elapsed         | 28108       |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010449026 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.45        |\n",
      "|    n_updates            | 15350       |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | -0.24709012 |\n",
      "|    std                  | 7.21        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1537         |\n",
      "|    time_elapsed         | 28126        |\n",
      "|    total_timesteps      | 3147776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039770994 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 15360        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -0.020698283 |\n",
      "|    std                  | 7.21         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1538         |\n",
      "|    time_elapsed         | 28144        |\n",
      "|    total_timesteps      | 3149824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035245544 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 15370        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | 1.8606236    |\n",
      "|    std                  | 7.21         |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3904285.72\n",
      "total_reward: 2904285.72\n",
      "total_cost: 42501.61\n",
      "total_trades: 50166\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1539       |\n",
      "|    time_elapsed         | 28162      |\n",
      "|    total_timesteps      | 3151872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00843087 |\n",
      "|    clip_fraction        | 0.0499     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.2      |\n",
      "|    explained_variance   | 0.568      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.93       |\n",
      "|    n_updates            | 15380      |\n",
      "|    policy_gradient_loss | -0.00298   |\n",
      "|    reward               | -1.3833904 |\n",
      "|    std                  | 7.22       |\n",
      "|    value_loss           | 17.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1540        |\n",
      "|    time_elapsed         | 28180       |\n",
      "|    total_timesteps      | 3153920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008413941 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 15390       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | -1.4915115  |\n",
      "|    std                  | 7.22        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1541         |\n",
      "|    time_elapsed         | 28198        |\n",
      "|    total_timesteps      | 3155968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043858252 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 15400        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | 2.029345     |\n",
      "|    std                  | 7.22         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1542         |\n",
      "|    time_elapsed         | 28216        |\n",
      "|    total_timesteps      | 3158016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080379285 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.3        |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 15410        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -3.9576166   |\n",
      "|    std                  | 7.23         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1543        |\n",
      "|    time_elapsed         | 28234       |\n",
      "|    total_timesteps      | 3160064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007574281 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 15420       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | -0.576122   |\n",
      "|    std                  | 7.24        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1544         |\n",
      "|    time_elapsed         | 28251        |\n",
      "|    total_timesteps      | 3162112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019301228 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.3        |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 15430        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 0.6894881    |\n",
      "|    std                  | 7.24         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1545       |\n",
      "|    time_elapsed         | 28269      |\n",
      "|    total_timesteps      | 3164160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00955083 |\n",
      "|    clip_fraction        | 0.0991     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.3      |\n",
      "|    explained_variance   | 0.684      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18         |\n",
      "|    n_updates            | 15440      |\n",
      "|    policy_gradient_loss | -0.00515   |\n",
      "|    reward               | 0.6298605  |\n",
      "|    std                  | 7.24       |\n",
      "|    value_loss           | 38.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1546        |\n",
      "|    time_elapsed         | 28287       |\n",
      "|    total_timesteps      | 3166208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008352315 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.02        |\n",
      "|    n_updates            | 15450       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 0.65330493  |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1547       |\n",
      "|    time_elapsed         | 28305      |\n",
      "|    total_timesteps      | 3168256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00886507 |\n",
      "|    clip_fraction        | 0.031      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.4      |\n",
      "|    explained_variance   | 0.753      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14         |\n",
      "|    n_updates            | 15460      |\n",
      "|    policy_gradient_loss | -0.00425   |\n",
      "|    reward               | 1.8508757  |\n",
      "|    std                  | 7.25       |\n",
      "|    value_loss           | 26.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1548        |\n",
      "|    time_elapsed         | 28324       |\n",
      "|    total_timesteps      | 3170304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005407967 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 15470       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    reward               | 0.6889688   |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1549         |\n",
      "|    time_elapsed         | 28342        |\n",
      "|    total_timesteps      | 3172352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052738935 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.4        |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 15480        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | 0.8754691    |\n",
      "|    std                  | 7.26         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1550        |\n",
      "|    time_elapsed         | 28360       |\n",
      "|    total_timesteps      | 3174400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008314476 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.87        |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -0.6246965  |\n",
      "|    std                  | 7.27        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1551         |\n",
      "|    time_elapsed         | 28378        |\n",
      "|    total_timesteps      | 3176448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061518895 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.5        |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 15500        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -8.994828    |\n",
      "|    std                  | 7.28         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1552        |\n",
      "|    time_elapsed         | 28396       |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002194176 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 15510       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | 0.082844265 |\n",
      "|    std                  | 7.28        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3775240.43\n",
      "total_reward: 2775240.43\n",
      "total_cost: 45297.32\n",
      "total_trades: 50777\n",
      "Sharpe: 0.797\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1553         |\n",
      "|    time_elapsed         | 28415        |\n",
      "|    total_timesteps      | 3180544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029505594 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.5        |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.18         |\n",
      "|    n_updates            | 15520        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | 1.4225643    |\n",
      "|    std                  | 7.29         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1554         |\n",
      "|    time_elapsed         | 28433        |\n",
      "|    total_timesteps      | 3182592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042247986 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.5        |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 15530        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | 0.092827626  |\n",
      "|    std                  | 7.29         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1555         |\n",
      "|    time_elapsed         | 28451        |\n",
      "|    total_timesteps      | 3184640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009863427 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 15540        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | -2.5075405   |\n",
      "|    std                  | 7.3          |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1556         |\n",
      "|    time_elapsed         | 28469        |\n",
      "|    total_timesteps      | 3186688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013845289 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.28         |\n",
      "|    n_updates            | 15550        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -3.1941688   |\n",
      "|    std                  | 7.3          |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1557        |\n",
      "|    time_elapsed         | 28487       |\n",
      "|    total_timesteps      | 3188736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010383409 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 15560       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | -2.217292   |\n",
      "|    std                  | 7.32        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1558        |\n",
      "|    time_elapsed         | 28504       |\n",
      "|    total_timesteps      | 3190784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009294541 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 15570       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | 0.34506032  |\n",
      "|    std                  | 7.32        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1559         |\n",
      "|    time_elapsed         | 28523        |\n",
      "|    total_timesteps      | 3192832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065803705 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.37         |\n",
      "|    n_updates            | 15580        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    reward               | -2.468137    |\n",
      "|    std                  | 7.32         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 28541       |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011976411 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 15590       |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | 1.2089146   |\n",
      "|    std                  | 7.31        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1561       |\n",
      "|    time_elapsed         | 28559      |\n",
      "|    total_timesteps      | 3196928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01597807 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.6      |\n",
      "|    explained_variance   | 0.695      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.7       |\n",
      "|    n_updates            | 15600      |\n",
      "|    policy_gradient_loss | -0.00789   |\n",
      "|    reward               | 0.21641941 |\n",
      "|    std                  | 7.31       |\n",
      "|    value_loss           | 23.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1562         |\n",
      "|    time_elapsed         | 28577        |\n",
      "|    total_timesteps      | 3198976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029729202 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 15610        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | -0.6619408   |\n",
      "|    std                  | 7.31         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1563         |\n",
      "|    time_elapsed         | 28595        |\n",
      "|    total_timesteps      | 3201024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007523466  |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.24         |\n",
      "|    n_updates            | 15620        |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    reward               | -0.016638275 |\n",
      "|    std                  | 7.31         |\n",
      "|    value_loss           | 14.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 28614       |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013003747 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | 0.5021289   |\n",
      "|    std                  | 7.31        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1565         |\n",
      "|    time_elapsed         | 28633        |\n",
      "|    total_timesteps      | 3205120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062200907 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 15640        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | -2.8151698   |\n",
      "|    std                  | 7.32         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1566        |\n",
      "|    time_elapsed         | 28652       |\n",
      "|    total_timesteps      | 3207168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008324632 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.97        |\n",
      "|    n_updates            | 15650       |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    reward               | -0.3899328  |\n",
      "|    std                  | 7.32        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3292870.52\n",
      "total_reward: 2292870.52\n",
      "total_cost: 41766.62\n",
      "total_trades: 50592\n",
      "Sharpe: 0.726\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1567         |\n",
      "|    time_elapsed         | 28671        |\n",
      "|    total_timesteps      | 3209216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071382467 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.7          |\n",
      "|    n_updates            | 15660        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    reward               | -0.29542935  |\n",
      "|    std                  | 7.33         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1568        |\n",
      "|    time_elapsed         | 28689       |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010679364 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.79        |\n",
      "|    n_updates            | 15670       |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | -0.7403243  |\n",
      "|    std                  | 7.34        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1569         |\n",
      "|    time_elapsed         | 28707        |\n",
      "|    total_timesteps      | 3213312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070720105 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 15680        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 0.24500233   |\n",
      "|    std                  | 7.34         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1570        |\n",
      "|    time_elapsed         | 28726       |\n",
      "|    total_timesteps      | 3215360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007711108 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.18        |\n",
      "|    n_updates            | 15690       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -0.18328317 |\n",
      "|    std                  | 7.34        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1571        |\n",
      "|    time_elapsed         | 28744       |\n",
      "|    total_timesteps      | 3217408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012809699 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.22        |\n",
      "|    n_updates            | 15700       |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | 0.044259127 |\n",
      "|    std                  | 7.36        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1572         |\n",
      "|    time_elapsed         | 28761        |\n",
      "|    total_timesteps      | 3219456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049005956 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.8        |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 15710        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | 0.41346633   |\n",
      "|    std                  | 7.37         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1573        |\n",
      "|    time_elapsed         | 28779       |\n",
      "|    total_timesteps      | 3221504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012827909 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.77        |\n",
      "|    n_updates            | 15720       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | -0.36065134 |\n",
      "|    std                  | 7.37        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1574        |\n",
      "|    time_elapsed         | 28796       |\n",
      "|    total_timesteps      | 3223552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006579909 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.66        |\n",
      "|    n_updates            | 15730       |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | -0.11896859 |\n",
      "|    std                  | 7.38        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1575        |\n",
      "|    time_elapsed         | 28813       |\n",
      "|    total_timesteps      | 3225600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004440427 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.31        |\n",
      "|    n_updates            | 15740       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    reward               | 0.44324848  |\n",
      "|    std                  | 7.39        |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1576         |\n",
      "|    time_elapsed         | 28831        |\n",
      "|    total_timesteps      | 3227648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065990584 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.9        |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 15750        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 0.3555971    |\n",
      "|    std                  | 7.4          |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1577        |\n",
      "|    time_elapsed         | 28849       |\n",
      "|    total_timesteps      | 3229696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011157097 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.04        |\n",
      "|    n_updates            | 15760       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -0.631516   |\n",
      "|    std                  | 7.42        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1578        |\n",
      "|    time_elapsed         | 28867       |\n",
      "|    total_timesteps      | 3231744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008488469 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 15770       |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | -0.63638645 |\n",
      "|    std                  | 7.42        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1579         |\n",
      "|    time_elapsed         | 28885        |\n",
      "|    total_timesteps      | 3233792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019300467 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 15780        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 3.3835378    |\n",
      "|    std                  | 7.42         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1580         |\n",
      "|    time_elapsed         | 28902        |\n",
      "|    total_timesteps      | 3235840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065975925 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.64         |\n",
      "|    n_updates            | 15790        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | 0.71523863   |\n",
      "|    std                  | 7.42         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3709453.14\n",
      "total_reward: 2709453.14\n",
      "total_cost: 36470.37\n",
      "total_trades: 50626\n",
      "Sharpe: 0.779\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1581        |\n",
      "|    time_elapsed         | 28920       |\n",
      "|    total_timesteps      | 3237888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013862727 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 15800       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 0.51922953  |\n",
      "|    std                  | 7.43        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1582        |\n",
      "|    time_elapsed         | 28938       |\n",
      "|    total_timesteps      | 3239936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006036952 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 15810       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | -5.2891097  |\n",
      "|    std                  | 7.44        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1583         |\n",
      "|    time_elapsed         | 28957        |\n",
      "|    total_timesteps      | 3241984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058559906 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 15820        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -0.57416034  |\n",
      "|    std                  | 7.44         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1584        |\n",
      "|    time_elapsed         | 28976       |\n",
      "|    total_timesteps      | 3244032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005986109 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 15830       |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | -0.27822068 |\n",
      "|    std                  | 7.45        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1585        |\n",
      "|    time_elapsed         | 28994       |\n",
      "|    total_timesteps      | 3246080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012509322 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 15840       |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    reward               | 1.0523767   |\n",
      "|    std                  | 7.47        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1586         |\n",
      "|    time_elapsed         | 29013        |\n",
      "|    total_timesteps      | 3248128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038751054 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 15850        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | -0.89293414  |\n",
      "|    std                  | 7.47         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1587         |\n",
      "|    time_elapsed         | 29031        |\n",
      "|    total_timesteps      | 3250176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078747785 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.95         |\n",
      "|    n_updates            | 15860        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | 3.1419437    |\n",
      "|    std                  | 7.47         |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 29049       |\n",
      "|    total_timesteps      | 3252224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002695894 |\n",
      "|    clip_fraction        | 0.00737     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 15870       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -0.54455215 |\n",
      "|    std                  | 7.47        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1589       |\n",
      "|    time_elapsed         | 29067      |\n",
      "|    total_timesteps      | 3254272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00365254 |\n",
      "|    clip_fraction        | 0.035      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -99.3      |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.3       |\n",
      "|    n_updates            | 15880      |\n",
      "|    policy_gradient_loss | -0.0061    |\n",
      "|    reward               | 0.2013592  |\n",
      "|    std                  | 7.48       |\n",
      "|    value_loss           | 28.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1590        |\n",
      "|    time_elapsed         | 29086       |\n",
      "|    total_timesteps      | 3256320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005217598 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 15890       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 0.2178703   |\n",
      "|    std                  | 7.48        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1591        |\n",
      "|    time_elapsed         | 29105       |\n",
      "|    total_timesteps      | 3258368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010377508 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 15900       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 4.7788916   |\n",
      "|    std                  | 7.5         |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1592         |\n",
      "|    time_elapsed         | 29123        |\n",
      "|    total_timesteps      | 3260416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066242544 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 15910        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | -0.21346883  |\n",
      "|    std                  | 7.5          |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1593         |\n",
      "|    time_elapsed         | 29141        |\n",
      "|    total_timesteps      | 3262464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031968623 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.4        |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 15920        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 0.13269651   |\n",
      "|    std                  | 7.5          |\n",
      "|    value_loss           | 46.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1594       |\n",
      "|    time_elapsed         | 29160      |\n",
      "|    total_timesteps      | 3264512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01177504 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -99.4      |\n",
      "|    explained_variance   | 0.47       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.35       |\n",
      "|    n_updates            | 15930      |\n",
      "|    policy_gradient_loss | -0.0014    |\n",
      "|    reward               | -1.3842876 |\n",
      "|    std                  | 7.5        |\n",
      "|    value_loss           | 17.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3655922.56\n",
      "total_reward: 2655922.56\n",
      "total_cost: 45482.51\n",
      "total_trades: 52130\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1595         |\n",
      "|    time_elapsed         | 29178        |\n",
      "|    total_timesteps      | 3266560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007822441  |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.4        |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 15940        |\n",
      "|    policy_gradient_loss | -0.0077      |\n",
      "|    reward               | -0.096928686 |\n",
      "|    std                  | 7.52         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1596         |\n",
      "|    time_elapsed         | 29196        |\n",
      "|    total_timesteps      | 3268608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073331846 |\n",
      "|    clip_fraction        | 0.0705       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.4        |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 15950        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | -1.9661741   |\n",
      "|    std                  | 7.52         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1597        |\n",
      "|    time_elapsed         | 29215       |\n",
      "|    total_timesteps      | 3270656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015529951 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    reward               | -5.0230403  |\n",
      "|    std                  | 7.53        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1598        |\n",
      "|    time_elapsed         | 29233       |\n",
      "|    total_timesteps      | 3272704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008090863 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 15970       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 0.6148138   |\n",
      "|    std                  | 7.53        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1599         |\n",
      "|    time_elapsed         | 29251        |\n",
      "|    total_timesteps      | 3274752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071734563 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.5        |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 15980        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -4.20302     |\n",
      "|    std                  | 7.55         |\n",
      "|    value_loss           | 36.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1600         |\n",
      "|    time_elapsed         | 29269        |\n",
      "|    total_timesteps      | 3276800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.003969566  |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.6        |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 15990        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -0.075614735 |\n",
      "|    std                  | 7.56         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1601        |\n",
      "|    time_elapsed         | 29288       |\n",
      "|    total_timesteps      | 3278848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009631819 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.08        |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    reward               | -3.1902132  |\n",
      "|    std                  | 7.56        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1602        |\n",
      "|    time_elapsed         | 29306       |\n",
      "|    total_timesteps      | 3280896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007032436 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 16010       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | -0.2105686  |\n",
      "|    std                  | 7.57        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1603         |\n",
      "|    time_elapsed         | 29324        |\n",
      "|    total_timesteps      | 3282944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010399728 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.6        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 16020        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 4.3687344    |\n",
      "|    std                  | 7.58         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1604        |\n",
      "|    time_elapsed         | 29341       |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003223502 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | 0.96530026  |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1605        |\n",
      "|    time_elapsed         | 29360       |\n",
      "|    total_timesteps      | 3287040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006865846 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.67        |\n",
      "|    n_updates            | 16040       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 1.1199234   |\n",
      "|    std                  | 7.6         |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1606         |\n",
      "|    time_elapsed         | 29378        |\n",
      "|    total_timesteps      | 3289088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067906715 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.7        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 16050        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    reward               | 0.35558388   |\n",
      "|    std                  | 7.6          |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1607         |\n",
      "|    time_elapsed         | 29396        |\n",
      "|    total_timesteps      | 3291136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019453017 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.7        |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 16060        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | 2.398022     |\n",
      "|    std                  | 7.61         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1608        |\n",
      "|    time_elapsed         | 29414       |\n",
      "|    total_timesteps      | 3293184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005987537 |\n",
      "|    clip_fraction        | 0.0373      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 16070       |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | -2.6754036  |\n",
      "|    std                  | 7.61        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3646029.49\n",
      "total_reward: 2646029.49\n",
      "total_cost: 44788.99\n",
      "total_trades: 52452\n",
      "Sharpe: 0.714\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1609        |\n",
      "|    time_elapsed         | 29432       |\n",
      "|    total_timesteps      | 3295232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005124645 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 16080       |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | 1.8291124   |\n",
      "|    std                  | 7.61        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1610         |\n",
      "|    time_elapsed         | 29449        |\n",
      "|    total_timesteps      | 3297280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018683627 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 16090        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | -0.6180966   |\n",
      "|    std                  | 7.61         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1611        |\n",
      "|    time_elapsed         | 29467       |\n",
      "|    total_timesteps      | 3299328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009566733 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.69        |\n",
      "|    n_updates            | 16100       |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | 1.4835614   |\n",
      "|    std                  | 7.6         |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1612       |\n",
      "|    time_elapsed         | 29485      |\n",
      "|    total_timesteps      | 3301376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01095867 |\n",
      "|    clip_fraction        | 0.0692     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -99.8      |\n",
      "|    explained_variance   | 0.598      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 16110      |\n",
      "|    policy_gradient_loss | -0.00526   |\n",
      "|    reward               | 0.38225183 |\n",
      "|    std                  | 7.62       |\n",
      "|    value_loss           | 28         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1613         |\n",
      "|    time_elapsed         | 29503        |\n",
      "|    total_timesteps      | 3303424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030024112 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 16120        |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    reward               | -6.94514     |\n",
      "|    std                  | 7.63         |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1614        |\n",
      "|    time_elapsed         | 29521       |\n",
      "|    total_timesteps      | 3305472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008041665 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -0.27228987 |\n",
      "|    std                  | 7.64        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1615         |\n",
      "|    time_elapsed         | 29539        |\n",
      "|    total_timesteps      | 3307520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018073142 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.9        |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 16140        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 0.71119386   |\n",
      "|    std                  | 7.64         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1616         |\n",
      "|    time_elapsed         | 29558        |\n",
      "|    total_timesteps      | 3309568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084080435 |\n",
      "|    clip_fraction        | 0.0356       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.9        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.48         |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 3.6407092    |\n",
      "|    std                  | 7.65         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1617          |\n",
      "|    time_elapsed         | 29576         |\n",
      "|    total_timesteps      | 3311616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047181794 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -99.9         |\n",
      "|    explained_variance   | 0.497         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.3          |\n",
      "|    n_updates            | 16160         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | -0.7846713    |\n",
      "|    std                  | 7.65          |\n",
      "|    value_loss           | 40.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1618        |\n",
      "|    time_elapsed         | 29594       |\n",
      "|    total_timesteps      | 3313664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008099551 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.6         |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 1.3480209   |\n",
      "|    std                  | 7.65        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1619         |\n",
      "|    time_elapsed         | 29612        |\n",
      "|    total_timesteps      | 3315712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048299013 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.9        |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.69         |\n",
      "|    n_updates            | 16180        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 1.6462946    |\n",
      "|    std                  | 7.65         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1620          |\n",
      "|    time_elapsed         | 29630         |\n",
      "|    total_timesteps      | 3317760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093913503 |\n",
      "|    clip_fraction        | 0.00229       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -99.9         |\n",
      "|    explained_variance   | 0.505         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.3          |\n",
      "|    n_updates            | 16190         |\n",
      "|    policy_gradient_loss | -0.0023       |\n",
      "|    reward               | 0.0           |\n",
      "|    std                  | 7.65          |\n",
      "|    value_loss           | 42.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1621         |\n",
      "|    time_elapsed         | 29649        |\n",
      "|    total_timesteps      | 3319808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150424875 |\n",
      "|    clip_fraction        | 0.0692       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.9        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 16200        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | -2.2915416   |\n",
      "|    std                  | 7.67         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1622         |\n",
      "|    time_elapsed         | 29667        |\n",
      "|    total_timesteps      | 3321856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029711844 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 16210        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | -0.16785978  |\n",
      "|    std                  | 7.67         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1623        |\n",
      "|    time_elapsed         | 29684       |\n",
      "|    total_timesteps      | 3323904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003777944 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 16220       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | -2.017972   |\n",
      "|    std                  | 7.67        |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3296889.43\n",
      "total_reward: 2296889.43\n",
      "total_cost: 37255.03\n",
      "total_trades: 51863\n",
      "Sharpe: 0.644\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1624         |\n",
      "|    time_elapsed         | 29702        |\n",
      "|    total_timesteps      | 3325952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028170662 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 16230        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 0.22796112   |\n",
      "|    std                  | 7.68         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 29720       |\n",
      "|    total_timesteps      | 3328000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013398794 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 16240       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | -0.15068829 |\n",
      "|    std                  | 7.7         |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1626         |\n",
      "|    time_elapsed         | 29738        |\n",
      "|    total_timesteps      | 3330048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018953483 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 16250        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | -0.728426    |\n",
      "|    std                  | 7.7          |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1627         |\n",
      "|    time_elapsed         | 29757        |\n",
      "|    total_timesteps      | 3332096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031289621 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 16260        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 3.248219     |\n",
      "|    std                  | 7.71         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1628        |\n",
      "|    time_elapsed         | 29775       |\n",
      "|    total_timesteps      | 3334144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009725018 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | -0.75831056 |\n",
      "|    std                  | 7.73        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1629         |\n",
      "|    time_elapsed         | 29794        |\n",
      "|    total_timesteps      | 3336192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025033662 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 16280        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 0.39116457   |\n",
      "|    std                  | 7.73         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1630        |\n",
      "|    time_elapsed         | 29812       |\n",
      "|    total_timesteps      | 3338240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004310579 |\n",
      "|    clip_fraction        | 0.00854     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 16290       |\n",
      "|    policy_gradient_loss | -0.000679   |\n",
      "|    reward               | 2.070448    |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1631        |\n",
      "|    time_elapsed         | 29830       |\n",
      "|    total_timesteps      | 3340288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009254289 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | -4.454092   |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 29848       |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011059356 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | -0.24253155 |\n",
      "|    std                  | 7.75        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1633        |\n",
      "|    time_elapsed         | 29866       |\n",
      "|    total_timesteps      | 3344384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008530837 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 16320       |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    reward               | 0.35661098  |\n",
      "|    std                  | 7.75        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1634         |\n",
      "|    time_elapsed         | 29884        |\n",
      "|    total_timesteps      | 3346432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021040938 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 16330        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | -0.52420896  |\n",
      "|    std                  | 7.75         |\n",
      "|    value_loss           | 60.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1635        |\n",
      "|    time_elapsed         | 29902       |\n",
      "|    total_timesteps      | 3348480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009965197 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | -5.0725155  |\n",
      "|    std                  | 7.76        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1636         |\n",
      "|    time_elapsed         | 29920        |\n",
      "|    total_timesteps      | 3350528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009168972 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 16350        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | -0.45604357  |\n",
      "|    std                  | 7.77         |\n",
      "|    value_loss           | 35.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1637         |\n",
      "|    time_elapsed         | 29939        |\n",
      "|    total_timesteps      | 3352576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039584986 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 16360        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 2.0137994    |\n",
      "|    std                  | 7.77         |\n",
      "|    value_loss           | 38.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3670102.37\n",
      "total_reward: 2670102.37\n",
      "total_cost: 36393.81\n",
      "total_trades: 51395\n",
      "Sharpe: 0.705\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1638         |\n",
      "|    time_elapsed         | 29957        |\n",
      "|    total_timesteps      | 3354624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011959025 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 16370        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 3.3118994    |\n",
      "|    std                  | 7.78         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1639        |\n",
      "|    time_elapsed         | 29975       |\n",
      "|    total_timesteps      | 3356672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002829106 |\n",
      "|    clip_fraction        | 0.00376     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 16380       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    reward               | 0.54391664  |\n",
      "|    std                  | 7.79        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1640        |\n",
      "|    time_elapsed         | 29993       |\n",
      "|    total_timesteps      | 3358720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008105788 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 16390       |\n",
      "|    policy_gradient_loss | -0.000867   |\n",
      "|    reward               | 11.053105   |\n",
      "|    std                  | 7.79        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1641          |\n",
      "|    time_elapsed         | 30011         |\n",
      "|    total_timesteps      | 3360768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029287874 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -100          |\n",
      "|    explained_variance   | 0.537         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.8          |\n",
      "|    n_updates            | 16400         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | -2.8890936    |\n",
      "|    std                  | 7.79          |\n",
      "|    value_loss           | 51.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1642        |\n",
      "|    time_elapsed         | 30029       |\n",
      "|    total_timesteps      | 3362816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009155238 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.73        |\n",
      "|    n_updates            | 16410       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | -0.26840144 |\n",
      "|    std                  | 7.79        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1643         |\n",
      "|    time_elapsed         | 30047        |\n",
      "|    total_timesteps      | 3364864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052679908 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 16420        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.6060209    |\n",
      "|    std                  | 7.81         |\n",
      "|    value_loss           | 39.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1644          |\n",
      "|    time_elapsed         | 30064         |\n",
      "|    total_timesteps      | 3366912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072527607 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -101          |\n",
      "|    explained_variance   | 0.579         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.8          |\n",
      "|    n_updates            | 16430         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | -8.748692     |\n",
      "|    std                  | 7.81          |\n",
      "|    value_loss           | 47            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1645         |\n",
      "|    time_elapsed         | 30082        |\n",
      "|    total_timesteps      | 3368960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016405025 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 16440        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 0.3993859    |\n",
      "|    std                  | 7.82         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1646        |\n",
      "|    time_elapsed         | 30100       |\n",
      "|    total_timesteps      | 3371008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003756439 |\n",
      "|    clip_fraction        | 0.00859     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.29        |\n",
      "|    n_updates            | 16450       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | 0.28446993  |\n",
      "|    std                  | 7.82        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1647         |\n",
      "|    time_elapsed         | 30118        |\n",
      "|    total_timesteps      | 3373056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006156631 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | 2.1925204    |\n",
      "|    std                  | 7.82         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1648         |\n",
      "|    time_elapsed         | 30136        |\n",
      "|    total_timesteps      | 3375104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041828323 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 16470        |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    reward               | 1.3799711    |\n",
      "|    std                  | 7.83         |\n",
      "|    value_loss           | 43.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1649         |\n",
      "|    time_elapsed         | 30154        |\n",
      "|    total_timesteps      | 3377152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056780563 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 16480        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | 0.73889345   |\n",
      "|    std                  | 7.84         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1650         |\n",
      "|    time_elapsed         | 30172        |\n",
      "|    total_timesteps      | 3379200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034380187 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.1         |\n",
      "|    n_updates            | 16490        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 0.15814802   |\n",
      "|    std                  | 7.84         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1651         |\n",
      "|    time_elapsed         | 30191        |\n",
      "|    total_timesteps      | 3381248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005100147 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 16500        |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    reward               | 1.9934754    |\n",
      "|    std                  | 7.84         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4007101.73\n",
      "total_reward: 3007101.73\n",
      "total_cost: 44906.79\n",
      "total_trades: 51564\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1652         |\n",
      "|    time_elapsed         | 30209        |\n",
      "|    total_timesteps      | 3383296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022846928 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 16510        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | -2.098891    |\n",
      "|    std                  | 7.85         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1653         |\n",
      "|    time_elapsed         | 30227        |\n",
      "|    total_timesteps      | 3385344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029670112 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 16520        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | 0.21405566   |\n",
      "|    std                  | 7.85         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1654         |\n",
      "|    time_elapsed         | 30245        |\n",
      "|    total_timesteps      | 3387392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010509385 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 16530        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | 1.2996321    |\n",
      "|    std                  | 7.85         |\n",
      "|    value_loss           | 47.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1655        |\n",
      "|    time_elapsed         | 30263       |\n",
      "|    total_timesteps      | 3389440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002707031 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | 0.8414025   |\n",
      "|    std                  | 7.85        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1656        |\n",
      "|    time_elapsed         | 30281       |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007313302 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 16550       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | -0.598332   |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1657        |\n",
      "|    time_elapsed         | 30299       |\n",
      "|    total_timesteps      | 3393536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008165754 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | 1.4263805   |\n",
      "|    std                  | 7.86        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1658         |\n",
      "|    time_elapsed         | 30317        |\n",
      "|    total_timesteps      | 3395584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003143489 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 16570        |\n",
      "|    policy_gradient_loss | -0.000881    |\n",
      "|    reward               | 0.15795247   |\n",
      "|    std                  | 7.86         |\n",
      "|    value_loss           | 48.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1659        |\n",
      "|    time_elapsed         | 30335       |\n",
      "|    total_timesteps      | 3397632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006148354 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 16580       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | -1.777442   |\n",
      "|    std                  | 7.88        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1660         |\n",
      "|    time_elapsed         | 30353        |\n",
      "|    total_timesteps      | 3399680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010093597 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | -0.09243341  |\n",
      "|    std                  | 7.88         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1661        |\n",
      "|    time_elapsed         | 30371       |\n",
      "|    total_timesteps      | 3401728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002640015 |\n",
      "|    clip_fraction        | 0.00322     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 16600       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    reward               | 1.4286793   |\n",
      "|    std                  | 7.89        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1662        |\n",
      "|    time_elapsed         | 30389       |\n",
      "|    total_timesteps      | 3403776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013522936 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | 0.000469    |\n",
      "|    reward               | -2.7364197  |\n",
      "|    std                  | 7.89        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1663        |\n",
      "|    time_elapsed         | 30407       |\n",
      "|    total_timesteps      | 3405824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007919217 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | 0.22973576  |\n",
      "|    std                  | 7.89        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1664        |\n",
      "|    time_elapsed         | 30425       |\n",
      "|    total_timesteps      | 3407872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004339996 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 16630       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -2.817829   |\n",
      "|    std                  | 7.89        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1665         |\n",
      "|    time_elapsed         | 30443        |\n",
      "|    total_timesteps      | 3409920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053914073 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 16640        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 2.2861304    |\n",
      "|    std                  | 7.9          |\n",
      "|    value_loss           | 51.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3529445.48\n",
      "total_reward: 2529445.48\n",
      "total_cost: 49287.69\n",
      "total_trades: 52066\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1666        |\n",
      "|    time_elapsed         | 30461       |\n",
      "|    total_timesteps      | 3411968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009747608 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    reward               | 2.2761056   |\n",
      "|    std                  | 7.91        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1667        |\n",
      "|    time_elapsed         | 30479       |\n",
      "|    total_timesteps      | 3414016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013384145 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 16660       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | -1.26317    |\n",
      "|    std                  | 7.91        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1668        |\n",
      "|    time_elapsed         | 30496       |\n",
      "|    total_timesteps      | 3416064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004989837 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 16670       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 5.031488    |\n",
      "|    std                  | 7.92        |\n",
      "|    value_loss           | 59.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1669       |\n",
      "|    time_elapsed         | 30515      |\n",
      "|    total_timesteps      | 3418112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01094348 |\n",
      "|    clip_fraction        | 0.0885     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.39       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 16680      |\n",
      "|    policy_gradient_loss | -0.00852   |\n",
      "|    reward               | 1.7646983  |\n",
      "|    std                  | 7.93       |\n",
      "|    value_loss           | 39.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1670         |\n",
      "|    time_elapsed         | 30533        |\n",
      "|    total_timesteps      | 3420160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083395075 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.81         |\n",
      "|    n_updates            | 16690        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    reward               | -0.5204056   |\n",
      "|    std                  | 7.95         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1671         |\n",
      "|    time_elapsed         | 30550        |\n",
      "|    total_timesteps      | 3422208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063203378 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 16700        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | 3.90283      |\n",
      "|    std                  | 7.97         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1672        |\n",
      "|    time_elapsed         | 30568       |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005994943 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | -2.106806   |\n",
      "|    std                  | 7.97        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1673         |\n",
      "|    time_elapsed         | 30586        |\n",
      "|    total_timesteps      | 3426304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061268294 |\n",
      "|    clip_fraction        | 0.0772       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 16720        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | -3.3250794   |\n",
      "|    std                  | 7.98         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1674        |\n",
      "|    time_elapsed         | 30604       |\n",
      "|    total_timesteps      | 3428352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011171567 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 16730       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | 0.6741293   |\n",
      "|    std                  | 7.98        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1675        |\n",
      "|    time_elapsed         | 30622       |\n",
      "|    total_timesteps      | 3430400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010819823 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 16740       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    reward               | -1.3637335  |\n",
      "|    std                  | 7.98        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1676         |\n",
      "|    time_elapsed         | 30640        |\n",
      "|    total_timesteps      | 3432448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065507186 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 16750        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | -5.8863697   |\n",
      "|    std                  | 7.99         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1677        |\n",
      "|    time_elapsed         | 30658       |\n",
      "|    total_timesteps      | 3434496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007704379 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 16760       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | 0.075264454 |\n",
      "|    std                  | 7.99        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1678        |\n",
      "|    time_elapsed         | 30676       |\n",
      "|    total_timesteps      | 3436544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009981083 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 16770       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -1.4264822  |\n",
      "|    std                  | 7.99        |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1679         |\n",
      "|    time_elapsed         | 30694        |\n",
      "|    total_timesteps      | 3438592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101917125 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 16780        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | -1.8141094   |\n",
      "|    std                  | 8            |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3307610.63\n",
      "total_reward: 2307610.63\n",
      "total_cost: 34689.30\n",
      "total_trades: 50345\n",
      "Sharpe: 0.635\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1680        |\n",
      "|    time_elapsed         | 30712       |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010709079 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 1.1219616   |\n",
      "|    std                  | 8.01        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1681        |\n",
      "|    time_elapsed         | 30730       |\n",
      "|    total_timesteps      | 3442688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006705384 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 16800       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | -0.7391422  |\n",
      "|    std                  | 8.02        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1682        |\n",
      "|    time_elapsed         | 30747       |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006141844 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    reward               | 0.25799784  |\n",
      "|    std                  | 8.03        |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1683        |\n",
      "|    time_elapsed         | 30766       |\n",
      "|    total_timesteps      | 3446784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013479401 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    reward               | -1.7093453  |\n",
      "|    std                  | 8.03        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1684         |\n",
      "|    time_elapsed         | 30783        |\n",
      "|    total_timesteps      | 3448832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011286162  |\n",
      "|    clip_fraction        | 0.0562       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 16830        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | -0.050560903 |\n",
      "|    std                  | 8.05         |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1685         |\n",
      "|    time_elapsed         | 30802        |\n",
      "|    total_timesteps      | 3450880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068674153 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 16840        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -5.894188    |\n",
      "|    std                  | 8.06         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1686        |\n",
      "|    time_elapsed         | 30821       |\n",
      "|    total_timesteps      | 3452928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011478603 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 16850       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -0.3862016  |\n",
      "|    std                  | 8.08        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1687        |\n",
      "|    time_elapsed         | 30840       |\n",
      "|    total_timesteps      | 3454976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005572488 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | 1.7535788   |\n",
      "|    std                  | 8.1         |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1688        |\n",
      "|    time_elapsed         | 30858       |\n",
      "|    total_timesteps      | 3457024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005645014 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 16870       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | -0.8921097  |\n",
      "|    std                  | 8.1         |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1689         |\n",
      "|    time_elapsed         | 30876        |\n",
      "|    total_timesteps      | 3459072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005421186 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 16880        |\n",
      "|    policy_gradient_loss | -0.000973    |\n",
      "|    reward               | -1.3283188   |\n",
      "|    std                  | 8.1          |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1690        |\n",
      "|    time_elapsed         | 30894       |\n",
      "|    total_timesteps      | 3461120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012203857 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 16890       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | 0.0123832   |\n",
      "|    std                  | 8.12        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1691         |\n",
      "|    time_elapsed         | 30911        |\n",
      "|    total_timesteps      | 3463168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055628708 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 16900        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 0.8262921    |\n",
      "|    std                  | 8.13         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1692         |\n",
      "|    time_elapsed         | 30929        |\n",
      "|    total_timesteps      | 3465216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057244534 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 16910        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | 2.2693257    |\n",
      "|    std                  | 8.13         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1693         |\n",
      "|    time_elapsed         | 30948        |\n",
      "|    total_timesteps      | 3467264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056618783 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 16920        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -0.12988192  |\n",
      "|    std                  | 8.15         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3398446.78\n",
      "total_reward: 2398446.78\n",
      "total_cost: 34104.67\n",
      "total_trades: 50434\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1694        |\n",
      "|    time_elapsed         | 30966       |\n",
      "|    total_timesteps      | 3469312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008253312 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 16930       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 0.14967287  |\n",
      "|    std                  | 8.15        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1695        |\n",
      "|    time_elapsed         | 30984       |\n",
      "|    total_timesteps      | 3471360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007619098 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 16940       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -2.3775077  |\n",
      "|    std                  | 8.15        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1696        |\n",
      "|    time_elapsed         | 31002       |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007455104 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | -0.3336142  |\n",
      "|    std                  | 8.16        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1697         |\n",
      "|    time_elapsed         | 31021        |\n",
      "|    total_timesteps      | 3475456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076329857 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.85         |\n",
      "|    n_updates            | 16960        |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    reward               | -0.56374574  |\n",
      "|    std                  | 8.16         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1698        |\n",
      "|    time_elapsed         | 31039       |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006113353 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | 0.47591776  |\n",
      "|    std                  | 8.17        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1699        |\n",
      "|    time_elapsed         | 31057       |\n",
      "|    total_timesteps      | 3479552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009935479 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 16980       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | -2.9096117  |\n",
      "|    std                  | 8.18        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1700        |\n",
      "|    time_elapsed         | 31075       |\n",
      "|    total_timesteps      | 3481600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009843996 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 16990       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 0.7405164   |\n",
      "|    std                  | 8.19        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1701         |\n",
      "|    time_elapsed         | 31093        |\n",
      "|    total_timesteps      | 3483648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021344044 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 17000        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 0.060437597  |\n",
      "|    std                  | 8.19         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1702         |\n",
      "|    time_elapsed         | 31111        |\n",
      "|    total_timesteps      | 3485696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047258968 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 17010        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    reward               | 0.3260637    |\n",
      "|    std                  | 8.2          |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1703        |\n",
      "|    time_elapsed         | 31130       |\n",
      "|    total_timesteps      | 3487744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008889488 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 1.2162918   |\n",
      "|    std                  | 8.22        |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1704        |\n",
      "|    time_elapsed         | 31147       |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009623584 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 17030       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | -1.0510446  |\n",
      "|    std                  | 8.23        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1705         |\n",
      "|    time_elapsed         | 31165        |\n",
      "|    total_timesteps      | 3491840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040264786 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 17040        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    reward               | 4.6881094    |\n",
      "|    std                  | 8.24         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 31182       |\n",
      "|    total_timesteps      | 3493888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009581052 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -0.27462444 |\n",
      "|    std                  | 8.24        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1707        |\n",
      "|    time_elapsed         | 31201       |\n",
      "|    total_timesteps      | 3495936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010203198 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 17060       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | -0.72813106 |\n",
      "|    std                  | 8.25        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3756057.01\n",
      "total_reward: 2756057.01\n",
      "total_cost: 36757.70\n",
      "total_trades: 50520\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1708         |\n",
      "|    time_elapsed         | 31241        |\n",
      "|    total_timesteps      | 3497984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026307772 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 17070        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -4.191395    |\n",
      "|    std                  | 8.25         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1709         |\n",
      "|    time_elapsed         | 31259        |\n",
      "|    total_timesteps      | 3500032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033002193 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 17080        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | 3.6492898    |\n",
      "|    std                  | 8.26         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1710         |\n",
      "|    time_elapsed         | 31277        |\n",
      "|    total_timesteps      | 3502080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047771367 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 17090        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | -1.6343814   |\n",
      "|    std                  | 8.27         |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1711         |\n",
      "|    time_elapsed         | 31294        |\n",
      "|    total_timesteps      | 3504128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097137205 |\n",
      "|    clip_fraction        | 0.0675       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 17100        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    reward               | 0.84793955   |\n",
      "|    std                  | 8.29         |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1712        |\n",
      "|    time_elapsed         | 31311       |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007485402 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 17110       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | -0.7090523  |\n",
      "|    std                  | 8.3         |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1713         |\n",
      "|    time_elapsed         | 31329        |\n",
      "|    total_timesteps      | 3508224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064862417 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 17120        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | -1.7880859   |\n",
      "|    std                  | 8.31         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1714        |\n",
      "|    time_elapsed         | 31347       |\n",
      "|    total_timesteps      | 3510272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011182613 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | -0.21051574 |\n",
      "|    std                  | 8.33        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 111        |\n",
      "|    iterations           | 1715       |\n",
      "|    time_elapsed         | 31365      |\n",
      "|    total_timesteps      | 3512320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01226764 |\n",
      "|    clip_fraction        | 0.0339     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | 0.521      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 17140      |\n",
      "|    policy_gradient_loss | -0.00437   |\n",
      "|    reward               | -1.1857995 |\n",
      "|    std                  | 8.34       |\n",
      "|    value_loss           | 33.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1716         |\n",
      "|    time_elapsed         | 31382        |\n",
      "|    total_timesteps      | 3514368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033626521 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 17150        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | 2.7649608    |\n",
      "|    std                  | 8.34         |\n",
      "|    value_loss           | 40.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1717         |\n",
      "|    time_elapsed         | 31400        |\n",
      "|    total_timesteps      | 3516416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108101275 |\n",
      "|    clip_fraction        | 0.0973       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 17160        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    reward               | -0.4893561   |\n",
      "|    std                  | 8.35         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1718        |\n",
      "|    time_elapsed         | 31418       |\n",
      "|    total_timesteps      | 3518464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005946883 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 17170       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | 0.052258525 |\n",
      "|    std                  | 8.36        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1719        |\n",
      "|    time_elapsed         | 31436       |\n",
      "|    total_timesteps      | 3520512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006537151 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 17180       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 2.7349887   |\n",
      "|    std                  | 8.37        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1720         |\n",
      "|    time_elapsed         | 31454        |\n",
      "|    total_timesteps      | 3522560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039515435 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 17190        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 0.6981271    |\n",
      "|    std                  | 8.38         |\n",
      "|    value_loss           | 39.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 31472       |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009101922 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.93        |\n",
      "|    n_updates            | 17200       |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | -1.28815    |\n",
      "|    std                  | 8.39        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3461288.83\n",
      "total_reward: 2461288.83\n",
      "total_cost: 40748.57\n",
      "total_trades: 49697\n",
      "Sharpe: 0.668\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1722         |\n",
      "|    time_elapsed         | 31490        |\n",
      "|    total_timesteps      | 3526656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051821833 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 17210        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | 0.40682322   |\n",
      "|    std                  | 8.4          |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1723        |\n",
      "|    time_elapsed         | 31508       |\n",
      "|    total_timesteps      | 3528704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003218487 |\n",
      "|    clip_fraction        | 0.00244     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    reward               | -1.6954834  |\n",
      "|    std                  | 8.4         |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1724        |\n",
      "|    time_elapsed         | 31526       |\n",
      "|    total_timesteps      | 3530752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011640204 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 17230       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -0.97683513 |\n",
      "|    std                  | 8.42        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1725        |\n",
      "|    time_elapsed         | 31545       |\n",
      "|    total_timesteps      | 3532800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007422517 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 17240       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | -0.85218966 |\n",
      "|    std                  | 8.42        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1726         |\n",
      "|    time_elapsed         | 31562        |\n",
      "|    total_timesteps      | 3534848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035325335 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | -0.48670363  |\n",
      "|    std                  | 8.43         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1727         |\n",
      "|    time_elapsed         | 31580        |\n",
      "|    total_timesteps      | 3536896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093551725 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 17260        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | -2.3419335   |\n",
      "|    std                  | 8.44         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1728        |\n",
      "|    time_elapsed         | 31598       |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011195022 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 0.19441323  |\n",
      "|    std                  | 8.46        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1729        |\n",
      "|    time_elapsed         | 31616       |\n",
      "|    total_timesteps      | 3540992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003925405 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 17280       |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    reward               | 3.0750327   |\n",
      "|    std                  | 8.47        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1730        |\n",
      "|    time_elapsed         | 31634       |\n",
      "|    total_timesteps      | 3543040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005540062 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 17290       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -5.066547   |\n",
      "|    std                  | 8.47        |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1731        |\n",
      "|    time_elapsed         | 31652       |\n",
      "|    total_timesteps      | 3545088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007952558 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    reward               | -0.7885047  |\n",
      "|    std                  | 8.48        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1732        |\n",
      "|    time_elapsed         | 31669       |\n",
      "|    total_timesteps      | 3547136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008258533 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    reward               | 0.54561937  |\n",
      "|    std                  | 8.48        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1733        |\n",
      "|    time_elapsed         | 31687       |\n",
      "|    total_timesteps      | 3549184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005945115 |\n",
      "|    clip_fraction        | 0.036       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | -0.17445853 |\n",
      "|    std                  | 8.49        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1734        |\n",
      "|    time_elapsed         | 31705       |\n",
      "|    total_timesteps      | 3551232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010542645 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 17330       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -0.21968366 |\n",
      "|    std                  | 8.51        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1735       |\n",
      "|    time_elapsed         | 31723      |\n",
      "|    total_timesteps      | 3553280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00996979 |\n",
      "|    clip_fraction        | 0.0577     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.8       |\n",
      "|    n_updates            | 17340      |\n",
      "|    policy_gradient_loss | -0.00598   |\n",
      "|    reward               | -0.9775814 |\n",
      "|    std                  | 8.52       |\n",
      "|    value_loss           | 23.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1736        |\n",
      "|    time_elapsed         | 31740       |\n",
      "|    total_timesteps      | 3555328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006501223 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 17350       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -6.5940413  |\n",
      "|    std                  | 8.53        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3709541.99\n",
      "total_reward: 2709541.99\n",
      "total_cost: 56241.08\n",
      "total_trades: 51456\n",
      "Sharpe: 0.692\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1737         |\n",
      "|    time_elapsed         | 31758        |\n",
      "|    total_timesteps      | 3557376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063931486 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 17360        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | 0.88356495   |\n",
      "|    std                  | 8.53         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1738        |\n",
      "|    time_elapsed         | 31776       |\n",
      "|    total_timesteps      | 3559424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012669317 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 17370       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | 0.007933154 |\n",
      "|    std                  | 8.55        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1739         |\n",
      "|    time_elapsed         | 31795        |\n",
      "|    total_timesteps      | 3561472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073351804 |\n",
      "|    clip_fraction        | 0.0673       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 17380        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 0.077182844  |\n",
      "|    std                  | 8.56         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1740        |\n",
      "|    time_elapsed         | 31813       |\n",
      "|    total_timesteps      | 3563520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004281897 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 17390       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 0.026859019 |\n",
      "|    std                  | 8.57        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1741        |\n",
      "|    time_elapsed         | 31831       |\n",
      "|    total_timesteps      | 3565568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010202857 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    reward               | 0.04854967  |\n",
      "|    std                  | 8.59        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1742         |\n",
      "|    time_elapsed         | 31849        |\n",
      "|    total_timesteps      | 3567616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061102035 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 17410        |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    reward               | -0.87187654  |\n",
      "|    std                  | 8.6          |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1743        |\n",
      "|    time_elapsed         | 31867       |\n",
      "|    total_timesteps      | 3569664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005797401 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 17420       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | -6.4939027  |\n",
      "|    std                  | 8.6         |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1744        |\n",
      "|    time_elapsed         | 31885       |\n",
      "|    total_timesteps      | 3571712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007319677 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 17430       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | -2.0957453  |\n",
      "|    std                  | 8.61        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1745         |\n",
      "|    time_elapsed         | 31902        |\n",
      "|    total_timesteps      | 3573760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076924497 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 17440        |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | -0.69322187  |\n",
      "|    std                  | 8.61         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1746        |\n",
      "|    time_elapsed         | 31920       |\n",
      "|    total_timesteps      | 3575808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004715161 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 17450       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | 0.94803214  |\n",
      "|    std                  | 8.61        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1747         |\n",
      "|    time_elapsed         | 31938        |\n",
      "|    total_timesteps      | 3577856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044612195 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 17460        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 7.032053     |\n",
      "|    std                  | 8.62         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1748        |\n",
      "|    time_elapsed         | 31956       |\n",
      "|    total_timesteps      | 3579904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009968248 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.69        |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | 0.6656918   |\n",
      "|    std                  | 8.62        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1749        |\n",
      "|    time_elapsed         | 31974       |\n",
      "|    total_timesteps      | 3581952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007836313 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 17480       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | -0.2511833  |\n",
      "|    std                  | 8.65        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1750         |\n",
      "|    time_elapsed         | 31992        |\n",
      "|    total_timesteps      | 3584000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065768557 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 17490        |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | -1.1322242   |\n",
      "|    std                  | 8.66         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3430401.56\n",
      "total_reward: 2430401.56\n",
      "total_cost: 47748.20\n",
      "total_trades: 51138\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1751        |\n",
      "|    time_elapsed         | 32010       |\n",
      "|    total_timesteps      | 3586048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012811359 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    reward               | -1.4860675  |\n",
      "|    std                  | 8.68        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1752        |\n",
      "|    time_elapsed         | 32027       |\n",
      "|    total_timesteps      | 3588096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007365267 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 17510       |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 1.7861294   |\n",
      "|    std                  | 8.69        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1753         |\n",
      "|    time_elapsed         | 32045        |\n",
      "|    total_timesteps      | 3590144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040416047 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 17520        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 2.2424467    |\n",
      "|    std                  | 8.71         |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1754       |\n",
      "|    time_elapsed         | 32063      |\n",
      "|    total_timesteps      | 3592192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00494222 |\n",
      "|    clip_fraction        | 0.0321     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | 0.679      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 17530      |\n",
      "|    policy_gradient_loss | -0.00272   |\n",
      "|    reward               | 0.7436377  |\n",
      "|    std                  | 8.71       |\n",
      "|    value_loss           | 44.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1755         |\n",
      "|    time_elapsed         | 32081        |\n",
      "|    total_timesteps      | 3594240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065009324 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.22         |\n",
      "|    n_updates            | 17540        |\n",
      "|    policy_gradient_loss | -0.00756     |\n",
      "|    reward               | 3.6646817    |\n",
      "|    std                  | 8.73         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1756        |\n",
      "|    time_elapsed         | 32099       |\n",
      "|    total_timesteps      | 3596288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011068657 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 17550       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | -0.01434943 |\n",
      "|    std                  | 8.73        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1757         |\n",
      "|    time_elapsed         | 32117        |\n",
      "|    total_timesteps      | 3598336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048079793 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 17560        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 2.85847      |\n",
      "|    std                  | 8.73         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1758        |\n",
      "|    time_elapsed         | 32135       |\n",
      "|    total_timesteps      | 3600384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006939686 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.94        |\n",
      "|    n_updates            | 17570       |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | -1.8859378  |\n",
      "|    std                  | 8.75        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1759         |\n",
      "|    time_elapsed         | 32154        |\n",
      "|    total_timesteps      | 3602432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042260448 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 17580        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | -0.87000155  |\n",
      "|    std                  | 8.76         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1760         |\n",
      "|    time_elapsed         | 32172        |\n",
      "|    total_timesteps      | 3604480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050433436 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    reward               | 1.8039596    |\n",
      "|    std                  | 8.76         |\n",
      "|    value_loss           | 39.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1761         |\n",
      "|    time_elapsed         | 32189        |\n",
      "|    total_timesteps      | 3606528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013248905 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 17600        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | -0.45046347  |\n",
      "|    std                  | 8.76         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 32207       |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006600711 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.62        |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 1.386784    |\n",
      "|    std                  | 8.76        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1763        |\n",
      "|    time_elapsed         | 32225       |\n",
      "|    total_timesteps      | 3610624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005747785 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 17620       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    reward               | 0.957761    |\n",
      "|    std                  | 8.76        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1764         |\n",
      "|    time_elapsed         | 32244        |\n",
      "|    total_timesteps      | 3612672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036070729 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 17630        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 10.014977    |\n",
      "|    std                  | 8.78         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3524855.68\n",
      "total_reward: 2524855.68\n",
      "total_cost: 51925.95\n",
      "total_trades: 51215\n",
      "Sharpe: 0.683\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 32262       |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008756911 |\n",
      "|    clip_fraction        | 0.0364      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | 1.1254009   |\n",
      "|    std                  | 8.79        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1766       |\n",
      "|    time_elapsed         | 32280      |\n",
      "|    total_timesteps      | 3616768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00504796 |\n",
      "|    clip_fraction        | 0.0231     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | 0.585      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.1       |\n",
      "|    n_updates            | 17650      |\n",
      "|    policy_gradient_loss | -0.00316   |\n",
      "|    reward               | 0.52521634 |\n",
      "|    std                  | 8.8        |\n",
      "|    value_loss           | 38.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1767         |\n",
      "|    time_elapsed         | 32298        |\n",
      "|    total_timesteps      | 3618816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054731667 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 17660        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | 0.60331786   |\n",
      "|    std                  | 8.82         |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1768        |\n",
      "|    time_elapsed         | 32316       |\n",
      "|    total_timesteps      | 3620864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005264036 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 17670       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 1.3529478   |\n",
      "|    std                  | 8.82        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 32334       |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012111917 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 1.8096237   |\n",
      "|    std                  | 8.83        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1770          |\n",
      "|    time_elapsed         | 32352         |\n",
      "|    total_timesteps      | 3624960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007375866   |\n",
      "|    clip_fraction        | 0.0489        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -104          |\n",
      "|    explained_variance   | 0.62          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.3          |\n",
      "|    n_updates            | 17690         |\n",
      "|    policy_gradient_loss | -0.00869      |\n",
      "|    reward               | -0.0151663255 |\n",
      "|    std                  | 8.85          |\n",
      "|    value_loss           | 38.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1771         |\n",
      "|    time_elapsed         | 32370        |\n",
      "|    total_timesteps      | 3627008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021876884 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 17700        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    reward               | -0.6159252   |\n",
      "|    std                  | 8.85         |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 32387       |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005505203 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | 0.6662627   |\n",
      "|    std                  | 8.84        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1773        |\n",
      "|    time_elapsed         | 32405       |\n",
      "|    total_timesteps      | 3631104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006466345 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 17720       |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -1.151165   |\n",
      "|    std                  | 8.85        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1774         |\n",
      "|    time_elapsed         | 32423        |\n",
      "|    total_timesteps      | 3633152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066792853 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 17730        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -1.8595604   |\n",
      "|    std                  | 8.88         |\n",
      "|    value_loss           | 46.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1775        |\n",
      "|    time_elapsed         | 32442       |\n",
      "|    total_timesteps      | 3635200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008592894 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 17740       |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    reward               | 1.5225352   |\n",
      "|    std                  | 8.87        |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1776        |\n",
      "|    time_elapsed         | 32461       |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011891816 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | -0.96984285 |\n",
      "|    std                  | 8.89        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1777       |\n",
      "|    time_elapsed         | 32479      |\n",
      "|    total_timesteps      | 3639296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00818251 |\n",
      "|    clip_fraction        | 0.0387     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.5       |\n",
      "|    n_updates            | 17760      |\n",
      "|    policy_gradient_loss | -0.00608   |\n",
      "|    reward               | 0.42177147 |\n",
      "|    std                  | 8.91       |\n",
      "|    value_loss           | 36.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1778         |\n",
      "|    time_elapsed         | 32497        |\n",
      "|    total_timesteps      | 3641344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061023654 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 17770        |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    reward               | 3.7791455    |\n",
      "|    std                  | 8.93         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3545540.18\n",
      "total_reward: 2545540.18\n",
      "total_cost: 80101.44\n",
      "total_trades: 53522\n",
      "Sharpe: 0.678\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 32515       |\n",
      "|    total_timesteps      | 3643392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011705731 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.17        |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 2.374301    |\n",
      "|    std                  | 8.94        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1780        |\n",
      "|    time_elapsed         | 32533       |\n",
      "|    total_timesteps      | 3645440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009212518 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 17790       |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | 0.3950827   |\n",
      "|    std                  | 8.95        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1781         |\n",
      "|    time_elapsed         | 32552        |\n",
      "|    total_timesteps      | 3647488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032571384 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 17800        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -2.747637    |\n",
      "|    std                  | 8.95         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1782        |\n",
      "|    time_elapsed         | 32570       |\n",
      "|    total_timesteps      | 3649536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010680783 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 17810       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 0.34528527  |\n",
      "|    std                  | 8.96        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1783       |\n",
      "|    time_elapsed         | 32588      |\n",
      "|    total_timesteps      | 3651584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00829179 |\n",
      "|    clip_fraction        | 0.0703     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.659      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 17820      |\n",
      "|    policy_gradient_loss | -0.00513   |\n",
      "|    reward               | 0.49262154 |\n",
      "|    std                  | 8.98       |\n",
      "|    value_loss           | 28.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1784        |\n",
      "|    time_elapsed         | 32606       |\n",
      "|    total_timesteps      | 3653632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007130248 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 17830       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | 2.4466882   |\n",
      "|    std                  | 8.99        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1785        |\n",
      "|    time_elapsed         | 32624       |\n",
      "|    total_timesteps      | 3655680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009462133 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | 1.8196108   |\n",
      "|    std                  | 8.98        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 32642       |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011564775 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.9         |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | -1.1141306  |\n",
      "|    std                  | 9           |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1787        |\n",
      "|    time_elapsed         | 32659       |\n",
      "|    total_timesteps      | 3659776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506751 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 17860       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | 1.452955    |\n",
      "|    std                  | 9.02        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1788         |\n",
      "|    time_elapsed         | 32677        |\n",
      "|    total_timesteps      | 3661824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047294227 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 17870        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | 2.313388     |\n",
      "|    std                  | 9.02         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 32695       |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009631084 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    reward               | 1.2610092   |\n",
      "|    std                  | 9.04        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1790         |\n",
      "|    time_elapsed         | 32713        |\n",
      "|    total_timesteps      | 3665920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069090477 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | 0.22613226   |\n",
      "|    std                  | 9.05         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1791         |\n",
      "|    time_elapsed         | 32731        |\n",
      "|    total_timesteps      | 3667968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076159155 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 17900        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -5.7416754   |\n",
      "|    std                  | 9.06         |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1792        |\n",
      "|    time_elapsed         | 32749       |\n",
      "|    total_timesteps      | 3670016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003292031 |\n",
      "|    clip_fraction        | 0.00439     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 17910       |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | 0.29716262  |\n",
      "|    std                  | 9.07        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3324472.05\n",
      "total_reward: 2324472.05\n",
      "total_cost: 69817.03\n",
      "total_trades: 52281\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1793        |\n",
      "|    time_elapsed         | 32767       |\n",
      "|    total_timesteps      | 3672064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008909154 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.01        |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -1.2222115  |\n",
      "|    std                  | 9.07        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1794         |\n",
      "|    time_elapsed         | 32785        |\n",
      "|    total_timesteps      | 3674112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065921675 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 17930        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | -0.018053982 |\n",
      "|    std                  | 9.08         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1795         |\n",
      "|    time_elapsed         | 32803        |\n",
      "|    total_timesteps      | 3676160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061210995 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 17940        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | 3.089223     |\n",
      "|    std                  | 9.09         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 32820       |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008926654 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.57        |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 3.160621    |\n",
      "|    std                  | 9.11        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1797         |\n",
      "|    time_elapsed         | 32838        |\n",
      "|    total_timesteps      | 3680256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078547755 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 17960        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | -0.20455447  |\n",
      "|    std                  | 9.13         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1798         |\n",
      "|    time_elapsed         | 32857        |\n",
      "|    total_timesteps      | 3682304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048928643 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 17970        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    reward               | -0.32292765  |\n",
      "|    std                  | 9.13         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 32876       |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009140126 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 4.7480164   |\n",
      "|    std                  | 9.15        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1800         |\n",
      "|    time_elapsed         | 32894        |\n",
      "|    total_timesteps      | 3686400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065191495 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 17990        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | 1.0066693    |\n",
      "|    std                  | 9.16         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1801        |\n",
      "|    time_elapsed         | 32912       |\n",
      "|    total_timesteps      | 3688448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004719409 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -0.56643766 |\n",
      "|    std                  | 9.16        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1802         |\n",
      "|    time_elapsed         | 32930        |\n",
      "|    total_timesteps      | 3690496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056351153 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 18010        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    reward               | -4.27913     |\n",
      "|    std                  | 9.16         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 32948       |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009729153 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 18020       |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | -0.476736   |\n",
      "|    std                  | 9.17        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1804        |\n",
      "|    time_elapsed         | 32966       |\n",
      "|    total_timesteps      | 3694592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006825731 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 18030       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | -0.23408048 |\n",
      "|    std                  | 9.18        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1805         |\n",
      "|    time_elapsed         | 32984        |\n",
      "|    total_timesteps      | 3696640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049752556 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 1.1471682    |\n",
      "|    std                  | 9.2          |\n",
      "|    value_loss           | 47.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1806        |\n",
      "|    time_elapsed         | 33003       |\n",
      "|    total_timesteps      | 3698688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007085519 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.01        |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 0.094507    |\n",
      "|    std                  | 9.23        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3239741.92\n",
      "total_reward: 2239741.92\n",
      "total_cost: 70930.37\n",
      "total_trades: 53502\n",
      "Sharpe: 0.626\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1807        |\n",
      "|    time_elapsed         | 33022       |\n",
      "|    total_timesteps      | 3700736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008769835 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 18060       |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | -1.0142746  |\n",
      "|    std                  | 9.24        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1808        |\n",
      "|    time_elapsed         | 33040       |\n",
      "|    total_timesteps      | 3702784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006889737 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 18070       |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | -1.8692305  |\n",
      "|    std                  | 9.24        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1809        |\n",
      "|    time_elapsed         | 33058       |\n",
      "|    total_timesteps      | 3704832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009689033 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | 0.6098003   |\n",
      "|    std                  | 9.27        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1810        |\n",
      "|    time_elapsed         | 33076       |\n",
      "|    total_timesteps      | 3706880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012102008 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 18090       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 1.1004479   |\n",
      "|    std                  | 9.29        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1811         |\n",
      "|    time_elapsed         | 33094        |\n",
      "|    total_timesteps      | 3708928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065331645 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 18100        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    reward               | 1.701615     |\n",
      "|    std                  | 9.3          |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1812         |\n",
      "|    time_elapsed         | 33112        |\n",
      "|    total_timesteps      | 3710976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068422523 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 18110        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -1.0530584   |\n",
      "|    std                  | 9.31         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1813        |\n",
      "|    time_elapsed         | 33131       |\n",
      "|    total_timesteps      | 3713024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010291278 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.69        |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 1.1946054   |\n",
      "|    std                  | 9.31        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1814        |\n",
      "|    time_elapsed         | 33150       |\n",
      "|    total_timesteps      | 3715072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009662978 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.28385568  |\n",
      "|    std                  | 9.33        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1815        |\n",
      "|    time_elapsed         | 33168       |\n",
      "|    total_timesteps      | 3717120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005877564 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 18140       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | -1.5661944  |\n",
      "|    std                  | 9.34        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1816        |\n",
      "|    time_elapsed         | 33186       |\n",
      "|    total_timesteps      | 3719168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004875449 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 18150       |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 1.5409253   |\n",
      "|    std                  | 9.35        |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1817        |\n",
      "|    time_elapsed         | 33203       |\n",
      "|    total_timesteps      | 3721216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011763465 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | 0.43937656  |\n",
      "|    std                  | 9.36        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1818         |\n",
      "|    time_elapsed         | 33222        |\n",
      "|    total_timesteps      | 3723264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070111863 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 18170        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | -2.0989096   |\n",
      "|    std                  | 9.38         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1819         |\n",
      "|    time_elapsed         | 33239        |\n",
      "|    total_timesteps      | 3725312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036097085 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 18180        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | -1.6432331   |\n",
      "|    std                  | 9.38         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 33257       |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01618946  |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | -0.59796256 |\n",
      "|    std                  | 9.42        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3364333.32\n",
      "total_reward: 2364333.32\n",
      "total_cost: 72418.32\n",
      "total_trades: 52847\n",
      "Sharpe: 0.655\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1821        |\n",
      "|    time_elapsed         | 33275       |\n",
      "|    total_timesteps      | 3729408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005396574 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 18200       |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | 0.6832777   |\n",
      "|    std                  | 9.43        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1822         |\n",
      "|    time_elapsed         | 33293        |\n",
      "|    total_timesteps      | 3731456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052650864 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 18210        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | -0.23002821  |\n",
      "|    std                  | 9.43         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1823         |\n",
      "|    time_elapsed         | 33311        |\n",
      "|    total_timesteps      | 3733504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068240636 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 18220        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | 0.10808823   |\n",
      "|    std                  | 9.45         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1824        |\n",
      "|    time_elapsed         | 33329       |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009319622 |\n",
      "|    clip_fraction        | 0.045       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 18230       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 0.6118775   |\n",
      "|    std                  | 9.46        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1825        |\n",
      "|    time_elapsed         | 33347       |\n",
      "|    total_timesteps      | 3737600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422327 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 18240       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | -4.811667   |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1826         |\n",
      "|    time_elapsed         | 33365        |\n",
      "|    total_timesteps      | 3739648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055540805 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 18250        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    reward               | 0.572511     |\n",
      "|    std                  | 9.46         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1827        |\n",
      "|    time_elapsed         | 33383       |\n",
      "|    total_timesteps      | 3741696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009561308 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    reward               | 2.3508804   |\n",
      "|    std                  | 9.48        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 33401       |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009233221 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 18270       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -0.9927604  |\n",
      "|    std                  | 9.49        |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1829        |\n",
      "|    time_elapsed         | 33420       |\n",
      "|    total_timesteps      | 3745792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007060885 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -0.64816433 |\n",
      "|    std                  | 9.5         |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 33439       |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010387681 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.004339402 |\n",
      "|    std                  | 9.5         |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1831         |\n",
      "|    time_elapsed         | 33457        |\n",
      "|    total_timesteps      | 3749888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026603267 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 18300        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 1.9514623    |\n",
      "|    std                  | 9.5          |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1832         |\n",
      "|    time_elapsed         | 33475        |\n",
      "|    total_timesteps      | 3751936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017080284 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 18310        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | -1.2057528   |\n",
      "|    std                  | 9.5          |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1833         |\n",
      "|    time_elapsed         | 33494        |\n",
      "|    total_timesteps      | 3753984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041393726 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 18320        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | 3.199556     |\n",
      "|    std                  | 9.51         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1834        |\n",
      "|    time_elapsed         | 33512       |\n",
      "|    total_timesteps      | 3756032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007637484 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | -0.7367718  |\n",
      "|    std                  | 9.53        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2938612.34\n",
      "total_reward: 1938612.34\n",
      "total_cost: 75559.86\n",
      "total_trades: 52618\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1835         |\n",
      "|    time_elapsed         | 33530        |\n",
      "|    total_timesteps      | 3758080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062354123 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.05         |\n",
      "|    n_updates            | 18340        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    reward               | -1.5047463   |\n",
      "|    std                  | 9.54         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1836         |\n",
      "|    time_elapsed         | 33547        |\n",
      "|    total_timesteps      | 3760128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048301006 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 18350        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 0.50060636   |\n",
      "|    std                  | 9.55         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 33565       |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011352189 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.26        |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -1.3688933  |\n",
      "|    std                  | 9.56        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1838         |\n",
      "|    time_elapsed         | 33583        |\n",
      "|    total_timesteps      | 3764224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038224405 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 18370        |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    reward               | 1.9490342    |\n",
      "|    std                  | 9.56         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1839         |\n",
      "|    time_elapsed         | 33601        |\n",
      "|    total_timesteps      | 3766272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028015825 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 18380        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 1.1295329    |\n",
      "|    std                  | 9.57         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1840         |\n",
      "|    time_elapsed         | 33619        |\n",
      "|    total_timesteps      | 3768320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044072866 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 18390        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    reward               | 2.3148458    |\n",
      "|    std                  | 9.58         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1841        |\n",
      "|    time_elapsed         | 33637       |\n",
      "|    total_timesteps      | 3770368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008877969 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.96        |\n",
      "|    n_updates            | 18400       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -2.7408853  |\n",
      "|    std                  | 9.59        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1842         |\n",
      "|    time_elapsed         | 33654        |\n",
      "|    total_timesteps      | 3772416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037349784 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 18410        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | 8.417643     |\n",
      "|    std                  | 9.6          |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1843         |\n",
      "|    time_elapsed         | 33673        |\n",
      "|    total_timesteps      | 3774464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015217793 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 18420        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | -2.164333    |\n",
      "|    std                  | 9.61         |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1844        |\n",
      "|    time_elapsed         | 33692       |\n",
      "|    total_timesteps      | 3776512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008959925 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.37        |\n",
      "|    n_updates            | 18430       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | -0.8097264  |\n",
      "|    std                  | 9.63        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1845         |\n",
      "|    time_elapsed         | 33711        |\n",
      "|    total_timesteps      | 3778560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049074674 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.67         |\n",
      "|    n_updates            | 18440        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | 0.3131968    |\n",
      "|    std                  | 9.65         |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1846         |\n",
      "|    time_elapsed         | 33729        |\n",
      "|    total_timesteps      | 3780608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034275353 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 18450        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 2.892477     |\n",
      "|    std                  | 9.64         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1847        |\n",
      "|    time_elapsed         | 33748       |\n",
      "|    total_timesteps      | 3782656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006925803 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.77        |\n",
      "|    n_updates            | 18460       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | -0.58255583 |\n",
      "|    std                  | 9.64        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1848         |\n",
      "|    time_elapsed         | 33766        |\n",
      "|    total_timesteps      | 3784704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069683264 |\n",
      "|    clip_fraction        | 0.0536       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.52         |\n",
      "|    n_updates            | 18470        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | 0.35685894   |\n",
      "|    std                  | 9.65         |\n",
      "|    value_loss           | 21.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1849         |\n",
      "|    time_elapsed         | 33784        |\n",
      "|    total_timesteps      | 3786752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037134879 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 18480        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    reward               | -2.3345401   |\n",
      "|    std                  | 9.66         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2911528.94\n",
      "total_reward: 1911528.94\n",
      "total_cost: 77864.10\n",
      "total_trades: 52940\n",
      "Sharpe: 0.569\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1850        |\n",
      "|    time_elapsed         | 33802       |\n",
      "|    total_timesteps      | 3788800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004739671 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 18490       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -0.24651724 |\n",
      "|    std                  | 9.67        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1851         |\n",
      "|    time_elapsed         | 33820        |\n",
      "|    total_timesteps      | 3790848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097868275 |\n",
      "|    clip_fraction        | 0.0793       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.34         |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.00952     |\n",
      "|    reward               | 1.3408628    |\n",
      "|    std                  | 9.68         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1852        |\n",
      "|    time_elapsed         | 33837       |\n",
      "|    total_timesteps      | 3792896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003281384 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 18510       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 0.6521311   |\n",
      "|    std                  | 9.69        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1853       |\n",
      "|    time_elapsed         | 33855      |\n",
      "|    total_timesteps      | 3794944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00369101 |\n",
      "|    clip_fraction        | 0.00444    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 18520      |\n",
      "|    policy_gradient_loss | -0.00296   |\n",
      "|    reward               | -1.2274845 |\n",
      "|    std                  | 9.69       |\n",
      "|    value_loss           | 26.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1854        |\n",
      "|    time_elapsed         | 33873       |\n",
      "|    total_timesteps      | 3796992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011280676 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.56        |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.31940922  |\n",
      "|    std                  | 9.75        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1855         |\n",
      "|    time_elapsed         | 33891        |\n",
      "|    total_timesteps      | 3799040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065913447 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 18540        |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    reward               | 0.07042904   |\n",
      "|    std                  | 9.75         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1856         |\n",
      "|    time_elapsed         | 33908        |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031058658 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | 0.65879154   |\n",
      "|    std                  | 9.76         |\n",
      "|    value_loss           | 39.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1857         |\n",
      "|    time_elapsed         | 33927        |\n",
      "|    total_timesteps      | 3803136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067681456 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 18560        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    reward               | -1.5196314   |\n",
      "|    std                  | 9.76         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1858        |\n",
      "|    time_elapsed         | 33944       |\n",
      "|    total_timesteps      | 3805184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008305789 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 18570       |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    reward               | 2.4554114   |\n",
      "|    std                  | 9.77        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1859         |\n",
      "|    time_elapsed         | 33962        |\n",
      "|    total_timesteps      | 3807232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078118863 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 18580        |\n",
      "|    policy_gradient_loss | -0.00852     |\n",
      "|    reward               | -0.22528656  |\n",
      "|    std                  | 9.78         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1860         |\n",
      "|    time_elapsed         | 33980        |\n",
      "|    total_timesteps      | 3809280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044857757 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 18590        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 1.0037078    |\n",
      "|    std                  | 9.8          |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1861        |\n",
      "|    time_elapsed         | 33998       |\n",
      "|    total_timesteps      | 3811328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011340287 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.87        |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    reward               | 0.037729867 |\n",
      "|    std                  | 9.82        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1862       |\n",
      "|    time_elapsed         | 34016      |\n",
      "|    total_timesteps      | 3813376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00655564 |\n",
      "|    clip_fraction        | 0.0239     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.607      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.3       |\n",
      "|    n_updates            | 18610      |\n",
      "|    policy_gradient_loss | -0.00696   |\n",
      "|    reward               | 0.97192824 |\n",
      "|    std                  | 9.84       |\n",
      "|    value_loss           | 35.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1863         |\n",
      "|    time_elapsed         | 34034        |\n",
      "|    total_timesteps      | 3815424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029508965 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 18620        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -1.5067183   |\n",
      "|    std                  | 9.84         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3477605.69\n",
      "total_reward: 2477605.69\n",
      "total_cost: 77815.10\n",
      "total_trades: 53567\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1864         |\n",
      "|    time_elapsed         | 34052        |\n",
      "|    total_timesteps      | 3817472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054456624 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 18630        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    reward               | -1.2219352   |\n",
      "|    std                  | 9.85         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1865        |\n",
      "|    time_elapsed         | 34070       |\n",
      "|    total_timesteps      | 3819520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010342038 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.9         |\n",
      "|    n_updates            | 18640       |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    reward               | 0.91766185  |\n",
      "|    std                  | 9.89        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1866         |\n",
      "|    time_elapsed         | 34088        |\n",
      "|    total_timesteps      | 3821568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050583007 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 18650        |\n",
      "|    policy_gradient_loss | -0.0083      |\n",
      "|    reward               | 24.247368    |\n",
      "|    std                  | 9.9          |\n",
      "|    value_loss           | 35.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1867         |\n",
      "|    time_elapsed         | 34106        |\n",
      "|    total_timesteps      | 3823616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050732084 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 18660        |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    reward               | 0.075272284  |\n",
      "|    std                  | 9.92         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1868        |\n",
      "|    time_elapsed         | 34124       |\n",
      "|    total_timesteps      | 3825664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015962854 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 18670       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 1.018317    |\n",
      "|    std                  | 9.96        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1869         |\n",
      "|    time_elapsed         | 34142        |\n",
      "|    total_timesteps      | 3827712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048685106 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 18680        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    reward               | -0.12876394  |\n",
      "|    std                  | 9.98         |\n",
      "|    value_loss           | 50.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1870         |\n",
      "|    time_elapsed         | 34160        |\n",
      "|    total_timesteps      | 3829760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013903226 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 18690        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -5.323233    |\n",
      "|    std                  | 9.98         |\n",
      "|    value_loss           | 44.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1871       |\n",
      "|    time_elapsed         | 34178      |\n",
      "|    total_timesteps      | 3831808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00410659 |\n",
      "|    clip_fraction        | 0.0101     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 18700      |\n",
      "|    policy_gradient_loss | -0.00439   |\n",
      "|    reward               | 0.5530414  |\n",
      "|    std                  | 9.99       |\n",
      "|    value_loss           | 42.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1872        |\n",
      "|    time_elapsed         | 34196       |\n",
      "|    total_timesteps      | 3833856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007338516 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.26        |\n",
      "|    n_updates            | 18710       |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    reward               | 0.525327    |\n",
      "|    std                  | 9.98        |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1873         |\n",
      "|    time_elapsed         | 34214        |\n",
      "|    total_timesteps      | 3835904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012685815 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 18720        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 3.379666     |\n",
      "|    std                  | 9.99         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1874        |\n",
      "|    time_elapsed         | 34233       |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005845922 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 18730       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | 1.995477    |\n",
      "|    std                  | 9.99        |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1875         |\n",
      "|    time_elapsed         | 34251        |\n",
      "|    total_timesteps      | 3840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010907531  |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.07         |\n",
      "|    n_updates            | 18740        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | -0.038677804 |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1876         |\n",
      "|    time_elapsed         | 34269        |\n",
      "|    total_timesteps      | 3842048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063912384 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.22         |\n",
      "|    n_updates            | 18750        |\n",
      "|    policy_gradient_loss | -0.00804     |\n",
      "|    reward               | 0.25082394   |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1877         |\n",
      "|    time_elapsed         | 34287        |\n",
      "|    total_timesteps      | 3844096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046542855 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 18760        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | -1.1610851   |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3696750.77\n",
      "total_reward: 2696750.77\n",
      "total_cost: 74331.12\n",
      "total_trades: 53242\n",
      "Sharpe: 0.701\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1878        |\n",
      "|    time_elapsed         | 34304       |\n",
      "|    total_timesteps      | 3846144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015314892 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.64        |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.12573917 |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 34322        |\n",
      "|    total_timesteps      | 3848192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057445616 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -0.12862597  |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1880        |\n",
      "|    time_elapsed         | 34340       |\n",
      "|    total_timesteps      | 3850240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002287237 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 18790       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    reward               | -1.4570673  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1881         |\n",
      "|    time_elapsed         | 34358        |\n",
      "|    total_timesteps      | 3852288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059453784 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 18800        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | 0.8171223    |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 35.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1882        |\n",
      "|    time_elapsed         | 34377       |\n",
      "|    total_timesteps      | 3854336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014062261 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.15        |\n",
      "|    n_updates            | 18810       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -3.3137376  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1883        |\n",
      "|    time_elapsed         | 34395       |\n",
      "|    total_timesteps      | 3856384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007096762 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 18820       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | 0.09083517  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1884         |\n",
      "|    time_elapsed         | 34413        |\n",
      "|    total_timesteps      | 3858432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018288818 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 18830        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | -0.38864243  |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1885         |\n",
      "|    time_elapsed         | 34432        |\n",
      "|    total_timesteps      | 3860480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076437457 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.74         |\n",
      "|    n_updates            | 18840        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | 0.47708976   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1886        |\n",
      "|    time_elapsed         | 34450       |\n",
      "|    total_timesteps      | 3862528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006174271 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 18850       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | -0.3287011  |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 31.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1887         |\n",
      "|    time_elapsed         | 34468        |\n",
      "|    total_timesteps      | 3864576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028232923 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 18860        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | -1.9365371   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1888         |\n",
      "|    time_elapsed         | 34486        |\n",
      "|    total_timesteps      | 3866624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066811983 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 18870        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    reward               | -0.4351542   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 39.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1889         |\n",
      "|    time_elapsed         | 34504        |\n",
      "|    total_timesteps      | 3868672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059461677 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 18880        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 0.026738066  |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1890         |\n",
      "|    time_elapsed         | 34522        |\n",
      "|    total_timesteps      | 3870720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019823906 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 18890        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -2.740256    |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1891         |\n",
      "|    time_elapsed         | 34541        |\n",
      "|    total_timesteps      | 3872768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056264326 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 18900        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | -0.62442476  |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3387794.10\n",
      "total_reward: 2387794.10\n",
      "total_cost: 74324.75\n",
      "total_trades: 53228\n",
      "Sharpe: 0.658\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1892         |\n",
      "|    time_elapsed         | 34559        |\n",
      "|    total_timesteps      | 3874816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077543585 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | -0.00743     |\n",
      "|    reward               | 0.9812517    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1893         |\n",
      "|    time_elapsed         | 34577        |\n",
      "|    total_timesteps      | 3876864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042163283 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 0.8598447    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1894         |\n",
      "|    time_elapsed         | 34595        |\n",
      "|    total_timesteps      | 3878912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048704892 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 18930        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | -1.694995    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1895        |\n",
      "|    time_elapsed         | 34613       |\n",
      "|    total_timesteps      | 3880960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012290083 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 18940       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.39984012  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1896        |\n",
      "|    time_elapsed         | 34631       |\n",
      "|    total_timesteps      | 3883008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008900916 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.88        |\n",
      "|    n_updates            | 18950       |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    reward               | -0.4344989  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1897         |\n",
      "|    time_elapsed         | 34650        |\n",
      "|    total_timesteps      | 3885056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039705513 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 18960        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | -0.57692647  |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1898         |\n",
      "|    time_elapsed         | 34668        |\n",
      "|    total_timesteps      | 3887104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039580734 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 18970        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 2.7605593    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1899        |\n",
      "|    time_elapsed         | 34687       |\n",
      "|    total_timesteps      | 3889152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009168244 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.87        |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | -2.1532815  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1900         |\n",
      "|    time_elapsed         | 34705        |\n",
      "|    total_timesteps      | 3891200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047755362 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 18990        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 0.31122202   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1901        |\n",
      "|    time_elapsed         | 34724       |\n",
      "|    total_timesteps      | 3893248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004244752 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 19000       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 2.121684    |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1902        |\n",
      "|    time_elapsed         | 34742       |\n",
      "|    total_timesteps      | 3895296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008020345 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 0.9592278   |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1903         |\n",
      "|    time_elapsed         | 34760        |\n",
      "|    total_timesteps      | 3897344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046059927 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.68         |\n",
      "|    n_updates            | 19020        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 0.22054297   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 32.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1904         |\n",
      "|    time_elapsed         | 34777        |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027739955 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 19030        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | -0.9776021   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1905        |\n",
      "|    time_elapsed         | 34795       |\n",
      "|    total_timesteps      | 3901440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003723625 |\n",
      "|    clip_fraction        | 0.00703     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 19040       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | -0.55714345 |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3388631.27\n",
      "total_reward: 2388631.27\n",
      "total_cost: 59134.14\n",
      "total_trades: 51689\n",
      "Sharpe: 0.653\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1906        |\n",
      "|    time_elapsed         | 34813       |\n",
      "|    total_timesteps      | 3903488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006132124 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 19050       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 1.2454954   |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1907         |\n",
      "|    time_elapsed         | 34831        |\n",
      "|    total_timesteps      | 3905536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070006726 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    reward               | -3.3182867   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1908         |\n",
      "|    time_elapsed         | 34848        |\n",
      "|    total_timesteps      | 3907584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035323356 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -1.3385826   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 34866       |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012407995 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.52        |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -1.5172546  |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1910        |\n",
      "|    time_elapsed         | 34884       |\n",
      "|    total_timesteps      | 3911680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006985837 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 19090       |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    reward               | 0.008105682 |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1911         |\n",
      "|    time_elapsed         | 34903        |\n",
      "|    total_timesteps      | 3913728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018842616 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 19100        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 0.3165225    |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 1912      |\n",
      "|    time_elapsed         | 34921     |\n",
      "|    total_timesteps      | 3915776   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0112211 |\n",
      "|    clip_fraction        | 0.0714    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -109      |\n",
      "|    explained_variance   | 0.577     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 9.65      |\n",
      "|    n_updates            | 19110     |\n",
      "|    policy_gradient_loss | -0.00987  |\n",
      "|    reward               | 0.6469633 |\n",
      "|    std                  | 10.5      |\n",
      "|    value_loss           | 21.4      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1913         |\n",
      "|    time_elapsed         | 34940        |\n",
      "|    total_timesteps      | 3917824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065775556 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 19120        |\n",
      "|    policy_gradient_loss | -0.0079      |\n",
      "|    reward               | 1.4579761    |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1914        |\n",
      "|    time_elapsed         | 34958       |\n",
      "|    total_timesteps      | 3919872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006470408 |\n",
      "|    clip_fraction        | 0.0363      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 19130       |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | 1.2071276   |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1915         |\n",
      "|    time_elapsed         | 34976        |\n",
      "|    total_timesteps      | 3921920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074118422 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 19140        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    reward               | -0.20988752  |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1916        |\n",
      "|    time_elapsed         | 34994       |\n",
      "|    total_timesteps      | 3923968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007856296 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.79        |\n",
      "|    n_updates            | 19150       |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    reward               | 0.34372967  |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1917        |\n",
      "|    time_elapsed         | 35012       |\n",
      "|    total_timesteps      | 3926016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007315998 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 19160       |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | 2.1961048   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1918         |\n",
      "|    time_elapsed         | 35030        |\n",
      "|    total_timesteps      | 3928064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029087532 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 19170        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 0.36147368   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1919        |\n",
      "|    time_elapsed         | 35049       |\n",
      "|    total_timesteps      | 3930112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010200785 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.76        |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 1.2393608   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2864063.33\n",
      "total_reward: 1864063.33\n",
      "total_cost: 69184.92\n",
      "total_trades: 52808\n",
      "Sharpe: 0.576\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1920         |\n",
      "|    time_elapsed         | 35067        |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036485898 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 19190        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -0.18485421  |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1921         |\n",
      "|    time_elapsed         | 35084        |\n",
      "|    total_timesteps      | 3934208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034197546 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 19200        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 1.7889769    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1922        |\n",
      "|    time_elapsed         | 35102       |\n",
      "|    total_timesteps      | 3936256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009176353 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 19210       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.0982866   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1923        |\n",
      "|    time_elapsed         | 35120       |\n",
      "|    total_timesteps      | 3938304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010073098 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.14978012  |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1924        |\n",
      "|    time_elapsed         | 35138       |\n",
      "|    total_timesteps      | 3940352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010421429 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 19230       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -0.8762952  |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1925         |\n",
      "|    time_elapsed         | 35156        |\n",
      "|    total_timesteps      | 3942400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021670184 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 19240        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | 1.5601145    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1926        |\n",
      "|    time_elapsed         | 35174       |\n",
      "|    total_timesteps      | 3944448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013089624 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.97        |\n",
      "|    n_updates            | 19250       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -1.0601202  |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1927         |\n",
      "|    time_elapsed         | 35192        |\n",
      "|    total_timesteps      | 3946496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077075385 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | -0.10549215  |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1928         |\n",
      "|    time_elapsed         | 35211        |\n",
      "|    total_timesteps      | 3948544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005766674 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 19270        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | 0.12833835   |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1929         |\n",
      "|    time_elapsed         | 35231        |\n",
      "|    total_timesteps      | 3950592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074083405 |\n",
      "|    clip_fraction        | 0.067        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 19280        |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    reward               | -0.78418916  |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1930         |\n",
      "|    time_elapsed         | 35249        |\n",
      "|    total_timesteps      | 3952640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065616807 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.45         |\n",
      "|    n_updates            | 19290        |\n",
      "|    policy_gradient_loss | -0.00869     |\n",
      "|    reward               | 0.4269687    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1931         |\n",
      "|    time_elapsed         | 35268        |\n",
      "|    total_timesteps      | 3954688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054384065 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 19300        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -5.761547    |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1932         |\n",
      "|    time_elapsed         | 35288        |\n",
      "|    total_timesteps      | 3956736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040677786 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 19310        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    reward               | 1.4435257    |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1933        |\n",
      "|    time_elapsed         | 35307       |\n",
      "|    total_timesteps      | 3958784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009287078 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.33        |\n",
      "|    n_updates            | 19320       |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | -0.47086737 |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3328832.23\n",
      "total_reward: 2328832.23\n",
      "total_cost: 52478.73\n",
      "total_trades: 51104\n",
      "Sharpe: 0.651\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1934         |\n",
      "|    time_elapsed         | 35325        |\n",
      "|    total_timesteps      | 3960832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040736375 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 19330        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -0.100636646 |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1935         |\n",
      "|    time_elapsed         | 35344        |\n",
      "|    total_timesteps      | 3962880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026557832 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.9         |\n",
      "|    n_updates            | 19340        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -0.9490725   |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 37.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1936        |\n",
      "|    time_elapsed         | 35363       |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007563212 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.76        |\n",
      "|    n_updates            | 19350       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    reward               | -6.707254   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1937        |\n",
      "|    time_elapsed         | 35381       |\n",
      "|    total_timesteps      | 3966976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008664965 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.55        |\n",
      "|    n_updates            | 19360       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | -2.8724597  |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1938         |\n",
      "|    time_elapsed         | 35400        |\n",
      "|    total_timesteps      | 3969024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019162849 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.58         |\n",
      "|    n_updates            | 19370        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -0.6809154   |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1939        |\n",
      "|    time_elapsed         | 35419       |\n",
      "|    total_timesteps      | 3971072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006897509 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 19380       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | 0.4194189   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1940        |\n",
      "|    time_elapsed         | 35437       |\n",
      "|    total_timesteps      | 3973120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00967631  |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.45        |\n",
      "|    n_updates            | 19390       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | -0.84880155 |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1941        |\n",
      "|    time_elapsed         | 35455       |\n",
      "|    total_timesteps      | 3975168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009053776 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 19400       |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    reward               | 0.53728205  |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1942         |\n",
      "|    time_elapsed         | 35473        |\n",
      "|    total_timesteps      | 3977216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027053163 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 19410        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | -3.3803136   |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1943         |\n",
      "|    time_elapsed         | 35492        |\n",
      "|    total_timesteps      | 3979264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010319036  |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.73         |\n",
      "|    n_updates            | 19420        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    reward               | -0.010099157 |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1944        |\n",
      "|    time_elapsed         | 35511       |\n",
      "|    total_timesteps      | 3981312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008741155 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.87        |\n",
      "|    n_updates            | 19430       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.25968325  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1945         |\n",
      "|    time_elapsed         | 35530        |\n",
      "|    total_timesteps      | 3983360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030744837 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 19440        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 1.8924637    |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 39           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1946        |\n",
      "|    time_elapsed         | 35548       |\n",
      "|    total_timesteps      | 3985408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004932696 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 19450       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | 1.1110961   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1947         |\n",
      "|    time_elapsed         | 35566        |\n",
      "|    total_timesteps      | 3987456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064406493 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | -0.00947     |\n",
      "|    reward               | -1.8984026   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3126326.72\n",
      "total_reward: 2126326.72\n",
      "total_cost: 73993.61\n",
      "total_trades: 53574\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1948        |\n",
      "|    time_elapsed         | 35585       |\n",
      "|    total_timesteps      | 3989504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007822451 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 19470       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | 0.26829013  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1949         |\n",
      "|    time_elapsed         | 35603        |\n",
      "|    total_timesteps      | 3991552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036421726 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 19480        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 1.3344313    |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1950        |\n",
      "|    time_elapsed         | 35622       |\n",
      "|    total_timesteps      | 3993600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011502074 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.43        |\n",
      "|    n_updates            | 19490       |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -1.3867003  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1951        |\n",
      "|    time_elapsed         | 35640       |\n",
      "|    total_timesteps      | 3995648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00593903  |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 19500       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.64971524 |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1952        |\n",
      "|    time_elapsed         | 35658       |\n",
      "|    total_timesteps      | 3997696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004211936 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 19510       |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | -2.7100675  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1953        |\n",
      "|    time_elapsed         | 35676       |\n",
      "|    total_timesteps      | 3999744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009453707 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 19520       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | -0.4153528  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1954         |\n",
      "|    time_elapsed         | 35694        |\n",
      "|    total_timesteps      | 4001792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067769643 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    reward               | -0.60660934  |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1955        |\n",
      "|    time_elapsed         | 35711       |\n",
      "|    total_timesteps      | 4003840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005749983 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 19540       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -7.6608887  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1956         |\n",
      "|    time_elapsed         | 35729        |\n",
      "|    total_timesteps      | 4005888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057677785 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 19550        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | 1.5654099    |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 35747       |\n",
      "|    total_timesteps      | 4007936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008794843 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 19560       |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | 0.18158607  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1958         |\n",
      "|    time_elapsed         | 35765        |\n",
      "|    total_timesteps      | 4009984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044779046 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 19570        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | -1.028837    |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1959         |\n",
      "|    time_elapsed         | 35783        |\n",
      "|    total_timesteps      | 4012032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045074904 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    reward               | -1.3641939   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1960        |\n",
      "|    time_elapsed         | 35800       |\n",
      "|    total_timesteps      | 4014080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007924245 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 19590       |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | 0.4500338   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1961        |\n",
      "|    time_elapsed         | 35818       |\n",
      "|    total_timesteps      | 4016128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00414165  |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.28        |\n",
      "|    n_updates            | 19600       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | -0.14021146 |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1962         |\n",
      "|    time_elapsed         | 35836        |\n",
      "|    total_timesteps      | 4018176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036381918 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 19610        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 1.3922001    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3314021.66\n",
      "total_reward: 2314021.66\n",
      "total_cost: 66485.54\n",
      "total_trades: 52879\n",
      "Sharpe: 0.622\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1963         |\n",
      "|    time_elapsed         | 35854        |\n",
      "|    total_timesteps      | 4020224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056411372 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 19620        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 0.04186468   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1964       |\n",
      "|    time_elapsed         | 35872      |\n",
      "|    total_timesteps      | 4022272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.009278   |\n",
      "|    clip_fraction        | 0.0628     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.68       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.76       |\n",
      "|    n_updates            | 19630      |\n",
      "|    policy_gradient_loss | -0.00924   |\n",
      "|    reward               | -0.9244447 |\n",
      "|    std                  | 11.2       |\n",
      "|    value_loss           | 17.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1965        |\n",
      "|    time_elapsed         | 35890       |\n",
      "|    total_timesteps      | 4024320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006492614 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 19640       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | 0.88920075  |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1966        |\n",
      "|    time_elapsed         | 35908       |\n",
      "|    total_timesteps      | 4026368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006734019 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 19650       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 0.7654641   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 35926       |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013566513 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 19660       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.6651206   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1968         |\n",
      "|    time_elapsed         | 35944        |\n",
      "|    total_timesteps      | 4030464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047521023 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 19670        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    reward               | -1.8990165   |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1969         |\n",
      "|    time_elapsed         | 35962        |\n",
      "|    total_timesteps      | 4032512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021361967 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | -0.29866156  |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1970        |\n",
      "|    time_elapsed         | 35980       |\n",
      "|    total_timesteps      | 4034560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006956638 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 19690       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 0.7198391   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1971         |\n",
      "|    time_elapsed         | 35998        |\n",
      "|    total_timesteps      | 4036608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070343553 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 19700        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    reward               | 0.4366764    |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1972        |\n",
      "|    time_elapsed         | 36017       |\n",
      "|    total_timesteps      | 4038656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004503095 |\n",
      "|    clip_fraction        | 0.0084      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 19710       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | 0.04339258  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1973         |\n",
      "|    time_elapsed         | 36035        |\n",
      "|    total_timesteps      | 4040704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036403881 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 19720        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | -0.6398503   |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 36053       |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008639123 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 19730       |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | -0.3046375  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1975         |\n",
      "|    time_elapsed         | 36071        |\n",
      "|    total_timesteps      | 4044800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037351009 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 19740        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | -3.201129    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1976         |\n",
      "|    time_elapsed         | 36091        |\n",
      "|    total_timesteps      | 4046848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031587174 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 19750        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | -1.3985268   |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3294247.66\n",
      "total_reward: 2294247.66\n",
      "total_cost: 81184.48\n",
      "total_trades: 54590\n",
      "Sharpe: 0.628\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1977        |\n",
      "|    time_elapsed         | 36109       |\n",
      "|    total_timesteps      | 4048896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006662848 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 19760       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | -0.7734436  |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1978         |\n",
      "|    time_elapsed         | 36128        |\n",
      "|    total_timesteps      | 4050944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065558995 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 19770        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    reward               | -2.291293    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1979         |\n",
      "|    time_elapsed         | 36146        |\n",
      "|    total_timesteps      | 4052992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048830826 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 19780        |\n",
      "|    policy_gradient_loss | -0.00851     |\n",
      "|    reward               | -1.4116638   |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1980         |\n",
      "|    time_elapsed         | 36164        |\n",
      "|    total_timesteps      | 4055040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025485756 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 19790        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | 2.0330305    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1981        |\n",
      "|    time_elapsed         | 36182       |\n",
      "|    total_timesteps      | 4057088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009623292 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 19800       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.04013926 |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1982         |\n",
      "|    time_elapsed         | 36200        |\n",
      "|    total_timesteps      | 4059136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059215445 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 19810        |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    reward               | 0.23037079   |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1983         |\n",
      "|    time_elapsed         | 36217        |\n",
      "|    total_timesteps      | 4061184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017123995 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | -2.4707923   |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1984         |\n",
      "|    time_elapsed         | 36235        |\n",
      "|    total_timesteps      | 4063232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097566545 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 19830        |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | 2.3776133    |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1985        |\n",
      "|    time_elapsed         | 36253       |\n",
      "|    total_timesteps      | 4065280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007756634 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 19840       |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -0.9123066  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 22.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1986         |\n",
      "|    time_elapsed         | 36271        |\n",
      "|    total_timesteps      | 4067328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065956176 |\n",
      "|    clip_fraction        | 0.0451       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 19850        |\n",
      "|    policy_gradient_loss | -0.00849     |\n",
      "|    reward               | 0.05369082   |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1987        |\n",
      "|    time_elapsed         | 36289       |\n",
      "|    total_timesteps      | 4069376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005106355 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 19860       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 1.2731755   |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1988        |\n",
      "|    time_elapsed         | 36307       |\n",
      "|    total_timesteps      | 4071424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009404138 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71        |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    reward               | -0.60287535 |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1989         |\n",
      "|    time_elapsed         | 36325        |\n",
      "|    total_timesteps      | 4073472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035496429 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 19880        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | -0.4204255   |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1990        |\n",
      "|    time_elapsed         | 36343       |\n",
      "|    total_timesteps      | 4075520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008497668 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 19890       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | -4.4078765  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3287371.80\n",
      "total_reward: 2287371.80\n",
      "total_cost: 79408.98\n",
      "total_trades: 54169\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1991        |\n",
      "|    time_elapsed         | 36360       |\n",
      "|    total_timesteps      | 4077568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010010647 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 19900       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.1223168   |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1992        |\n",
      "|    time_elapsed         | 36378       |\n",
      "|    total_timesteps      | 4079616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005449972 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 19910       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | 0.9052029   |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1993        |\n",
      "|    time_elapsed         | 36396       |\n",
      "|    total_timesteps      | 4081664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005104105 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 19920       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | -1.0426601  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1994        |\n",
      "|    time_elapsed         | 36414       |\n",
      "|    total_timesteps      | 4083712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008759281 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | -3.2433708  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1995         |\n",
      "|    time_elapsed         | 36432        |\n",
      "|    total_timesteps      | 4085760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040976526 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 19940        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 0.5782558    |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 25.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1996        |\n",
      "|    time_elapsed         | 36450       |\n",
      "|    total_timesteps      | 4087808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004505085 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 19950       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    reward               | 2.1143327   |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1997         |\n",
      "|    time_elapsed         | 36468        |\n",
      "|    total_timesteps      | 4089856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033294996 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 19960        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 5.46304      |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1998        |\n",
      "|    time_elapsed         | 36486       |\n",
      "|    total_timesteps      | 4091904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011727128 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.28        |\n",
      "|    n_updates            | 19970       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.08463613  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1999         |\n",
      "|    time_elapsed         | 36504        |\n",
      "|    total_timesteps      | 4093952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043409793 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 19980        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -3.9117205   |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2000        |\n",
      "|    time_elapsed         | 36522       |\n",
      "|    total_timesteps      | 4096000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007358596 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 19990       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | 0.98924357  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2001        |\n",
      "|    time_elapsed         | 36541       |\n",
      "|    total_timesteps      | 4098048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011562115 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 20000       |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    reward               | -1.7487231  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2002        |\n",
      "|    time_elapsed         | 36559       |\n",
      "|    total_timesteps      | 4100096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008026984 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 20010       |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | 1.8435612   |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2003        |\n",
      "|    time_elapsed         | 36577       |\n",
      "|    total_timesteps      | 4102144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006245143 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 20020       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 1.2772646   |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2004         |\n",
      "|    time_elapsed         | 36596        |\n",
      "|    total_timesteps      | 4104192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032387848 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    reward               | -1.1645178   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3346401.63\n",
      "total_reward: 2346401.63\n",
      "total_cost: 70560.26\n",
      "total_trades: 53295\n",
      "Sharpe: 0.640\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2005        |\n",
      "|    time_elapsed         | 36614       |\n",
      "|    total_timesteps      | 4106240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010850515 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.13        |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -1.4837006  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2006         |\n",
      "|    time_elapsed         | 36632        |\n",
      "|    total_timesteps      | 4108288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051535573 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 20050        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | -1.7120116   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2007         |\n",
      "|    time_elapsed         | 36650        |\n",
      "|    total_timesteps      | 4110336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020904788 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 20060        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | 4.4718347    |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2008        |\n",
      "|    time_elapsed         | 36668       |\n",
      "|    total_timesteps      | 4112384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011743031 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.63119036 |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2009         |\n",
      "|    time_elapsed         | 36686        |\n",
      "|    total_timesteps      | 4114432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067802714 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 20080        |\n",
      "|    policy_gradient_loss | -0.00877     |\n",
      "|    reward               | -0.25987294  |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2010        |\n",
      "|    time_elapsed         | 36705       |\n",
      "|    total_timesteps      | 4116480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002668687 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 20090       |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    reward               | 2.2377071   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2011         |\n",
      "|    time_elapsed         | 36723        |\n",
      "|    total_timesteps      | 4118528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040635085 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 20100        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -1.2432079   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2012        |\n",
      "|    time_elapsed         | 36743       |\n",
      "|    total_timesteps      | 4120576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007956285 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.21        |\n",
      "|    n_updates            | 20110       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 0.2133779   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2013        |\n",
      "|    time_elapsed         | 36762       |\n",
      "|    total_timesteps      | 4122624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006636493 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 20120       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | -1.1418567  |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2014        |\n",
      "|    time_elapsed         | 36782       |\n",
      "|    total_timesteps      | 4124672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006485878 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 20130       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | 2.990488    |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2015        |\n",
      "|    time_elapsed         | 36800       |\n",
      "|    total_timesteps      | 4126720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010020725 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.89        |\n",
      "|    n_updates            | 20140       |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | 0.43148544  |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2016         |\n",
      "|    time_elapsed         | 36818        |\n",
      "|    total_timesteps      | 4128768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030093207 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 20150        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | 0.4089388    |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2017         |\n",
      "|    time_elapsed         | 36836        |\n",
      "|    total_timesteps      | 4130816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017372856 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 20160        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    reward               | -3.2800405   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2018         |\n",
      "|    time_elapsed         | 36854        |\n",
      "|    total_timesteps      | 4132864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062365774 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 20170        |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    reward               | -3.8340194   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3187511.84\n",
      "total_reward: 2187511.84\n",
      "total_cost: 62985.58\n",
      "total_trades: 52292\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2019        |\n",
      "|    time_elapsed         | 36872       |\n",
      "|    total_timesteps      | 4134912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007211679 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 20180       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | -0.58464354 |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2020         |\n",
      "|    time_elapsed         | 36890        |\n",
      "|    total_timesteps      | 4136960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041203564 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.55         |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | -7.9477434   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2021         |\n",
      "|    time_elapsed         | 36909        |\n",
      "|    total_timesteps      | 4139008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026452357 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 20200        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 1.2132652    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2022        |\n",
      "|    time_elapsed         | 36927       |\n",
      "|    total_timesteps      | 4141056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011980832 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 20210       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 1.079729    |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2023        |\n",
      "|    time_elapsed         | 36944       |\n",
      "|    total_timesteps      | 4143104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006461816 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 20220       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | 0.78244597  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2024         |\n",
      "|    time_elapsed         | 36962        |\n",
      "|    total_timesteps      | 4145152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032441262 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 20230        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | -0.6068311   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2025        |\n",
      "|    time_elapsed         | 36980       |\n",
      "|    total_timesteps      | 4147200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009408655 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 20240       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    reward               | 1.1568863   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2026        |\n",
      "|    time_elapsed         | 36999       |\n",
      "|    total_timesteps      | 4149248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006518705 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 20250       |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | -4.971276   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2027        |\n",
      "|    time_elapsed         | 37016       |\n",
      "|    total_timesteps      | 4151296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005611926 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 20260       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 0.1972902   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2028         |\n",
      "|    time_elapsed         | 37035        |\n",
      "|    total_timesteps      | 4153344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030758858 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 20270        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | 1.7489202    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2029        |\n",
      "|    time_elapsed         | 37053       |\n",
      "|    total_timesteps      | 4155392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009476872 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.32        |\n",
      "|    n_updates            | 20280       |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 1.0879871   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2030        |\n",
      "|    time_elapsed         | 37071       |\n",
      "|    total_timesteps      | 4157440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004946764 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.55        |\n",
      "|    n_updates            | 20290       |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    reward               | -1.9679644  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2031         |\n",
      "|    time_elapsed         | 37089        |\n",
      "|    total_timesteps      | 4159488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026902612 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 20300        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | 2.0716684    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2032        |\n",
      "|    time_elapsed         | 37108       |\n",
      "|    total_timesteps      | 4161536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011401195 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.66        |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -1.5324252  |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3067895.48\n",
      "total_reward: 2067895.48\n",
      "total_cost: 66896.93\n",
      "total_trades: 52290\n",
      "Sharpe: 0.598\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2033        |\n",
      "|    time_elapsed         | 37126       |\n",
      "|    total_timesteps      | 4163584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004559218 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.34        |\n",
      "|    n_updates            | 20320       |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | 2.0018365   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2034         |\n",
      "|    time_elapsed         | 37144        |\n",
      "|    total_timesteps      | 4165632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033261175 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 20330        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | 6.3375936    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2035         |\n",
      "|    time_elapsed         | 37162        |\n",
      "|    total_timesteps      | 4167680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046807528 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 20340        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | 0.16443022   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2036       |\n",
      "|    time_elapsed         | 37180      |\n",
      "|    total_timesteps      | 4169728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00470196 |\n",
      "|    clip_fraction        | 0.0144     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.667      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.36       |\n",
      "|    n_updates            | 20350      |\n",
      "|    policy_gradient_loss | -0.00598   |\n",
      "|    reward               | 0.5941477  |\n",
      "|    std                  | 12.1       |\n",
      "|    value_loss           | 23.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2037         |\n",
      "|    time_elapsed         | 37198        |\n",
      "|    total_timesteps      | 4171776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040491684 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | 1.2715575    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2038        |\n",
      "|    time_elapsed         | 37216       |\n",
      "|    total_timesteps      | 4173824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005603812 |\n",
      "|    clip_fraction        | 0.0084      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 20370       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | -0.4955045  |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2039        |\n",
      "|    time_elapsed         | 37233       |\n",
      "|    total_timesteps      | 4175872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009851939 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 20380       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -1.2739625  |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2040         |\n",
      "|    time_elapsed         | 37251        |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029021597 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.4          |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 0.7448021    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2041         |\n",
      "|    time_elapsed         | 37269        |\n",
      "|    total_timesteps      | 4179968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034274969 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 20400        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 0.8823167    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2042        |\n",
      "|    time_elapsed         | 37288       |\n",
      "|    total_timesteps      | 4182016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003476751 |\n",
      "|    clip_fraction        | 0.00869     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | 0.63650256  |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2043        |\n",
      "|    time_elapsed         | 37306       |\n",
      "|    total_timesteps      | 4184064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008082256 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 20420       |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | -1.4316388  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2044        |\n",
      "|    time_elapsed         | 37324       |\n",
      "|    total_timesteps      | 4186112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004126781 |\n",
      "|    clip_fraction        | 0.00806     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 20430       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | -11.648103  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2045        |\n",
      "|    time_elapsed         | 37342       |\n",
      "|    total_timesteps      | 4188160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003631907 |\n",
      "|    clip_fraction        | 0.00488     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 20440       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 0.88973427  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2046        |\n",
      "|    time_elapsed         | 37360       |\n",
      "|    total_timesteps      | 4190208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009767527 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.82        |\n",
      "|    n_updates            | 20450       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.4948268  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3155490.43\n",
      "total_reward: 2155490.43\n",
      "total_cost: 67837.84\n",
      "total_trades: 52111\n",
      "Sharpe: 0.615\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2047         |\n",
      "|    time_elapsed         | 37378        |\n",
      "|    total_timesteps      | 4192256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029496658 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.81         |\n",
      "|    n_updates            | 20460        |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | 0.6459842    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2048         |\n",
      "|    time_elapsed         | 37395        |\n",
      "|    total_timesteps      | 4194304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033568726 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 20470        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -3.0156028   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2049         |\n",
      "|    time_elapsed         | 37413        |\n",
      "|    total_timesteps      | 4196352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076338695 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 20480        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    reward               | -2.113068    |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2050         |\n",
      "|    time_elapsed         | 37432        |\n",
      "|    total_timesteps      | 4198400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047686617 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 20490        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | 3.353758     |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2051        |\n",
      "|    time_elapsed         | 37450       |\n",
      "|    total_timesteps      | 4200448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004175842 |\n",
      "|    clip_fraction        | 0.00625     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 20500       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -4.610743   |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2052         |\n",
      "|    time_elapsed         | 37469        |\n",
      "|    total_timesteps      | 4202496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048887236 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 20510        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 1.7454396    |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2053        |\n",
      "|    time_elapsed         | 37487       |\n",
      "|    total_timesteps      | 4204544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008601755 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 20520       |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 1.7361836   |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2054         |\n",
      "|    time_elapsed         | 37504        |\n",
      "|    total_timesteps      | 4206592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044476837 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    reward               | 0.55592364   |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2055         |\n",
      "|    time_elapsed         | 37522        |\n",
      "|    total_timesteps      | 4208640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018261853 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 20540        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -1.8677229   |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2056        |\n",
      "|    time_elapsed         | 37541       |\n",
      "|    total_timesteps      | 4210688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010952003 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 20550       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 1.6112709   |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2057         |\n",
      "|    time_elapsed         | 37559        |\n",
      "|    total_timesteps      | 4212736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042428058 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    reward               | 0.57402474   |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2058        |\n",
      "|    time_elapsed         | 37577       |\n",
      "|    total_timesteps      | 4214784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004791623 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 20570       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 1.056654    |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2059        |\n",
      "|    time_elapsed         | 37595       |\n",
      "|    total_timesteps      | 4216832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004051026 |\n",
      "|    clip_fraction        | 0.00977     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 20580       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | 5.0652413   |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2060         |\n",
      "|    time_elapsed         | 37613        |\n",
      "|    total_timesteps      | 4218880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035715038 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 20590        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | -0.5911206   |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3685412.09\n",
      "total_reward: 2685412.09\n",
      "total_cost: 79300.64\n",
      "total_trades: 53063\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2061        |\n",
      "|    time_elapsed         | 37631       |\n",
      "|    total_timesteps      | 4220928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005355013 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 20600       |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | 0.3829694   |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2062         |\n",
      "|    time_elapsed         | 37649        |\n",
      "|    total_timesteps      | 4222976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030488768 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 20610        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | 0.37103382   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2063         |\n",
      "|    time_elapsed         | 37667        |\n",
      "|    total_timesteps      | 4225024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01152857   |\n",
      "|    clip_fraction        | 0.0892       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.27         |\n",
      "|    n_updates            | 20620        |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    reward               | -0.066084474 |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2064        |\n",
      "|    time_elapsed         | 37685       |\n",
      "|    total_timesteps      | 4227072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004457777 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 20630       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | 0.33733183  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2065         |\n",
      "|    time_elapsed         | 37703        |\n",
      "|    total_timesteps      | 4229120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010543878 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 20640        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 0.39568707   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2066         |\n",
      "|    time_elapsed         | 37722        |\n",
      "|    total_timesteps      | 4231168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069064824 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 20650        |\n",
      "|    policy_gradient_loss | -0.00941     |\n",
      "|    reward               | 1.3190814    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2067         |\n",
      "|    time_elapsed         | 37740        |\n",
      "|    total_timesteps      | 4233216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053617368 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.63         |\n",
      "|    n_updates            | 20660        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    reward               | 0.13496126   |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 19.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2068         |\n",
      "|    time_elapsed         | 37758        |\n",
      "|    total_timesteps      | 4235264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050573135 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | -1.6950115   |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2069         |\n",
      "|    time_elapsed         | 37776        |\n",
      "|    total_timesteps      | 4237312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041106986 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 20680        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | 0.62088317   |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2070         |\n",
      "|    time_elapsed         | 37795        |\n",
      "|    total_timesteps      | 4239360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090614185 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.01         |\n",
      "|    n_updates            | 20690        |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | -1.5189645   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2071         |\n",
      "|    time_elapsed         | 37813        |\n",
      "|    total_timesteps      | 4241408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029028119 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 20700        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -1.2454889   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2072         |\n",
      "|    time_elapsed         | 37832        |\n",
      "|    total_timesteps      | 4243456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013541484 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | 1.2856592    |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2073        |\n",
      "|    time_elapsed         | 37851       |\n",
      "|    total_timesteps      | 4245504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006761279 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 20720       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 1.3857884   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2074        |\n",
      "|    time_elapsed         | 37869       |\n",
      "|    total_timesteps      | 4247552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006911493 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 20730       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | 2.2396388   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2075         |\n",
      "|    time_elapsed         | 37887        |\n",
      "|    total_timesteps      | 4249600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027722176 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 20740        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -0.059932172 |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3220468.28\n",
      "total_reward: 2220468.28\n",
      "total_cost: 88429.32\n",
      "total_trades: 53492\n",
      "Sharpe: 0.624\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2076         |\n",
      "|    time_elapsed         | 37905        |\n",
      "|    total_timesteps      | 4251648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031865612 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 0.9208208    |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2077        |\n",
      "|    time_elapsed         | 37923       |\n",
      "|    total_timesteps      | 4253696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008561887 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.91        |\n",
      "|    n_updates            | 20760       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.4042379  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2078         |\n",
      "|    time_elapsed         | 37940        |\n",
      "|    total_timesteps      | 4255744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036228974 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.41         |\n",
      "|    n_updates            | 20770        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -0.09173551  |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2079         |\n",
      "|    time_elapsed         | 37959        |\n",
      "|    total_timesteps      | 4257792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032378808 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 20780        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | 0.6229074    |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2080        |\n",
      "|    time_elapsed         | 37977       |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011572912 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.38        |\n",
      "|    n_updates            | 20790       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.70766455  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2081         |\n",
      "|    time_elapsed         | 37994        |\n",
      "|    total_timesteps      | 4261888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037739347 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.45         |\n",
      "|    n_updates            | 20800        |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    reward               | 0.19890292   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2082        |\n",
      "|    time_elapsed         | 38012       |\n",
      "|    total_timesteps      | 4263936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002420377 |\n",
      "|    clip_fraction        | 0.00264     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 20810       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | 4.7334976   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2083         |\n",
      "|    time_elapsed         | 38030        |\n",
      "|    total_timesteps      | 4265984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058704726 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 20820        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 1.5761316    |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2084         |\n",
      "|    time_elapsed         | 38048        |\n",
      "|    total_timesteps      | 4268032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074494435 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | -0.00997     |\n",
      "|    reward               | 2.344123     |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2085         |\n",
      "|    time_elapsed         | 38066        |\n",
      "|    total_timesteps      | 4270080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014013606 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 20840        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.51199937   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2086         |\n",
      "|    time_elapsed         | 38084        |\n",
      "|    total_timesteps      | 4272128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018150166 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 20850        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | 0.63212764   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2087        |\n",
      "|    time_elapsed         | 38102       |\n",
      "|    total_timesteps      | 4274176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00805903  |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.95        |\n",
      "|    n_updates            | 20860       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.37309456 |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2088        |\n",
      "|    time_elapsed         | 38121       |\n",
      "|    total_timesteps      | 4276224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006492773 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 20870       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | 0.118202895 |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2089         |\n",
      "|    time_elapsed         | 38139        |\n",
      "|    total_timesteps      | 4278272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017294327 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 3.130074     |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 52           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3298523.24\n",
      "total_reward: 2298523.24\n",
      "total_cost: 88362.81\n",
      "total_trades: 53820\n",
      "Sharpe: 0.638\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2090       |\n",
      "|    time_elapsed         | 38157      |\n",
      "|    total_timesteps      | 4280320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00559697 |\n",
      "|    clip_fraction        | 0.022      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.548      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.6       |\n",
      "|    n_updates            | 20890      |\n",
      "|    policy_gradient_loss | -0.00735   |\n",
      "|    reward               | 0.3723506  |\n",
      "|    std                  | 13.1       |\n",
      "|    value_loss           | 31.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2091         |\n",
      "|    time_elapsed         | 38175        |\n",
      "|    total_timesteps      | 4282368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038163597 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.59         |\n",
      "|    n_updates            | 20900        |\n",
      "|    policy_gradient_loss | -0.00665     |\n",
      "|    reward               | -3.7273352   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2092         |\n",
      "|    time_elapsed         | 38194        |\n",
      "|    total_timesteps      | 4284416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018412776 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 20910        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 1.0022587    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2093         |\n",
      "|    time_elapsed         | 38212        |\n",
      "|    total_timesteps      | 4286464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045456495 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 20920        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | -0.7872082   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2094        |\n",
      "|    time_elapsed         | 38230       |\n",
      "|    total_timesteps      | 4288512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004477998 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.05        |\n",
      "|    n_updates            | 20930       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 0.014470439 |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2095        |\n",
      "|    time_elapsed         | 38248       |\n",
      "|    total_timesteps      | 4290560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007087214 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 20940       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.27443224  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2096        |\n",
      "|    time_elapsed         | 38267       |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000985537 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 20950       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    reward               | 2.2114992   |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2097        |\n",
      "|    time_elapsed         | 38284       |\n",
      "|    total_timesteps      | 4294656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013843585 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 20960       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -0.44742563 |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2098        |\n",
      "|    time_elapsed         | 38302       |\n",
      "|    total_timesteps      | 4296704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005793864 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 20970       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | 0.06517323  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2099         |\n",
      "|    time_elapsed         | 38320        |\n",
      "|    total_timesteps      | 4298752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010933139 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 20980        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | 2.5898554    |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2100         |\n",
      "|    time_elapsed         | 38338        |\n",
      "|    total_timesteps      | 4300800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033089924 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 20990        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | -0.7996962   |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2101        |\n",
      "|    time_elapsed         | 38356       |\n",
      "|    total_timesteps      | 4302848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007340973 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 21000       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.45542756  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2102        |\n",
      "|    time_elapsed         | 38375       |\n",
      "|    total_timesteps      | 4304896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004191503 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 21010       |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | -1.2559031  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2103        |\n",
      "|    time_elapsed         | 38393       |\n",
      "|    total_timesteps      | 4306944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002776568 |\n",
      "|    clip_fraction        | 0.00464     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 21020       |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | 0.08375755  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3882015.68\n",
      "total_reward: 2882015.68\n",
      "total_cost: 114396.74\n",
      "total_trades: 56046\n",
      "Sharpe: 0.723\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2104        |\n",
      "|    time_elapsed         | 38411       |\n",
      "|    total_timesteps      | 4308992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011134451 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 21030       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -1.5113168  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2105        |\n",
      "|    time_elapsed         | 38429       |\n",
      "|    total_timesteps      | 4311040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004437384 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 21040       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | -0.8452568  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2106         |\n",
      "|    time_elapsed         | 38447        |\n",
      "|    total_timesteps      | 4313088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034015556 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 21050        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 1.616379     |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2107        |\n",
      "|    time_elapsed         | 38465       |\n",
      "|    total_timesteps      | 4315136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007915713 |\n",
      "|    clip_fraction        | 0.0268      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 21060       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | 5.7773385   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2108        |\n",
      "|    time_elapsed         | 38483       |\n",
      "|    total_timesteps      | 4317184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011829043 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.29        |\n",
      "|    n_updates            | 21070       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 2.3893502   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2109        |\n",
      "|    time_elapsed         | 38502       |\n",
      "|    total_timesteps      | 4319232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005650676 |\n",
      "|    clip_fraction        | 0.0298      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 21080       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | -1.0253383  |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2110         |\n",
      "|    time_elapsed         | 38520        |\n",
      "|    total_timesteps      | 4321280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073538776 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.00826     |\n",
      "|    reward               | -2.922049    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2111        |\n",
      "|    time_elapsed         | 38538       |\n",
      "|    total_timesteps      | 4323328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007841896 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.33        |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    reward               | 0.32730505  |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2112         |\n",
      "|    time_elapsed         | 38556        |\n",
      "|    total_timesteps      | 4325376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040484704 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 21110        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    reward               | 2.30364      |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2113        |\n",
      "|    time_elapsed         | 38574       |\n",
      "|    total_timesteps      | 4327424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00558847  |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 21120       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | -0.57214135 |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2114       |\n",
      "|    time_elapsed         | 38592      |\n",
      "|    total_timesteps      | 4329472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00785738 |\n",
      "|    clip_fraction        | 0.0409     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -116       |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 21130      |\n",
      "|    policy_gradient_loss | -0.00991   |\n",
      "|    reward               | 0.71854854 |\n",
      "|    std                  | 13.5       |\n",
      "|    value_loss           | 25.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2115        |\n",
      "|    time_elapsed         | 38610       |\n",
      "|    total_timesteps      | 4331520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003949577 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 21140       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | 0.45979062  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 38628       |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002756436 |\n",
      "|    clip_fraction        | 0.0062      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 21150       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | 0.37467593  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2117         |\n",
      "|    time_elapsed         | 38647        |\n",
      "|    total_timesteps      | 4335616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069448547 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 21160        |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    reward               | 0.4923826    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3256832.50\n",
      "total_reward: 2256832.50\n",
      "total_cost: 112238.78\n",
      "total_trades: 55752\n",
      "Sharpe: 0.637\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2118         |\n",
      "|    time_elapsed         | 38667        |\n",
      "|    total_timesteps      | 4337664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067977435 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.33         |\n",
      "|    n_updates            | 21170        |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    reward               | 0.23287626   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2119         |\n",
      "|    time_elapsed         | 38685        |\n",
      "|    total_timesteps      | 4339712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069043664 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 21180        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 0.30699077   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2120         |\n",
      "|    time_elapsed         | 38703        |\n",
      "|    total_timesteps      | 4341760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028416307 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 21190        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 0.39782798   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2121        |\n",
      "|    time_elapsed         | 38721       |\n",
      "|    total_timesteps      | 4343808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010403983 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.4         |\n",
      "|    n_updates            | 21200       |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | 1.374793    |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2122        |\n",
      "|    time_elapsed         | 38739       |\n",
      "|    total_timesteps      | 4345856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003434904 |\n",
      "|    clip_fraction        | 0.00576     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.17        |\n",
      "|    n_updates            | 21210       |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | -0.07715808 |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2123        |\n",
      "|    time_elapsed         | 38757       |\n",
      "|    total_timesteps      | 4347904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003835846 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 21220       |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    reward               | 0.2510614   |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2124         |\n",
      "|    time_elapsed         | 38775        |\n",
      "|    total_timesteps      | 4349952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017286949 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 21230        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | -4.0760794   |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2125        |\n",
      "|    time_elapsed         | 38793       |\n",
      "|    total_timesteps      | 4352000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004177088 |\n",
      "|    clip_fraction        | 0.00728     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 21240       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | 0.88302547  |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2126         |\n",
      "|    time_elapsed         | 38811        |\n",
      "|    total_timesteps      | 4354048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051571587 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 1.7793123    |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2127         |\n",
      "|    time_elapsed         | 38829        |\n",
      "|    total_timesteps      | 4356096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056763086 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    reward               | 1.560339     |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2128        |\n",
      "|    time_elapsed         | 38847       |\n",
      "|    total_timesteps      | 4358144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011283625 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.14        |\n",
      "|    n_updates            | 21270       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.41116124  |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2129         |\n",
      "|    time_elapsed         | 38864        |\n",
      "|    total_timesteps      | 4360192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043851594 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.77         |\n",
      "|    n_updates            | 21280        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    reward               | -1.0590518   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2130        |\n",
      "|    time_elapsed         | 38882       |\n",
      "|    total_timesteps      | 4362240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003564868 |\n",
      "|    clip_fraction        | 0.00542     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 21290       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | -6.3726473  |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2131         |\n",
      "|    time_elapsed         | 38900        |\n",
      "|    total_timesteps      | 4364288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055044484 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 21300        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 0.41428223   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3082569.31\n",
      "total_reward: 2082569.31\n",
      "total_cost: 98333.54\n",
      "total_trades: 55222\n",
      "Sharpe: 0.621\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2132        |\n",
      "|    time_elapsed         | 38918       |\n",
      "|    total_timesteps      | 4366336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005243193 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.72        |\n",
      "|    n_updates            | 21310       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | -3.684477   |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2133         |\n",
      "|    time_elapsed         | 38936        |\n",
      "|    total_timesteps      | 4368384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052416036 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.00799     |\n",
      "|    reward               | -2.8333578   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2134         |\n",
      "|    time_elapsed         | 38953        |\n",
      "|    total_timesteps      | 4370432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050855395 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | -1.1321388   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2135        |\n",
      "|    time_elapsed         | 38972       |\n",
      "|    total_timesteps      | 4372480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010046933 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.13        |\n",
      "|    n_updates            | 21340       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 1.2315034   |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2136         |\n",
      "|    time_elapsed         | 38990        |\n",
      "|    total_timesteps      | 4374528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076328097 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 21350        |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    reward               | -0.37713993  |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2137         |\n",
      "|    time_elapsed         | 39008        |\n",
      "|    total_timesteps      | 4376576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006988769 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    reward               | -1.9662676   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2138        |\n",
      "|    time_elapsed         | 39026       |\n",
      "|    total_timesteps      | 4378624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009456106 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 21370       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | -2.3612652  |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2139         |\n",
      "|    time_elapsed         | 39045        |\n",
      "|    total_timesteps      | 4380672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050748847 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.14         |\n",
      "|    n_updates            | 21380        |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    reward               | 0.6407984    |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 16.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2140         |\n",
      "|    time_elapsed         | 39063        |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032674624 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 1.4882342    |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2141        |\n",
      "|    time_elapsed         | 39081       |\n",
      "|    total_timesteps      | 4384768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006912614 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 21400       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | -1.3389205  |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2142        |\n",
      "|    time_elapsed         | 39099       |\n",
      "|    total_timesteps      | 4386816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008269999 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.92        |\n",
      "|    n_updates            | 21410       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -1.9005095  |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2143         |\n",
      "|    time_elapsed         | 39117        |\n",
      "|    total_timesteps      | 4388864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037506653 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.89         |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    reward               | -0.39594314  |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2144         |\n",
      "|    time_elapsed         | 39135        |\n",
      "|    total_timesteps      | 4390912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022262894 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 21430        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 1.6330254    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2145        |\n",
      "|    time_elapsed         | 39153       |\n",
      "|    total_timesteps      | 4392960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009430429 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.45        |\n",
      "|    n_updates            | 21440       |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    reward               | 1.2192701   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3186783.43\n",
      "total_reward: 2186783.43\n",
      "total_cost: 90162.46\n",
      "total_trades: 54934\n",
      "Sharpe: 0.625\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2146         |\n",
      "|    time_elapsed         | 39171        |\n",
      "|    total_timesteps      | 4395008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050963704 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 21450        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    reward               | 0.54619503   |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2147         |\n",
      "|    time_elapsed         | 39188        |\n",
      "|    total_timesteps      | 4397056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020292988 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 21460        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.6500084    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2148         |\n",
      "|    time_elapsed         | 39206        |\n",
      "|    total_timesteps      | 4399104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036726333 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 21470        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | 2.0418172    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2149        |\n",
      "|    time_elapsed         | 39225       |\n",
      "|    total_timesteps      | 4401152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005645397 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 21480       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 2.8939714   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2150         |\n",
      "|    time_elapsed         | 39244        |\n",
      "|    total_timesteps      | 4403200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049225753 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 21490        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    reward               | 1.3188137    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2151         |\n",
      "|    time_elapsed         | 39263        |\n",
      "|    total_timesteps      | 4405248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018629665 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 21500        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | 1.1253285    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2152        |\n",
      "|    time_elapsed         | 39281       |\n",
      "|    total_timesteps      | 4407296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007869075 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.73        |\n",
      "|    n_updates            | 21510       |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | 0.14151548  |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2153         |\n",
      "|    time_elapsed         | 39299        |\n",
      "|    total_timesteps      | 4409344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023386667 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | -0.718963    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2154        |\n",
      "|    time_elapsed         | 39317       |\n",
      "|    total_timesteps      | 4411392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001970137 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 21530       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -3.140068   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2155        |\n",
      "|    time_elapsed         | 39335       |\n",
      "|    total_timesteps      | 4413440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006731621 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.67        |\n",
      "|    n_updates            | 21540       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -1.7073307  |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2156         |\n",
      "|    time_elapsed         | 39354        |\n",
      "|    total_timesteps      | 4415488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027240333 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.37         |\n",
      "|    n_updates            | 21550        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 0.5716889    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2157         |\n",
      "|    time_elapsed         | 39398        |\n",
      "|    total_timesteps      | 4417536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036320626 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | -18.976093   |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2158          |\n",
      "|    time_elapsed         | 39417         |\n",
      "|    total_timesteps      | 4419584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096031604 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.683         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.9          |\n",
      "|    n_updates            | 21570         |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    reward               | 0.3628677     |\n",
      "|    std                  | 14.2          |\n",
      "|    value_loss           | 29.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2159         |\n",
      "|    time_elapsed         | 39436        |\n",
      "|    total_timesteps      | 4421632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037875506 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.07         |\n",
      "|    n_updates            | 21580        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 0.63961      |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3266198.73\n",
      "total_reward: 2266198.73\n",
      "total_cost: 63385.25\n",
      "total_trades: 52296\n",
      "Sharpe: 0.637\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2160        |\n",
      "|    time_elapsed         | 39454       |\n",
      "|    total_timesteps      | 4423680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004949064 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 21590       |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    reward               | 0.647197    |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2161         |\n",
      "|    time_elapsed         | 39473        |\n",
      "|    total_timesteps      | 4425728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034061435 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 21600        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -0.98147786  |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2162        |\n",
      "|    time_elapsed         | 39491       |\n",
      "|    total_timesteps      | 4427776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006028803 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.26        |\n",
      "|    n_updates            | 21610       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | 0.078839116 |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2163         |\n",
      "|    time_elapsed         | 39509        |\n",
      "|    total_timesteps      | 4429824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070109153 |\n",
      "|    clip_fraction        | 0.0358       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    reward               | 0.314734     |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2164         |\n",
      "|    time_elapsed         | 39527        |\n",
      "|    total_timesteps      | 4431872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041155447 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 21630        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    reward               | -0.76646876  |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2165         |\n",
      "|    time_elapsed         | 39545        |\n",
      "|    total_timesteps      | 4433920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057843975 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 21640        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 1.9074242    |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2166        |\n",
      "|    time_elapsed         | 39563       |\n",
      "|    total_timesteps      | 4435968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004333413 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 21650       |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | 1.1657788   |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2167         |\n",
      "|    time_elapsed         | 39581        |\n",
      "|    total_timesteps      | 4438016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009190037 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 21660        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | 0.48344636   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2168         |\n",
      "|    time_elapsed         | 39599        |\n",
      "|    total_timesteps      | 4440064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073439525 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 21670        |\n",
      "|    policy_gradient_loss | -0.00827     |\n",
      "|    reward               | 0.83721805   |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2169         |\n",
      "|    time_elapsed         | 39617        |\n",
      "|    total_timesteps      | 4442112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006564888  |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.83         |\n",
      "|    n_updates            | 21680        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | -0.059253376 |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2170          |\n",
      "|    time_elapsed         | 39635         |\n",
      "|    total_timesteps      | 4444160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067283143 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -118          |\n",
      "|    explained_variance   | 0.496         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.4          |\n",
      "|    n_updates            | 21690         |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    reward               | 0.3353403     |\n",
      "|    std                  | 14.4          |\n",
      "|    value_loss           | 36.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2171         |\n",
      "|    time_elapsed         | 39653        |\n",
      "|    total_timesteps      | 4446208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033030175 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 21700        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -2.4484046   |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2172        |\n",
      "|    time_elapsed         | 39671       |\n",
      "|    total_timesteps      | 4448256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007545615 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 21710       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -0.82471067 |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2173         |\n",
      "|    time_elapsed         | 39689        |\n",
      "|    total_timesteps      | 4450304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016252599 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 0.31218696   |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4136352.46\n",
      "total_reward: 3136352.46\n",
      "total_cost: 58149.77\n",
      "total_trades: 51773\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2174         |\n",
      "|    time_elapsed         | 39707        |\n",
      "|    total_timesteps      | 4452352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005206922  |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 21730        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | -0.019258093 |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2175         |\n",
      "|    time_elapsed         | 39725        |\n",
      "|    total_timesteps      | 4454400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005601401 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 21740        |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    reward               | 1.2104203    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2176        |\n",
      "|    time_elapsed         | 39743       |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007645449 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.55        |\n",
      "|    n_updates            | 21750       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2177         |\n",
      "|    time_elapsed         | 39761        |\n",
      "|    total_timesteps      | 4458496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042993794 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 21760        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    reward               | 2.518275     |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2178         |\n",
      "|    time_elapsed         | 39780        |\n",
      "|    total_timesteps      | 4460544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030113235 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 21770        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | -1.5000522   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2179         |\n",
      "|    time_elapsed         | 39799        |\n",
      "|    total_timesteps      | 4462592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048693093 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 21780        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    reward               | 1.962194     |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2180         |\n",
      "|    time_elapsed         | 39819        |\n",
      "|    total_timesteps      | 4464640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029811682 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.07         |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 0.8429878    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2181         |\n",
      "|    time_elapsed         | 39837        |\n",
      "|    total_timesteps      | 4466688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030622412 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 21800        |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | -0.68813795  |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2182        |\n",
      "|    time_elapsed         | 39855       |\n",
      "|    total_timesteps      | 4468736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006562141 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 21810       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 0.22271815  |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2183         |\n",
      "|    time_elapsed         | 39873        |\n",
      "|    total_timesteps      | 4470784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061172005 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.61         |\n",
      "|    n_updates            | 21820        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | -3.607271    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2184        |\n",
      "|    time_elapsed         | 39892       |\n",
      "|    total_timesteps      | 4472832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005770619 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 21830       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | -0.20194982 |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2185        |\n",
      "|    time_elapsed         | 39910       |\n",
      "|    total_timesteps      | 4474880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004746761 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 21840       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | 0.57865554  |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2186        |\n",
      "|    time_elapsed         | 39928       |\n",
      "|    total_timesteps      | 4476928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008571713 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -3.9397879  |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2187         |\n",
      "|    time_elapsed         | 39946        |\n",
      "|    total_timesteps      | 4478976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036811528 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -0.98421836  |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2188         |\n",
      "|    time_elapsed         | 39964        |\n",
      "|    total_timesteps      | 4481024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014511733 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 21870        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -0.6063774   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 42.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3329226.92\n",
      "total_reward: 2329226.92\n",
      "total_cost: 65805.77\n",
      "total_trades: 52855\n",
      "Sharpe: 0.639\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2189        |\n",
      "|    time_elapsed         | 39982       |\n",
      "|    total_timesteps      | 4483072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009163979 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.19        |\n",
      "|    n_updates            | 21880       |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    reward               | 2.7372584   |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2190        |\n",
      "|    time_elapsed         | 40001       |\n",
      "|    total_timesteps      | 4485120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007892437 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.69        |\n",
      "|    n_updates            | 21890       |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    reward               | -1.8166906  |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2191         |\n",
      "|    time_elapsed         | 40018        |\n",
      "|    total_timesteps      | 4487168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028050044 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 21900        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | -1.6502182   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2192         |\n",
      "|    time_elapsed         | 40036        |\n",
      "|    total_timesteps      | 4489216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020360057 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 21910        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 1.1629704    |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 112       |\n",
      "|    iterations           | 2193      |\n",
      "|    time_elapsed         | 40054     |\n",
      "|    total_timesteps      | 4491264   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0080637 |\n",
      "|    clip_fraction        | 0.0607    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -119      |\n",
      "|    explained_variance   | 0.666     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 9.24      |\n",
      "|    n_updates            | 21920     |\n",
      "|    policy_gradient_loss | -0.00766  |\n",
      "|    reward               | 2.2876961 |\n",
      "|    std                  | 14.6      |\n",
      "|    value_loss           | 23.7      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2194         |\n",
      "|    time_elapsed         | 40072        |\n",
      "|    total_timesteps      | 4493312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019080711 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 21930        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    reward               | 1.1943753    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2195         |\n",
      "|    time_elapsed         | 40090        |\n",
      "|    total_timesteps      | 4495360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042053396 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 21940        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -1.0805638   |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2196         |\n",
      "|    time_elapsed         | 40109        |\n",
      "|    total_timesteps      | 4497408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043169716 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 21950        |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    reward               | 0.107509926  |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2197        |\n",
      "|    time_elapsed         | 40127       |\n",
      "|    total_timesteps      | 4499456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005545621 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 21960       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -1.0716811  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 31          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2198         |\n",
      "|    time_elapsed         | 40144        |\n",
      "|    total_timesteps      | 4501504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050682873 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | -1.6702187   |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2199         |\n",
      "|    time_elapsed         | 40163        |\n",
      "|    total_timesteps      | 4503552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027723894 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 21980        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | 0.08641237   |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2200        |\n",
      "|    time_elapsed         | 40180       |\n",
      "|    total_timesteps      | 4505600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008008471 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 21990       |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | 2.321816    |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2201        |\n",
      "|    time_elapsed         | 40199       |\n",
      "|    total_timesteps      | 4507648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002472412 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 22000       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -1.1674135  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2202         |\n",
      "|    time_elapsed         | 40217        |\n",
      "|    total_timesteps      | 4509696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025839577 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 22010        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | -0.9609844   |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3343660.15\n",
      "total_reward: 2343660.15\n",
      "total_cost: 68096.80\n",
      "total_trades: 53212\n",
      "Sharpe: 0.652\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2203         |\n",
      "|    time_elapsed         | 40236        |\n",
      "|    total_timesteps      | 4511744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060901754 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | 2.9577324    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2204         |\n",
      "|    time_elapsed         | 40253        |\n",
      "|    total_timesteps      | 4513792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035186054 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 22030        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | -1.2170572   |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2205        |\n",
      "|    time_elapsed         | 40271       |\n",
      "|    total_timesteps      | 4515840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004873326 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 22040       |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | 0.71059537  |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2206        |\n",
      "|    time_elapsed         | 40289       |\n",
      "|    total_timesteps      | 4517888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002573546 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 22050       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | -0.4183575  |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2207        |\n",
      "|    time_elapsed         | 40307       |\n",
      "|    total_timesteps      | 4519936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008395102 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.94        |\n",
      "|    n_updates            | 22060       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 0.44162405  |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2208         |\n",
      "|    time_elapsed         | 40325        |\n",
      "|    total_timesteps      | 4521984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026976108 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 22070        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | 1.5915656    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 35.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2209         |\n",
      "|    time_elapsed         | 40343        |\n",
      "|    total_timesteps      | 4524032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021636118 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 22080        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 2.4892583    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2210         |\n",
      "|    time_elapsed         | 40362        |\n",
      "|    total_timesteps      | 4526080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055218153 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 22090        |\n",
      "|    policy_gradient_loss | -0.00783     |\n",
      "|    reward               | 2.3660614    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2211         |\n",
      "|    time_elapsed         | 40380        |\n",
      "|    total_timesteps      | 4528128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029990722 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 22100        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    reward               | 0.9956388    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2212         |\n",
      "|    time_elapsed         | 40398        |\n",
      "|    total_timesteps      | 4530176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034429664 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 22110        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | 1.3402756    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 40416       |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009164199 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 22120       |\n",
      "|    policy_gradient_loss | -0.00948    |\n",
      "|    reward               | -0.27432272 |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2214         |\n",
      "|    time_elapsed         | 40435        |\n",
      "|    total_timesteps      | 4534272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042062197 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | -0.4871977   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2215         |\n",
      "|    time_elapsed         | 40453        |\n",
      "|    total_timesteps      | 4536320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032698973 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 22140        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -0.20417276  |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2216         |\n",
      "|    time_elapsed         | 40472        |\n",
      "|    total_timesteps      | 4538368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043055345 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 22150        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    reward               | 0.6473092    |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3456575.51\n",
      "total_reward: 2456575.51\n",
      "total_cost: 66976.08\n",
      "total_trades: 53638\n",
      "Sharpe: 0.653\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2217        |\n",
      "|    time_elapsed         | 40490       |\n",
      "|    total_timesteps      | 4540416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009438309 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.13        |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    reward               | 2.3931758   |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2218         |\n",
      "|    time_elapsed         | 40508        |\n",
      "|    total_timesteps      | 4542464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025603771 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 22170        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 0.42650443   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2219         |\n",
      "|    time_elapsed         | 40526        |\n",
      "|    total_timesteps      | 4544512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035741644 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | -0.27402535  |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2220         |\n",
      "|    time_elapsed         | 40544        |\n",
      "|    total_timesteps      | 4546560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056988136 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.66         |\n",
      "|    n_updates            | 22190        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | 0.17407747   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2221         |\n",
      "|    time_elapsed         | 40562        |\n",
      "|    total_timesteps      | 4548608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042271037 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 22200        |\n",
      "|    policy_gradient_loss | -0.00715     |\n",
      "|    reward               | 0.41142702   |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2222         |\n",
      "|    time_elapsed         | 40580        |\n",
      "|    total_timesteps      | 4550656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019048336 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 22210        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -0.86695635  |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2223         |\n",
      "|    time_elapsed         | 40598        |\n",
      "|    total_timesteps      | 4552704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016304429 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 22220        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 1.2333173    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2224         |\n",
      "|    time_elapsed         | 40616        |\n",
      "|    total_timesteps      | 4554752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069648554 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.12         |\n",
      "|    n_updates            | 22230        |\n",
      "|    policy_gradient_loss | -0.00797     |\n",
      "|    reward               | -0.8313409   |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2225         |\n",
      "|    time_elapsed         | 40634        |\n",
      "|    total_timesteps      | 4556800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030675014 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 22240        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | 0.80196875   |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2226         |\n",
      "|    time_elapsed         | 40653        |\n",
      "|    total_timesteps      | 4558848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026056415 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 22250        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 1.2052294    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2227         |\n",
      "|    time_elapsed         | 40671        |\n",
      "|    total_timesteps      | 4560896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064719897 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 22260        |\n",
      "|    policy_gradient_loss | -0.00733     |\n",
      "|    reward               | 2.6089838    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2228        |\n",
      "|    time_elapsed         | 40689       |\n",
      "|    total_timesteps      | 4562944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002745476 |\n",
      "|    clip_fraction        | 0.00234     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 22270       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | -1.0447577  |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2229         |\n",
      "|    time_elapsed         | 40706        |\n",
      "|    total_timesteps      | 4564992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051995665 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 22280        |\n",
      "|    policy_gradient_loss | -0.0066      |\n",
      "|    reward               | 2.1438434    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2230         |\n",
      "|    time_elapsed         | 40724        |\n",
      "|    total_timesteps      | 4567040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027648583 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 22290        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | 1.5445626    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3561558.75\n",
      "total_reward: 2561558.75\n",
      "total_cost: 70121.07\n",
      "total_trades: 54010\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2231         |\n",
      "|    time_elapsed         | 40742        |\n",
      "|    total_timesteps      | 4569088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073806783 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.72         |\n",
      "|    n_updates            | 22300        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | 0.32948968   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2232         |\n",
      "|    time_elapsed         | 40760        |\n",
      "|    total_timesteps      | 4571136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031736202 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 22310        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    reward               | -0.54176134  |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2233       |\n",
      "|    time_elapsed         | 40779      |\n",
      "|    total_timesteps      | 4573184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00142309 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -120       |\n",
      "|    explained_variance   | 0.74       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.6       |\n",
      "|    n_updates            | 22320      |\n",
      "|    policy_gradient_loss | -0.00226   |\n",
      "|    reward               | -0.8978742 |\n",
      "|    std                  | 15.3       |\n",
      "|    value_loss           | 37.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2234        |\n",
      "|    time_elapsed         | 40797       |\n",
      "|    total_timesteps      | 4575232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008222059 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.97        |\n",
      "|    n_updates            | 22330       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -1.0487792  |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2235       |\n",
      "|    time_elapsed         | 40815      |\n",
      "|    total_timesteps      | 4577280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00408927 |\n",
      "|    clip_fraction        | 0.0082     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -120       |\n",
      "|    explained_variance   | 0.553      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 22340      |\n",
      "|    policy_gradient_loss | -0.00403   |\n",
      "|    reward               | -1.8813633 |\n",
      "|    std                  | 15.4       |\n",
      "|    value_loss           | 26.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2236         |\n",
      "|    time_elapsed         | 40834        |\n",
      "|    total_timesteps      | 4579328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019667097 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 22350        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | -4.092393    |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2237        |\n",
      "|    time_elapsed         | 40852       |\n",
      "|    total_timesteps      | 4581376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003515006 |\n",
      "|    clip_fraction        | 0.00254     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 22360       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | -0.8163071  |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2238        |\n",
      "|    time_elapsed         | 40870       |\n",
      "|    total_timesteps      | 4583424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003674711 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 22370       |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 1.0706903   |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2239         |\n",
      "|    time_elapsed         | 40888        |\n",
      "|    total_timesteps      | 4585472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013982297 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 22380        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 2.7860754    |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2240       |\n",
      "|    time_elapsed         | 40905      |\n",
      "|    total_timesteps      | 4587520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00407332 |\n",
      "|    clip_fraction        | 0.00522    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -120       |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 22390      |\n",
      "|    policy_gradient_loss | -0.00499   |\n",
      "|    reward               | 0.06065966 |\n",
      "|    std                  | 15.4       |\n",
      "|    value_loss           | 46.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2241        |\n",
      "|    time_elapsed         | 40924       |\n",
      "|    total_timesteps      | 4589568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007876309 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.57        |\n",
      "|    n_updates            | 22400       |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | -0.93642116 |\n",
      "|    std                  | 15.5        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2242         |\n",
      "|    time_elapsed         | 40941        |\n",
      "|    total_timesteps      | 4591616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017437573 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 22410        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | 0.5587788    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2243         |\n",
      "|    time_elapsed         | 40959        |\n",
      "|    total_timesteps      | 4593664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023023747 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 22420        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 2.5477798    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2244         |\n",
      "|    time_elapsed         | 40977        |\n",
      "|    total_timesteps      | 4595712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063743894 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 22430        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | -0.59652835  |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3462463.70\n",
      "total_reward: 2462463.70\n",
      "total_cost: 79916.25\n",
      "total_trades: 54462\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2245         |\n",
      "|    time_elapsed         | 40995        |\n",
      "|    total_timesteps      | 4597760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022978792 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 22440        |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | -0.2604509   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2246         |\n",
      "|    time_elapsed         | 41013        |\n",
      "|    total_timesteps      | 4599808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018773982 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 22450        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | 15.919923    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2247         |\n",
      "|    time_elapsed         | 41031        |\n",
      "|    total_timesteps      | 4601856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013818273 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 22460        |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | 2.3601048    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2248         |\n",
      "|    time_elapsed         | 41049        |\n",
      "|    total_timesteps      | 4603904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005562295  |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 22470        |\n",
      "|    policy_gradient_loss | -0.00773     |\n",
      "|    reward               | -0.007875839 |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2249        |\n",
      "|    time_elapsed         | 41067       |\n",
      "|    total_timesteps      | 4605952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004254884 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 22480       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | 0.08024897  |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2250         |\n",
      "|    time_elapsed         | 41085        |\n",
      "|    total_timesteps      | 4608000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005221702 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.1         |\n",
      "|    n_updates            | 22490        |\n",
      "|    policy_gradient_loss | -0.000845    |\n",
      "|    reward               | 2.6525474    |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 69.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2251         |\n",
      "|    time_elapsed         | 41103        |\n",
      "|    total_timesteps      | 4610048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053988695 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 22500        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | -3.5016344   |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2252         |\n",
      "|    time_elapsed         | 41121        |\n",
      "|    total_timesteps      | 4612096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028640595 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 22510        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -6.449283    |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2253         |\n",
      "|    time_elapsed         | 41139        |\n",
      "|    total_timesteps      | 4614144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022889604 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 22520        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | 0.4525504    |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 47.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2254         |\n",
      "|    time_elapsed         | 41158        |\n",
      "|    total_timesteps      | 4616192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012892296 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 22530        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 19.947773    |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 42.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2255        |\n",
      "|    time_elapsed         | 41175       |\n",
      "|    total_timesteps      | 4618240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005285637 |\n",
      "|    clip_fraction        | 0.00898     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 22540       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | -0.19703984 |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2256         |\n",
      "|    time_elapsed         | 41193        |\n",
      "|    total_timesteps      | 4620288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022278698 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 22550        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -1.0906358   |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 50.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2257         |\n",
      "|    time_elapsed         | 41211        |\n",
      "|    total_timesteps      | 4622336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035214983 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 22560        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | 0.57517254   |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 60.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2258        |\n",
      "|    time_elapsed         | 41228       |\n",
      "|    total_timesteps      | 4624384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009571933 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -1.2419152  |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3726510.57\n",
      "total_reward: 2726510.57\n",
      "total_cost: 66436.58\n",
      "total_trades: 52741\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2259         |\n",
      "|    time_elapsed         | 41246        |\n",
      "|    total_timesteps      | 4626432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019562622 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 22580        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 0.3450766    |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2260         |\n",
      "|    time_elapsed         | 41264        |\n",
      "|    total_timesteps      | 4628480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021759751 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 22590        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 0.57609993   |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2261        |\n",
      "|    time_elapsed         | 41282       |\n",
      "|    total_timesteps      | 4630528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004644256 |\n",
      "|    clip_fraction        | 0.00894     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 22600       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -1.9341557  |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2262        |\n",
      "|    time_elapsed         | 41301       |\n",
      "|    total_timesteps      | 4632576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004257531 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 22610       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | 0.6863292   |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2263         |\n",
      "|    time_elapsed         | 41319        |\n",
      "|    total_timesteps      | 4634624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014486207 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 22620        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | -0.38371092  |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2264         |\n",
      "|    time_elapsed         | 41338        |\n",
      "|    total_timesteps      | 4636672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012450778 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 22630        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 1.2320632    |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2265        |\n",
      "|    time_elapsed         | 41356       |\n",
      "|    total_timesteps      | 4638720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009405525 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 22640       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 1.6769662   |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2266         |\n",
      "|    time_elapsed         | 41374        |\n",
      "|    total_timesteps      | 4640768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007175619 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 22650        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | 0.5655487    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2267         |\n",
      "|    time_elapsed         | 41392        |\n",
      "|    total_timesteps      | 4642816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026016687 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 22660        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | 2.066511     |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2268         |\n",
      "|    time_elapsed         | 41410        |\n",
      "|    total_timesteps      | 4644864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045506554 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 22670        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 2.4433339    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2269         |\n",
      "|    time_elapsed         | 41428        |\n",
      "|    total_timesteps      | 4646912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038300478 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 22680        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | 1.0477953    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2270          |\n",
      "|    time_elapsed         | 41446         |\n",
      "|    total_timesteps      | 4648960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089075376 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -121          |\n",
      "|    explained_variance   | 0.679         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.4          |\n",
      "|    n_updates            | 22690         |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    reward               | 3.072054      |\n",
      "|    std                  | 15.9          |\n",
      "|    value_loss           | 45.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2271         |\n",
      "|    time_elapsed         | 41464        |\n",
      "|    total_timesteps      | 4651008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011844074 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 22700        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | -2.128302    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 45           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2272        |\n",
      "|    time_elapsed         | 41481       |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007503555 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 22710       |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | -2.293071   |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3763187.55\n",
      "total_reward: 2763187.55\n",
      "total_cost: 74021.85\n",
      "total_trades: 53800\n",
      "Sharpe: 0.690\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2273        |\n",
      "|    time_elapsed         | 41499       |\n",
      "|    total_timesteps      | 4655104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001290539 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 22720       |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    reward               | -0.27493834 |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2274         |\n",
      "|    time_elapsed         | 41517        |\n",
      "|    total_timesteps      | 4657152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017164829 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 22730        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | -0.5033888   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 50.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2275         |\n",
      "|    time_elapsed         | 41535        |\n",
      "|    total_timesteps      | 4659200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073952586 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.84         |\n",
      "|    n_updates            | 22740        |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    reward               | 3.0111597    |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2276         |\n",
      "|    time_elapsed         | 41553        |\n",
      "|    total_timesteps      | 4661248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028402961 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 22750        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | 0.40311533   |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 36.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2277         |\n",
      "|    time_elapsed         | 41571        |\n",
      "|    total_timesteps      | 4663296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010967725 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | 1.0027325    |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 54.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2278         |\n",
      "|    time_elapsed         | 41591        |\n",
      "|    total_timesteps      | 4665344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019848952 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 22770        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | -0.44031763  |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2279        |\n",
      "|    time_elapsed         | 41608       |\n",
      "|    total_timesteps      | 4667392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005457581 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 22780       |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | 2.5296957   |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2280        |\n",
      "|    time_elapsed         | 41626       |\n",
      "|    total_timesteps      | 4669440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001903723 |\n",
      "|    clip_fraction        | 0.00166     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 22790       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | -0.19946022 |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2281        |\n",
      "|    time_elapsed         | 41644       |\n",
      "|    total_timesteps      | 4671488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003550216 |\n",
      "|    clip_fraction        | 0.00391     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 22800       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | -3.2135816  |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2282         |\n",
      "|    time_elapsed         | 41663        |\n",
      "|    total_timesteps      | 4673536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025111395 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.24         |\n",
      "|    n_updates            | 22810        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | -1.4543586   |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2283        |\n",
      "|    time_elapsed         | 41681       |\n",
      "|    total_timesteps      | 4675584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004508795 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 22820       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 0.36413613  |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2284         |\n",
      "|    time_elapsed         | 41700        |\n",
      "|    total_timesteps      | 4677632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039300406 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 22830        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | 2.3161495    |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2285        |\n",
      "|    time_elapsed         | 41718       |\n",
      "|    total_timesteps      | 4679680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005600797 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 22840       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 2.2698755   |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2286         |\n",
      "|    time_elapsed         | 41737        |\n",
      "|    total_timesteps      | 4681728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035588427 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 22850        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    reward               | 1.920364     |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3767019.22\n",
      "total_reward: 2767019.22\n",
      "total_cost: 74192.58\n",
      "total_trades: 53866\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2287        |\n",
      "|    time_elapsed         | 41756       |\n",
      "|    total_timesteps      | 4683776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004754823 |\n",
      "|    clip_fraction        | 0.00996     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 22860       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 0.049530804 |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2288         |\n",
      "|    time_elapsed         | 41775        |\n",
      "|    total_timesteps      | 4685824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021338328 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 22870        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    reward               | -0.030790968 |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2289        |\n",
      "|    time_elapsed         | 41794       |\n",
      "|    total_timesteps      | 4687872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062094 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 22880       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.908278   |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2290        |\n",
      "|    time_elapsed         | 41812       |\n",
      "|    total_timesteps      | 4689920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003091987 |\n",
      "|    clip_fraction        | 0.00332     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 22890       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 0.32957485  |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2291         |\n",
      "|    time_elapsed         | 41830        |\n",
      "|    total_timesteps      | 4691968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013308561 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 22900        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.29592317   |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2292         |\n",
      "|    time_elapsed         | 41849        |\n",
      "|    total_timesteps      | 4694016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062320554 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 22910        |\n",
      "|    policy_gradient_loss | -0.00819     |\n",
      "|    reward               | -0.79950756  |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2293         |\n",
      "|    time_elapsed         | 41867        |\n",
      "|    total_timesteps      | 4696064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050767297 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.47         |\n",
      "|    n_updates            | 22920        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | -1.9321804   |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2294         |\n",
      "|    time_elapsed         | 41886        |\n",
      "|    total_timesteps      | 4698112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058428994 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 22930        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | 3.5324006    |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2295         |\n",
      "|    time_elapsed         | 41905        |\n",
      "|    total_timesteps      | 4700160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032510897 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 22940        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | -0.2924425   |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2296         |\n",
      "|    time_elapsed         | 41923        |\n",
      "|    total_timesteps      | 4702208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052265995 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.23         |\n",
      "|    n_updates            | 22950        |\n",
      "|    policy_gradient_loss | -0.00846     |\n",
      "|    reward               | -2.0873814   |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2297         |\n",
      "|    time_elapsed         | 41942        |\n",
      "|    total_timesteps      | 4704256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021054617 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 22960        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | 0.4740576    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2298         |\n",
      "|    time_elapsed         | 41960        |\n",
      "|    total_timesteps      | 4706304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011224684 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 22970        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    reward               | -3.4489071   |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2299        |\n",
      "|    time_elapsed         | 41979       |\n",
      "|    total_timesteps      | 4708352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006906894 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 22980       |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 4.008353    |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2300         |\n",
      "|    time_elapsed         | 41997        |\n",
      "|    total_timesteps      | 4710400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022600591 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 22990        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | -0.02106451  |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2301          |\n",
      "|    time_elapsed         | 42015         |\n",
      "|    total_timesteps      | 4712448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089472183 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.728         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.3          |\n",
      "|    n_updates            | 23000         |\n",
      "|    policy_gradient_loss | -0.0019       |\n",
      "|    reward               | 2.2790384     |\n",
      "|    std                  | 16.5          |\n",
      "|    value_loss           | 44.5          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3761011.30\n",
      "total_reward: 2761011.30\n",
      "total_cost: 72724.50\n",
      "total_trades: 53727\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2302         |\n",
      "|    time_elapsed         | 42034        |\n",
      "|    total_timesteps      | 4714496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073471875 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 23010        |\n",
      "|    policy_gradient_loss | -0.00976     |\n",
      "|    reward               | -4.3853836   |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2303         |\n",
      "|    time_elapsed         | 42052        |\n",
      "|    total_timesteps      | 4716544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052525634 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    reward               | 3.1643035    |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2304          |\n",
      "|    time_elapsed         | 42071         |\n",
      "|    total_timesteps      | 4718592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047966896 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.492         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.6          |\n",
      "|    n_updates            | 23030         |\n",
      "|    policy_gradient_loss | -0.000941     |\n",
      "|    reward               | -0.6773707    |\n",
      "|    std                  | 16.6          |\n",
      "|    value_loss           | 36            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2305         |\n",
      "|    time_elapsed         | 42090        |\n",
      "|    total_timesteps      | 4720640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023952518 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 23040        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 0.08274061   |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2306        |\n",
      "|    time_elapsed         | 42108       |\n",
      "|    total_timesteps      | 4722688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011756726 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.28        |\n",
      "|    n_updates            | 23050       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 1.9523938   |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2307         |\n",
      "|    time_elapsed         | 42126        |\n",
      "|    total_timesteps      | 4724736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025934111 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 23060        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | -0.79434025  |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2308        |\n",
      "|    time_elapsed         | 42144       |\n",
      "|    total_timesteps      | 4726784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002393084 |\n",
      "|    clip_fraction        | 0.00176     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 23070       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | 2.9712849   |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2309         |\n",
      "|    time_elapsed         | 42163        |\n",
      "|    total_timesteps      | 4728832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035966747 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 23080        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -5.365325    |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2310         |\n",
      "|    time_elapsed         | 42181        |\n",
      "|    total_timesteps      | 4730880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037463852 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.47         |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    reward               | 2.1873558    |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2311         |\n",
      "|    time_elapsed         | 42200        |\n",
      "|    total_timesteps      | 4732928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032706684 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 23100        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    reward               | -1.5156022   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2312         |\n",
      "|    time_elapsed         | 42218        |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014745727 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 23110        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 2.1693509    |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2313        |\n",
      "|    time_elapsed         | 42236       |\n",
      "|    total_timesteps      | 4737024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009823931 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 23120       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | 1.2772166   |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2314          |\n",
      "|    time_elapsed         | 42254         |\n",
      "|    total_timesteps      | 4739072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039800032 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.614         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.1          |\n",
      "|    n_updates            | 23130         |\n",
      "|    policy_gradient_loss | -0.000829     |\n",
      "|    reward               | -1.4282556    |\n",
      "|    std                  | 16.9          |\n",
      "|    value_loss           | 41.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2315          |\n",
      "|    time_elapsed         | 42272         |\n",
      "|    total_timesteps      | 4741120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030830287 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.688         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24            |\n",
      "|    n_updates            | 23140         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    reward               | -1.4776632    |\n",
      "|    std                  | 16.9          |\n",
      "|    value_loss           | 56.2          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3573815.91\n",
      "total_reward: 2573815.91\n",
      "total_cost: 72228.76\n",
      "total_trades: 53712\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2316         |\n",
      "|    time_elapsed         | 42290        |\n",
      "|    total_timesteps      | 4743168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065437383 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 23150        |\n",
      "|    policy_gradient_loss | -0.00854     |\n",
      "|    reward               | 0.86431277   |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2317         |\n",
      "|    time_elapsed         | 42308        |\n",
      "|    total_timesteps      | 4745216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020679012 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.55         |\n",
      "|    n_updates            | 23160        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 1.5959219    |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2318        |\n",
      "|    time_elapsed         | 42327       |\n",
      "|    total_timesteps      | 4747264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002969898 |\n",
      "|    clip_fraction        | 0.00415     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 23170       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | 0.8360439   |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2319        |\n",
      "|    time_elapsed         | 42345       |\n",
      "|    total_timesteps      | 4749312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002850995 |\n",
      "|    clip_fraction        | 0.00337     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 23180       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | 0.39880484  |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2320         |\n",
      "|    time_elapsed         | 42363        |\n",
      "|    total_timesteps      | 4751360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049627246 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.72         |\n",
      "|    n_updates            | 23190        |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | 0.1280236    |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2321         |\n",
      "|    time_elapsed         | 42381        |\n",
      "|    total_timesteps      | 4753408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012428741 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 23200        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | -4.117611    |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 39           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2322         |\n",
      "|    time_elapsed         | 42399        |\n",
      "|    total_timesteps      | 4755456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027592133 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 23210        |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    reward               | 2.8617198    |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2323        |\n",
      "|    time_elapsed         | 42417       |\n",
      "|    total_timesteps      | 4757504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008230411 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 23220       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | -0.5438969  |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2324         |\n",
      "|    time_elapsed         | 42435        |\n",
      "|    total_timesteps      | 4759552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017980235 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 23230        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 0.6073366    |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2325         |\n",
      "|    time_elapsed         | 42454        |\n",
      "|    total_timesteps      | 4761600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012661869 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | 2.3555405    |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2326        |\n",
      "|    time_elapsed         | 42472       |\n",
      "|    total_timesteps      | 4763648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004371688 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 23250       |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    reward               | 3.3447497   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2327         |\n",
      "|    time_elapsed         | 42490        |\n",
      "|    total_timesteps      | 4765696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072143227 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 23260        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    reward               | 1.8588854    |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2328         |\n",
      "|    time_elapsed         | 42508        |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005317211 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | 1.3750532    |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2329         |\n",
      "|    time_elapsed         | 42526        |\n",
      "|    total_timesteps      | 4769792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010741403 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | -11.373986   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3769556.94\n",
      "total_reward: 2769556.94\n",
      "total_cost: 79927.51\n",
      "total_trades: 54640\n",
      "Sharpe: 0.699\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2330        |\n",
      "|    time_elapsed         | 42544       |\n",
      "|    total_timesteps      | 4771840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008161493 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 23290       |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    reward               | 2.2445722   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2331         |\n",
      "|    time_elapsed         | 42562        |\n",
      "|    total_timesteps      | 4773888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023756204 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 23300        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | -0.12308189  |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 35.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2332          |\n",
      "|    time_elapsed         | 42580         |\n",
      "|    total_timesteps      | 4775936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039822966 |\n",
      "|    clip_fraction        | 0.00161       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.752         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.1          |\n",
      "|    n_updates            | 23310         |\n",
      "|    policy_gradient_loss | -0.000967     |\n",
      "|    reward               | -6.04413      |\n",
      "|    std                  | 17.2          |\n",
      "|    value_loss           | 38            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2333        |\n",
      "|    time_elapsed         | 42598       |\n",
      "|    total_timesteps      | 4777984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004225788 |\n",
      "|    clip_fraction        | 0.00527     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 23320       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 2.2646315   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2334         |\n",
      "|    time_elapsed         | 42616        |\n",
      "|    total_timesteps      | 4780032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018009662 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 23330        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | -0.5020472   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2335         |\n",
      "|    time_elapsed         | 42634        |\n",
      "|    total_timesteps      | 4782080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021219938 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 23340        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | 7.352902     |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2336          |\n",
      "|    time_elapsed         | 42651         |\n",
      "|    total_timesteps      | 4784128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022116533 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.597         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.1          |\n",
      "|    n_updates            | 23350         |\n",
      "|    policy_gradient_loss | -0.000783     |\n",
      "|    reward               | -0.718625     |\n",
      "|    std                  | 17.2          |\n",
      "|    value_loss           | 52.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2337         |\n",
      "|    time_elapsed         | 42669        |\n",
      "|    total_timesteps      | 4786176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010533521  |\n",
      "|    clip_fraction        | 0.0678       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.59         |\n",
      "|    n_updates            | 23360        |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    reward               | -0.026439374 |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2338         |\n",
      "|    time_elapsed         | 42687        |\n",
      "|    total_timesteps      | 4788224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024764217 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 23370        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | 0.119670115  |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2339          |\n",
      "|    time_elapsed         | 42705         |\n",
      "|    total_timesteps      | 4790272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084523053 |\n",
      "|    clip_fraction        | 0.00303       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -123          |\n",
      "|    explained_variance   | 0.619         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.9          |\n",
      "|    n_updates            | 23380         |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    reward               | 0.348888      |\n",
      "|    std                  | 17.3          |\n",
      "|    value_loss           | 41.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2340         |\n",
      "|    time_elapsed         | 42724        |\n",
      "|    total_timesteps      | 4792320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063191364 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    reward               | 1.8575313    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2341         |\n",
      "|    time_elapsed         | 42742        |\n",
      "|    total_timesteps      | 4794368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025906586 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.64         |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -2.135391    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2342         |\n",
      "|    time_elapsed         | 42760        |\n",
      "|    total_timesteps      | 4796416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025886477 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 23410        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | -0.3211337   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2343         |\n",
      "|    time_elapsed         | 42778        |\n",
      "|    total_timesteps      | 4798464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024540396 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 23420        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 0.7877992    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4142266.02\n",
      "total_reward: 3142266.02\n",
      "total_cost: 60593.43\n",
      "total_trades: 52430\n",
      "Sharpe: 0.746\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2344         |\n",
      "|    time_elapsed         | 42796        |\n",
      "|    total_timesteps      | 4800512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058500376 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 23430        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | -0.29864314  |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2345         |\n",
      "|    time_elapsed         | 42814        |\n",
      "|    total_timesteps      | 4802560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005699028 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 23440        |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    reward               | -0.5995826   |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2346         |\n",
      "|    time_elapsed         | 42832        |\n",
      "|    total_timesteps      | 4804608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012772038 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 23450        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | 0.70192826   |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2347        |\n",
      "|    time_elapsed         | 42850       |\n",
      "|    total_timesteps      | 4806656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009151264 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 23460       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.93994886  |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2348         |\n",
      "|    time_elapsed         | 42869        |\n",
      "|    total_timesteps      | 4808704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022010268 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 23470        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | -2.9828877   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2349         |\n",
      "|    time_elapsed         | 42887        |\n",
      "|    total_timesteps      | 4810752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013456503 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 23480        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 2.1095488    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2350         |\n",
      "|    time_elapsed         | 42905        |\n",
      "|    total_timesteps      | 4812800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063178875 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 23490        |\n",
      "|    policy_gradient_loss | -0.00826     |\n",
      "|    reward               | -0.45743707  |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2351        |\n",
      "|    time_elapsed         | 42923       |\n",
      "|    total_timesteps      | 4814848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005102674 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 23500       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | 0.724937    |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2352         |\n",
      "|    time_elapsed         | 42942        |\n",
      "|    total_timesteps      | 4816896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017821046 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | 0.3825474    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2353         |\n",
      "|    time_elapsed         | 42960        |\n",
      "|    total_timesteps      | 4818944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021559244 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 23520        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 0.43903783   |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2354        |\n",
      "|    time_elapsed         | 42978       |\n",
      "|    total_timesteps      | 4820992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009081255 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 23530       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 1.101719    |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2355         |\n",
      "|    time_elapsed         | 42996        |\n",
      "|    total_timesteps      | 4823040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027167131 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 23540        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 0.25502697   |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2356          |\n",
      "|    time_elapsed         | 43014         |\n",
      "|    total_timesteps      | 4825088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069338107 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.773         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.3          |\n",
      "|    n_updates            | 23550         |\n",
      "|    policy_gradient_loss | -0.00232      |\n",
      "|    reward               | -3.010447     |\n",
      "|    std                  | 17.7          |\n",
      "|    value_loss           | 35.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2357         |\n",
      "|    time_elapsed         | 43032        |\n",
      "|    total_timesteps      | 4827136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037455093 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 23560        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | 1.3218496    |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3930893.05\n",
      "total_reward: 2930893.05\n",
      "total_cost: 70722.01\n",
      "total_trades: 52952\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2358         |\n",
      "|    time_elapsed         | 43050        |\n",
      "|    total_timesteps      | 4829184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015218508 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 23570        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 1.4888467    |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2359        |\n",
      "|    time_elapsed         | 43069       |\n",
      "|    total_timesteps      | 4831232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001304422 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 23580       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | -17.477093  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 43086        |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020910073 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 23590        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | 0.45365807   |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2361         |\n",
      "|    time_elapsed         | 43104        |\n",
      "|    total_timesteps      | 4835328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046026083 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.42         |\n",
      "|    n_updates            | 23600        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | 1.5013136    |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 25.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2362         |\n",
      "|    time_elapsed         | 43122        |\n",
      "|    total_timesteps      | 4837376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008721141 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 23610        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | -0.38405168  |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2363         |\n",
      "|    time_elapsed         | 43140        |\n",
      "|    total_timesteps      | 4839424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008551616 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 23620        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 1.2736795    |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2364        |\n",
      "|    time_elapsed         | 43157       |\n",
      "|    total_timesteps      | 4841472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003906786 |\n",
      "|    clip_fraction        | 0.0083      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 23630       |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    reward               | 0.17481916  |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2365       |\n",
      "|    time_elapsed         | 43176      |\n",
      "|    total_timesteps      | 4843520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00245704 |\n",
      "|    clip_fraction        | 0.00186    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -124       |\n",
      "|    explained_variance   | 0.628      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.8       |\n",
      "|    n_updates            | 23640      |\n",
      "|    policy_gradient_loss | -0.00437   |\n",
      "|    reward               | 0.32374427 |\n",
      "|    std                  | 17.9       |\n",
      "|    value_loss           | 29.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2366        |\n",
      "|    time_elapsed         | 43194       |\n",
      "|    total_timesteps      | 4845568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001840954 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 23650       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | -1.0748216  |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2367         |\n",
      "|    time_elapsed         | 43212        |\n",
      "|    total_timesteps      | 4847616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044332426 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.69         |\n",
      "|    n_updates            | 23660        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 0.33237737   |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2368         |\n",
      "|    time_elapsed         | 43230        |\n",
      "|    total_timesteps      | 4849664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025763037 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.75         |\n",
      "|    n_updates            | 23670        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 1.4409472    |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2369         |\n",
      "|    time_elapsed         | 43247        |\n",
      "|    total_timesteps      | 4851712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034263327 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 23680        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | -0.69449204  |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2370         |\n",
      "|    time_elapsed         | 43265        |\n",
      "|    total_timesteps      | 4853760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030922499 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 23690        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    reward               | -0.29746202  |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 35.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2371         |\n",
      "|    time_elapsed         | 43283        |\n",
      "|    total_timesteps      | 4855808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095829535 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.19         |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    reward               | -0.077873155 |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3414468.11\n",
      "total_reward: 2414468.11\n",
      "total_cost: 52793.46\n",
      "total_trades: 50755\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2372         |\n",
      "|    time_elapsed         | 43301        |\n",
      "|    total_timesteps      | 4857856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021552772 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 23710        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | -0.24276733  |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2373          |\n",
      "|    time_elapsed         | 43318         |\n",
      "|    total_timesteps      | 4859904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084126845 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.666         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.8          |\n",
      "|    n_updates            | 23720         |\n",
      "|    policy_gradient_loss | -0.00172      |\n",
      "|    reward               | -0.23637809   |\n",
      "|    std                  | 18.1          |\n",
      "|    value_loss           | 39.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2374         |\n",
      "|    time_elapsed         | 43336        |\n",
      "|    total_timesteps      | 4861952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047947154 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 23730        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    reward               | -0.33111745  |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2375         |\n",
      "|    time_elapsed         | 43354        |\n",
      "|    total_timesteps      | 4864000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020907384 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 23740        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | 1.4711579    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2376         |\n",
      "|    time_elapsed         | 43372        |\n",
      "|    total_timesteps      | 4866048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012858683 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 23750        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 0.027543413  |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2377        |\n",
      "|    time_elapsed         | 43391       |\n",
      "|    total_timesteps      | 4868096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003533062 |\n",
      "|    clip_fraction        | 0.00381     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 23760       |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -0.7539175  |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2378        |\n",
      "|    time_elapsed         | 43409       |\n",
      "|    total_timesteps      | 4870144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009455223 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.17        |\n",
      "|    n_updates            | 23770       |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | 0.91947514  |\n",
      "|    std                  | 18.3        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2379         |\n",
      "|    time_elapsed         | 43427        |\n",
      "|    total_timesteps      | 4872192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009102394 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 23780        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | 1.0205065    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2380         |\n",
      "|    time_elapsed         | 43446        |\n",
      "|    total_timesteps      | 4874240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016034569 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -0.6963324   |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2381         |\n",
      "|    time_elapsed         | 43464        |\n",
      "|    total_timesteps      | 4876288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048872866 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 23800        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 0.6966935    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2382         |\n",
      "|    time_elapsed         | 43482        |\n",
      "|    total_timesteps      | 4878336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027105818 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 23810        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 0.907303     |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2383         |\n",
      "|    time_elapsed         | 43501        |\n",
      "|    total_timesteps      | 4880384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013739762 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 23820        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -2.230068    |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2384         |\n",
      "|    time_elapsed         | 43519        |\n",
      "|    total_timesteps      | 4882432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013175309 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 23830        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -2.0914068   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2385        |\n",
      "|    time_elapsed         | 43537       |\n",
      "|    total_timesteps      | 4884480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006466604 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.8         |\n",
      "|    n_updates            | 23840       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -0.6218797  |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3627644.32\n",
      "total_reward: 2627644.32\n",
      "total_cost: 61361.38\n",
      "total_trades: 51882\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2386         |\n",
      "|    time_elapsed         | 43555        |\n",
      "|    total_timesteps      | 4886528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016506026 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 23850        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -1.0178573   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2387        |\n",
      "|    time_elapsed         | 43573       |\n",
      "|    total_timesteps      | 4888576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001252385 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 23860       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | -7.2920423  |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2388        |\n",
      "|    time_elapsed         | 43591       |\n",
      "|    total_timesteps      | 4890624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006104082 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | -2.188109   |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2389         |\n",
      "|    time_elapsed         | 43609        |\n",
      "|    total_timesteps      | 4892672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010711331 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 23880        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | -0.6687131   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2390         |\n",
      "|    time_elapsed         | 43627        |\n",
      "|    total_timesteps      | 4894720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013253253 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 23890        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 0.6096332    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2391         |\n",
      "|    time_elapsed         | 43646        |\n",
      "|    total_timesteps      | 4896768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031285957 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 23900        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | -0.3220292   |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2392         |\n",
      "|    time_elapsed         | 43664        |\n",
      "|    total_timesteps      | 4898816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032532667 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 23910        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | 0.8420993    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2393       |\n",
      "|    time_elapsed         | 43682      |\n",
      "|    total_timesteps      | 4900864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00182249 |\n",
      "|    clip_fraction        | 0.000195   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -125       |\n",
      "|    explained_variance   | 0.639      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 23920      |\n",
      "|    policy_gradient_loss | -0.00288   |\n",
      "|    reward               | 0.4281716  |\n",
      "|    std                  | 18.6       |\n",
      "|    value_loss           | 38.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2394         |\n",
      "|    time_elapsed         | 43700        |\n",
      "|    total_timesteps      | 4902912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010805819 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 23930        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 0.59909916   |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2395        |\n",
      "|    time_elapsed         | 43718       |\n",
      "|    total_timesteps      | 4904960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007926247 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 23940       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | -0.513481   |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2396         |\n",
      "|    time_elapsed         | 43737        |\n",
      "|    total_timesteps      | 4907008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026154616 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 23950        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -0.1848708   |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2397         |\n",
      "|    time_elapsed         | 43755        |\n",
      "|    total_timesteps      | 4909056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022380776 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.77         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 23960        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 2.7103593    |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2398         |\n",
      "|    time_elapsed         | 43773        |\n",
      "|    total_timesteps      | 4911104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054233065 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 23970        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    reward               | -3.0165122   |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2399         |\n",
      "|    time_elapsed         | 43791        |\n",
      "|    total_timesteps      | 4913152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009141936 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.5762631    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2400        |\n",
      "|    time_elapsed         | 43808       |\n",
      "|    total_timesteps      | 4915200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001615664 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 23990       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 5.2400765   |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3447834.92\n",
      "total_reward: 2447834.92\n",
      "total_cost: 63249.10\n",
      "total_trades: 52298\n",
      "Sharpe: 0.657\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2401         |\n",
      "|    time_elapsed         | 43826        |\n",
      "|    total_timesteps      | 4917248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011214475 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 24000        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | -2.5689094   |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2402        |\n",
      "|    time_elapsed         | 43844       |\n",
      "|    total_timesteps      | 4919296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010717648 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.71        |\n",
      "|    n_updates            | 24010       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | -1.2265971  |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2403         |\n",
      "|    time_elapsed         | 43862        |\n",
      "|    total_timesteps      | 4921344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015833393 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.82         |\n",
      "|    n_updates            | 24020        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -0.46029505  |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2404          |\n",
      "|    time_elapsed         | 43880         |\n",
      "|    total_timesteps      | 4923392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044982345 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.679         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24            |\n",
      "|    n_updates            | 24030         |\n",
      "|    policy_gradient_loss | -0.00192      |\n",
      "|    reward               | -0.18967578   |\n",
      "|    std                  | 18.8          |\n",
      "|    value_loss           | 31.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2405         |\n",
      "|    time_elapsed         | 43899        |\n",
      "|    total_timesteps      | 4925440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050646197 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 24040        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | 0.87463164   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2406         |\n",
      "|    time_elapsed         | 43917        |\n",
      "|    total_timesteps      | 4927488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012287877 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.12         |\n",
      "|    n_updates            | 24050        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | -1.5760459   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2407          |\n",
      "|    time_elapsed         | 43935         |\n",
      "|    total_timesteps      | 4929536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072273164 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.713         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.4          |\n",
      "|    n_updates            | 24060         |\n",
      "|    policy_gradient_loss | -0.00238      |\n",
      "|    reward               | 0.8062418     |\n",
      "|    std                  | 18.9          |\n",
      "|    value_loss           | 39.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2408         |\n",
      "|    time_elapsed         | 43953        |\n",
      "|    total_timesteps      | 4931584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012464847 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 24070        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | -1.1820925   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2409         |\n",
      "|    time_elapsed         | 43971        |\n",
      "|    total_timesteps      | 4933632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056064283 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 24080        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | 1.9399885    |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2410         |\n",
      "|    time_elapsed         | 43988        |\n",
      "|    total_timesteps      | 4935680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014522747 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 24090        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | -0.13863742  |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2411        |\n",
      "|    time_elapsed         | 44006       |\n",
      "|    total_timesteps      | 4937728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001174003 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 24100       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | -3.7730422  |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2412         |\n",
      "|    time_elapsed         | 44024        |\n",
      "|    total_timesteps      | 4939776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047598453 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 24110        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | -0.0934696   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2413        |\n",
      "|    time_elapsed         | 44042       |\n",
      "|    total_timesteps      | 4941824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003828249 |\n",
      "|    clip_fraction        | 0.00679     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 24120       |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | 0.13351579  |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2414          |\n",
      "|    time_elapsed         | 44060         |\n",
      "|    total_timesteps      | 4943872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00059369113 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.757         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.1          |\n",
      "|    n_updates            | 24130         |\n",
      "|    policy_gradient_loss | -0.00222      |\n",
      "|    reward               | -0.6293265    |\n",
      "|    std                  | 19.1          |\n",
      "|    value_loss           | 39.1          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4300177.31\n",
      "total_reward: 3300177.31\n",
      "total_cost: 67123.08\n",
      "total_trades: 52973\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2415         |\n",
      "|    time_elapsed         | 44077        |\n",
      "|    total_timesteps      | 4945920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009822358 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.4         |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | -1.8665829   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 46.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2416        |\n",
      "|    time_elapsed         | 44095       |\n",
      "|    total_timesteps      | 4947968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004324836 |\n",
      "|    clip_fraction        | 0.00986     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.7         |\n",
      "|    n_updates            | 24150       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | -0.6628128  |\n",
      "|    std                  | 19.1        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2417       |\n",
      "|    time_elapsed         | 44114      |\n",
      "|    total_timesteps      | 4950016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00184469 |\n",
      "|    clip_fraction        | 0.000244   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -126       |\n",
      "|    explained_variance   | 0.641      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.3       |\n",
      "|    n_updates            | 24160      |\n",
      "|    policy_gradient_loss | -0.00492   |\n",
      "|    reward               | 2.2753735  |\n",
      "|    std                  | 19.2       |\n",
      "|    value_loss           | 33.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2418         |\n",
      "|    time_elapsed         | 44132        |\n",
      "|    total_timesteps      | 4952064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029480164 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 24170        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 0.4507616    |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2419        |\n",
      "|    time_elapsed         | 44150       |\n",
      "|    total_timesteps      | 4954112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007874074 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | -0.5340498  |\n",
      "|    std                  | 19.2        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2420         |\n",
      "|    time_elapsed         | 44169        |\n",
      "|    total_timesteps      | 4956160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005619365 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 24190        |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    reward               | 0.38391873   |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 41.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2421          |\n",
      "|    time_elapsed         | 44186         |\n",
      "|    total_timesteps      | 4958208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057853654 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.73          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.9          |\n",
      "|    n_updates            | 24200         |\n",
      "|    policy_gradient_loss | -0.00202      |\n",
      "|    reward               | -1.5396168    |\n",
      "|    std                  | 19.2          |\n",
      "|    value_loss           | 42.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2422         |\n",
      "|    time_elapsed         | 44204        |\n",
      "|    total_timesteps      | 4960256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013199399 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -0.18705869  |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2423         |\n",
      "|    time_elapsed         | 44222        |\n",
      "|    total_timesteps      | 4962304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056197783 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.76         |\n",
      "|    n_updates            | 24220        |\n",
      "|    policy_gradient_loss | -0.00855     |\n",
      "|    reward               | -0.045311753 |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2424         |\n",
      "|    time_elapsed         | 44240        |\n",
      "|    total_timesteps      | 4964352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018393002 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 24230        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 2.1449738    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2425         |\n",
      "|    time_elapsed         | 44258        |\n",
      "|    total_timesteps      | 4966400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016410671 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -0.13330862  |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 36.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2426        |\n",
      "|    time_elapsed         | 44276       |\n",
      "|    total_timesteps      | 4968448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008961849 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.95        |\n",
      "|    n_updates            | 24250       |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | -0.1565837  |\n",
      "|    std                  | 19.4        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2427         |\n",
      "|    time_elapsed         | 44294        |\n",
      "|    total_timesteps      | 4970496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013023767 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 24260        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 0.22574943   |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2428          |\n",
      "|    time_elapsed         | 44312         |\n",
      "|    total_timesteps      | 4972544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038440365 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.432         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20            |\n",
      "|    n_updates            | 24270         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | 7.1255555     |\n",
      "|    std                  | 19.4          |\n",
      "|    value_loss           | 55.1          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3652348.64\n",
      "total_reward: 2652348.64\n",
      "total_cost: 59750.06\n",
      "total_trades: 52492\n",
      "Sharpe: 0.688\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2429         |\n",
      "|    time_elapsed         | 44330        |\n",
      "|    total_timesteps      | 4974592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032963033 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.96         |\n",
      "|    n_updates            | 24280        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 0.4723424    |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2430        |\n",
      "|    time_elapsed         | 44349       |\n",
      "|    total_timesteps      | 4976640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002419074 |\n",
      "|    clip_fraction        | 0.00195     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 24290       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | 1.6624615   |\n",
      "|    std                  | 19.4        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2431         |\n",
      "|    time_elapsed         | 44367        |\n",
      "|    total_timesteps      | 4978688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023019342 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 24300        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | -0.14646085  |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2432         |\n",
      "|    time_elapsed         | 44385        |\n",
      "|    total_timesteps      | 4980736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015308078 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.99         |\n",
      "|    n_updates            | 24310        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | -1.5796419   |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2433         |\n",
      "|    time_elapsed         | 44403        |\n",
      "|    total_timesteps      | 4982784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028131984 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.03         |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | -1.1932769   |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2434         |\n",
      "|    time_elapsed         | 44421        |\n",
      "|    total_timesteps      | 4984832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017930456 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 24330        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 0.43737203   |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2435          |\n",
      "|    time_elapsed         | 44439         |\n",
      "|    total_timesteps      | 4986880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067157974 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.603         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.1          |\n",
      "|    n_updates            | 24340         |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    reward               | 0.004314297   |\n",
      "|    std                  | 19.5          |\n",
      "|    value_loss           | 37.7          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2436       |\n",
      "|    time_elapsed         | 44457      |\n",
      "|    total_timesteps      | 4988928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01287603 |\n",
      "|    clip_fraction        | 0.0745     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -127       |\n",
      "|    explained_variance   | 0.693      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.22       |\n",
      "|    n_updates            | 24350      |\n",
      "|    policy_gradient_loss | -0.00901   |\n",
      "|    reward               | -0.3169085 |\n",
      "|    std                  | 19.6       |\n",
      "|    value_loss           | 19.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2437         |\n",
      "|    time_elapsed         | 44475        |\n",
      "|    total_timesteps      | 4990976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019894647 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.33         |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 0.70485085   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2438         |\n",
      "|    time_elapsed         | 44493        |\n",
      "|    total_timesteps      | 4993024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014619593 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 24370        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | -0.6331681   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2439        |\n",
      "|    time_elapsed         | 44511       |\n",
      "|    total_timesteps      | 4995072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001719802 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 24380       |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    reward               | 2.0295799   |\n",
      "|    std                  | 19.6        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2440       |\n",
      "|    time_elapsed         | 44529      |\n",
      "|    total_timesteps      | 4997120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00404652 |\n",
      "|    clip_fraction        | 0.00596    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -127       |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.88       |\n",
      "|    n_updates            | 24390      |\n",
      "|    policy_gradient_loss | -0.00588   |\n",
      "|    reward               | -0.438689  |\n",
      "|    std                  | 19.7       |\n",
      "|    value_loss           | 23.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2441         |\n",
      "|    time_elapsed         | 44547        |\n",
      "|    total_timesteps      | 4999168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018513885 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 24400        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | -0.18445984  |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2442        |\n",
      "|    time_elapsed         | 44565       |\n",
      "|    total_timesteps      | 5001216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001464583 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 24410       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | -0.9547583  |\n",
      "|    std                  | 19.7        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3407378.02\n",
      "total_reward: 2407378.02\n",
      "total_cost: 72971.47\n",
      "total_trades: 53482\n",
      "Sharpe: 0.649\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2443        |\n",
      "|    time_elapsed         | 44583       |\n",
      "|    total_timesteps      | 5003264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007128932 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.52        |\n",
      "|    n_updates            | 24420       |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | -0.7132046  |\n",
      "|    std                  | 19.8        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2444        |\n",
      "|    time_elapsed         | 44601       |\n",
      "|    total_timesteps      | 5005312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001085334 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.32        |\n",
      "|    n_updates            | 24430       |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | -1.2241791  |\n",
      "|    std                  | 19.8        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2445         |\n",
      "|    time_elapsed         | 44619        |\n",
      "|    total_timesteps      | 5007360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010517956 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 24440        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | -0.70563334  |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2446         |\n",
      "|    time_elapsed         | 44637        |\n",
      "|    total_timesteps      | 5009408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015799082 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 24450        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | 0.75307935   |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2447         |\n",
      "|    time_elapsed         | 44655        |\n",
      "|    total_timesteps      | 5011456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016700048 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.24         |\n",
      "|    n_updates            | 24460        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | -0.124891005 |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2448         |\n",
      "|    time_elapsed         | 44673        |\n",
      "|    total_timesteps      | 5013504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013902247 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 24470        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | 17.371117    |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2449        |\n",
      "|    time_elapsed         | 44691       |\n",
      "|    total_timesteps      | 5015552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001159968 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 24480       |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    reward               | -0.08274755 |\n",
      "|    std                  | 19.8        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2450        |\n",
      "|    time_elapsed         | 44708       |\n",
      "|    total_timesteps      | 5017600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008115495 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 24490       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | 0.33804947  |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2451         |\n",
      "|    time_elapsed         | 44727        |\n",
      "|    total_timesteps      | 5019648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014310256 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.51         |\n",
      "|    n_updates            | 24500        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 0.36958385   |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2452         |\n",
      "|    time_elapsed         | 44744        |\n",
      "|    total_timesteps      | 5021696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013175929 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 24510        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -2.9176922   |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 42.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2453         |\n",
      "|    time_elapsed         | 44762        |\n",
      "|    total_timesteps      | 5023744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062843063 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 24520        |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    reward               | 2.1420739    |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2454         |\n",
      "|    time_elapsed         | 44780        |\n",
      "|    total_timesteps      | 5025792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028109571 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 24530        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | -0.039685454 |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2455         |\n",
      "|    time_elapsed         | 44798        |\n",
      "|    total_timesteps      | 5027840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008720049 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 24540        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 2.2962477    |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2456       |\n",
      "|    time_elapsed         | 44816      |\n",
      "|    total_timesteps      | 5029888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00253615 |\n",
      "|    clip_fraction        | 0.00254    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -128       |\n",
      "|    explained_variance   | 0.759      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 24550      |\n",
      "|    policy_gradient_loss | -0.00523   |\n",
      "|    reward               | 2.9517379  |\n",
      "|    std                  | 20.1       |\n",
      "|    value_loss           | 30.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3575243.65\n",
      "total_reward: 2575243.65\n",
      "total_cost: 55825.97\n",
      "total_trades: 51744\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2457         |\n",
      "|    time_elapsed         | 44834        |\n",
      "|    total_timesteps      | 5031936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025640987 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.39         |\n",
      "|    n_updates            | 24560        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | -1.6358736   |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 20.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2458         |\n",
      "|    time_elapsed         | 44852        |\n",
      "|    total_timesteps      | 5033984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010259415 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 24570        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 0.24472935   |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2459         |\n",
      "|    time_elapsed         | 44870        |\n",
      "|    total_timesteps      | 5036032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019617416 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 24580        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | -2.8865333   |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2460         |\n",
      "|    time_elapsed         | 44888        |\n",
      "|    total_timesteps      | 5038080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024751525 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 24590        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | -0.81543297  |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2461         |\n",
      "|    time_elapsed         | 44906        |\n",
      "|    total_timesteps      | 5040128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023615176 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 24600        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | -2.458359    |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2462          |\n",
      "|    time_elapsed         | 44925         |\n",
      "|    total_timesteps      | 5042176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038157514 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.636         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28            |\n",
      "|    n_updates            | 24610         |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    reward               | 1.5366455     |\n",
      "|    std                  | 20.2          |\n",
      "|    value_loss           | 49.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2463         |\n",
      "|    time_elapsed         | 44943        |\n",
      "|    total_timesteps      | 5044224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054150545 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 24620        |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    reward               | -0.840546    |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2464        |\n",
      "|    time_elapsed         | 44961       |\n",
      "|    total_timesteps      | 5046272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001424599 |\n",
      "|    clip_fraction        | 0.002       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 24630       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    reward               | 3.6456559   |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2465         |\n",
      "|    time_elapsed         | 44980        |\n",
      "|    total_timesteps      | 5048320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012360432 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 24640        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 0.96249354   |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2466        |\n",
      "|    time_elapsed         | 44997       |\n",
      "|    total_timesteps      | 5050368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001099998 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 24650       |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    reward               | 0.020761555 |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2467        |\n",
      "|    time_elapsed         | 45015       |\n",
      "|    total_timesteps      | 5052416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009857744 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.45        |\n",
      "|    n_updates            | 24660       |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    reward               | -0.06679159 |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2468         |\n",
      "|    time_elapsed         | 45033        |\n",
      "|    total_timesteps      | 5054464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024364062 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 24670        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -0.61629814  |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 28.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2469          |\n",
      "|    time_elapsed         | 45051         |\n",
      "|    total_timesteps      | 5056512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064188126 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.691         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.9          |\n",
      "|    n_updates            | 24680         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | -3.0657673    |\n",
      "|    std                  | 20.4          |\n",
      "|    value_loss           | 39.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2470         |\n",
      "|    time_elapsed         | 45069        |\n",
      "|    total_timesteps      | 5058560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035466568 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 24690        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | 1.7188591    |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4620874.50\n",
      "total_reward: 3620874.50\n",
      "total_cost: 60360.15\n",
      "total_trades: 52164\n",
      "Sharpe: 0.796\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2471         |\n",
      "|    time_elapsed         | 45087        |\n",
      "|    total_timesteps      | 5060608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021050256 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 24700        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 1.5744711    |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2472          |\n",
      "|    time_elapsed         | 45105         |\n",
      "|    total_timesteps      | 5062656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093798724 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.683         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.8          |\n",
      "|    n_updates            | 24710         |\n",
      "|    policy_gradient_loss | -0.00238      |\n",
      "|    reward               | 5.8790216     |\n",
      "|    std                  | 20.4          |\n",
      "|    value_loss           | 47.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2473         |\n",
      "|    time_elapsed         | 45123        |\n",
      "|    total_timesteps      | 5064704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017330176 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 24720        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | -7.1856112   |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2474         |\n",
      "|    time_elapsed         | 45140        |\n",
      "|    total_timesteps      | 5066752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051213456 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.98         |\n",
      "|    n_updates            | 24730        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | -2.2220767   |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2475         |\n",
      "|    time_elapsed         | 45159        |\n",
      "|    total_timesteps      | 5068800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016086638 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 24740        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -2.3306575   |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2476         |\n",
      "|    time_elapsed         | 45177        |\n",
      "|    total_timesteps      | 5070848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009594988 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 24750        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    reward               | -2.652708    |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2477        |\n",
      "|    time_elapsed         | 45196       |\n",
      "|    total_timesteps      | 5072896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007074048 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 24760       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 0.15114199  |\n",
      "|    std                  | 20.6        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2478         |\n",
      "|    time_elapsed         | 45215        |\n",
      "|    total_timesteps      | 5074944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011383729 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 24770        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -1.1637752   |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2479         |\n",
      "|    time_elapsed         | 45234        |\n",
      "|    total_timesteps      | 5076992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012111538 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 24780        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | 7.71488      |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2480         |\n",
      "|    time_elapsed         | 45252        |\n",
      "|    total_timesteps      | 5079040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029904065 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 24790        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | -1.5305557   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2481         |\n",
      "|    time_elapsed         | 45270        |\n",
      "|    total_timesteps      | 5081088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047341436 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 24800        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | 2.9785676    |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2482          |\n",
      "|    time_elapsed         | 45287         |\n",
      "|    total_timesteps      | 5083136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067521736 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.679         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21            |\n",
      "|    n_updates            | 24810         |\n",
      "|    policy_gradient_loss | -0.00258      |\n",
      "|    reward               | 0.47182414    |\n",
      "|    std                  | 20.7          |\n",
      "|    value_loss           | 41.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2483         |\n",
      "|    time_elapsed         | 45305        |\n",
      "|    total_timesteps      | 5085184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013942953 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.745        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 24820        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 4.77427      |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2484        |\n",
      "|    time_elapsed         | 45323       |\n",
      "|    total_timesteps      | 5087232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009159642 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.17        |\n",
      "|    n_updates            | 24830       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -0.39389065 |\n",
      "|    std                  | 20.8        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3683427.82\n",
      "total_reward: 2683427.82\n",
      "total_cost: 56144.72\n",
      "total_trades: 51786\n",
      "Sharpe: 0.696\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2485          |\n",
      "|    time_elapsed         | 45341         |\n",
      "|    total_timesteps      | 5089280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064028223 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.677         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.1          |\n",
      "|    n_updates            | 24840         |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    reward               | 0.90949863    |\n",
      "|    std                  | 20.9          |\n",
      "|    value_loss           | 40.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2486         |\n",
      "|    time_elapsed         | 45360        |\n",
      "|    total_timesteps      | 5091328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006838214 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 24850        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 3.2911458    |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2487       |\n",
      "|    time_elapsed         | 45378      |\n",
      "|    total_timesteps      | 5093376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00200284 |\n",
      "|    clip_fraction        | 0.000781   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -129       |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 24860      |\n",
      "|    policy_gradient_loss | -0.00449   |\n",
      "|    reward               | 0.06207102 |\n",
      "|    std                  | 20.9       |\n",
      "|    value_loss           | 29.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2488         |\n",
      "|    time_elapsed         | 45396        |\n",
      "|    total_timesteps      | 5095424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041032434 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.89         |\n",
      "|    n_updates            | 24870        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    reward               | 1.0499713    |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2489        |\n",
      "|    time_elapsed         | 45413       |\n",
      "|    total_timesteps      | 5097472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000307633 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 24880       |\n",
      "|    policy_gradient_loss | -0.000873   |\n",
      "|    reward               | -0.06769241 |\n",
      "|    std                  | 21          |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2490          |\n",
      "|    time_elapsed         | 45431         |\n",
      "|    total_timesteps      | 5099520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075991603 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.744         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.5          |\n",
      "|    n_updates            | 24890         |\n",
      "|    policy_gradient_loss | -0.00224      |\n",
      "|    reward               | 1.0884329     |\n",
      "|    std                  | 21            |\n",
      "|    value_loss           | 39.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2491        |\n",
      "|    time_elapsed         | 45450       |\n",
      "|    total_timesteps      | 5101568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009750221 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 24900       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 2.563009    |\n",
      "|    std                  | 21          |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2492          |\n",
      "|    time_elapsed         | 45468         |\n",
      "|    total_timesteps      | 5103616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023819492 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.659         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.2          |\n",
      "|    n_updates            | 24910         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | 2.1047626     |\n",
      "|    std                  | 21            |\n",
      "|    value_loss           | 48            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2493        |\n",
      "|    time_elapsed         | 45487       |\n",
      "|    total_timesteps      | 5105664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000729186 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 24920       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | 1.510787    |\n",
      "|    std                  | 21          |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2494        |\n",
      "|    time_elapsed         | 45505       |\n",
      "|    total_timesteps      | 5107712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002833842 |\n",
      "|    clip_fraction        | 0.00186     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 24930       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 1.5905421   |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2495         |\n",
      "|    time_elapsed         | 45523        |\n",
      "|    total_timesteps      | 5109760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010918439 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 24940        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | 2.9037564    |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2496         |\n",
      "|    time_elapsed         | 45541        |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005850226 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 24950        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | -0.77727187  |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2497         |\n",
      "|    time_elapsed         | 45559        |\n",
      "|    total_timesteps      | 5113856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009532496 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 24960        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | -2.9748344   |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2498         |\n",
      "|    time_elapsed         | 45577        |\n",
      "|    total_timesteps      | 5115904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057225176 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 24970        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | 3.258921     |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4105918.31\n",
      "total_reward: 3105918.31\n",
      "total_cost: 77139.41\n",
      "total_trades: 53990\n",
      "Sharpe: 0.744\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2499         |\n",
      "|    time_elapsed         | 45595        |\n",
      "|    total_timesteps      | 5117952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009512458 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    reward               | -0.99191636  |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2500          |\n",
      "|    time_elapsed         | 45614         |\n",
      "|    total_timesteps      | 5120000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054521905 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.733         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.4          |\n",
      "|    n_updates            | 24990         |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    reward               | 4.078702      |\n",
      "|    std                  | 21.2          |\n",
      "|    value_loss           | 41            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2501        |\n",
      "|    time_elapsed         | 45631       |\n",
      "|    total_timesteps      | 5122048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002808075 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 25000       |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | 1.769362    |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2502        |\n",
      "|    time_elapsed         | 45649       |\n",
      "|    total_timesteps      | 5124096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001046831 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 25010       |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    reward               | -0.20661172 |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2503        |\n",
      "|    time_elapsed         | 45667       |\n",
      "|    total_timesteps      | 5126144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001386116 |\n",
      "|    clip_fraction        | 0.000537    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 25020       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 3.0186174   |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2504         |\n",
      "|    time_elapsed         | 45685        |\n",
      "|    total_timesteps      | 5128192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020388174 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 25030        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | 2.988126     |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2505         |\n",
      "|    time_elapsed         | 45703        |\n",
      "|    total_timesteps      | 5130240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037206877 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 25040        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | 1.7170532    |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2506        |\n",
      "|    time_elapsed         | 45721       |\n",
      "|    total_timesteps      | 5132288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001027626 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 25050       |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | -0.12171764 |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2507          |\n",
      "|    time_elapsed         | 45739         |\n",
      "|    total_timesteps      | 5134336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031758752 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.7           |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.5          |\n",
      "|    n_updates            | 25060         |\n",
      "|    policy_gradient_loss | -0.000892     |\n",
      "|    reward               | 4.225729      |\n",
      "|    std                  | 21.2          |\n",
      "|    value_loss           | 44.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2508         |\n",
      "|    time_elapsed         | 45756        |\n",
      "|    total_timesteps      | 5136384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025406252 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.64         |\n",
      "|    n_updates            | 25070        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.27795517   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2509         |\n",
      "|    time_elapsed         | 45774        |\n",
      "|    total_timesteps      | 5138432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019812086 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 25080        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | 2.388569     |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2510          |\n",
      "|    time_elapsed         | 45792         |\n",
      "|    total_timesteps      | 5140480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035764204 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.434         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.7          |\n",
      "|    n_updates            | 25090         |\n",
      "|    policy_gradient_loss | -0.000933     |\n",
      "|    reward               | 13.82006      |\n",
      "|    std                  | 21.3          |\n",
      "|    value_loss           | 38            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2511         |\n",
      "|    time_elapsed         | 45810        |\n",
      "|    total_timesteps      | 5142528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031646886 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 25100        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | -6.3341527   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2512        |\n",
      "|    time_elapsed         | 45829       |\n",
      "|    total_timesteps      | 5144576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004536444 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.06        |\n",
      "|    n_updates            | 25110       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -1.1337109  |\n",
      "|    std                  | 21.4        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2513         |\n",
      "|    time_elapsed         | 45847        |\n",
      "|    total_timesteps      | 5146624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010553363 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 25120        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 1.0612869    |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3466254.72\n",
      "total_reward: 2466254.72\n",
      "total_cost: 55829.43\n",
      "total_trades: 51777\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2514         |\n",
      "|    time_elapsed         | 45864        |\n",
      "|    total_timesteps      | 5148672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021288935 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 25130        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | -1.7501386   |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2515        |\n",
      "|    time_elapsed         | 45882       |\n",
      "|    total_timesteps      | 5150720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005658851 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.12        |\n",
      "|    n_updates            | 25140       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | 0.42826188  |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2516         |\n",
      "|    time_elapsed         | 45901        |\n",
      "|    total_timesteps      | 5152768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018245728 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 25150        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | -1.832822    |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2517         |\n",
      "|    time_elapsed         | 45919        |\n",
      "|    total_timesteps      | 5154816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016626733 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 25160        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 1.7272112    |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2518         |\n",
      "|    time_elapsed         | 45937        |\n",
      "|    total_timesteps      | 5156864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047618346 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.72         |\n",
      "|    n_updates            | 25170        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -1.0638396   |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2519       |\n",
      "|    time_elapsed         | 45955      |\n",
      "|    total_timesteps      | 5158912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00240325 |\n",
      "|    clip_fraction        | 0.00234    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -130       |\n",
      "|    explained_variance   | 0.643      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.1       |\n",
      "|    n_updates            | 25180      |\n",
      "|    policy_gradient_loss | -0.00367   |\n",
      "|    reward               | -1.2527924 |\n",
      "|    std                  | 21.6       |\n",
      "|    value_loss           | 23.9       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2520          |\n",
      "|    time_elapsed         | 45973         |\n",
      "|    total_timesteps      | 5160960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085185864 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.732         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.4          |\n",
      "|    n_updates            | 25190         |\n",
      "|    policy_gradient_loss | -0.00178      |\n",
      "|    reward               | 2.2650132     |\n",
      "|    std                  | 21.6          |\n",
      "|    value_loss           | 36.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2521         |\n",
      "|    time_elapsed         | 45991        |\n",
      "|    total_timesteps      | 5163008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029878046 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 25200        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -0.09734575  |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 33.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2522         |\n",
      "|    time_elapsed         | 46009        |\n",
      "|    total_timesteps      | 5165056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046083317 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 25210        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    reward               | 0.707676     |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2523         |\n",
      "|    time_elapsed         | 46028        |\n",
      "|    total_timesteps      | 5167104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008725112 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 25220        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    reward               | -0.6779442   |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2524         |\n",
      "|    time_elapsed         | 46046        |\n",
      "|    total_timesteps      | 5169152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007755686 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 25230        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | -1.9719756   |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2525         |\n",
      "|    time_elapsed         | 46064        |\n",
      "|    total_timesteps      | 5171200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075898753 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.98         |\n",
      "|    n_updates            | 25240        |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    reward               | 2.1677632    |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2526         |\n",
      "|    time_elapsed         | 46082        |\n",
      "|    total_timesteps      | 5173248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008148092 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 25250        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 0.010396356  |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2527          |\n",
      "|    time_elapsed         | 46101         |\n",
      "|    total_timesteps      | 5175296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046930058 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.55          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.2          |\n",
      "|    n_updates            | 25260         |\n",
      "|    policy_gradient_loss | -0.00178      |\n",
      "|    reward               | -1.203819     |\n",
      "|    std                  | 21.8          |\n",
      "|    value_loss           | 45.9          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3623054.38\n",
      "total_reward: 2623054.38\n",
      "total_cost: 56778.36\n",
      "total_trades: 51585\n",
      "Sharpe: 0.686\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2528         |\n",
      "|    time_elapsed         | 46119        |\n",
      "|    total_timesteps      | 5177344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026818654 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 25270        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | 2.030169     |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2529         |\n",
      "|    time_elapsed         | 46137        |\n",
      "|    total_timesteps      | 5179392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023936443 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 25280        |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | 0.91578954   |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2530          |\n",
      "|    time_elapsed         | 46155         |\n",
      "|    total_timesteps      | 5181440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048753727 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.655         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.2          |\n",
      "|    n_updates            | 25290         |\n",
      "|    policy_gradient_loss | -0.000837     |\n",
      "|    reward               | 0.6300128     |\n",
      "|    std                  | 21.8          |\n",
      "|    value_loss           | 41.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2531         |\n",
      "|    time_elapsed         | 46172        |\n",
      "|    total_timesteps      | 5183488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006821956 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 25300        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 0.78913      |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 40.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2532        |\n",
      "|    time_elapsed         | 46190       |\n",
      "|    total_timesteps      | 5185536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006737713 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.11        |\n",
      "|    n_updates            | 25310       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 0.14124246  |\n",
      "|    std                  | 21.9        |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2533         |\n",
      "|    time_elapsed         | 46209        |\n",
      "|    total_timesteps      | 5187584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009931712 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 25320        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 2.028921     |\n",
      "|    std                  | 21.9         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2534         |\n",
      "|    time_elapsed         | 46227        |\n",
      "|    total_timesteps      | 5189632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007398585 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 25330        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -5.427083    |\n",
      "|    std                  | 21.9         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2535        |\n",
      "|    time_elapsed         | 46245       |\n",
      "|    total_timesteps      | 5191680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001625921 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 25340       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    reward               | -2.75854    |\n",
      "|    std                  | 21.9        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2536        |\n",
      "|    time_elapsed         | 46263       |\n",
      "|    total_timesteps      | 5193728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001443874 |\n",
      "|    clip_fraction        | 0.00122     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 25350       |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | -0.76007277 |\n",
      "|    std                  | 22          |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2537          |\n",
      "|    time_elapsed         | 46281         |\n",
      "|    total_timesteps      | 5195776       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047281402 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.447         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.9          |\n",
      "|    n_updates            | 25360         |\n",
      "|    policy_gradient_loss | -0.00167      |\n",
      "|    reward               | -0.7948803    |\n",
      "|    std                  | 22            |\n",
      "|    value_loss           | 64.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2538         |\n",
      "|    time_elapsed         | 46299        |\n",
      "|    total_timesteps      | 5197824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022073372 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 25370        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 1.2862179    |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 53.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2539         |\n",
      "|    time_elapsed         | 46317        |\n",
      "|    total_timesteps      | 5199872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037771254 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.69         |\n",
      "|    n_updates            | 25380        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 0.19447152   |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2540         |\n",
      "|    time_elapsed         | 46335        |\n",
      "|    total_timesteps      | 5201920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010359893 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 0.96630627   |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2541         |\n",
      "|    time_elapsed         | 46353        |\n",
      "|    total_timesteps      | 5203968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016635957 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 25400        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 0.42680138   |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3432834.25\n",
      "total_reward: 2432834.25\n",
      "total_cost: 63432.07\n",
      "total_trades: 52730\n",
      "Sharpe: 0.660\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2542       |\n",
      "|    time_elapsed         | 46371      |\n",
      "|    total_timesteps      | 5206016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00537092 |\n",
      "|    clip_fraction        | 0.0143     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -130       |\n",
      "|    explained_variance   | 0.728      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.59       |\n",
      "|    n_updates            | 25410      |\n",
      "|    policy_gradient_loss | -0.00604   |\n",
      "|    reward               | -2.5911267 |\n",
      "|    std                  | 22.2       |\n",
      "|    value_loss           | 25.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2543         |\n",
      "|    time_elapsed         | 46391        |\n",
      "|    total_timesteps      | 5208064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033179468 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.06         |\n",
      "|    n_updates            | 25420        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | -0.16098742  |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2544          |\n",
      "|    time_elapsed         | 46409         |\n",
      "|    total_timesteps      | 5210112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071123685 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.754         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.4          |\n",
      "|    n_updates            | 25430         |\n",
      "|    policy_gradient_loss | -0.00257      |\n",
      "|    reward               | 2.0905411     |\n",
      "|    std                  | 22.2          |\n",
      "|    value_loss           | 36.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2545         |\n",
      "|    time_elapsed         | 46427        |\n",
      "|    total_timesteps      | 5212160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006766995 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 25440        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | -0.24077404  |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2546         |\n",
      "|    time_elapsed         | 46445        |\n",
      "|    total_timesteps      | 5214208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039019894 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 25450        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | -1.1495899   |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2547         |\n",
      "|    time_elapsed         | 46463        |\n",
      "|    total_timesteps      | 5216256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004411472 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 25460        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | 1.3722541    |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2548          |\n",
      "|    time_elapsed         | 46481         |\n",
      "|    total_timesteps      | 5218304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069618726 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.772         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13            |\n",
      "|    n_updates            | 25470         |\n",
      "|    policy_gradient_loss | -0.00209      |\n",
      "|    reward               | 2.618864      |\n",
      "|    std                  | 22.3          |\n",
      "|    value_loss           | 38.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2549         |\n",
      "|    time_elapsed         | 46500        |\n",
      "|    total_timesteps      | 5220352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041447203 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.795        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.86         |\n",
      "|    n_updates            | 25480        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | 1.1098017    |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2550         |\n",
      "|    time_elapsed         | 46518        |\n",
      "|    total_timesteps      | 5222400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003946521 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    reward               | 0.15905096   |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2551        |\n",
      "|    time_elapsed         | 46535       |\n",
      "|    total_timesteps      | 5224448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000977817 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 25500       |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    reward               | -1.9824188  |\n",
      "|    std                  | 22.3        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2552        |\n",
      "|    time_elapsed         | 46554       |\n",
      "|    total_timesteps      | 5226496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001213366 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 25510       |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    reward               | -1.0323783  |\n",
      "|    std                  | 22.3        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2553         |\n",
      "|    time_elapsed         | 46572        |\n",
      "|    total_timesteps      | 5228544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012554543 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -2.7185194   |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2554         |\n",
      "|    time_elapsed         | 46590        |\n",
      "|    total_timesteps      | 5230592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032915547 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 25530        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | 0.46414793   |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2555          |\n",
      "|    time_elapsed         | 46609         |\n",
      "|    total_timesteps      | 5232640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096701295 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.777         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.7          |\n",
      "|    n_updates            | 25540         |\n",
      "|    policy_gradient_loss | -0.00203      |\n",
      "|    reward               | 0.83326954    |\n",
      "|    std                  | 22.4          |\n",
      "|    value_loss           | 41.2          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3672106.39\n",
      "total_reward: 2672106.39\n",
      "total_cost: 51014.04\n",
      "total_trades: 50605\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2556         |\n",
      "|    time_elapsed         | 46628        |\n",
      "|    total_timesteps      | 5234688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066250823 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.59         |\n",
      "|    n_updates            | 25550        |\n",
      "|    policy_gradient_loss | -0.00751     |\n",
      "|    reward               | 0.47383228   |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 16.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2557         |\n",
      "|    time_elapsed         | 46646        |\n",
      "|    total_timesteps      | 5236736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008203375 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 25560        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    reward               | -0.46398675  |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2558         |\n",
      "|    time_elapsed         | 46664        |\n",
      "|    total_timesteps      | 5238784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017653184 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 25570        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 2.1043124    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2559         |\n",
      "|    time_elapsed         | 46682        |\n",
      "|    total_timesteps      | 5240832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040305182 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.26         |\n",
      "|    n_updates            | 25580        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | 0.724371     |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2560         |\n",
      "|    time_elapsed         | 46700        |\n",
      "|    total_timesteps      | 5242880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011580421 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 25590        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | -0.04142165  |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2561         |\n",
      "|    time_elapsed         | 46718        |\n",
      "|    total_timesteps      | 5244928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010367184 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 25600        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 4.088023     |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2562         |\n",
      "|    time_elapsed         | 46736        |\n",
      "|    total_timesteps      | 5246976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016585025 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 25610        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | 0.5532289    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2563         |\n",
      "|    time_elapsed         | 46754        |\n",
      "|    total_timesteps      | 5249024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048780823 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 25620        |\n",
      "|    policy_gradient_loss | -0.00773     |\n",
      "|    reward               | -3.8188012   |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2564         |\n",
      "|    time_elapsed         | 46772        |\n",
      "|    total_timesteps      | 5251072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005385212 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | 1.1056374    |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2565         |\n",
      "|    time_elapsed         | 46789        |\n",
      "|    total_timesteps      | 5253120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013325803 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 25640        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 2.9965518    |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2566         |\n",
      "|    time_elapsed         | 46807        |\n",
      "|    total_timesteps      | 5255168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006730248 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 25650        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | 0.300717     |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2567         |\n",
      "|    time_elapsed         | 46825        |\n",
      "|    total_timesteps      | 5257216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026960932 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.73         |\n",
      "|    n_updates            | 25660        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -0.18254596  |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2568          |\n",
      "|    time_elapsed         | 46844         |\n",
      "|    total_timesteps      | 5259264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026014308 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.688         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.4          |\n",
      "|    n_updates            | 25670         |\n",
      "|    policy_gradient_loss | -0.000782     |\n",
      "|    reward               | 0.5462296     |\n",
      "|    std                  | 22.6          |\n",
      "|    value_loss           | 30.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2569         |\n",
      "|    time_elapsed         | 46862        |\n",
      "|    total_timesteps      | 5261312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016856492 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 25680        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | 0.6782272    |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3622278.27\n",
      "total_reward: 2622278.27\n",
      "total_cost: 60040.61\n",
      "total_trades: 51880\n",
      "Sharpe: 0.680\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2570         |\n",
      "|    time_elapsed         | 46880        |\n",
      "|    total_timesteps      | 5263360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050075464 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 25690        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    reward               | -2.8750007   |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2571        |\n",
      "|    time_elapsed         | 46898       |\n",
      "|    total_timesteps      | 5265408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004188927 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.34        |\n",
      "|    n_updates            | 25700       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -0.3199913  |\n",
      "|    std                  | 22.7        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2572          |\n",
      "|    time_elapsed         | 46916         |\n",
      "|    total_timesteps      | 5267456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029115184 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.503         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.7          |\n",
      "|    n_updates            | 25710         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | -1.6697142    |\n",
      "|    std                  | 22.8          |\n",
      "|    value_loss           | 72.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2573         |\n",
      "|    time_elapsed         | 46934        |\n",
      "|    total_timesteps      | 5269504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072872974 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.33         |\n",
      "|    n_updates            | 25720        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    reward               | 0.7764292    |\n",
      "|    std                  | 22.8         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2574          |\n",
      "|    time_elapsed         | 46952         |\n",
      "|    total_timesteps      | 5271552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051948056 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.727         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.6          |\n",
      "|    n_updates            | 25730         |\n",
      "|    policy_gradient_loss | -0.00209      |\n",
      "|    reward               | 0.11620494    |\n",
      "|    std                  | 22.8          |\n",
      "|    value_loss           | 39.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2575         |\n",
      "|    time_elapsed         | 46971        |\n",
      "|    total_timesteps      | 5273600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014684353 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 25740        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -1.9145888   |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2576         |\n",
      "|    time_elapsed         | 46989        |\n",
      "|    total_timesteps      | 5275648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018234525 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 25750        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | -1.1728045   |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 35.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2577         |\n",
      "|    time_elapsed         | 47007        |\n",
      "|    total_timesteps      | 5277696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015350096 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.26         |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.3548612    |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2578         |\n",
      "|    time_elapsed         | 47026        |\n",
      "|    total_timesteps      | 5279744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011280433 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.38         |\n",
      "|    n_updates            | 25770        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | -0.39036176  |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2579         |\n",
      "|    time_elapsed         | 47044        |\n",
      "|    total_timesteps      | 5281792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008248829 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 25780        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | -0.2888096   |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2580         |\n",
      "|    time_elapsed         | 47062        |\n",
      "|    total_timesteps      | 5283840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067739394 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    reward               | 1.0121373    |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2581          |\n",
      "|    time_elapsed         | 47080         |\n",
      "|    total_timesteps      | 5285888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087284076 |\n",
      "|    clip_fraction        | 0.00151       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.721         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.6          |\n",
      "|    n_updates            | 25800         |\n",
      "|    policy_gradient_loss | -0.00237      |\n",
      "|    reward               | -0.6965596    |\n",
      "|    std                  | 22.9          |\n",
      "|    value_loss           | 38.3          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2582         |\n",
      "|    time_elapsed         | 47099        |\n",
      "|    total_timesteps      | 5287936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007731758 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 25810        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | 0.24110813   |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2583        |\n",
      "|    time_elapsed         | 47117       |\n",
      "|    total_timesteps      | 5289984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004182851 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 25820       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | -1.2404581  |\n",
      "|    std                  | 23          |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3905965.68\n",
      "total_reward: 2905965.68\n",
      "total_cost: 59427.88\n",
      "total_trades: 50911\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2584         |\n",
      "|    time_elapsed         | 47135        |\n",
      "|    total_timesteps      | 5292032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011625369 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 25830        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -0.4432066   |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2585         |\n",
      "|    time_elapsed         | 47153        |\n",
      "|    total_timesteps      | 5294080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009359772 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 25840        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | -4.6950493   |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2586         |\n",
      "|    time_elapsed         | 47172        |\n",
      "|    total_timesteps      | 5296128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023818668 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 25850        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | 0.27536887   |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2587         |\n",
      "|    time_elapsed         | 47191        |\n",
      "|    total_timesteps      | 5298176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039029387 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.36         |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    reward               | -0.07321262  |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2588          |\n",
      "|    time_elapsed         | 47210         |\n",
      "|    total_timesteps      | 5300224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046845924 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.635         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30.9          |\n",
      "|    n_updates            | 25870         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    reward               | 0.0762404     |\n",
      "|    std                  | 23.1          |\n",
      "|    value_loss           | 50.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2589          |\n",
      "|    time_elapsed         | 47228         |\n",
      "|    total_timesteps      | 5302272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065850664 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.606         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15            |\n",
      "|    n_updates            | 25880         |\n",
      "|    policy_gradient_loss | -0.00184      |\n",
      "|    reward               | 4.3994184     |\n",
      "|    std                  | 23.1          |\n",
      "|    value_loss           | 45.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2590         |\n",
      "|    time_elapsed         | 47246        |\n",
      "|    total_timesteps      | 5304320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062352004 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.43         |\n",
      "|    n_updates            | 25890        |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    reward               | 2.3815427    |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2591        |\n",
      "|    time_elapsed         | 47265       |\n",
      "|    total_timesteps      | 5306368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001623989 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.67        |\n",
      "|    n_updates            | 25900       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    reward               | 1.1540989   |\n",
      "|    std                  | 23.2        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2592         |\n",
      "|    time_elapsed         | 47283        |\n",
      "|    total_timesteps      | 5308416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006273963 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 25910        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    reward               | -3.2799914   |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2593         |\n",
      "|    time_elapsed         | 47301        |\n",
      "|    total_timesteps      | 5310464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016506297 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 25920        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -0.74629223  |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2594         |\n",
      "|    time_elapsed         | 47320        |\n",
      "|    total_timesteps      | 5312512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010297108 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 25930        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 0.7177701    |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2595         |\n",
      "|    time_elapsed         | 47338        |\n",
      "|    total_timesteps      | 5314560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011485814 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 25940        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | -0.5328578   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2596          |\n",
      "|    time_elapsed         | 47356         |\n",
      "|    total_timesteps      | 5316608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072310935 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.786         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.4          |\n",
      "|    n_updates            | 25950         |\n",
      "|    policy_gradient_loss | -0.00245      |\n",
      "|    reward               | -0.8984917    |\n",
      "|    std                  | 23.3          |\n",
      "|    value_loss           | 40.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2597         |\n",
      "|    time_elapsed         | 47375        |\n",
      "|    total_timesteps      | 5318656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039332854 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.8          |\n",
      "|    n_updates            | 25960        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | -0.40116906  |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3482021.12\n",
      "total_reward: 2482021.12\n",
      "total_cost: 49105.40\n",
      "total_trades: 50052\n",
      "Sharpe: 0.664\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2598         |\n",
      "|    time_elapsed         | 47394        |\n",
      "|    total_timesteps      | 5320704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027648732 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 25970        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | -1.862867    |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2599          |\n",
      "|    time_elapsed         | 47412         |\n",
      "|    total_timesteps      | 5322752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020549126 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.556         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14            |\n",
      "|    n_updates            | 25980         |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    reward               | 4.1516933     |\n",
      "|    std                  | 23.3          |\n",
      "|    value_loss           | 47.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2600         |\n",
      "|    time_elapsed         | 47430        |\n",
      "|    total_timesteps      | 5324800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012305905 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 25990        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -2.7580628   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2601         |\n",
      "|    time_elapsed         | 47448        |\n",
      "|    total_timesteps      | 5326848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045828763 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.34         |\n",
      "|    n_updates            | 26000        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | 3.0168586    |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2602        |\n",
      "|    time_elapsed         | 47466       |\n",
      "|    total_timesteps      | 5328896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000985124 |\n",
      "|    clip_fraction        | 0.00107     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 26010       |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    reward               | -2.3460245  |\n",
      "|    std                  | 23.3        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2603          |\n",
      "|    time_elapsed         | 47484         |\n",
      "|    total_timesteps      | 5330944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030032347 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.723         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.5          |\n",
      "|    n_updates            | 26020         |\n",
      "|    policy_gradient_loss | -0.00146      |\n",
      "|    reward               | 1.3948603     |\n",
      "|    std                  | 23.4          |\n",
      "|    value_loss           | 49.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2604         |\n",
      "|    time_elapsed         | 47502        |\n",
      "|    total_timesteps      | 5332992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059924684 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.54         |\n",
      "|    n_updates            | 26030        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    reward               | -1.1833417   |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2605         |\n",
      "|    time_elapsed         | 47520        |\n",
      "|    total_timesteps      | 5335040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018709883 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 26040        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | 1.4938962    |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2606         |\n",
      "|    time_elapsed         | 47539        |\n",
      "|    total_timesteps      | 5337088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015935705 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 26050        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | -2.1035323   |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 49.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2607         |\n",
      "|    time_elapsed         | 47557        |\n",
      "|    total_timesteps      | 5339136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024142654 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | -2.218357    |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2608         |\n",
      "|    time_elapsed         | 47575        |\n",
      "|    total_timesteps      | 5341184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016724432 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.62         |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 0.7317012    |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2609         |\n",
      "|    time_elapsed         | 47593        |\n",
      "|    total_timesteps      | 5343232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036500464 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 26080        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | -0.49102765  |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2610         |\n",
      "|    time_elapsed         | 47612        |\n",
      "|    total_timesteps      | 5345280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006786559 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 26090        |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    reward               | -0.59489125  |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2611         |\n",
      "|    time_elapsed         | 47630        |\n",
      "|    total_timesteps      | 5347328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036836704 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.66         |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    reward               | -0.21539344  |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3898947.61\n",
      "total_reward: 2898947.61\n",
      "total_cost: 88821.13\n",
      "total_trades: 54451\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2612         |\n",
      "|    time_elapsed         | 47648        |\n",
      "|    total_timesteps      | 5349376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011720031 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 26110        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 0.70631516   |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2613         |\n",
      "|    time_elapsed         | 47665        |\n",
      "|    total_timesteps      | 5351424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013870902 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 26120        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 0.259902     |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2614        |\n",
      "|    time_elapsed         | 47683       |\n",
      "|    total_timesteps      | 5353472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005636692 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 26130       |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | 0.8804566   |\n",
      "|    std                  | 23.6        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2615         |\n",
      "|    time_elapsed         | 47701        |\n",
      "|    total_timesteps      | 5355520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018850148 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 26140        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | -1.2849696   |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2616         |\n",
      "|    time_elapsed         | 47719        |\n",
      "|    total_timesteps      | 5357568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025116545 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 26150        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | 4.2232156    |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2617         |\n",
      "|    time_elapsed         | 47737        |\n",
      "|    total_timesteps      | 5359616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024459525 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.792        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 26160        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 6.2365656    |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2618         |\n",
      "|    time_elapsed         | 47755        |\n",
      "|    total_timesteps      | 5361664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024244231 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.3          |\n",
      "|    n_updates            | 26170        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | -0.11231421  |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2619         |\n",
      "|    time_elapsed         | 47773        |\n",
      "|    total_timesteps      | 5363712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010666146 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | -1.0095516   |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2620         |\n",
      "|    time_elapsed         | 47791        |\n",
      "|    total_timesteps      | 5365760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009832045 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 26190        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | -0.715911    |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2621         |\n",
      "|    time_elapsed         | 47809        |\n",
      "|    total_timesteps      | 5367808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045604683 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.21         |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    reward               | 0.5914085    |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 17           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2622        |\n",
      "|    time_elapsed         | 47827       |\n",
      "|    total_timesteps      | 5369856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002049083 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 26210       |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    reward               | -0.46981218 |\n",
      "|    std                  | 23.8        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2623         |\n",
      "|    time_elapsed         | 47844        |\n",
      "|    total_timesteps      | 5371904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012953199 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 26220        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 1.0063057    |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2624         |\n",
      "|    time_elapsed         | 47862        |\n",
      "|    total_timesteps      | 5373952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011569364 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 26230        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -0.6060628   |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2625         |\n",
      "|    time_elapsed         | 47880        |\n",
      "|    total_timesteps      | 5376000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025441928 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.812        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.2          |\n",
      "|    n_updates            | 26240        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 0.36430696   |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2626          |\n",
      "|    time_elapsed         | 47898         |\n",
      "|    total_timesteps      | 5378048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075640634 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.668         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.3          |\n",
      "|    n_updates            | 26250         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | -4.2392097    |\n",
      "|    std                  | 23.9          |\n",
      "|    value_loss           | 37            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3397402.40\n",
      "total_reward: 2397402.40\n",
      "total_cost: 59046.05\n",
      "total_trades: 51680\n",
      "Sharpe: 0.655\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2627          |\n",
      "|    time_elapsed         | 47915         |\n",
      "|    total_timesteps      | 5380096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078250474 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.763         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.8          |\n",
      "|    n_updates            | 26260         |\n",
      "|    policy_gradient_loss | -0.00208      |\n",
      "|    reward               | -0.15479277   |\n",
      "|    std                  | 23.9          |\n",
      "|    value_loss           | 35.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2628          |\n",
      "|    time_elapsed         | 47933         |\n",
      "|    total_timesteps      | 5382144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051343534 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.732         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.5          |\n",
      "|    n_updates            | 26270         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | -1.2876576    |\n",
      "|    std                  | 23.9          |\n",
      "|    value_loss           | 22.5          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2629       |\n",
      "|    time_elapsed         | 47951      |\n",
      "|    total_timesteps      | 5384192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00092436 |\n",
      "|    clip_fraction        | 0.00283    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -133       |\n",
      "|    explained_variance   | 0.572      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 26280      |\n",
      "|    policy_gradient_loss | -0.00198   |\n",
      "|    reward               | 0.29045713 |\n",
      "|    std                  | 23.9       |\n",
      "|    value_loss           | 40.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2630         |\n",
      "|    time_elapsed         | 47969        |\n",
      "|    total_timesteps      | 5386240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009108014 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 26290        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 5.0911493    |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2631         |\n",
      "|    time_elapsed         | 47987        |\n",
      "|    total_timesteps      | 5388288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025667907 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | -0.137001    |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2632         |\n",
      "|    time_elapsed         | 48005        |\n",
      "|    total_timesteps      | 5390336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015535072 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.06         |\n",
      "|    n_updates            | 26310        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | -2.120186    |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 22.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2633         |\n",
      "|    time_elapsed         | 48023        |\n",
      "|    total_timesteps      | 5392384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016797768 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 2.6147697    |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2634          |\n",
      "|    time_elapsed         | 48042         |\n",
      "|    total_timesteps      | 5394432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025134278 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.641         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12            |\n",
      "|    n_updates            | 26330         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | 0.78232056    |\n",
      "|    std                  | 24.1          |\n",
      "|    value_loss           | 33.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2635         |\n",
      "|    time_elapsed         | 48060        |\n",
      "|    total_timesteps      | 5396480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056766546 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.13         |\n",
      "|    n_updates            | 26340        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    reward               | 0.018958282  |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2636        |\n",
      "|    time_elapsed         | 48078       |\n",
      "|    total_timesteps      | 5398528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002747487 |\n",
      "|    clip_fraction        | 0.00293     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 26350       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 1.450799    |\n",
      "|    std                  | 24.1        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2637         |\n",
      "|    time_elapsed         | 48095        |\n",
      "|    total_timesteps      | 5400576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006842996 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 26360        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    reward               | -2.7732577   |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2638        |\n",
      "|    time_elapsed         | 48114       |\n",
      "|    total_timesteps      | 5402624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004127512 |\n",
      "|    clip_fraction        | 0.00537     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 26370       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -0.7050347  |\n",
      "|    std                  | 24.2        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2639         |\n",
      "|    time_elapsed         | 48132        |\n",
      "|    total_timesteps      | 5404672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015586466 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.93         |\n",
      "|    n_updates            | 26380        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | 1.0348915    |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2640         |\n",
      "|    time_elapsed         | 48151        |\n",
      "|    total_timesteps      | 5406720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013098379 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 26390        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 0.07747808   |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3164932.69\n",
      "total_reward: 2164932.69\n",
      "total_cost: 56842.00\n",
      "total_trades: 51520\n",
      "Sharpe: 0.621\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 2641       |\n",
      "|    time_elapsed         | 48169      |\n",
      "|    total_timesteps      | 5408768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00310406 |\n",
      "|    clip_fraction        | 0.00439    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -133       |\n",
      "|    explained_variance   | 0.777      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.89       |\n",
      "|    n_updates            | 26400      |\n",
      "|    policy_gradient_loss | -0.00393   |\n",
      "|    reward               | 1.9127837  |\n",
      "|    std                  | 24.1       |\n",
      "|    value_loss           | 24         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2642         |\n",
      "|    time_elapsed         | 48187        |\n",
      "|    total_timesteps      | 5410816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023831849 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 26410        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -0.7286626   |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2643         |\n",
      "|    time_elapsed         | 48205        |\n",
      "|    total_timesteps      | 5412864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014445444 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | 0.8540009    |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2644         |\n",
      "|    time_elapsed         | 48224        |\n",
      "|    total_timesteps      | 5414912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029808043 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 26430        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 3.415416     |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2645         |\n",
      "|    time_elapsed         | 48243        |\n",
      "|    total_timesteps      | 5416960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064210016 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.14         |\n",
      "|    n_updates            | 26440        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    reward               | -0.1315241   |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2646          |\n",
      "|    time_elapsed         | 48262         |\n",
      "|    total_timesteps      | 5419008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064413913 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.734         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.5          |\n",
      "|    n_updates            | 26450         |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    reward               | 3.4760296     |\n",
      "|    std                  | 24.3          |\n",
      "|    value_loss           | 29            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2647         |\n",
      "|    time_elapsed         | 48280        |\n",
      "|    total_timesteps      | 5421056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011936453 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.73         |\n",
      "|    n_updates            | 26460        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | 3.137699     |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2648         |\n",
      "|    time_elapsed         | 48298        |\n",
      "|    total_timesteps      | 5423104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012418877 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 26470        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -1.4319527   |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2649         |\n",
      "|    time_elapsed         | 48316        |\n",
      "|    total_timesteps      | 5425152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027298671 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 26480        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -0.4772606   |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2650         |\n",
      "|    time_elapsed         | 48334        |\n",
      "|    total_timesteps      | 5427200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018598605 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 26490        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -15.871829   |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2651          |\n",
      "|    time_elapsed         | 48352         |\n",
      "|    total_timesteps      | 5429248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055903185 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.6          |\n",
      "|    n_updates            | 26500         |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    reward               | -0.5157439    |\n",
      "|    std                  | 24.5          |\n",
      "|    value_loss           | 33.6          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2652         |\n",
      "|    time_elapsed         | 48370        |\n",
      "|    total_timesteps      | 5431296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043226928 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 26510        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 0.90767866   |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2653          |\n",
      "|    time_elapsed         | 48388         |\n",
      "|    total_timesteps      | 5433344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090267963 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.84          |\n",
      "|    n_updates            | 26520         |\n",
      "|    policy_gradient_loss | -0.00292      |\n",
      "|    reward               | 0.60208493    |\n",
      "|    std                  | 24.6          |\n",
      "|    value_loss           | 30.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2654         |\n",
      "|    time_elapsed         | 48405        |\n",
      "|    total_timesteps      | 5435392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012543722 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 26530        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -0.94759786  |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3427226.75\n",
      "total_reward: 2427226.75\n",
      "total_cost: 51406.79\n",
      "total_trades: 50994\n",
      "Sharpe: 0.659\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2655         |\n",
      "|    time_elapsed         | 48423        |\n",
      "|    total_timesteps      | 5437440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023476556 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 26540        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | 0.27828285   |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2656         |\n",
      "|    time_elapsed         | 48441        |\n",
      "|    total_timesteps      | 5439488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014240914 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 26550        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | -0.9494991   |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2657         |\n",
      "|    time_elapsed         | 48459        |\n",
      "|    total_timesteps      | 5441536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012784745 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 26560        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | -0.15989628  |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2658         |\n",
      "|    time_elapsed         | 48476        |\n",
      "|    total_timesteps      | 5443584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016864482 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 26570        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | -5.506083    |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2659         |\n",
      "|    time_elapsed         | 48494        |\n",
      "|    total_timesteps      | 5445632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057674106 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.0085      |\n",
      "|    reward               | 2.623061     |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2660         |\n",
      "|    time_elapsed         | 48512        |\n",
      "|    total_timesteps      | 5447680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010360933 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 26590        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -0.078018494 |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2661         |\n",
      "|    time_elapsed         | 48531        |\n",
      "|    total_timesteps      | 5449728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005259098 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 26600        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    reward               | 4.665144     |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2662         |\n",
      "|    time_elapsed         | 48549        |\n",
      "|    total_timesteps      | 5451776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016348832 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.05         |\n",
      "|    n_updates            | 26610        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 0.5162285    |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2663        |\n",
      "|    time_elapsed         | 48567       |\n",
      "|    total_timesteps      | 5453824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001996079 |\n",
      "|    clip_fraction        | 0.00317     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 26620       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | 1.2215582   |\n",
      "|    std                  | 24.9        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2664        |\n",
      "|    time_elapsed         | 48584       |\n",
      "|    total_timesteps      | 5455872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000607314 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 26630       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | 3.6736386   |\n",
      "|    std                  | 24.9        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2665        |\n",
      "|    time_elapsed         | 48602       |\n",
      "|    total_timesteps      | 5457920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001864323 |\n",
      "|    clip_fraction        | 0.00342     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 26640       |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    reward               | 0.6696607   |\n",
      "|    std                  | 24.9        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2666         |\n",
      "|    time_elapsed         | 48621        |\n",
      "|    total_timesteps      | 5459968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017004514 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.9          |\n",
      "|    n_updates            | 26650        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 1.1391195    |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2667         |\n",
      "|    time_elapsed         | 48639        |\n",
      "|    total_timesteps      | 5462016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025434317 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.47         |\n",
      "|    n_updates            | 26660        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | -0.18700743  |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2668         |\n",
      "|    time_elapsed         | 48657        |\n",
      "|    total_timesteps      | 5464064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007364269 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 26670        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | 4.2039495    |\n",
      "|    std                  | 25.1         |\n",
      "|    value_loss           | 36.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3680660.04\n",
      "total_reward: 2680660.04\n",
      "total_cost: 65467.31\n",
      "total_trades: 52465\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2669        |\n",
      "|    time_elapsed         | 48675       |\n",
      "|    total_timesteps      | 5466112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006912311 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.54        |\n",
      "|    n_updates            | 26680       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 0.5999325   |\n",
      "|    std                  | 25.1        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2670         |\n",
      "|    time_elapsed         | 48693        |\n",
      "|    total_timesteps      | 5468160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013463995 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 26690        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | 2.201576     |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2671         |\n",
      "|    time_elapsed         | 48711        |\n",
      "|    total_timesteps      | 5470208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010649208 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 26700        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    reward               | 3.2251322    |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2672         |\n",
      "|    time_elapsed         | 48729        |\n",
      "|    total_timesteps      | 5472256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026526852 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 26710        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 1.6506009    |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2673         |\n",
      "|    time_elapsed         | 48747        |\n",
      "|    total_timesteps      | 5474304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019652243 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.4          |\n",
      "|    n_updates            | 26720        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 3.6970859    |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2674         |\n",
      "|    time_elapsed         | 48765        |\n",
      "|    total_timesteps      | 5476352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012392048 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 26730        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    reward               | 1.1825829    |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2675        |\n",
      "|    time_elapsed         | 48783       |\n",
      "|    total_timesteps      | 5478400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000441167 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 26740       |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    reward               | -0.30288193 |\n",
      "|    std                  | 25.2        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2676         |\n",
      "|    time_elapsed         | 48801        |\n",
      "|    total_timesteps      | 5480448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011418639 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.59         |\n",
      "|    n_updates            | 26750        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 0.16317284   |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2677         |\n",
      "|    time_elapsed         | 48819        |\n",
      "|    total_timesteps      | 5482496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017577307 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 26760        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -0.78154     |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2678         |\n",
      "|    time_elapsed         | 48838        |\n",
      "|    total_timesteps      | 5484544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007646236 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 26770        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    reward               | -4.1129117   |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2679         |\n",
      "|    time_elapsed         | 48857        |\n",
      "|    total_timesteps      | 5486592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021930542 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 26780        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | 0.56857026   |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2680         |\n",
      "|    time_elapsed         | 48875        |\n",
      "|    total_timesteps      | 5488640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027841348 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.09         |\n",
      "|    n_updates            | 26790        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 0.18466063   |\n",
      "|    std                  | 25.4         |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2681         |\n",
      "|    time_elapsed         | 48894        |\n",
      "|    total_timesteps      | 5490688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009602586 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 26800        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | 2.0636132    |\n",
      "|    std                  | 25.4         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2682         |\n",
      "|    time_elapsed         | 48912        |\n",
      "|    total_timesteps      | 5492736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007711339 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 26810        |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    reward               | -0.97821665  |\n",
      "|    std                  | 25.4         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3980255.38\n",
      "total_reward: 2980255.38\n",
      "total_cost: 104654.80\n",
      "total_trades: 56037\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2683        |\n",
      "|    time_elapsed         | 48930       |\n",
      "|    total_timesteps      | 5494784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003850236 |\n",
      "|    clip_fraction        | 0.00693     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.42        |\n",
      "|    n_updates            | 26820       |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | 2.9300292   |\n",
      "|    std                  | 25.4        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2684         |\n",
      "|    time_elapsed         | 48948        |\n",
      "|    total_timesteps      | 5496832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012231914 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 26830        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 0.124582425  |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2685        |\n",
      "|    time_elapsed         | 48967       |\n",
      "|    total_timesteps      | 5498880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001178554 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 26840       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    reward               | -0.7180861  |\n",
      "|    std                  | 25.5        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2686         |\n",
      "|    time_elapsed         | 48984        |\n",
      "|    total_timesteps      | 5500928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069984915 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.84         |\n",
      "|    n_updates            | 26850        |\n",
      "|    policy_gradient_loss | -0.00836     |\n",
      "|    reward               | 0.81377333   |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2687        |\n",
      "|    time_elapsed         | 49002       |\n",
      "|    total_timesteps      | 5502976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000737946 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 26860       |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    reward               | 0.29356396  |\n",
      "|    std                  | 25.6        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2688          |\n",
      "|    time_elapsed         | 49020         |\n",
      "|    total_timesteps      | 5505024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046822088 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.1          |\n",
      "|    n_updates            | 26870         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | 2.760156      |\n",
      "|    std                  | 25.6          |\n",
      "|    value_loss           | 38.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2689         |\n",
      "|    time_elapsed         | 49038        |\n",
      "|    total_timesteps      | 5507072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017999753 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 26880        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | 0.2884924    |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2690         |\n",
      "|    time_elapsed         | 49056        |\n",
      "|    total_timesteps      | 5509120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007076199 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 26890        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | -0.23001683  |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2691         |\n",
      "|    time_elapsed         | 49074        |\n",
      "|    total_timesteps      | 5511168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007623731 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 26900        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | -0.17608155  |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2692         |\n",
      "|    time_elapsed         | 49093        |\n",
      "|    total_timesteps      | 5513216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008772829 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 26910        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -1.8253787   |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2693         |\n",
      "|    time_elapsed         | 49111        |\n",
      "|    total_timesteps      | 5515264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060453485 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.89         |\n",
      "|    n_updates            | 26920        |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    reward               | 0.44295767   |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2694          |\n",
      "|    time_elapsed         | 49129         |\n",
      "|    total_timesteps      | 5517312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085033907 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.728         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.1          |\n",
      "|    n_updates            | 26930         |\n",
      "|    policy_gradient_loss | -0.0024       |\n",
      "|    reward               | 2.8127968     |\n",
      "|    std                  | 25.8          |\n",
      "|    value_loss           | 30            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2695         |\n",
      "|    time_elapsed         | 49148        |\n",
      "|    total_timesteps      | 5519360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011446011 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 26940        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 2.264662     |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2696         |\n",
      "|    time_elapsed         | 49166        |\n",
      "|    total_timesteps      | 5521408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026443405 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | 0.20975845   |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4075771.71\n",
      "total_reward: 3075771.71\n",
      "total_cost: 71407.78\n",
      "total_trades: 52878\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2697         |\n",
      "|    time_elapsed         | 49184        |\n",
      "|    total_timesteps      | 5523456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015717112 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 26960        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 3.1672683    |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2698         |\n",
      "|    time_elapsed         | 49201        |\n",
      "|    total_timesteps      | 5525504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004989691 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 26970        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | -1.9728006   |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 42.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2699        |\n",
      "|    time_elapsed         | 49220       |\n",
      "|    total_timesteps      | 5527552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0018608   |\n",
      "|    clip_fraction        | 0.000488    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 26980       |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    reward               | -0.33434877 |\n",
      "|    std                  | 25.9        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2700         |\n",
      "|    time_elapsed         | 49238        |\n",
      "|    total_timesteps      | 5529600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050952844 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.77         |\n",
      "|    n_updates            | 26990        |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    reward               | 0.5296828    |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2701        |\n",
      "|    time_elapsed         | 49256       |\n",
      "|    total_timesteps      | 5531648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001359931 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.86        |\n",
      "|    n_updates            | 27000       |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    reward               | -0.8497908  |\n",
      "|    std                  | 26.1        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2702         |\n",
      "|    time_elapsed         | 49275        |\n",
      "|    total_timesteps      | 5533696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012061145 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 27010        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | -0.36575693  |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2703        |\n",
      "|    time_elapsed         | 49293       |\n",
      "|    total_timesteps      | 5535744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002132666 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 27020       |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 1.3604596   |\n",
      "|    std                  | 26.1        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2704         |\n",
      "|    time_elapsed         | 49311        |\n",
      "|    total_timesteps      | 5537792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010902412 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 27030        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 0.056364488  |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2705          |\n",
      "|    time_elapsed         | 49329         |\n",
      "|    total_timesteps      | 5539840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044530415 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.801         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.4          |\n",
      "|    n_updates            | 27040         |\n",
      "|    policy_gradient_loss | -0.0019       |\n",
      "|    reward               | -0.1988815    |\n",
      "|    std                  | 26.1          |\n",
      "|    value_loss           | 32.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2706         |\n",
      "|    time_elapsed         | 49347        |\n",
      "|    total_timesteps      | 5541888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005341158 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 27050        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | -6.088768    |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2707         |\n",
      "|    time_elapsed         | 49364        |\n",
      "|    total_timesteps      | 5543936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037361921 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 27060        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | 1.5218502    |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2708         |\n",
      "|    time_elapsed         | 49383        |\n",
      "|    total_timesteps      | 5545984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008010196 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 27070        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | -0.35519645  |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2709         |\n",
      "|    time_elapsed         | 49401        |\n",
      "|    total_timesteps      | 5548032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010230474 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.77         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 27080        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 0.44484854   |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2710         |\n",
      "|    time_elapsed         | 49419        |\n",
      "|    total_timesteps      | 5550080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054623457 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.792        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.31         |\n",
      "|    n_updates            | 27090        |\n",
      "|    policy_gradient_loss | -0.00901     |\n",
      "|    reward               | -1.7039862   |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3757253.86\n",
      "total_reward: 2757253.86\n",
      "total_cost: 55475.18\n",
      "total_trades: 50789\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2711         |\n",
      "|    time_elapsed         | 49438        |\n",
      "|    total_timesteps      | 5552128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011761393 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 27100        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | -0.42841187  |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2712          |\n",
      "|    time_elapsed         | 49456         |\n",
      "|    total_timesteps      | 5554176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058981485 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.76          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.2          |\n",
      "|    n_updates            | 27110         |\n",
      "|    policy_gradient_loss | -0.00173      |\n",
      "|    reward               | -11.688283    |\n",
      "|    std                  | 26.4          |\n",
      "|    value_loss           | 38.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2713         |\n",
      "|    time_elapsed         | 49509        |\n",
      "|    total_timesteps      | 5556224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031509325 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 27120        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | -1.2521373   |\n",
      "|    std                  | 26.4         |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2714         |\n",
      "|    time_elapsed         | 49526        |\n",
      "|    total_timesteps      | 5558272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032352644 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | -1.4818205   |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2715          |\n",
      "|    time_elapsed         | 49544         |\n",
      "|    total_timesteps      | 5560320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093690935 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.583         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.8          |\n",
      "|    n_updates            | 27140         |\n",
      "|    policy_gradient_loss | -0.00192      |\n",
      "|    reward               | -1.3792623    |\n",
      "|    std                  | 26.5          |\n",
      "|    value_loss           | 26.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2716        |\n",
      "|    time_elapsed         | 49561       |\n",
      "|    total_timesteps      | 5562368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001268361 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 27150       |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | -2.2254694  |\n",
      "|    std                  | 26.5        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2717         |\n",
      "|    time_elapsed         | 49579        |\n",
      "|    total_timesteps      | 5564416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069304784 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.73         |\n",
      "|    n_updates            | 27160        |\n",
      "|    policy_gradient_loss | -0.00932     |\n",
      "|    reward               | -0.21782021  |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2718         |\n",
      "|    time_elapsed         | 49597        |\n",
      "|    total_timesteps      | 5566464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012264798 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 27170        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | 1.8094846    |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2719         |\n",
      "|    time_elapsed         | 49615        |\n",
      "|    total_timesteps      | 5568512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005756245 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 27180        |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | -2.2237332   |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2720         |\n",
      "|    time_elapsed         | 49633        |\n",
      "|    total_timesteps      | 5570560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045719426 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 27190        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    reward               | -3.7728262   |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2721        |\n",
      "|    time_elapsed         | 49650       |\n",
      "|    total_timesteps      | 5572608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003234078 |\n",
      "|    clip_fraction        | 0.00776     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 27200       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | -2.184929   |\n",
      "|    std                  | 26.6        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2722        |\n",
      "|    time_elapsed         | 49668       |\n",
      "|    total_timesteps      | 5574656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000515548 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 27210       |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    reward               | 4.2816596   |\n",
      "|    std                  | 26.6        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2723         |\n",
      "|    time_elapsed         | 49687        |\n",
      "|    total_timesteps      | 5576704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010394647 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 27220        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | -2.2961001   |\n",
      "|    std                  | 26.7         |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2724         |\n",
      "|    time_elapsed         | 49705        |\n",
      "|    total_timesteps      | 5578752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035233223 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 27230        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | 1.0470554    |\n",
      "|    std                  | 26.7         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3258906.62\n",
      "total_reward: 2258906.62\n",
      "total_cost: 49973.98\n",
      "total_trades: 50335\n",
      "Sharpe: 0.631\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2725          |\n",
      "|    time_elapsed         | 49723         |\n",
      "|    total_timesteps      | 5580800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015064608 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.707         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.1          |\n",
      "|    n_updates            | 27240         |\n",
      "|    policy_gradient_loss | -0.000455     |\n",
      "|    reward               | 1.2166127     |\n",
      "|    std                  | 26.7          |\n",
      "|    value_loss           | 27.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2726         |\n",
      "|    time_elapsed         | 49742        |\n",
      "|    total_timesteps      | 5582848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010003095 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 27250        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 0.91735876   |\n",
      "|    std                  | 26.7         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2727        |\n",
      "|    time_elapsed         | 49760       |\n",
      "|    total_timesteps      | 5584896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006941217 |\n",
      "|    clip_fraction        | 0.0251      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 27260       |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | -0.5332301  |\n",
      "|    std                  | 26.8        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2728         |\n",
      "|    time_elapsed         | 49777        |\n",
      "|    total_timesteps      | 5586944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032160687 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.11         |\n",
      "|    n_updates            | 27270        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | 0.33889464   |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2729         |\n",
      "|    time_elapsed         | 49795        |\n",
      "|    total_timesteps      | 5588992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003058186 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.792        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 27280        |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    reward               | 4.77605      |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2730         |\n",
      "|    time_elapsed         | 49813        |\n",
      "|    total_timesteps      | 5591040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014709153 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 27290        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 1.8045069    |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2731         |\n",
      "|    time_elapsed         | 49831        |\n",
      "|    total_timesteps      | 5593088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020233006 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.8          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 27300        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 1.303266     |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2732         |\n",
      "|    time_elapsed         | 49850        |\n",
      "|    total_timesteps      | 5595136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006650984 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.82         |\n",
      "|    n_updates            | 27310        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 0.6639538    |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2733         |\n",
      "|    time_elapsed         | 49868        |\n",
      "|    total_timesteps      | 5597184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012566334 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 27320        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | -0.6299119   |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2734        |\n",
      "|    time_elapsed         | 49886       |\n",
      "|    total_timesteps      | 5599232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007938232 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.94        |\n",
      "|    n_updates            | 27330       |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | 1.743504    |\n",
      "|    std                  | 26.9        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2735          |\n",
      "|    time_elapsed         | 49904         |\n",
      "|    total_timesteps      | 5601280       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062161044 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.687         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.7          |\n",
      "|    n_updates            | 27340         |\n",
      "|    policy_gradient_loss | -0.00179      |\n",
      "|    reward               | -0.12419827   |\n",
      "|    std                  | 27            |\n",
      "|    value_loss           | 29.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2736         |\n",
      "|    time_elapsed         | 49922        |\n",
      "|    total_timesteps      | 5603328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005098134 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 27350        |\n",
      "|    policy_gradient_loss | -0.000789    |\n",
      "|    reward               | 2.7147896    |\n",
      "|    std                  | 27           |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2737         |\n",
      "|    time_elapsed         | 49940        |\n",
      "|    total_timesteps      | 5605376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018611369 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.98         |\n",
      "|    n_updates            | 27360        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -0.058345847 |\n",
      "|    std                  | 27           |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2738         |\n",
      "|    time_elapsed         | 49959        |\n",
      "|    total_timesteps      | 5607424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016095319 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.73         |\n",
      "|    n_updates            | 27370        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | -3.095413    |\n",
      "|    std                  | 27.1         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2739          |\n",
      "|    time_elapsed         | 49977         |\n",
      "|    total_timesteps      | 5609472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034623969 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.739         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.8          |\n",
      "|    n_updates            | 27380         |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    reward               | 10.883345     |\n",
      "|    std                  | 27.1          |\n",
      "|    value_loss           | 34            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3532141.51\n",
      "total_reward: 2532141.51\n",
      "total_cost: 67863.51\n",
      "total_trades: 52368\n",
      "Sharpe: 0.673\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2740         |\n",
      "|    time_elapsed         | 49995        |\n",
      "|    total_timesteps      | 5611520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005489094 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 27390        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | 0.685064     |\n",
      "|    std                  | 27.1         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2741         |\n",
      "|    time_elapsed         | 50014        |\n",
      "|    total_timesteps      | 5613568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060122274 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.808        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.34         |\n",
      "|    n_updates            | 27400        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    reward               | -0.028515879 |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2742          |\n",
      "|    time_elapsed         | 50032         |\n",
      "|    total_timesteps      | 5615616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034083167 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.747         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.9          |\n",
      "|    n_updates            | 27410         |\n",
      "|    policy_gradient_loss | -0.000953     |\n",
      "|    reward               | 0.74585193    |\n",
      "|    std                  | 27.2          |\n",
      "|    value_loss           | 28.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2743          |\n",
      "|    time_elapsed         | 50051         |\n",
      "|    total_timesteps      | 5617664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070417905 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.791         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.3          |\n",
      "|    n_updates            | 27420         |\n",
      "|    policy_gradient_loss | -0.0027       |\n",
      "|    reward               | -5.8049893    |\n",
      "|    std                  | 27.2          |\n",
      "|    value_loss           | 30.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2744         |\n",
      "|    time_elapsed         | 50069        |\n",
      "|    total_timesteps      | 5619712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035774107 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.23         |\n",
      "|    n_updates            | 27430        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 1.3075514    |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2745         |\n",
      "|    time_elapsed         | 50087        |\n",
      "|    total_timesteps      | 5621760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020070435 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.74         |\n",
      "|    n_updates            | 27440        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -0.20693833  |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2746          |\n",
      "|    time_elapsed         | 50105         |\n",
      "|    total_timesteps      | 5623808       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051203696 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.583         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.3          |\n",
      "|    n_updates            | 27450         |\n",
      "|    policy_gradient_loss | -0.000926     |\n",
      "|    reward               | 0.90049756    |\n",
      "|    std                  | 27.4          |\n",
      "|    value_loss           | 51.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2747         |\n",
      "|    time_elapsed         | 50124        |\n",
      "|    total_timesteps      | 5625856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012889212 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 27460        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 0.08090405   |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2748         |\n",
      "|    time_elapsed         | 50142        |\n",
      "|    total_timesteps      | 5627904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032859347 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 27470        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | 0.8359304    |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2749         |\n",
      "|    time_elapsed         | 50160        |\n",
      "|    total_timesteps      | 5629952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011318886 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 27480        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | -0.095263034 |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2750          |\n",
      "|    time_elapsed         | 50179         |\n",
      "|    total_timesteps      | 5632000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096698845 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.74          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.57          |\n",
      "|    n_updates            | 27490         |\n",
      "|    policy_gradient_loss | -0.00243      |\n",
      "|    reward               | -3.5792372    |\n",
      "|    std                  | 27.5          |\n",
      "|    value_loss           | 25.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2751         |\n",
      "|    time_elapsed         | 50197        |\n",
      "|    total_timesteps      | 5634048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032847088 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.6          |\n",
      "|    n_updates            | 27500        |\n",
      "|    policy_gradient_loss | -0.007       |\n",
      "|    reward               | 0.4678822    |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2752         |\n",
      "|    time_elapsed         | 50216        |\n",
      "|    total_timesteps      | 5636096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005908684 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.742        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 27510        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | 0.5408662    |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2753        |\n",
      "|    time_elapsed         | 50234       |\n",
      "|    total_timesteps      | 5638144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001187602 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 27520       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | 2.516224    |\n",
      "|    std                  | 27.7        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3372567.29\n",
      "total_reward: 2372567.29\n",
      "total_cost: 53254.28\n",
      "total_trades: 50638\n",
      "Sharpe: 0.644\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2754         |\n",
      "|    time_elapsed         | 50253        |\n",
      "|    total_timesteps      | 5640192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012796668 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 27530        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | 0.5888492    |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2755          |\n",
      "|    time_elapsed         | 50271         |\n",
      "|    total_timesteps      | 5642240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048225975 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.2          |\n",
      "|    n_updates            | 27540         |\n",
      "|    policy_gradient_loss | -0.000912     |\n",
      "|    reward               | -0.50343794   |\n",
      "|    std                  | 27.7          |\n",
      "|    value_loss           | 34.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2756         |\n",
      "|    time_elapsed         | 50290        |\n",
      "|    total_timesteps      | 5644288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013797682 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 1.8231971    |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2757         |\n",
      "|    time_elapsed         | 50309        |\n",
      "|    total_timesteps      | 5646336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004278385 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | 0.026417356  |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2758         |\n",
      "|    time_elapsed         | 50326        |\n",
      "|    total_timesteps      | 5648384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074614603 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.61         |\n",
      "|    n_updates            | 27570        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    reward               | -1.1415416   |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2759         |\n",
      "|    time_elapsed         | 50344        |\n",
      "|    total_timesteps      | 5650432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018543978 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.64         |\n",
      "|    n_updates            | 27580        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | -0.60434115  |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2760         |\n",
      "|    time_elapsed         | 50362        |\n",
      "|    total_timesteps      | 5652480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012715582 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.2          |\n",
      "|    n_updates            | 27590        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    reward               | -1.3411367   |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2761         |\n",
      "|    time_elapsed         | 50380        |\n",
      "|    total_timesteps      | 5654528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016844776 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 27600        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 0.5927325    |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2762         |\n",
      "|    time_elapsed         | 50399        |\n",
      "|    total_timesteps      | 5656576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011282917 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.807        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.96         |\n",
      "|    n_updates            | 27610        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | -0.2503626   |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 20.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2763         |\n",
      "|    time_elapsed         | 50417        |\n",
      "|    total_timesteps      | 5658624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008013084 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.8          |\n",
      "|    n_updates            | 27620        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | -9.010374    |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2764         |\n",
      "|    time_elapsed         | 50436        |\n",
      "|    total_timesteps      | 5660672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004501345 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 27630        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | -0.4632749   |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2765        |\n",
      "|    time_elapsed         | 50454       |\n",
      "|    total_timesteps      | 5662720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004459136 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.72        |\n",
      "|    n_updates            | 27640       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | -0.3450271  |\n",
      "|    std                  | 28          |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2766        |\n",
      "|    time_elapsed         | 50472       |\n",
      "|    total_timesteps      | 5664768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002074326 |\n",
      "|    clip_fraction        | 0.00186     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 27650       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | -2.9634109  |\n",
      "|    std                  | 28.1        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2767         |\n",
      "|    time_elapsed         | 50490        |\n",
      "|    total_timesteps      | 5666816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009747861 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 27660        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 6.1190977    |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3682682.30\n",
      "total_reward: 2682682.30\n",
      "total_cost: 73977.28\n",
      "total_trades: 53096\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2768         |\n",
      "|    time_elapsed         | 50507        |\n",
      "|    total_timesteps      | 5668864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011210488 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 27670        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 9.844897     |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2769         |\n",
      "|    time_elapsed         | 50526        |\n",
      "|    total_timesteps      | 5670912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023918417 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.8          |\n",
      "|    n_updates            | 27680        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 1.8420104    |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2770         |\n",
      "|    time_elapsed         | 50545        |\n",
      "|    total_timesteps      | 5672960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010515868 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 27690        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 1.3475069    |\n",
      "|    std                  | 28.2         |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2771          |\n",
      "|    time_elapsed         | 50565         |\n",
      "|    total_timesteps      | 5675008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076965627 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.795         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.2          |\n",
      "|    n_updates            | 27700         |\n",
      "|    policy_gradient_loss | -0.00222      |\n",
      "|    reward               | -0.24000077   |\n",
      "|    std                  | 28.2          |\n",
      "|    value_loss           | 33.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2772         |\n",
      "|    time_elapsed         | 50583        |\n",
      "|    total_timesteps      | 5677056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007477795 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 27710        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | 1.6193506    |\n",
      "|    std                  | 28.2         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2773         |\n",
      "|    time_elapsed         | 50602        |\n",
      "|    total_timesteps      | 5679104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013449359 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 27720        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | -0.10484649  |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2774         |\n",
      "|    time_elapsed         | 50620        |\n",
      "|    total_timesteps      | 5681152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012754761 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 27730        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | 0.14161174   |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2775         |\n",
      "|    time_elapsed         | 50638        |\n",
      "|    total_timesteps      | 5683200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046397615 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.08         |\n",
      "|    n_updates            | 27740        |\n",
      "|    policy_gradient_loss | -0.00808     |\n",
      "|    reward               | -0.024626749 |\n",
      "|    std                  | 28.4         |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2776         |\n",
      "|    time_elapsed         | 50656        |\n",
      "|    total_timesteps      | 5685248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010009606 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 27750        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | 0.07172119   |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2777         |\n",
      "|    time_elapsed         | 50674        |\n",
      "|    total_timesteps      | 5687296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010028267 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.15         |\n",
      "|    n_updates            | 27760        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 0.53469706   |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2778          |\n",
      "|    time_elapsed         | 50692         |\n",
      "|    total_timesteps      | 5689344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016940566 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.358         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.7          |\n",
      "|    n_updates            | 27770         |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    reward               | -0.48376048   |\n",
      "|    std                  | 28.5          |\n",
      "|    value_loss           | 44.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2779          |\n",
      "|    time_elapsed         | 50712         |\n",
      "|    total_timesteps      | 5691392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058411935 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.621         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.83          |\n",
      "|    n_updates            | 27780         |\n",
      "|    policy_gradient_loss | -0.00155      |\n",
      "|    reward               | 0.68601286    |\n",
      "|    std                  | 28.5          |\n",
      "|    value_loss           | 25            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2780         |\n",
      "|    time_elapsed         | 50731        |\n",
      "|    total_timesteps      | 5693440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024155932 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 27790        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 0.26981902   |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2781         |\n",
      "|    time_elapsed         | 50749        |\n",
      "|    total_timesteps      | 5695488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002259899 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 27800        |\n",
      "|    policy_gradient_loss | -0.000733    |\n",
      "|    reward               | -0.4156223   |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3611844.13\n",
      "total_reward: 2611844.13\n",
      "total_cost: 64157.66\n",
      "total_trades: 51754\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2782        |\n",
      "|    time_elapsed         | 50768       |\n",
      "|    total_timesteps      | 5697536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008018453 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.58        |\n",
      "|    n_updates            | 27810       |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | -0.14710219 |\n",
      "|    std                  | 28.6        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2783         |\n",
      "|    time_elapsed         | 50787        |\n",
      "|    total_timesteps      | 5699584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035667552 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 27820        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | -3.5135624   |\n",
      "|    std                  | 28.7         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2784         |\n",
      "|    time_elapsed         | 50806        |\n",
      "|    total_timesteps      | 5701632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006388576 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 27830        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | 24.27882     |\n",
      "|    std                  | 28.7         |\n",
      "|    value_loss           | 51.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2785        |\n",
      "|    time_elapsed         | 50824       |\n",
      "|    total_timesteps      | 5703680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003501588 |\n",
      "|    clip_fraction        | 0.00615     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.9         |\n",
      "|    n_updates            | 27840       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | -0.5286798  |\n",
      "|    std                  | 28.8        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2786         |\n",
      "|    time_elapsed         | 50843        |\n",
      "|    total_timesteps      | 5705728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023491103 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.12         |\n",
      "|    n_updates            | 27850        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | 1.6129249    |\n",
      "|    std                  | 28.8         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2787         |\n",
      "|    time_elapsed         | 50861        |\n",
      "|    total_timesteps      | 5707776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009977479 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 27860        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | 1.9282653    |\n",
      "|    std                  | 28.8         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2788          |\n",
      "|    time_elapsed         | 50880         |\n",
      "|    total_timesteps      | 5709824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076493406 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.754         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 27870         |\n",
      "|    policy_gradient_loss | -0.00217      |\n",
      "|    reward               | -5.125794     |\n",
      "|    std                  | 28.9          |\n",
      "|    value_loss           | 31.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2789        |\n",
      "|    time_elapsed         | 50898       |\n",
      "|    total_timesteps      | 5711872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003245741 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 27880       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 1.9795085   |\n",
      "|    std                  | 28.9        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2790         |\n",
      "|    time_elapsed         | 50916        |\n",
      "|    total_timesteps      | 5713920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007470052 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 27890        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | 0.35681063   |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 39           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2791         |\n",
      "|    time_elapsed         | 50934        |\n",
      "|    total_timesteps      | 5715968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003012186 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 27900        |\n",
      "|    policy_gradient_loss | -0.00083     |\n",
      "|    reward               | 0.45324737   |\n",
      "|    std                  | 29           |\n",
      "|    value_loss           | 35.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2792         |\n",
      "|    time_elapsed         | 50953        |\n",
      "|    total_timesteps      | 5718016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016917696 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.16         |\n",
      "|    n_updates            | 27910        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 2.89292      |\n",
      "|    std                  | 29           |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2793         |\n",
      "|    time_elapsed         | 50971        |\n",
      "|    total_timesteps      | 5720064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017216001 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.08         |\n",
      "|    n_updates            | 27920        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | 0.26792458   |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2794        |\n",
      "|    time_elapsed         | 50990       |\n",
      "|    total_timesteps      | 5722112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002755709 |\n",
      "|    clip_fraction        | 0.00366     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 27930       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | -0.51152885 |\n",
      "|    std                  | 29.1        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2795         |\n",
      "|    time_elapsed         | 51008        |\n",
      "|    total_timesteps      | 5724160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008448622 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 27940        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    reward               | 0.39961058   |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3527076.76\n",
      "total_reward: 2527076.76\n",
      "total_cost: 55854.95\n",
      "total_trades: 51042\n",
      "Sharpe: 0.672\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2796         |\n",
      "|    time_elapsed         | 51026        |\n",
      "|    total_timesteps      | 5726208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.002127579  |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.55         |\n",
      "|    n_updates            | 27950        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -0.053926937 |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2797        |\n",
      "|    time_elapsed         | 51044       |\n",
      "|    total_timesteps      | 5728256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002579352 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 27960       |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | -0.16891298 |\n",
      "|    std                  | 29.3        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2798         |\n",
      "|    time_elapsed         | 51063        |\n",
      "|    total_timesteps      | 5730304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010845626 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 27970        |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    reward               | 0.8969013    |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2799         |\n",
      "|    time_elapsed         | 51081        |\n",
      "|    total_timesteps      | 5732352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036897892 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.779        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.43         |\n",
      "|    n_updates            | 27980        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 0.9469843    |\n",
      "|    std                  | 29.4         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2800         |\n",
      "|    time_elapsed         | 51101        |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010938235 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 27990        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 1.4635832    |\n",
      "|    std                  | 29.4         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2801          |\n",
      "|    time_elapsed         | 51118         |\n",
      "|    total_timesteps      | 5736448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035526327 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.786         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.9          |\n",
      "|    n_updates            | 28000         |\n",
      "|    policy_gradient_loss | -0.00133      |\n",
      "|    reward               | 0.23655103    |\n",
      "|    std                  | 29.4          |\n",
      "|    value_loss           | 40.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2802          |\n",
      "|    time_elapsed         | 51137         |\n",
      "|    total_timesteps      | 5738496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047612507 |\n",
      "|    clip_fraction        | 0.00225       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.723         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.4          |\n",
      "|    n_updates            | 28010         |\n",
      "|    policy_gradient_loss | -0.000991     |\n",
      "|    reward               | -2.6986108    |\n",
      "|    std                  | 29.4          |\n",
      "|    value_loss           | 38.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2803        |\n",
      "|    time_elapsed         | 51154       |\n",
      "|    total_timesteps      | 5740544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003204397 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 28020       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | -4.34907    |\n",
      "|    std                  | 29.5        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2804         |\n",
      "|    time_elapsed         | 51173        |\n",
      "|    total_timesteps      | 5742592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010732033 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 28030        |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | -8.079105    |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2805         |\n",
      "|    time_elapsed         | 51191        |\n",
      "|    total_timesteps      | 5744640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004635064 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 28040        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 1.3267015    |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2806         |\n",
      "|    time_elapsed         | 51210        |\n",
      "|    total_timesteps      | 5746688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046182647 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.59         |\n",
      "|    n_updates            | 28050        |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | -2.7487268   |\n",
      "|    std                  | 29.6         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2807        |\n",
      "|    time_elapsed         | 51228       |\n",
      "|    total_timesteps      | 5748736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001145868 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 28060       |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    reward               | -1.1327889  |\n",
      "|    std                  | 29.7        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2808         |\n",
      "|    time_elapsed         | 51246        |\n",
      "|    total_timesteps      | 5750784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004328285 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 28070        |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    reward               | -0.18820651  |\n",
      "|    std                  | 29.7         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2809         |\n",
      "|    time_elapsed         | 51264        |\n",
      "|    total_timesteps      | 5752832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022054964 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.64         |\n",
      "|    n_updates            | 28080        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | 0.2882814    |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3094855.11\n",
      "total_reward: 2094855.11\n",
      "total_cost: 83758.50\n",
      "total_trades: 54107\n",
      "Sharpe: 0.599\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2810         |\n",
      "|    time_elapsed         | 51282        |\n",
      "|    total_timesteps      | 5754880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016886161 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.47         |\n",
      "|    n_updates            | 28090        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | -2.242017    |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2811         |\n",
      "|    time_elapsed         | 51300        |\n",
      "|    total_timesteps      | 5756928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006115446 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.66         |\n",
      "|    n_updates            | 28100        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | 3.013102     |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2812         |\n",
      "|    time_elapsed         | 51318        |\n",
      "|    total_timesteps      | 5758976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022125263 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 28110        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | -0.8325543   |\n",
      "|    std                  | 29.9         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2813        |\n",
      "|    time_elapsed         | 51337       |\n",
      "|    total_timesteps      | 5761024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003951491 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 28120       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | 2.8224719   |\n",
      "|    std                  | 29.9        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2814         |\n",
      "|    time_elapsed         | 51355        |\n",
      "|    total_timesteps      | 5763072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008501937 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 28130        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | -0.098465286 |\n",
      "|    std                  | 29.9         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2815         |\n",
      "|    time_elapsed         | 51374        |\n",
      "|    total_timesteps      | 5765120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007636866 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 28140        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | -1.8623002   |\n",
      "|    std                  | 29.9         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2816         |\n",
      "|    time_elapsed         | 51392        |\n",
      "|    total_timesteps      | 5767168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039524995 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.79         |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    reward               | 0.510528     |\n",
      "|    std                  | 30           |\n",
      "|    value_loss           | 19.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2817         |\n",
      "|    time_elapsed         | 51411        |\n",
      "|    total_timesteps      | 5769216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005212076 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 28160        |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    reward               | -0.1398353   |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2818         |\n",
      "|    time_elapsed         | 51429        |\n",
      "|    total_timesteps      | 5771264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010528426 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 28170        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | 5.5121164    |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2819         |\n",
      "|    time_elapsed         | 51447        |\n",
      "|    total_timesteps      | 5773312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012722691 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 28180        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 1.6696497    |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2820         |\n",
      "|    time_elapsed         | 51465        |\n",
      "|    total_timesteps      | 5775360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013544685 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.38         |\n",
      "|    n_updates            | 28190        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 3.5396268    |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2821         |\n",
      "|    time_elapsed         | 51484        |\n",
      "|    total_timesteps      | 5777408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007299513 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 28200        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    reward               | 1.0057135    |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 35           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2822         |\n",
      "|    time_elapsed         | 51502        |\n",
      "|    total_timesteps      | 5779456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016702267 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 28210        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | 1.4016241    |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2823         |\n",
      "|    time_elapsed         | 51520        |\n",
      "|    total_timesteps      | 5781504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027915696 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.16         |\n",
      "|    n_updates            | 28220        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | -1.5443143   |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3845900.19\n",
      "total_reward: 2845900.19\n",
      "total_cost: 76983.64\n",
      "total_trades: 53244\n",
      "Sharpe: 0.705\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2824        |\n",
      "|    time_elapsed         | 51538       |\n",
      "|    total_timesteps      | 5783552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001239788 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 28230       |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    reward               | 0.4468613   |\n",
      "|    std                  | 30.2        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2825          |\n",
      "|    time_elapsed         | 51556         |\n",
      "|    total_timesteps      | 5785600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047482832 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.722         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.8          |\n",
      "|    n_updates            | 28240         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | -0.29762638   |\n",
      "|    std                  | 30.3          |\n",
      "|    value_loss           | 34.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2826         |\n",
      "|    time_elapsed         | 51574        |\n",
      "|    total_timesteps      | 5787648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021775272 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 28250        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | 1.2855213    |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2827         |\n",
      "|    time_elapsed         | 51592        |\n",
      "|    total_timesteps      | 5789696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006380429 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.09         |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | 1.5360199    |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2828         |\n",
      "|    time_elapsed         | 51610        |\n",
      "|    total_timesteps      | 5791744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012516688 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 28270        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | 4.331913     |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 38.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2829         |\n",
      "|    time_elapsed         | 51628        |\n",
      "|    total_timesteps      | 5793792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004361603 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 28280        |\n",
      "|    policy_gradient_loss | -0.00088     |\n",
      "|    reward               | 1.0154232    |\n",
      "|    std                  | 30.4         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2830        |\n",
      "|    time_elapsed         | 51646       |\n",
      "|    total_timesteps      | 5795840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004868739 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 28290       |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -1.1180301  |\n",
      "|    std                  | 30.4        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2831         |\n",
      "|    time_elapsed         | 51664        |\n",
      "|    total_timesteps      | 5797888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006849024 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.58         |\n",
      "|    n_updates            | 28300        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | -0.562744    |\n",
      "|    std                  | 30.4         |\n",
      "|    value_loss           | 50.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2832          |\n",
      "|    time_elapsed         | 51682         |\n",
      "|    total_timesteps      | 5799936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027072695 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.431         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.12          |\n",
      "|    n_updates            | 28310         |\n",
      "|    policy_gradient_loss | -0.00108      |\n",
      "|    reward               | -0.4675136    |\n",
      "|    std                  | 30.4          |\n",
      "|    value_loss           | 36.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2833         |\n",
      "|    time_elapsed         | 51701        |\n",
      "|    total_timesteps      | 5801984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024454405 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 28320        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 2.0255094    |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2834         |\n",
      "|    time_elapsed         | 51719        |\n",
      "|    total_timesteps      | 5804032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032487833 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.62         |\n",
      "|    n_updates            | 28330        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -1.445319    |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 19.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2835          |\n",
      "|    time_elapsed         | 51737         |\n",
      "|    total_timesteps      | 5806080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077057554 |\n",
      "|    clip_fraction        | 0.00303       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.763         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.9          |\n",
      "|    n_updates            | 28340         |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    reward               | -0.20086944   |\n",
      "|    std                  | 30.5          |\n",
      "|    value_loss           | 27.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2836         |\n",
      "|    time_elapsed         | 51754        |\n",
      "|    total_timesteps      | 5808128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005096906 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 28350        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | -0.9311633   |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2837          |\n",
      "|    time_elapsed         | 51772         |\n",
      "|    total_timesteps      | 5810176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086686655 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.768         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.07          |\n",
      "|    n_updates            | 28360         |\n",
      "|    policy_gradient_loss | -0.00221      |\n",
      "|    reward               | 0.79005575    |\n",
      "|    std                  | 30.5          |\n",
      "|    value_loss           | 18.8          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3547613.99\n",
      "total_reward: 2547613.99\n",
      "total_cost: 79184.91\n",
      "total_trades: 53441\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2838         |\n",
      "|    time_elapsed         | 51790        |\n",
      "|    total_timesteps      | 5812224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014903195 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 28370        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | 0.04167083   |\n",
      "|    std                  | 30.6         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2839          |\n",
      "|    time_elapsed         | 51808         |\n",
      "|    total_timesteps      | 5814272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068139203 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.717         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 28380         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | 26.554468     |\n",
      "|    std                  | 30.6          |\n",
      "|    value_loss           | 30.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2840         |\n",
      "|    time_elapsed         | 51826        |\n",
      "|    total_timesteps      | 5816320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028278986 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.11         |\n",
      "|    n_updates            | 28390        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | -0.7047595   |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2841         |\n",
      "|    time_elapsed         | 51844        |\n",
      "|    total_timesteps      | 5818368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006633406 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 28400        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | 1.6298066    |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2842          |\n",
      "|    time_elapsed         | 51862         |\n",
      "|    total_timesteps      | 5820416       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036048164 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.776         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 28410         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | 1.3135175     |\n",
      "|    std                  | 30.7          |\n",
      "|    value_loss           | 31.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2843         |\n",
      "|    time_elapsed         | 51880        |\n",
      "|    total_timesteps      | 5822464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014615791 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.77         |\n",
      "|    n_updates            | 28420        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -0.6366038   |\n",
      "|    std                  | 30.8         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2844         |\n",
      "|    time_elapsed         | 51900        |\n",
      "|    total_timesteps      | 5824512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032222315 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.79         |\n",
      "|    n_updates            | 28430        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 0.6043499    |\n",
      "|    std                  | 30.8         |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2845         |\n",
      "|    time_elapsed         | 51919        |\n",
      "|    total_timesteps      | 5826560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009256946 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 28440        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | -0.29949844  |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 36           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2846          |\n",
      "|    time_elapsed         | 51937         |\n",
      "|    total_timesteps      | 5828608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017318907 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.681         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.6          |\n",
      "|    n_updates            | 28450         |\n",
      "|    policy_gradient_loss | -0.00118      |\n",
      "|    reward               | -3.1382794    |\n",
      "|    std                  | 30.9          |\n",
      "|    value_loss           | 46.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2847         |\n",
      "|    time_elapsed         | 51956        |\n",
      "|    total_timesteps      | 5830656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043453556 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.03         |\n",
      "|    n_updates            | 28460        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | 0.6446623    |\n",
      "|    std                  | 31           |\n",
      "|    value_loss           | 15.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2848         |\n",
      "|    time_elapsed         | 51974        |\n",
      "|    total_timesteps      | 5832704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013103411 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 28470        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | 1.75134      |\n",
      "|    std                  | 31.1         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2849          |\n",
      "|    time_elapsed         | 51992         |\n",
      "|    total_timesteps      | 5834752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046589796 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.716         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.3          |\n",
      "|    n_updates            | 28480         |\n",
      "|    policy_gradient_loss | -0.000873     |\n",
      "|    reward               | 6.1477146     |\n",
      "|    std                  | 31.1          |\n",
      "|    value_loss           | 33.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2850         |\n",
      "|    time_elapsed         | 52011        |\n",
      "|    total_timesteps      | 5836800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018534744 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.7          |\n",
      "|    n_updates            | 28490        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 1.2434583    |\n",
      "|    std                  | 31.2         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2851          |\n",
      "|    time_elapsed         | 52030         |\n",
      "|    total_timesteps      | 5838848       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052197423 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.851         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.83          |\n",
      "|    n_updates            | 28500         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | 1.1732432     |\n",
      "|    std                  | 31.2          |\n",
      "|    value_loss           | 19.9          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2852         |\n",
      "|    time_elapsed         | 52049        |\n",
      "|    total_timesteps      | 5840896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005181934 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 28510        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -17.37354    |\n",
      "|    std                  | 31.2         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3629098.81\n",
      "total_reward: 2629098.81\n",
      "total_cost: 52606.17\n",
      "total_trades: 50595\n",
      "Sharpe: 0.686\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2853          |\n",
      "|    time_elapsed         | 52067         |\n",
      "|    total_timesteps      | 5842944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045335852 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.81          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.9          |\n",
      "|    n_updates            | 28520         |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    reward               | 0.028484417   |\n",
      "|    std                  | 31.2          |\n",
      "|    value_loss           | 32.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2854        |\n",
      "|    time_elapsed         | 52085       |\n",
      "|    total_timesteps      | 5844992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002824533 |\n",
      "|    clip_fraction        | 0.00332     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.57        |\n",
      "|    n_updates            | 28530       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 0.26216382  |\n",
      "|    std                  | 31.3        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2855         |\n",
      "|    time_elapsed         | 52104        |\n",
      "|    total_timesteps      | 5847040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023052453 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 28540        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | 1.0250424    |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2856         |\n",
      "|    time_elapsed         | 52121        |\n",
      "|    total_timesteps      | 5849088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012890488 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 28550        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | 1.8939143    |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2857         |\n",
      "|    time_elapsed         | 52140        |\n",
      "|    total_timesteps      | 5851136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029833782 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 28560        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | -2.846509    |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 31.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2858         |\n",
      "|    time_elapsed         | 52158        |\n",
      "|    total_timesteps      | 5853184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010274686 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.89         |\n",
      "|    n_updates            | 28570        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | -1.0883489   |\n",
      "|    std                  | 31.5         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2859          |\n",
      "|    time_elapsed         | 52175         |\n",
      "|    total_timesteps      | 5855232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049889437 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.815         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.6          |\n",
      "|    n_updates            | 28580         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | -5.6021414    |\n",
      "|    std                  | 31.5          |\n",
      "|    value_loss           | 32.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2860         |\n",
      "|    time_elapsed         | 52194        |\n",
      "|    total_timesteps      | 5857280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012571837 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 28590        |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    reward               | 2.7476661    |\n",
      "|    std                  | 31.6         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2861        |\n",
      "|    time_elapsed         | 52212       |\n",
      "|    total_timesteps      | 5859328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002485263 |\n",
      "|    clip_fraction        | 0.00601     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.31        |\n",
      "|    n_updates            | 28600       |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | 0.2963455   |\n",
      "|    std                  | 31.6        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2862          |\n",
      "|    time_elapsed         | 52230         |\n",
      "|    total_timesteps      | 5861376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039747052 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.766         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11            |\n",
      "|    n_updates            | 28610         |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    reward               | 0.4607763     |\n",
      "|    std                  | 31.6          |\n",
      "|    value_loss           | 23.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2863          |\n",
      "|    time_elapsed         | 52248         |\n",
      "|    total_timesteps      | 5863424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035038675 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.795         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.4          |\n",
      "|    n_updates            | 28620         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    reward               | -1.106076     |\n",
      "|    std                  | 31.7          |\n",
      "|    value_loss           | 32.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2864         |\n",
      "|    time_elapsed         | 52267        |\n",
      "|    total_timesteps      | 5865472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013829469 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.58         |\n",
      "|    n_updates            | 28630        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | 0.080868855  |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2865          |\n",
      "|    time_elapsed         | 52285         |\n",
      "|    total_timesteps      | 5867520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095557363 |\n",
      "|    clip_fraction        | 0.00552       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.736         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.4          |\n",
      "|    n_updates            | 28640         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | 1.8933213     |\n",
      "|    std                  | 31.7          |\n",
      "|    value_loss           | 25.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2866          |\n",
      "|    time_elapsed         | 52303         |\n",
      "|    total_timesteps      | 5869568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058652175 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.801         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.6          |\n",
      "|    n_updates            | 28650         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | 2.0849054     |\n",
      "|    std                  | 31.8          |\n",
      "|    value_loss           | 31.2          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3899935.46\n",
      "total_reward: 2899935.46\n",
      "total_cost: 53804.12\n",
      "total_trades: 50819\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2867         |\n",
      "|    time_elapsed         | 52321        |\n",
      "|    total_timesteps      | 5871616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010996806 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 28660        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -2.1245284   |\n",
      "|    std                  | 31.8         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2868         |\n",
      "|    time_elapsed         | 52339        |\n",
      "|    total_timesteps      | 5873664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014982971 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | -2.8138046   |\n",
      "|    std                  | 31.8         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2869          |\n",
      "|    time_elapsed         | 52357         |\n",
      "|    total_timesteps      | 5875712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061673624 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.738         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.4          |\n",
      "|    n_updates            | 28680         |\n",
      "|    policy_gradient_loss | -0.00257      |\n",
      "|    reward               | -0.2741786    |\n",
      "|    std                  | 31.8          |\n",
      "|    value_loss           | 29.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2870         |\n",
      "|    time_elapsed         | 52375        |\n",
      "|    total_timesteps      | 5877760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004667094 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 28690        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 0.49008977   |\n",
      "|    std                  | 31.9         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2871         |\n",
      "|    time_elapsed         | 52394        |\n",
      "|    total_timesteps      | 5879808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044075446 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.44         |\n",
      "|    n_updates            | 28700        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | 2.1568353    |\n",
      "|    std                  | 31.9         |\n",
      "|    value_loss           | 15.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2872          |\n",
      "|    time_elapsed         | 52413         |\n",
      "|    total_timesteps      | 5881856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089123554 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.719         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 28710         |\n",
      "|    policy_gradient_loss | -0.00113      |\n",
      "|    reward               | 0.4291088     |\n",
      "|    std                  | 32            |\n",
      "|    value_loss           | 24.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2873          |\n",
      "|    time_elapsed         | 52432         |\n",
      "|    total_timesteps      | 5883904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037947716 |\n",
      "|    clip_fraction        | 0.002         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.827         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.9          |\n",
      "|    n_updates            | 28720         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | 3.9311264     |\n",
      "|    std                  | 32            |\n",
      "|    value_loss           | 33.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2874         |\n",
      "|    time_elapsed         | 52451        |\n",
      "|    total_timesteps      | 5885952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015258255 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 28730        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | -3.6328013   |\n",
      "|    std                  | 32.1         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2875        |\n",
      "|    time_elapsed         | 52469       |\n",
      "|    total_timesteps      | 5888000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002942382 |\n",
      "|    clip_fraction        | 0.00435     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 28740       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | 0.7381084   |\n",
      "|    std                  | 32.2        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2876         |\n",
      "|    time_elapsed         | 52487        |\n",
      "|    total_timesteps      | 5890048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017607564 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 28750        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | 0.3902956    |\n",
      "|    std                  | 32.2         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2877          |\n",
      "|    time_elapsed         | 52505         |\n",
      "|    total_timesteps      | 5892096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076587056 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.732         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 28760         |\n",
      "|    policy_gradient_loss | -0.00233      |\n",
      "|    reward               | -1.6662093    |\n",
      "|    std                  | 32.2          |\n",
      "|    value_loss           | 35.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2878        |\n",
      "|    time_elapsed         | 52523       |\n",
      "|    total_timesteps      | 5894144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005643637 |\n",
      "|    clip_fraction        | 0.0199      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 28770       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | -0.37869614 |\n",
      "|    std                  | 32.4        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2879         |\n",
      "|    time_elapsed         | 52541        |\n",
      "|    total_timesteps      | 5896192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005939554 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.755        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 28780        |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    reward               | -0.48400402  |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2880         |\n",
      "|    time_elapsed         | 52559        |\n",
      "|    total_timesteps      | 5898240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007279477 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 28790        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.9826058   |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3791567.53\n",
      "total_reward: 2791567.53\n",
      "total_cost: 59642.35\n",
      "total_trades: 51480\n",
      "Sharpe: 0.699\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2881         |\n",
      "|    time_elapsed         | 52578        |\n",
      "|    total_timesteps      | 5900288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017384092 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 28800        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | 0.02609602   |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2882         |\n",
      "|    time_elapsed         | 52596        |\n",
      "|    total_timesteps      | 5902336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011764708 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.74         |\n",
      "|    n_updates            | 28810        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 1.4686521    |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2883         |\n",
      "|    time_elapsed         | 52616        |\n",
      "|    total_timesteps      | 5904384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004624516 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 28820        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | -10.7526045  |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2884          |\n",
      "|    time_elapsed         | 52634         |\n",
      "|    total_timesteps      | 5906432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044237758 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.824         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.3          |\n",
      "|    n_updates            | 28830         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    reward               | 0.3581806     |\n",
      "|    std                  | 32.5          |\n",
      "|    value_loss           | 28.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2885         |\n",
      "|    time_elapsed         | 52652        |\n",
      "|    total_timesteps      | 5908480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013679932 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.59         |\n",
      "|    n_updates            | 28840        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -2.698316    |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2886         |\n",
      "|    time_elapsed         | 52670        |\n",
      "|    total_timesteps      | 5910528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006156408 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 28850        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 0.45039567   |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2887         |\n",
      "|    time_elapsed         | 52688        |\n",
      "|    total_timesteps      | 5912576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006226578 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 28860        |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    reward               | 0.80728704   |\n",
      "|    std                  | 32.6         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2888         |\n",
      "|    time_elapsed         | 52706        |\n",
      "|    total_timesteps      | 5914624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039548986 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.76         |\n",
      "|    n_updates            | 28870        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    reward               | -0.01662617  |\n",
      "|    std                  | 32.6         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2889          |\n",
      "|    time_elapsed         | 52724         |\n",
      "|    total_timesteps      | 5916672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077017595 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.69          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.03          |\n",
      "|    n_updates            | 28880         |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    reward               | 0.2880882     |\n",
      "|    std                  | 32.6          |\n",
      "|    value_loss           | 24.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2890         |\n",
      "|    time_elapsed         | 52742        |\n",
      "|    total_timesteps      | 5918720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008167689 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 28890        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -5.8491473   |\n",
      "|    std                  | 32.7         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2891          |\n",
      "|    time_elapsed         | 52761         |\n",
      "|    total_timesteps      | 5920768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072222634 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.832         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.2          |\n",
      "|    n_updates            | 28900         |\n",
      "|    policy_gradient_loss | -0.00269      |\n",
      "|    reward               | 1.0865556     |\n",
      "|    std                  | 32.7          |\n",
      "|    value_loss           | 25.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2892         |\n",
      "|    time_elapsed         | 52781        |\n",
      "|    total_timesteps      | 5922816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011982638 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 28910        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 0.6672556    |\n",
      "|    std                  | 32.7         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2893         |\n",
      "|    time_elapsed         | 52800        |\n",
      "|    total_timesteps      | 5924864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012285758 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 28920        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 2.3029594    |\n",
      "|    std                  | 32.8         |\n",
      "|    value_loss           | 31.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2894        |\n",
      "|    time_elapsed         | 52819       |\n",
      "|    total_timesteps      | 5926912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000824391 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 28930       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    reward               | 0.79799336  |\n",
      "|    std                  | 32.8        |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3966600.36\n",
      "total_reward: 2966600.36\n",
      "total_cost: 76106.37\n",
      "total_trades: 53226\n",
      "Sharpe: 0.722\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2895         |\n",
      "|    time_elapsed         | 52837        |\n",
      "|    total_timesteps      | 5928960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048552323 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.815        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.7          |\n",
      "|    n_updates            | 28940        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    reward               | -0.35374948  |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2896          |\n",
      "|    time_elapsed         | 52855         |\n",
      "|    total_timesteps      | 5931008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012861157 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.738         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.5          |\n",
      "|    n_updates            | 28950         |\n",
      "|    policy_gradient_loss | -0.000383     |\n",
      "|    reward               | -1.1028647    |\n",
      "|    std                  | 32.9          |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2897          |\n",
      "|    time_elapsed         | 52873         |\n",
      "|    total_timesteps      | 5933056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041705082 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.773         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.1          |\n",
      "|    n_updates            | 28960         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | -0.19115615   |\n",
      "|    std                  | 32.9          |\n",
      "|    value_loss           | 35.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2898         |\n",
      "|    time_elapsed         | 52891        |\n",
      "|    total_timesteps      | 5935104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002989508 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.833        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.72         |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | -0.23417254  |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2899          |\n",
      "|    time_elapsed         | 52909         |\n",
      "|    total_timesteps      | 5937152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054983073 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.812         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.5          |\n",
      "|    n_updates            | 28980         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | 1.7689791     |\n",
      "|    std                  | 33            |\n",
      "|    value_loss           | 19.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2900         |\n",
      "|    time_elapsed         | 52927        |\n",
      "|    total_timesteps      | 5939200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018605744 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 28990        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | 0.0317115    |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2901         |\n",
      "|    time_elapsed         | 52946        |\n",
      "|    total_timesteps      | 5941248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013007515 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 29000        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | 0.13197018   |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2902        |\n",
      "|    time_elapsed         | 52964       |\n",
      "|    total_timesteps      | 5943296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002877328 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 29010       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | 1.0621635   |\n",
      "|    std                  | 33.1        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2903         |\n",
      "|    time_elapsed         | 52983        |\n",
      "|    total_timesteps      | 5945344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004776565 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 29020        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | 0.4958037    |\n",
      "|    std                  | 33.1         |\n",
      "|    value_loss           | 39.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2904          |\n",
      "|    time_elapsed         | 53001         |\n",
      "|    total_timesteps      | 5947392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034212298 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.811         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.7          |\n",
      "|    n_updates            | 29030         |\n",
      "|    policy_gradient_loss | -0.00184      |\n",
      "|    reward               | 0.8166741     |\n",
      "|    std                  | 33.1          |\n",
      "|    value_loss           | 33.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2905         |\n",
      "|    time_elapsed         | 53019        |\n",
      "|    total_timesteps      | 5949440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016768367 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.824        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.1          |\n",
      "|    n_updates            | 29040        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -1.1215101   |\n",
      "|    std                  | 33.1         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2906         |\n",
      "|    time_elapsed         | 53037        |\n",
      "|    total_timesteps      | 5951488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015012394 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.25         |\n",
      "|    n_updates            | 29050        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 0.40915707   |\n",
      "|    std                  | 33.2         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2907         |\n",
      "|    time_elapsed         | 53055        |\n",
      "|    total_timesteps      | 5953536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013371551 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 29060        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | 0.3028792    |\n",
      "|    std                  | 33.2         |\n",
      "|    value_loss           | 31.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2908          |\n",
      "|    time_elapsed         | 53073         |\n",
      "|    total_timesteps      | 5955584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078997365 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.748         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13            |\n",
      "|    n_updates            | 29070         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | 2.3540533     |\n",
      "|    std                  | 33.3          |\n",
      "|    value_loss           | 26.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3615849.78\n",
      "total_reward: 2615849.78\n",
      "total_cost: 61241.99\n",
      "total_trades: 51193\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2909         |\n",
      "|    time_elapsed         | 53092        |\n",
      "|    total_timesteps      | 5957632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017529987 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.73         |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -0.5488725   |\n",
      "|    std                  | 33.3         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2910         |\n",
      "|    time_elapsed         | 53112        |\n",
      "|    total_timesteps      | 5959680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006449094 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | 0.694855     |\n",
      "|    std                  | 33.3         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2911         |\n",
      "|    time_elapsed         | 53131        |\n",
      "|    total_timesteps      | 5961728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014619419 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 29100        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | 0.08555592   |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2912        |\n",
      "|    time_elapsed         | 53149       |\n",
      "|    total_timesteps      | 5963776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004634459 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.4         |\n",
      "|    n_updates            | 29110       |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | -0.41030148 |\n",
      "|    std                  | 33.4        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2913         |\n",
      "|    time_elapsed         | 53167        |\n",
      "|    total_timesteps      | 5965824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003442019 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 29120        |\n",
      "|    policy_gradient_loss | -0.000729    |\n",
      "|    reward               | -0.8474709   |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2914          |\n",
      "|    time_elapsed         | 53186         |\n",
      "|    total_timesteps      | 5967872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042542585 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.804         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.2          |\n",
      "|    n_updates            | 29130         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | -3.8706002    |\n",
      "|    std                  | 33.4          |\n",
      "|    value_loss           | 29.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2915        |\n",
      "|    time_elapsed         | 53205       |\n",
      "|    total_timesteps      | 5969920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001425414 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 29140       |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | 0.8571984   |\n",
      "|    std                  | 33.5        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2916         |\n",
      "|    time_elapsed         | 53223        |\n",
      "|    total_timesteps      | 5971968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016680472 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.76         |\n",
      "|    n_updates            | 29150        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -0.8025574   |\n",
      "|    std                  | 33.5         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2917          |\n",
      "|    time_elapsed         | 53240         |\n",
      "|    total_timesteps      | 5974016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047946326 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.678         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.2          |\n",
      "|    n_updates            | 29160         |\n",
      "|    policy_gradient_loss | -0.0013       |\n",
      "|    reward               | 1.465516      |\n",
      "|    std                  | 33.5          |\n",
      "|    value_loss           | 45            |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2918          |\n",
      "|    time_elapsed         | 53258         |\n",
      "|    total_timesteps      | 5976064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018179163 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.467         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.2          |\n",
      "|    n_updates            | 29170         |\n",
      "|    policy_gradient_loss | -0.000777     |\n",
      "|    reward               | -1.4833751    |\n",
      "|    std                  | 33.5          |\n",
      "|    value_loss           | 43.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2919         |\n",
      "|    time_elapsed         | 53277        |\n",
      "|    total_timesteps      | 5978112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021035392 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.66         |\n",
      "|    n_updates            | 29180        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | -0.80971867  |\n",
      "|    std                  | 33.6         |\n",
      "|    value_loss           | 18           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2920          |\n",
      "|    time_elapsed         | 53295         |\n",
      "|    total_timesteps      | 5980160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073644146 |\n",
      "|    clip_fraction        | 0.00493       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.698         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.7          |\n",
      "|    n_updates            | 29190         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | -0.78441274   |\n",
      "|    std                  | 33.6          |\n",
      "|    value_loss           | 30.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2921          |\n",
      "|    time_elapsed         | 53313         |\n",
      "|    total_timesteps      | 5982208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026643762 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.836         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.6          |\n",
      "|    n_updates            | 29200         |\n",
      "|    policy_gradient_loss | -0.0015       |\n",
      "|    reward               | -0.032802824  |\n",
      "|    std                  | 33.6          |\n",
      "|    value_loss           | 32.1          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2922         |\n",
      "|    time_elapsed         | 53332        |\n",
      "|    total_timesteps      | 5984256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024433262 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 29210        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | 1.6604227    |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4270586.90\n",
      "total_reward: 3270586.90\n",
      "total_cost: 137857.61\n",
      "total_trades: 58687\n",
      "Sharpe: 0.774\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2923        |\n",
      "|    time_elapsed         | 53350       |\n",
      "|    total_timesteps      | 5986304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002269347 |\n",
      "|    clip_fraction        | 0.00249     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.46        |\n",
      "|    n_updates            | 29220       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | 1.7346374   |\n",
      "|    std                  | 33.8        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2924          |\n",
      "|    time_elapsed         | 53368         |\n",
      "|    total_timesteps      | 5988352       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043722792 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.765         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 29230         |\n",
      "|    policy_gradient_loss | -0.00103      |\n",
      "|    reward               | 5.84266       |\n",
      "|    std                  | 33.8          |\n",
      "|    value_loss           | 38.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2925         |\n",
      "|    time_elapsed         | 53386        |\n",
      "|    total_timesteps      | 5990400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011272042 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.56         |\n",
      "|    n_updates            | 29240        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | -0.7366976   |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 2926        |\n",
      "|    time_elapsed         | 53405       |\n",
      "|    total_timesteps      | 5992448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002257474 |\n",
      "|    clip_fraction        | 0.00264     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 29250       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | -1.6269206  |\n",
      "|    std                  | 34          |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2927          |\n",
      "|    time_elapsed         | 53423         |\n",
      "|    total_timesteps      | 5994496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062962883 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.579         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.58          |\n",
      "|    n_updates            | 29260         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | 0.75357884    |\n",
      "|    std                  | 34            |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 2928          |\n",
      "|    time_elapsed         | 53442         |\n",
      "|    total_timesteps      | 5996544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037154474 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.542         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.8          |\n",
      "|    n_updates            | 29270         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | -1.5036781    |\n",
      "|    std                  | 34            |\n",
      "|    value_loss           | 41.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2929         |\n",
      "|    time_elapsed         | 53461        |\n",
      "|    total_timesteps      | 5998592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047734845 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.65         |\n",
      "|    n_updates            | 29280        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    reward               | -3.358376    |\n",
      "|    std                  | 34           |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 2930         |\n",
      "|    time_elapsed         | 53479        |\n",
      "|    total_timesteps      | 6000640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025405898 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.09         |\n",
      "|    n_updates            | 29290        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | -0.7101884   |\n",
      "|    std                  | 34.1         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model_ppo2.load('42')\n",
    "print('load')\n",
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tb_log_name=\"8\",\n",
    "                             total_timesteps=6000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
    "\n",
    "trained_ppo2.save('84')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.45132359815483"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_ppo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/536458364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     environment = e_trade_gym)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_account_value, df_actions = DRLAgent.DRL_prediction(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_ppo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     environment = e_trade_gym)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_ppo' is not defined"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/1680983300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/2509563385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/1118186915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_actions' is not defined"
     ]
    }
   ],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/2746174370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d-%Hh%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktest_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_stats_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mperf_stats_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/perf_stats_all_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/57827447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m baseline_df = get_baseline(\n\u001b[1;32m      4\u001b[0m         \u001b[0mticker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"^DJI\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         end = df_account_value.loc[len(df_account_value)-1,'date'])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/2351900042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/1309470278.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_account_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50403/2064601725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dow Jones Index: ^DJI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NASDAQ 100: ^NDX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m backtest_plot(df_account_value, \n\u001b[0m\u001b[1;32m      7\u001b[0m              \u001b[0mbaseline_ticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'^DJI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m              \u001b[0mbaseline_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_account_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_account_value' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>1.403663e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.407926e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.407052e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.411823e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.423684e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "331  2021-10-22   1.403663e+06\n",
       "332  2021-10-25   1.407926e+06\n",
       "333  2021-10-26   1.407052e+06\n",
       "334  2021-10-27   1.411823e+06\n",
       "335  2021-10-28   1.423684e+06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)\n",
    "df_account_value2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.303347\n",
      "Cumulative returns     0.423684\n",
      "Annual volatility      0.131964\n",
      "Sharpe ratio           2.080563\n",
      "Calmar ratio           4.477709\n",
      "Stability              0.947425\n",
      "Max drawdown          -0.067746\n",
      "Omega ratio            1.401004\n",
      "Sortino ratio          3.104847\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.195164\n",
      "Daily value at risk   -0.015536\n",
      "dtype: float64\n",
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n",
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>30.335%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>42.368%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>13.196%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-6.775%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.554%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.77</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.03</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.00</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.54</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.39</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.11%</td>\n",
       "      <td>-3.49%</td>\n",
       "      <td>2.14%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
