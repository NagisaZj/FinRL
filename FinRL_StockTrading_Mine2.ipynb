{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zj/anaconda3/envs/finrl/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -72.8      |\n",
      "|    reward             | 0.19451597 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.68       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 68         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -0.115     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -1.4624771 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -167     |\n",
      "|    reward             | 5.02583  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    reward             | 5.606354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | -7.546301 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.0793    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 145       |\n",
      "|    reward             | 0.4507672 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -0.0998    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | -2.1521304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0.00557     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.80710465 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 70.3        |\n",
      "|    reward             | -0.11950674 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | -4.1389766 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -245     |\n",
      "|    reward             | 6.363784 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -63.1      |\n",
      "|    reward             | 0.07753525 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -0.000831 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 48.9      |\n",
      "|    reward             | -4.088032 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 179       |\n",
      "|    reward             | 2.0626597 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | 4.8591986 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 85.1       |\n",
      "|    reward             | 0.85958314 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -141     |\n",
      "|    reward             | 5.65319  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | 1.1973313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | 0.36287376 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | -0.0091     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -83.6       |\n",
      "|    reward             | -0.30971453 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 204       |\n",
      "|    reward             | 1.7650424 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | -7.5710273 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -2.04e+03  |\n",
      "|    reward             | -14.886115 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3e+03      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.0559524 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -46.7     |\n",
      "|    reward             | -0.434364 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    reward             | 4.8586307 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -0.4118847 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    reward             | 1.0554261 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 66.3      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.88      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 2.3091433 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -20.7      |\n",
      "|    reward             | 0.38583377 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 43.7       |\n",
      "|    reward             | -0.3664559 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -38.8      |\n",
      "|    reward             | -0.4616701 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | 0.11014476 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -3.93     |\n",
      "|    reward             | 2.1390972 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 76.4       |\n",
      "|    reward             | 0.16336557 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -85.2     |\n",
      "|    reward             | 1.0221922 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | 1.1701288 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 33.2      |\n",
      "|    reward             | 2.4472284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.2081411 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -0.481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -5.13     |\n",
      "|    reward             | 1.3224076 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2         |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.25540048 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.000881  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 1.3826902 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -64       |\n",
      "|    reward             | 3.9822705 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 63.9       |\n",
      "|    reward             | 0.95108056 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | -2.1539907 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    reward             | 4.8509326 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.00948     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -105        |\n",
      "|    reward             | -0.22313617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -104        |\n",
      "|    reward             | -0.99914765 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 353        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | 0.20132123 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -7.57e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 46.2       |\n",
      "|    reward             | 0.26696855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -83.4      |\n",
      "|    reward             | -1.8360271 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | 3.2874866 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 92.2      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161472.69\n",
      "total_reward: 2161472.69\n",
      "total_cost: 19221.41\n",
      "total_trades: 41334\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.54     |\n",
      "|    reward             | 0.2828299 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.19252001 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 2.0577734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.6       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -46.9       |\n",
      "|    reward             | -0.06746031 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.00117    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | 0.18157594 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0.0166    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | 0.6473793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.22656512 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 59.9       |\n",
      "|    reward             | -0.8028962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 439        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7693416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 446         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | -0.10761352 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 454      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 203      |\n",
      "|    reward             | 3.869458 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -0.0428   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 110       |\n",
      "|    reward             | 1.2343621 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -2.028344 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.33169752 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.98       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -869     |\n",
      "|    reward             | -8.09732 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 536      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.56556416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | -2.9329143 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 88.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 504        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 72.3       |\n",
      "|    reward             | 0.22214015 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -0.6425189 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -360        |\n",
      "|    reward             | -0.22756429 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 80.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -430        |\n",
      "|    reward             | -0.44158605 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 131         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 404        |\n",
      "|    reward             | -5.8487034 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -14.82644 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 832       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 548       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | 1.4826734 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.0473    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | 0.34629944 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -42       |\n",
      "|    reward             | -2.415951 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.0485888 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 42.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -207       |\n",
      "|    reward             | -3.2154734 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 56.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 5.370093  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | 0.03019213 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 118        |\n",
      "|    reward             | -1.1561224 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -214        |\n",
      "|    reward             | -0.94865924 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 30.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 613       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 1.1797212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 41.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 411        |\n",
      "|    reward             | -22.785406 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 627       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | 3.2164123 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 87          |\n",
      "|    reward             | -0.17441794 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 262         |\n",
      "|    reward             | -0.85795397 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 48.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 72.7       |\n",
      "|    reward             | -2.2230675 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 22.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -49.2     |\n",
      "|    reward             | 2.6728501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -238     |\n",
      "|    reward             | 8.656925 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0.000219    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.62001467 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 1.1713017 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 1.3898315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -52.5     |\n",
      "|    reward             | -6.044222 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    reward             | 1.8213228 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 706      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 177      |\n",
      "|    reward             | 8.957433 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.26523116 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | -0.00926   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | -0.6623605 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_2\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 113       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 18        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.7089172 |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015674507 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0239     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.51        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | 0.49858078  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014924305 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00408     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | -1.5313485  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016326863 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0227     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    reward               | 2.4658284   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019096106 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00282    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.67        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    reward               | 2.9346743   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015927956 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.0154     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 1.9419128   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016921107 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.00431     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | 2.47163     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020489657 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.022      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | -0.40566492 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015726987 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.0114     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -0.09988106 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3477079.87\n",
      "total_reward: 2477079.87\n",
      "total_cost: 339548.69\n",
      "total_trades: 79252\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 192        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02170109 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | 0.0124     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.42       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    reward               | 0.46614277 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 51.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025320135 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.00283    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | 3.7603202   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020878986 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.00445    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    reward               | 0.19243628  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017231094 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.00357    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | 0.41704965  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014763339 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.000111    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | -1.3835832  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021707159 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.0105     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | 4.834399    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 307          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01863564   |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.8        |\n",
      "|    explained_variance   | 0.0253       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.026       |\n",
      "|    reward               | -0.093619764 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021621335 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.00169    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 0.9201581   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 345        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01634153 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.9      |\n",
      "|    explained_variance   | 0.00898    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27         |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 0.45173138 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 64.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021086566 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.0045      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.87        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 0.2391538   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015062243 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.00601     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.4589027  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028622104 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | -0.00342    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    reward               | -8.351565   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 65.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 421        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0228916  |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42        |\n",
      "|    explained_variance   | -0.0159    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    reward               | 0.31981114 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 31.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023305248 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.00941     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | -0.44252673 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 68.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018721137 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 4.153468    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 57.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3249860.00\n",
      "total_reward: 2249860.00\n",
      "total_cost: 308952.62\n",
      "total_trades: 76937\n",
      "Sharpe: 0.612\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 478         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018170066 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0062      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    reward               | -0.5702815  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 68.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 497        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02122226 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.1      |\n",
      "|    explained_variance   | 0.0318     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    reward               | 1.8647404  |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 21.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021428794 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -1.5397772  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029159006 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.00411    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.1        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.2499744  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 84.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 553          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.025600363  |\n",
      "|    clip_fraction        | 0.309        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.2        |\n",
      "|    explained_variance   | 0.0265       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0218      |\n",
      "|    reward               | 0.0021598581 |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 573        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03236839 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.3      |\n",
      "|    explained_variance   | -0.00601   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.3       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    reward               | 0.7087055  |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 55         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 592        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0248825  |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.4      |\n",
      "|    explained_variance   | 0.0109     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.4       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    reward               | -0.8552878 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 78.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028351089 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.0044      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | -0.03902703 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 630          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022084348  |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.5        |\n",
      "|    explained_variance   | -0.0017      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0231      |\n",
      "|    reward               | -0.039366018 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025189545 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.00257     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 0.80960417  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 668        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02886751 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | 0.0165     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.2       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    reward               | 0.18709674 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 79.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034230184 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00791     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -5.0283813  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 706        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02931857 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.8      |\n",
      "|    explained_variance   | 0.022      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27         |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | -0.3086114 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 89.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 726         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023010453 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0248      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.1        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -6.5840964  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3928731.63\n",
      "total_reward: 2928731.63\n",
      "total_cost: 320142.48\n",
      "total_trades: 78274\n",
      "Sharpe: 0.752\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035847034 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.00429     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | -1.9764769  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03361225  |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -0.65023863 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 783         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02228109  |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | 0.0199      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    reward               | 0.024881516 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 75.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050841734 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | -0.00521    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | 0.15137213  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 90.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 821         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033419915 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.46        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -1.1259693  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 840         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034661382 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0414      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.13618208  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 860        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04301531 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0247     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 76.7       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | 0.000698   |\n",
      "|    reward               | -1.1987457 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 155        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 878         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026249848 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -5.2059135  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 897         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021847598 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0839      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 0.8759813   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030400695 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0216      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 24.953707   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 89.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 935         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028785449 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.6        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | -1.7373701  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 954         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027080273 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.4       |\n",
      "|    explained_variance   | -0.0463     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.055598978 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 973         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028124977 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.0508      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.5        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | -0.46923915 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 992         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031559117 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.00941     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59          |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -3.3073916  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6510891.58\n",
      "total_reward: 5510891.58\n",
      "total_cost: 285004.65\n",
      "total_trades: 74261\n",
      "Sharpe: 0.947\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 1010        |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028937586 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.5       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 2.3245926   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1029        |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058062438 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    reward               | 0.95329493  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1048        |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034922585 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0627      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.2        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | 7.403482    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 1067         |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.041707788  |\n",
      "|    clip_fraction        | 0.331        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.8        |\n",
      "|    explained_variance   | 0.0603       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | -0.017793102 |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 1086       |\n",
      "|    total_timesteps      | 116736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0357335  |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.058      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.1       |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.00518   |\n",
      "|    reward               | -0.0726471 |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 120        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 1104       |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03416177 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.9      |\n",
      "|    explained_variance   | 0.0238     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 82.6       |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | 0.00446    |\n",
      "|    reward               | 1.7156948  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 246        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 1124       |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03450838 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44        |\n",
      "|    explained_variance   | 0.0314     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.6       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | 0.00798    |\n",
      "|    reward               | 0.15701988 |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 167        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1143        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01963497  |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | -0.26761398 |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1162        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025955785 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    reward               | 0.9607981   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1181        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021719757 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0836      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.000624   |\n",
      "|    reward               | 4.9674025   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1200        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031134969 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.000438    |\n",
      "|    reward               | 5.290297    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1219        |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027133271 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | -0.80781907 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1238        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025247905 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.9960269  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1257        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023661772 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0229      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.7        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 2.604047    |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6236678.70\n",
      "total_reward: 5236678.70\n",
      "total_cost: 211378.76\n",
      "total_trades: 69402\n",
      "Sharpe: 0.888\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1276        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021533236 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.05        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | -2.5407302  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1295        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019314947 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    reward               | -0.42164513 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1313        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032274306 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.2        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -4.9186864  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 1332       |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03519131 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.6      |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.5       |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.0029    |\n",
      "|    reward               | 1.221297   |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 29.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1351        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020209903 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | 0.4720221   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 1370       |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02942952 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.8      |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.9       |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.00159   |\n",
      "|    reward               | -26.454447 |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 95.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1389        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021654816 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.0634      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.2        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | -1.8617206  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1408        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036662467 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -1.8593036  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1427        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023075856 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.4824715   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1446        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025011204 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -4.147438   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1464        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022137005 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 0.106696464 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 1483       |\n",
      "|    total_timesteps      | 159744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01823147 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.1      |\n",
      "|    explained_variance   | 0.229      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 76         |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | -0.00387   |\n",
      "|    reward               | 2.778411   |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 123        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 1502        |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022388335 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.1       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.000976   |\n",
      "|    reward               | -2.1347709  |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1521        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013498474 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    reward               | 1.0879102   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6210673.97\n",
      "total_reward: 5210673.97\n",
      "total_cost: 257438.92\n",
      "total_trades: 72083\n",
      "Sharpe: 0.928\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 1539       |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02467088 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.2      |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 69.6       |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0049    |\n",
      "|    reward               | -0.6998728 |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 91.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1558        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013957405 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.2       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | -0.09901426 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1577        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028478002 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.6        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | 2.3150241   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1596        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025331961 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.3       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.6914437   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1614        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027448293 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    reward               | 0.12243402  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 76          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1634        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021293068 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.000898   |\n",
      "|    reward               | -1.6572617  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 1654        |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022238174 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | 1.4452592   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1673        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014467318 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -1.4821999  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 62.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1692        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02635841  |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.4       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | 0.00286     |\n",
      "|    reward               | -0.19119689 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1711        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016319457 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | -0.30450392 |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 98.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1730        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031248003 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.63        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -2.2735775  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 1748       |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0176704  |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.5      |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.5       |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    reward               | -1.4198929 |\n",
      "|    std                  | 1.16       |\n",
      "|    value_loss           | 43.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 1768        |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020096783 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.6       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.7        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | 0.4501221   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 1787       |\n",
      "|    total_timesteps      | 192512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02961174 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.6      |\n",
      "|    explained_variance   | 0.427      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.5       |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    reward               | 1.4841743  |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 23.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5681867.90\n",
      "total_reward: 4681867.90\n",
      "total_cost: 247244.48\n",
      "total_trades: 71949\n",
      "Sharpe: 0.912\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1806        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03829085  |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | -0.41603163 |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1825        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027172733 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.1        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | 0.00823     |\n",
      "|    reward               | 7.1405053   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1844        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045977887 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.7       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    reward               | 1.7683499   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1863        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049595848 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.0934      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -0.820793   |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1882        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037181586 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.8       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    reward               | -1.5057708  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 100        |\n",
      "|    time_elapsed         | 1901       |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03160774 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45.9      |\n",
      "|    explained_variance   | 0.0563     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 72.9       |\n",
      "|    n_updates            | 990        |\n",
      "|    policy_gradient_loss | -0.0086    |\n",
      "|    reward               | -0.6052063 |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 161        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 101        |\n",
      "|    time_elapsed         | 1920       |\n",
      "|    total_timesteps      | 206848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03482233 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46        |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.4       |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | -0.00252   |\n",
      "|    reward               | -0.3701391 |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 25.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 1940       |\n",
      "|    total_timesteps      | 208896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02435002 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46        |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 93.3       |\n",
      "|    n_updates            | 1010       |\n",
      "|    policy_gradient_loss | -0.00952   |\n",
      "|    reward               | -1.6037109 |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 131        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1959        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047594856 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 7.020846    |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1979        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042815443 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.1       |\n",
      "|    explained_variance   | 0.0606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.000175   |\n",
      "|    reward               | -0.77257526 |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 1997       |\n",
      "|    total_timesteps      | 215040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03318473 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.1      |\n",
      "|    explained_variance   | 0.124      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 103        |\n",
      "|    n_updates            | 1040       |\n",
      "|    policy_gradient_loss | 0.00181    |\n",
      "|    reward               | -2.2783444 |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 128        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 2016        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032671493 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.1        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -0.17838891 |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 87.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 2035        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020673148 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.2       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.6        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | 2.1576722   |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 2054        |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032761443 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.3       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | -0.3860841  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5357492.57\n",
      "total_reward: 4357492.57\n",
      "total_cost: 287257.78\n",
      "total_trades: 73227\n",
      "Sharpe: 0.895\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 2073        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029784396 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.3       |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | -0.8212162  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 2092        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031070076 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.3       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | 1.0110577   |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 89          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 2110       |\n",
      "|    total_timesteps      | 227328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06040521 |\n",
      "|    clip_fraction        | 0.399      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.4      |\n",
      "|    explained_variance   | 0.0503     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.8       |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | -0.00161   |\n",
      "|    reward               | 8.832765   |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 47.2       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 2129        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030606706 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.5       |\n",
      "|    explained_variance   | 0.0626      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | -1.6134235  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 2148       |\n",
      "|    total_timesteps      | 231424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01997577 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.5      |\n",
      "|    explained_variance   | -0.00583   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 84.7       |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | -0.00627   |\n",
      "|    reward               | -1.1526299 |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 228        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 2167       |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04214705 |\n",
      "|    clip_fraction        | 0.364      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -46.6      |\n",
      "|    explained_variance   | 0.0391     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 114        |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | 0.000985   |\n",
      "|    reward               | -2.428379  |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 286        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 2186        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037904974 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.6       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.9         |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | -1.1280035  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2205        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023637898 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.0324      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.3        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | -1.5205891  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 2224        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041882645 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.7        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | 0.00195     |\n",
      "|    reward               | 1.8511508   |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 2243        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039942168 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.7       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | 0.00168     |\n",
      "|    reward               | -1.4749243  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2262        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032225944 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.8       |\n",
      "|    explained_variance   | 0.0532      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.8        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    reward               | 0.33687174  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 2281        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011142963 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.0724      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | -3.052568   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 2300        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035676114 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | -0.7161055  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 2320        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023920154 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.0621      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.6        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | 0.14565659  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7227035.78\n",
      "total_reward: 6227035.78\n",
      "total_cost: 259606.51\n",
      "total_trades: 71022\n",
      "Sharpe: 0.918\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 2339        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030865926 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.2        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | 1.4712604   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 2357        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023588507 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -46.9       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82          |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -1.1672716  |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 2377        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036529038 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | 0.000161    |\n",
      "|    reward               | 2.056259    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 2398        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016301628 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 197         |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -0.36982533 |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 330         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 2418        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031791285 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47         |\n",
      "|    explained_variance   | 0.0726      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | 0.00541     |\n",
      "|    reward               | -5.387685   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 2439        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015683549 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.7        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | -2.006383   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 93.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 2460       |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01429252 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.1      |\n",
      "|    explained_variance   | 0.144      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 158        |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | -0.00524   |\n",
      "|    reward               | -2.0265462 |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 198        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 2481        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025182098 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.000829   |\n",
      "|    reward               | 0.37591687  |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 2500        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025618892 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.0577      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    reward               | 2.159895    |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 2520        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038381714 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.1       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | 0.00725     |\n",
      "|    reward               | 1.5610416   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 2539        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034762777 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | 1.76962     |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 2558        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030123655 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | 0.000348    |\n",
      "|    reward               | -1.606946   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 2576        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028133037 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.2       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | 0.00756     |\n",
      "|    reward               | -2.0980601  |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 65.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 2595        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027230633 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.3       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | -0.13900024 |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 2615       |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03205733 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.3      |\n",
      "|    explained_variance   | 0.0902     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 133        |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | -0.00192   |\n",
      "|    reward               | -7.661555  |\n",
      "|    std                  | 1.24       |\n",
      "|    value_loss           | 232        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6524879.61\n",
      "total_reward: 5524879.61\n",
      "total_cost: 240039.96\n",
      "total_trades: 67719\n",
      "Sharpe: 0.931\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 2634        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036118522 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | -0.0128     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | 0.00128     |\n",
      "|    reward               | 1.7184378   |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2654        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050017983 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.4       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    reward               | -1.6935219  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 2673        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039732695 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.0838      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | 0.00211     |\n",
      "|    reward               | 0.6645856   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 2692        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021975137 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.5       |\n",
      "|    explained_variance   | 0.0584      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.8        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.000858   |\n",
      "|    reward               | 5.5514417   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 142        |\n",
      "|    time_elapsed         | 2711       |\n",
      "|    total_timesteps      | 290816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03672291 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.6      |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.8       |\n",
      "|    n_updates            | 1410       |\n",
      "|    policy_gradient_loss | 0.00397    |\n",
      "|    reward               | -1.5591931 |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 48.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 2730        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034523457 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.7       |\n",
      "|    explained_variance   | 0.0989      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.7        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 1.235673    |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 144        |\n",
      "|    time_elapsed         | 2750       |\n",
      "|    total_timesteps      | 294912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02339435 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.8      |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 95.5       |\n",
      "|    n_updates            | 1430       |\n",
      "|    policy_gradient_loss | -0.000631  |\n",
      "|    reward               | 8.717218   |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 177        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 145        |\n",
      "|    time_elapsed         | 2769       |\n",
      "|    total_timesteps      | 296960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03305026 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -47.8      |\n",
      "|    explained_variance   | 0.139      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.6       |\n",
      "|    n_updates            | 1440       |\n",
      "|    policy_gradient_loss | -0.00339   |\n",
      "|    reward               | 0.06947805 |\n",
      "|    std                  | 1.26       |\n",
      "|    value_loss           | 73.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 2787        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017195841 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.8       |\n",
      "|    explained_variance   | 0.09        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.6        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    reward               | 3.2586606   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 2806        |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027166974 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.0649      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.1        |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | 0.00034     |\n",
      "|    reward               | -1.0857536  |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 2848        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023308907 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.0633      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.9        |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    reward               | 1.8855757   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 2867        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018010233 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.9       |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    reward               | 2.483265    |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 2886        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024770873 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48         |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.000768   |\n",
      "|    reward               | 0.7552895   |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 2905       |\n",
      "|    total_timesteps      | 309248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04575312 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48        |\n",
      "|    explained_variance   | 0.0915     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | 0.00187    |\n",
      "|    reward               | 9.196513   |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 176        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7100638.33\n",
      "total_reward: 6100638.33\n",
      "total_cost: 196861.85\n",
      "total_trades: 64317\n",
      "Sharpe: 0.944\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 2923        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028777253 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.1       |\n",
      "|    explained_variance   | 0.0872      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | 0.00659     |\n",
      "|    reward               | -1.6172957  |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 79.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 2942        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024342932 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | -0.2314522  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 2961        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020836905 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.9        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    reward               | -0.7820573  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 2979        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015042046 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.2       |\n",
      "|    explained_variance   | 0.0827      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | -0.55123365 |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 156        |\n",
      "|    time_elapsed         | 3000       |\n",
      "|    total_timesteps      | 319488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02447729 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.2      |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.5       |\n",
      "|    n_updates            | 1550       |\n",
      "|    policy_gradient_loss | 0.000242   |\n",
      "|    reward               | -1.5015393 |\n",
      "|    std                  | 1.28       |\n",
      "|    value_loss           | 29.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 3020        |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019951984 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.7        |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | -1.5140582  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 3040        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024951022 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.1        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | -12.370541  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 3060        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023587283 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    reward               | -1.4384084  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 3081        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028757846 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.4       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.7        |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | 0.000149    |\n",
      "|    reward               | 1.0759282   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 106       |\n",
      "|    iterations           | 161       |\n",
      "|    time_elapsed         | 3100      |\n",
      "|    total_timesteps      | 329728    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0182534 |\n",
      "|    clip_fraction        | 0.247     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -48.5     |\n",
      "|    explained_variance   | 0.112     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 117       |\n",
      "|    n_updates            | 1600      |\n",
      "|    policy_gradient_loss | -0.00122  |\n",
      "|    reward               | 33.964394 |\n",
      "|    std                  | 1.29      |\n",
      "|    value_loss           | 184       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 3119        |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018351482 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    reward               | -0.6981484  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 3138        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024014562 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.5       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    reward               | -2.1856945  |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 164        |\n",
      "|    time_elapsed         | 3157       |\n",
      "|    total_timesteps      | 335872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02153029 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.6      |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 84.3       |\n",
      "|    n_updates            | 1630       |\n",
      "|    policy_gradient_loss | -0.000126  |\n",
      "|    reward               | -0.4340197 |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 123        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 3176        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025946675 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.6       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.2        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | 0.000909    |\n",
      "|    reward               | 12.272715   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8134646.95\n",
      "total_reward: 7134646.95\n",
      "total_cost: 145863.00\n",
      "total_trades: 58834\n",
      "Sharpe: 0.999\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 3195       |\n",
      "|    total_timesteps      | 339968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03976216 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -48.6      |\n",
      "|    explained_variance   | 0.229      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.9       |\n",
      "|    n_updates            | 1650       |\n",
      "|    policy_gradient_loss | 0.00248    |\n",
      "|    reward               | 1.9337612  |\n",
      "|    std                  | 1.3        |\n",
      "|    value_loss           | 64.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 3214        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026054952 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | 2.2182171   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 3233        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022050343 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    reward               | 4.953142    |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 3251        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018029384 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.7       |\n",
      "|    explained_variance   | 0.0477      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55          |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -0.8961402  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 3270        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026572466 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | 0.00151     |\n",
      "|    reward               | -1.2023765  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 3289        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013334071 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    reward               | -0.69653785 |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3308        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015313614 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.8       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.3        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | 3.409034    |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 3327        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021096747 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.000513   |\n",
      "|    reward               | -0.73931813 |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 3346        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034613743 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -1.22e-05   |\n",
      "|    reward               | 1.9468629   |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 3365        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024999931 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.9       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    reward               | 2.8814795   |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 3384        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032554474 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | 0.00276     |\n",
      "|    reward               | 4.242863    |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 66.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 3404        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027247824 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49         |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | 0.00245     |\n",
      "|    reward               | 0.74002725  |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 3423        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028045822 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.8        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.000922   |\n",
      "|    reward               | -0.9023365  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 3442        |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013687782 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.1       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.9        |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 2.7230675   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6364733.09\n",
      "total_reward: 5364733.09\n",
      "total_cost: 174232.82\n",
      "total_trades: 60601\n",
      "Sharpe: 0.928\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 3461         |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022359151  |\n",
      "|    clip_fraction        | 0.26         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.1        |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -0.059982404 |\n",
      "|    std                  | 1.32         |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 181          |\n",
      "|    time_elapsed         | 3480         |\n",
      "|    total_timesteps      | 370688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0178953    |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.2        |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.9         |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | -0.028490847 |\n",
      "|    std                  | 1.32         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 3499        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032646917 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    reward               | -0.65165514 |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3518        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046245117 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | 0.51408327  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 3537        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017676461 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.3        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -1.4947783  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 3556       |\n",
      "|    total_timesteps      | 378880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01477056 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -49.3      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 71.1       |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.000728  |\n",
      "|    reward               | 10.703546  |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 3575        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016431091 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.3       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.000666   |\n",
      "|    reward               | -0.41529924 |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 3594        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018814834 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 1.2906215   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 3613        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024992384 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.9        |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    reward               | 2.0668442   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 3633        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017317306 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.2        |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    reward               | -5.680724   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 3651        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026255853 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.5       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | 2.55e-05    |\n",
      "|    reward               | 4.872283    |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 3670        |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012915122 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | 3.184787    |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 3689        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027962402 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    reward               | -14.2857485 |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 3708        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023816314 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | 0.00619     |\n",
      "|    reward               | 1.3641539   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6609066.86\n",
      "total_reward: 5609066.86\n",
      "total_cost: 172999.37\n",
      "total_trades: 61315\n",
      "Sharpe: 0.987\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 3727        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021760337 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.6        |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    reward               | -0.6905856  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 97.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 3746        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017620623 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -4.65e-05   |\n",
      "|    reward               | 1.0597036   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 3764        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005312165 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.6       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 4.8704624   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 3783        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04155266  |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.7       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | 0.00257     |\n",
      "|    reward               | -0.21761985 |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 198          |\n",
      "|    time_elapsed         | 3802         |\n",
      "|    total_timesteps      | 405504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01850849   |\n",
      "|    clip_fraction        | 0.243        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.7        |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.8         |\n",
      "|    n_updates            | 1970         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | -0.116483785 |\n",
      "|    std                  | 1.35         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 3821        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016787361 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    reward               | 0.45777914  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 3839        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033548072 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.8       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    reward               | 1.1188954   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 54.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 3858        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016839888 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    reward               | 1.1335722   |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 94.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 3877        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019027485 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | 0.00099     |\n",
      "|    reward               | -17.351904  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 3896        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030207057 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.9       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.6        |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | 0.0105      |\n",
      "|    reward               | 0.390522    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 3915        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040512756 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | 0.0041      |\n",
      "|    reward               | 0.12361329  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 205        |\n",
      "|    time_elapsed         | 3934       |\n",
      "|    total_timesteps      | 419840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02910762 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50        |\n",
      "|    explained_variance   | -0.0339    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 115        |\n",
      "|    n_updates            | 2040       |\n",
      "|    policy_gradient_loss | -0.00838   |\n",
      "|    reward               | 2.8928132  |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 112        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 206          |\n",
      "|    time_elapsed         | 3952         |\n",
      "|    total_timesteps      | 421888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148622375 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50          |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.7         |\n",
      "|    n_updates            | 2050         |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -0.8213799   |\n",
      "|    std                  | 1.36         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 3973        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034649998 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.1       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    reward               | 0.5929886   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6857977.53\n",
      "total_reward: 5857977.53\n",
      "total_cost: 178560.74\n",
      "total_trades: 62789\n",
      "Sharpe: 0.950\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 3992        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023741633 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.2       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    reward               | -2.8077528  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 4011       |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01696593 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.3      |\n",
      "|    explained_variance   | 0.258      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 118        |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | -0.00118   |\n",
      "|    reward               | 1.782876   |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 164        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 4030         |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.023935392  |\n",
      "|    clip_fraction        | 0.213        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.3        |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 2090         |\n",
      "|    policy_gradient_loss | 0.00248      |\n",
      "|    reward               | -0.076077804 |\n",
      "|    std                  | 1.37         |\n",
      "|    value_loss           | 75.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 211        |\n",
      "|    time_elapsed         | 4048       |\n",
      "|    total_timesteps      | 432128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03282158 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.4      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.1       |\n",
      "|    n_updates            | 2100       |\n",
      "|    policy_gradient_loss | -0.00963   |\n",
      "|    reward               | 0.4044952  |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 68.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 4067        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011404158 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | 0.17390761  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 4086        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013768354 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.4       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.5        |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | 5.590874    |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 4105       |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03764426 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.5      |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 2130       |\n",
      "|    policy_gradient_loss | -0.00492   |\n",
      "|    reward               | -0.5604051 |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 31.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 215        |\n",
      "|    time_elapsed         | 4125       |\n",
      "|    total_timesteps      | 440320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01821466 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.5      |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.1       |\n",
      "|    n_updates            | 2140       |\n",
      "|    policy_gradient_loss | -0.00175   |\n",
      "|    reward               | 1.1575135  |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 102        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 4144        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017880823 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | 0.000907    |\n",
      "|    reward               | 4.5397844   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 88.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 4163        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037138704 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.5       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | 0.00472     |\n",
      "|    reward               | 0.14337079  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 218        |\n",
      "|    time_elapsed         | 4182       |\n",
      "|    total_timesteps      | 446464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02140199 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.6      |\n",
      "|    explained_variance   | 0.251      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 39.1       |\n",
      "|    n_updates            | 2170       |\n",
      "|    policy_gradient_loss | -0.00349   |\n",
      "|    reward               | 1.40036    |\n",
      "|    std                  | 1.39       |\n",
      "|    value_loss           | 59.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 4201        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037662968 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.6       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.1        |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | 0.000235    |\n",
      "|    reward               | -0.53967243 |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 4220        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028882463 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.0862      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.1        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.000216   |\n",
      "|    reward               | 2.1900384   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 82.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 4239        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032314878 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | 0.000353    |\n",
      "|    reward               | -1.6825966  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5989812.63\n",
      "total_reward: 4989812.63\n",
      "total_cost: 155274.21\n",
      "total_trades: 60717\n",
      "Sharpe: 0.962\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 4258         |\n",
      "|    total_timesteps      | 454656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.018380795  |\n",
      "|    clip_fraction        | 0.222        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.7        |\n",
      "|    explained_variance   | 0.0168       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 2210         |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -0.032298118 |\n",
      "|    std                  | 1.39         |\n",
      "|    value_loss           | 91.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 4276        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025874391 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | 0.00139     |\n",
      "|    reward               | -3.5152948  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 4296        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020378694 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 3.9217415   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 4315        |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021002736 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.5839849   |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 4334        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019317668 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.8       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.000414   |\n",
      "|    reward               | -0.36883786 |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 227        |\n",
      "|    time_elapsed         | 4352       |\n",
      "|    total_timesteps      | 464896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01685702 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.9      |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 60.6       |\n",
      "|    n_updates            | 2260       |\n",
      "|    policy_gradient_loss | -0.0083    |\n",
      "|    reward               | 1.6710438  |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 129        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 228        |\n",
      "|    time_elapsed         | 4371       |\n",
      "|    total_timesteps      | 466944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03241179 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.9      |\n",
      "|    explained_variance   | 0.614      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 2270       |\n",
      "|    policy_gradient_loss | 0.00378    |\n",
      "|    reward               | -0.5115886 |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 21.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 4390        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027548146 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51         |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.3        |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | -1.1034218  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 4409         |\n",
      "|    total_timesteps      | 471040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090774335 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51          |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51           |\n",
      "|    n_updates            | 2290         |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | 3.4684794    |\n",
      "|    std                  | 1.41         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 4428        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039776593 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    reward               | -3.3284388  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 4447        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018791936 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | 0.791627    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 4467        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015337541 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.1        |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -3.0970628  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 4486        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017777268 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    reward               | 0.9059092   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 61.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 4504        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026322976 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    reward               | -1.9279771  |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7518118.13\n",
      "total_reward: 6518118.13\n",
      "total_cost: 160987.19\n",
      "total_trades: 61361\n",
      "Sharpe: 1.058\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 4523        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021157373 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.8        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    reward               | 2.058529    |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 4542        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024805294 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | 0.00479     |\n",
      "|    reward               | -3.6138935  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 4561        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042887677 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.4       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.98        |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | 0.00311     |\n",
      "|    reward               | 1.5400794   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 4580        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021845844 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83          |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | 2.0446968   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 4599        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023315176 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.3        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | 0.00507     |\n",
      "|    reward               | 1.9743371   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 241        |\n",
      "|    time_elapsed         | 4618       |\n",
      "|    total_timesteps      | 493568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02841903 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.5      |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.8       |\n",
      "|    n_updates            | 2400       |\n",
      "|    policy_gradient_loss | 0.00802    |\n",
      "|    reward               | 0.48670626 |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 64         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 4637        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020150831 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 0.8839737   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 4656        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026938101 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | 0.88148624  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 244        |\n",
      "|    time_elapsed         | 4675       |\n",
      "|    total_timesteps      | 499712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02572104 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.6      |\n",
      "|    explained_variance   | 0.0359     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 254        |\n",
      "|    n_updates            | 2430       |\n",
      "|    policy_gradient_loss | -0.000803  |\n",
      "|    reward               | 2.0070987  |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 313        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 4694        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040228635 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | 0.00759     |\n",
      "|    reward               | -0.52098346 |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 4713        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019784398 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    reward               | 0.7517957   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 300         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 4732        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017287895 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.6        |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    reward               | 3.359725    |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 4751        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016517326 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | -5.60408    |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 4770        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028288413 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | 0.82979655  |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 4789        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023337942 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -21.501318  |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7728058.70\n",
      "total_reward: 6728058.70\n",
      "total_cost: 131627.88\n",
      "total_trades: 58366\n",
      "Sharpe: 1.068\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 4808        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049464606 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.0381      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | 0.00518     |\n",
      "|    reward               | -0.14927614 |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 4827        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375556 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 4.912503    |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 4846        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026087059 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | 0.000272    |\n",
      "|    reward               | 0.24856727  |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 4865        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021141743 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 235         |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | 1.2819504   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 4884        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015447032 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | 8.52e-05    |\n",
      "|    reward               | 8.74332     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 256        |\n",
      "|    time_elapsed         | 4903       |\n",
      "|    total_timesteps      | 524288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02510043 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.9      |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 2550       |\n",
      "|    policy_gradient_loss | -0.00528   |\n",
      "|    reward               | 6.440216   |\n",
      "|    std                  | 1.45       |\n",
      "|    value_loss           | 270        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 4923        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018887026 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.8        |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.00087    |\n",
      "|    reward               | -1.6405644  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 4942        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015953587 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | 0.00224     |\n",
      "|    reward               | 2.8482354   |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 82.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 4961        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023770053 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.9        |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    reward               | -0.11489584 |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 260        |\n",
      "|    time_elapsed         | 4980       |\n",
      "|    total_timesteps      | 532480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04107596 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.1      |\n",
      "|    explained_variance   | 0.283      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 79.3       |\n",
      "|    n_updates            | 2590       |\n",
      "|    policy_gradient_loss | 0.000803   |\n",
      "|    reward               | 0.17744002 |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 251        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 4999        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036201775 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.8        |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.000881   |\n",
      "|    reward               | 9.232334    |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 5018       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04145121 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.2      |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.9       |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | 0.00366    |\n",
      "|    reward               | -2.2156405 |\n",
      "|    std                  | 1.47       |\n",
      "|    value_loss           | 37.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 5038        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018158041 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | 1.5134227   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 387         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 5058        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029878458 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | 0.0011      |\n",
      "|    reward               | -3.3765864  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7821090.27\n",
      "total_reward: 6821090.27\n",
      "total_cost: 152570.80\n",
      "total_trades: 59407\n",
      "Sharpe: 0.999\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 265        |\n",
      "|    time_elapsed         | 5079       |\n",
      "|    total_timesteps      | 542720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02852304 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.4      |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 2640       |\n",
      "|    policy_gradient_loss | -0.00156   |\n",
      "|    reward               | -3.5205193 |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 74.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 5099        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026796669 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    reward               | -0.74062866 |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 5119        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027353369 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | 0.00377     |\n",
      "|    reward               | -0.9279182  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 336         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 5140        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013883956 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    reward               | 0.88951737  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 339         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 269        |\n",
      "|    time_elapsed         | 5160       |\n",
      "|    total_timesteps      | 550912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06579571 |\n",
      "|    clip_fraction        | 0.442      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.5      |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.7       |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | 0.0159     |\n",
      "|    reward               | 0.4125414  |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 31.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 5181        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013533463 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | 1.7631108   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 5202        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019637197 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -9.61e-05   |\n",
      "|    reward               | 2.6106348   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 5222        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032374904 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | 0.00274     |\n",
      "|    reward               | 2.6471298   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 53.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 5243        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014260606 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    reward               | -1.1881281  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 5263        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015738446 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -53.117157  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 5284        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022767883 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.00972     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55          |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | 1.5626526   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 5305        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024065208 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.000671   |\n",
      "|    reward               | 3.0525117   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 5324        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018366884 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | 0.000816    |\n",
      "|    reward               | 1.0987226   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 5345        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014593454 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | -1.8827415  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7836424.01\n",
      "total_reward: 6836424.01\n",
      "total_cost: 143541.21\n",
      "total_trades: 58787\n",
      "Sharpe: 1.006\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 5365        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044652533 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | 0.00407     |\n",
      "|    reward               | 1.9254323   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 5387        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030003984 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | 0.000809    |\n",
      "|    reward               | 1.9246453   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 5407        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01616445  |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.8       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | 0.00322     |\n",
      "|    reward               | -0.89895624 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 5427        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017876452 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.5        |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | -0.17694026 |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 5446        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023393665 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | 6.15e-05    |\n",
      "|    reward               | 2.6048758   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 5465        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013361717 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.1        |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | 2.1707773   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 5484        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029865393 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | 0.00293     |\n",
      "|    reward               | 6.8096347   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 270         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 286        |\n",
      "|    time_elapsed         | 5503       |\n",
      "|    total_timesteps      | 585728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06338419 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53        |\n",
      "|    explained_variance   | 0.693      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 2850       |\n",
      "|    policy_gradient_loss | 0.00649    |\n",
      "|    reward               | 1.8941482  |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 23.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 287        |\n",
      "|    time_elapsed         | 5522       |\n",
      "|    total_timesteps      | 587776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03416517 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53        |\n",
      "|    explained_variance   | 0.352      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 288        |\n",
      "|    n_updates            | 2860       |\n",
      "|    policy_gradient_loss | -0.000479  |\n",
      "|    reward               | 1.014273   |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 278        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 5543        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019050632 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.6        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    reward               | 2.6837842   |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 5564        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014641448 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | 4.627834    |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 71.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 290        |\n",
      "|    time_elapsed         | 5584       |\n",
      "|    total_timesteps      | 593920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02122587 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.1      |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 2890       |\n",
      "|    policy_gradient_loss | -0.00599   |\n",
      "|    reward               | 1.3732616  |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 195        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 5604        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013457028 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    reward               | 0.04775638  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 5624        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030978331 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.0897      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | 0.00534     |\n",
      "|    reward               | -0.19171081 |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8256171.09\n",
      "total_reward: 7256171.09\n",
      "total_cost: 167142.88\n",
      "total_trades: 61913\n",
      "Sharpe: 1.053\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 5644        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030173603 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.75        |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    reward               | -1.1587873  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 5666        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026399888 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.2       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | 0.000989    |\n",
      "|    reward               | 0.5465867   |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 5686        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013950568 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | 2.9066968   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5706        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020177472 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.3       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    reward               | -0.71456116 |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 5727        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017567547 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | -1.2330027  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 298          |\n",
      "|    time_elapsed         | 5748         |\n",
      "|    total_timesteps      | 610304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054272115 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -53.4        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.8         |\n",
      "|    n_updates            | 2970         |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | 2.022072     |\n",
      "|    std                  | 1.53         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 5769        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029489502 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.4        |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | 0.00156     |\n",
      "|    reward               | -1.3033634  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 5788        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033691563 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | 0.00088     |\n",
      "|    reward               | 3.202408    |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 5807        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010867693 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 1.1323115   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 5827        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014136979 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    reward               | -11.592411  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 5848        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036964506 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    reward               | -4.001669   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 5869        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0205543   |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | 0.00107     |\n",
      "|    reward               | -0.12699936 |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 5889        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027393254 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | 0.0105      |\n",
      "|    reward               | -6.244639   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 5910        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024413524 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -9.19e-05   |\n",
      "|    reward               | -4.3813653  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 72.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6715685.41\n",
      "total_reward: 5715685.41\n",
      "total_cost: 118443.47\n",
      "total_trades: 58237\n",
      "Sharpe: 0.984\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 5931        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023271795 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | -1.1438416  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 75.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 5950        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016385196 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -0.66833353 |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 5969        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014017959 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    reward               | 2.5256684   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 5988        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044461377 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | 0.012001012 |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 6007        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022761552 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | 0.00166     |\n",
      "|    reward               | 0.22161624  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 6026        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015868261 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.8       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | -10.390863  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 6044        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016774291 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | -13.37986   |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 6063        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014683973 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -1.5217594  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 6082        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010597569 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62          |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    reward               | -10.126798  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 6101        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012823697 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.1        |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.06948669  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 6120        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018892262 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | -0.8990496  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 6139        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012485017 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.5        |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | 4.412848    |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 6158        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010197468 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -2.9875743  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 6177        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019796453 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | 0.36364743  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7374518.32\n",
      "total_reward: 6374518.32\n",
      "total_cost: 102390.98\n",
      "total_trades: 56357\n",
      "Sharpe: 1.025\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 6196        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022059165 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | -0.1250935  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 6216        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012714403 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.3        |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | -0.15653981 |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 6235        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012994524 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | -0.9579419  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 99.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 6254        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020830985 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 1.4687254   |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 73.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 6273        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013169659 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    reward               | 0.77673477  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 326        |\n",
      "|    time_elapsed         | 6292       |\n",
      "|    total_timesteps      | 667648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00810291 |\n",
      "|    clip_fraction        | 0.0408     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.2      |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 86.9       |\n",
      "|    n_updates            | 3250       |\n",
      "|    policy_gradient_loss | -0.00353   |\n",
      "|    reward               | 0.3776351  |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 6311        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019134937 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | 0.76679707  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 6330        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017891435 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.6        |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | 0.00484     |\n",
      "|    reward               | -0.80089504 |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 6349        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016760048 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | 0.00197     |\n",
      "|    reward               | -12.550613  |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 6368        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018609893 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | -3.692161   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 106           |\n",
      "|    iterations           | 331           |\n",
      "|    time_elapsed         | 6387          |\n",
      "|    total_timesteps      | 677888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.021259878   |\n",
      "|    clip_fraction        | 0.225         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -54.4         |\n",
      "|    explained_variance   | 0.26          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.3          |\n",
      "|    n_updates            | 3300          |\n",
      "|    policy_gradient_loss | -0.00747      |\n",
      "|    reward               | 0.00031970692 |\n",
      "|    std                  | 1.58          |\n",
      "|    value_loss           | 133           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 6406         |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01677302   |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -54.4        |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.4         |\n",
      "|    n_updates            | 3310         |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    reward               | -0.091920994 |\n",
      "|    std                  | 1.59         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 6425        |\n",
      "|    total_timesteps      | 681984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018360307 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | 2.6067984   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 6444        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021420943 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | 0.00574     |\n",
      "|    reward               | -3.0629134  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7732827.80\n",
      "total_reward: 6732827.80\n",
      "total_cost: 109040.19\n",
      "total_trades: 55634\n",
      "Sharpe: 0.979\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 6463        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020045362 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77          |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | -0.3014395  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 6481        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009003625 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    reward               | 16.583408   |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 6500        |\n",
      "|    total_timesteps      | 690176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031119607 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | 0.00629     |\n",
      "|    reward               | 5.7027      |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 338          |\n",
      "|    time_elapsed         | 6519         |\n",
      "|    total_timesteps      | 692224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010524999  |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -54.7        |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.8         |\n",
      "|    n_updates            | 3370         |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    reward               | -0.088102646 |\n",
      "|    std                  | 1.6          |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 6538        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014157408 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.5        |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 15.697166   |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 6557        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012428811 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -0.6113264  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 6576        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015094543 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | -0.4237047  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 6595        |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011137032 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | 0.6362594   |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 6614        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008687401 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.7        |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | 4.800823    |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 6633        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019844767 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.9       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | 1.8578489   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 345        |\n",
      "|    time_elapsed         | 6652       |\n",
      "|    total_timesteps      | 706560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01204768 |\n",
      "|    clip_fraction        | 0.0607     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55        |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 85.1       |\n",
      "|    n_updates            | 3440       |\n",
      "|    policy_gradient_loss | -0.0072    |\n",
      "|    reward               | 1.5266347  |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 190        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 6671        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014117112 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | 14.31425    |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 6690        |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021757016 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    reward               | 1.4190702   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 6709        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016180363 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | -1.5502391  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8148736.95\n",
      "total_reward: 7148736.95\n",
      "total_cost: 106907.53\n",
      "total_trades: 55755\n",
      "Sharpe: 0.998\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 6727        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013181647 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | 0.22783715  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 350          |\n",
      "|    time_elapsed         | 6746         |\n",
      "|    total_timesteps      | 716800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152435135 |\n",
      "|    clip_fraction        | 0.232        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55.1        |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 3490         |\n",
      "|    policy_gradient_loss | -7.25e-06    |\n",
      "|    reward               | -4.1526303   |\n",
      "|    std                  | 1.62         |\n",
      "|    value_loss           | 237          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 6765        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059477244 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | 0.00139     |\n",
      "|    reward               | 1.7762336   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 6784        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010246839 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.2        |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -1.038408   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 6803        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013773921 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.000608   |\n",
      "|    reward               | 13.592569   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 6821        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014608967 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    reward               | -6.1140285  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 89.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 6840        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014636409 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.6        |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.000952   |\n",
      "|    reward               | -4.504005   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 356          |\n",
      "|    time_elapsed         | 6859         |\n",
      "|    total_timesteps      | 729088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093716085 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -55.2        |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 3550         |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | -1.0459988   |\n",
      "|    std                  | 1.63         |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 6880        |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007854024 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.6        |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 0.6847369   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 358        |\n",
      "|    time_elapsed         | 6900       |\n",
      "|    total_timesteps      | 733184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0333578  |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.3      |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.9       |\n",
      "|    n_updates            | 3570       |\n",
      "|    policy_gradient_loss | -0.00366   |\n",
      "|    reward               | -0.2818306 |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 30.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 6921        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018664125 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | 0.00154     |\n",
      "|    reward               | -2.0017364  |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 6942        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009984449 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.5        |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | -0.1286996  |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 6962        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028213732 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.4        |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.000535   |\n",
      "|    reward               | -4.0342555  |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 362        |\n",
      "|    time_elapsed         | 6983       |\n",
      "|    total_timesteps      | 741376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01951179 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.4      |\n",
      "|    explained_variance   | 0.435      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 56         |\n",
      "|    n_updates            | 3610       |\n",
      "|    policy_gradient_loss | -0.00491   |\n",
      "|    reward               | -0.8853037 |\n",
      "|    std                  | 1.64       |\n",
      "|    value_loss           | 122        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 7002        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012287031 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | -64.69791   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7713612.53\n",
      "total_reward: 6713612.53\n",
      "total_cost: 102327.49\n",
      "total_trades: 56756\n",
      "Sharpe: 1.009\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 7022        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019745007 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | 1.65067     |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 365        |\n",
      "|    time_elapsed         | 7041       |\n",
      "|    total_timesteps      | 747520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02769045 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.5      |\n",
      "|    explained_variance   | 0.405      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.5       |\n",
      "|    n_updates            | 3640       |\n",
      "|    policy_gradient_loss | -0.00221   |\n",
      "|    reward               | 0.56406593 |\n",
      "|    std                  | 1.65       |\n",
      "|    value_loss           | 72.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 366        |\n",
      "|    time_elapsed         | 7061       |\n",
      "|    total_timesteps      | 749568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01696381 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.5      |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 91.8       |\n",
      "|    n_updates            | 3650       |\n",
      "|    policy_gradient_loss | -0.00507   |\n",
      "|    reward               | 1.3976002  |\n",
      "|    std                  | 1.65       |\n",
      "|    value_loss           | 198        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 7079        |\n",
      "|    total_timesteps      | 751616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018998913 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | 0.0034      |\n",
      "|    reward               | 1.4178752   |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 7098        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022209357 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | -0.9937964  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 7117        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012183008 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.8        |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    reward               | -0.68267924 |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 7136        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012552056 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    reward               | 0.30984876  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 7156        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033063263 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.2        |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | 0.00297     |\n",
      "|    reward               | -3.0271518  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 7176        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021263015 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | 1.0402968   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 7197        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014746712 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.8        |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | -0.7599807  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 106       |\n",
      "|    iterations           | 374       |\n",
      "|    time_elapsed         | 7218      |\n",
      "|    total_timesteps      | 765952    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0170302 |\n",
      "|    clip_fraction        | 0.27      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -55.8     |\n",
      "|    explained_variance   | 0.501     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 91.6      |\n",
      "|    n_updates            | 3730      |\n",
      "|    policy_gradient_loss | 0.00177   |\n",
      "|    reward               | 3.3332365 |\n",
      "|    std                  | 1.66      |\n",
      "|    value_loss           | 187       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 375        |\n",
      "|    time_elapsed         | 7238       |\n",
      "|    total_timesteps      | 768000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03228586 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.8      |\n",
      "|    explained_variance   | 0.426      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | 0.00585    |\n",
      "|    reward               | 1.3628991  |\n",
      "|    std                  | 1.67       |\n",
      "|    value_loss           | 44.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 376        |\n",
      "|    time_elapsed         | 7259       |\n",
      "|    total_timesteps      | 770048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01944145 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.9      |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 88.7       |\n",
      "|    n_updates            | 3750       |\n",
      "|    policy_gradient_loss | -0.00442   |\n",
      "|    reward               | 0.6149767  |\n",
      "|    std                  | 1.67       |\n",
      "|    value_loss           | 225        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 7279        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015523852 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79          |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 12.288613   |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8588598.65\n",
      "total_reward: 7588598.65\n",
      "total_cost: 110029.90\n",
      "total_trades: 57317\n",
      "Sharpe: 1.010\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 378        |\n",
      "|    time_elapsed         | 7300       |\n",
      "|    total_timesteps      | 774144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02971612 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56        |\n",
      "|    explained_variance   | 0.355      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 65.8       |\n",
      "|    n_updates            | 3770       |\n",
      "|    policy_gradient_loss | 0.00062    |\n",
      "|    reward               | -6.298914  |\n",
      "|    std                  | 1.68       |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 7319        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02296988  |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.6        |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | -0.12717561 |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 7340        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022890996 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    reward               | 0.2609455   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 7360        |\n",
      "|    total_timesteps      | 780288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012013728 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | 0.00149     |\n",
      "|    reward               | -2.0693426  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 7380        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026610516 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    reward               | 1.2877116   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 7402        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030388009 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.3        |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | 0.012       |\n",
      "|    reward               | 1.4033847   |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 384        |\n",
      "|    time_elapsed         | 7422       |\n",
      "|    total_timesteps      | 786432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01832066 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.2      |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 77.8       |\n",
      "|    n_updates            | 3830       |\n",
      "|    policy_gradient_loss | -0.00136   |\n",
      "|    reward               | 6.502474   |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 234        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 7442        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018892366 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    reward               | 1.1730381   |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 58          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 7463        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012977109 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | 2.4819689   |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 387        |\n",
      "|    time_elapsed         | 7483       |\n",
      "|    total_timesteps      | 792576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01712904 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.2      |\n",
      "|    explained_variance   | 0.544      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 66.8       |\n",
      "|    n_updates            | 3860       |\n",
      "|    policy_gradient_loss | 0.0015     |\n",
      "|    reward               | -5.5519977 |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 208        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 7503        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015143262 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.8        |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    reward               | -0.34422618 |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 7524        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024312107 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.2        |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | 0.31545526  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 7545        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021396516 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | 0.00226     |\n",
      "|    reward               | 1.7837217   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 7567        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015213099 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80          |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | 0.000625    |\n",
      "|    reward               | 4.1476655   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8532338.39\n",
      "total_reward: 7532338.39\n",
      "total_cost: 135357.94\n",
      "total_trades: 59221\n",
      "Sharpe: 1.016\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 7588        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034249783 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | 0.000257    |\n",
      "|    reward               | -2.4906726  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 7609        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015834708 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    reward               | -1.5052506  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7631        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021240158 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    reward               | 8.468816    |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 7651        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020421188 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.7        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | 0.00192     |\n",
      "|    reward               | 0.2352877   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 98.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 396        |\n",
      "|    time_elapsed         | 7669       |\n",
      "|    total_timesteps      | 811008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03172303 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.4      |\n",
      "|    explained_variance   | 0.477      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.9       |\n",
      "|    n_updates            | 3950       |\n",
      "|    policy_gradient_loss | -0.00238   |\n",
      "|    reward               | 2.5453167  |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 70.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 7688        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019187585 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    reward               | -0.45903382 |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 398        |\n",
      "|    time_elapsed         | 7707       |\n",
      "|    total_timesteps      | 815104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03804919 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.5      |\n",
      "|    explained_variance   | 0.15       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 121        |\n",
      "|    n_updates            | 3970       |\n",
      "|    policy_gradient_loss | 0.0187     |\n",
      "|    reward               | -3.479324  |\n",
      "|    std                  | 1.71       |\n",
      "|    value_loss           | 309        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 399        |\n",
      "|    time_elapsed         | 7726       |\n",
      "|    total_timesteps      | 817152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03328806 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.6      |\n",
      "|    explained_variance   | 0.516      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 3980       |\n",
      "|    policy_gradient_loss | 0.00595    |\n",
      "|    reward               | -4.819262  |\n",
      "|    std                  | 1.72       |\n",
      "|    value_loss           | 41.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 400          |\n",
      "|    time_elapsed         | 7745         |\n",
      "|    total_timesteps      | 819200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147570465 |\n",
      "|    clip_fraction        | 0.0995       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.7        |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 3990         |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    reward               | -0.12750477  |\n",
      "|    std                  | 1.72         |\n",
      "|    value_loss           | 253          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 7764        |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011028862 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | 0.3214695   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 356         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 402          |\n",
      "|    time_elapsed         | 7783         |\n",
      "|    total_timesteps      | 823296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043102214 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.7        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.1         |\n",
      "|    n_updates            | 4010         |\n",
      "|    policy_gradient_loss | -0.000751    |\n",
      "|    reward               | 5.456528     |\n",
      "|    std                  | 1.72         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 7803        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010989908 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | -0.9489914  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 7824        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018637568 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | 13.662894   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 7843        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007641177 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    reward               | 2.9566505   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 373         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9243023.20\n",
      "total_reward: 8243023.20\n",
      "total_cost: 125731.70\n",
      "total_trades: 57873\n",
      "Sharpe: 0.984\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 7864        |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026642535 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | 1.243477    |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 7884        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010253549 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | 2.7445898   |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 324         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 7904        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012102276 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | -16.96724   |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 7925       |\n",
      "|    total_timesteps      | 837632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01979979 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.9      |\n",
      "|    explained_variance   | 0.464      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.4       |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | 0.000371   |\n",
      "|    reward               | -7.602924  |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 64.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 410          |\n",
      "|    time_elapsed         | 7946         |\n",
      "|    total_timesteps      | 839680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091266325 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -56.9        |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.3         |\n",
      "|    n_updates            | 4090         |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | 1.2158095    |\n",
      "|    std                  | 1.73         |\n",
      "|    value_loss           | 259          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 7965        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013837125 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | -3.9280763  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 345         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 7985        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006195906 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.1        |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    reward               | -0.69251    |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 8004        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012338951 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    reward               | -1.2567275  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 8022        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010069104 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    reward               | -1.0695168  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 8042        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012225835 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | 0.00549     |\n",
      "|    reward               | -3.984659   |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 268         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 416        |\n",
      "|    time_elapsed         | 8061       |\n",
      "|    total_timesteps      | 851968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03411317 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57        |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.9       |\n",
      "|    n_updates            | 4150       |\n",
      "|    policy_gradient_loss | 0.00816    |\n",
      "|    reward               | 1.1661874  |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 53.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 8082         |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.023691304  |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -57          |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.4         |\n",
      "|    n_updates            | 4160         |\n",
      "|    policy_gradient_loss | 0.00101      |\n",
      "|    reward               | -0.103583746 |\n",
      "|    std                  | 1.74         |\n",
      "|    value_loss           | 239          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 8101        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008321398 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.000419   |\n",
      "|    reward               | 5.242251    |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 419        |\n",
      "|    time_elapsed         | 8120       |\n",
      "|    total_timesteps      | 858112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03392096 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.1      |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.6       |\n",
      "|    n_updates            | 4180       |\n",
      "|    policy_gradient_loss | 0.01       |\n",
      "|    reward               | 3.0373745  |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 135        |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8507053.69\n",
      "total_reward: 7507053.69\n",
      "total_cost: 98675.59\n",
      "total_trades: 55081\n",
      "Sharpe: 0.999\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 8139        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022770114 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | -0.6779442  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 8158        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013756769 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 222         |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | -0.76468474 |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 8176        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017102657 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | 2.5491037   |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 8197        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024632994 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    reward               | 2.2376518   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 8217        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011733973 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | -1.9232606  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 8237        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019422991 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.9        |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | 0.00384     |\n",
      "|    reward               | -17.082636  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 8257        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020412872 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.000282   |\n",
      "|    reward               | 0.8287863   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 8278         |\n",
      "|    total_timesteps      | 874496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127027575 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -57.5        |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.8         |\n",
      "|    n_updates            | 4260         |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | -1.1522294   |\n",
      "|    std                  | 1.77         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 428        |\n",
      "|    time_elapsed         | 8298       |\n",
      "|    total_timesteps      | 876544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01986297 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.6      |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 126        |\n",
      "|    n_updates            | 4270       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | -4.842585  |\n",
      "|    std                  | 1.77       |\n",
      "|    value_loss           | 329        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 8318        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010605181 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | 4.09e-05    |\n",
      "|    reward               | -2.9237528  |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 268         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 8337        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019807281 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | 1.8803364   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 8358        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016697278 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | 0.000812    |\n",
      "|    reward               | -0.762879   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 432          |\n",
      "|    time_elapsed         | 8378         |\n",
      "|    total_timesteps      | 884736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064570126 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -57.8        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 211          |\n",
      "|    n_updates            | 4310         |\n",
      "|    policy_gradient_loss | -0.000456    |\n",
      "|    reward               | -0.3070137   |\n",
      "|    std                  | 1.78         |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 8399        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027412433 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | 0.00176     |\n",
      "|    reward               | -4.992108   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9184871.36\n",
      "total_reward: 8184871.36\n",
      "total_cost: 97596.13\n",
      "total_trades: 54809\n",
      "Sharpe: 1.005\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 8420        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019981636 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 274         |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    reward               | 3.9141386   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 269         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 8439        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013027279 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | -3.051326   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 331         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 8458        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015816038 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.7        |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | 3.6547568   |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 8477        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021930829 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | -2.4768717  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 8496        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012072945 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | 0.690309    |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 225         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 439        |\n",
      "|    time_elapsed         | 8515       |\n",
      "|    total_timesteps      | 899072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02008265 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.1      |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 177        |\n",
      "|    n_updates            | 4380       |\n",
      "|    policy_gradient_loss | 0.00103    |\n",
      "|    reward               | 11.910947  |\n",
      "|    std                  | 1.8        |\n",
      "|    value_loss           | 261        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 8535        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029763373 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    reward               | -0.35763812 |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 441        |\n",
      "|    time_elapsed         | 8556       |\n",
      "|    total_timesteps      | 903168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01044237 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.1      |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 125        |\n",
      "|    n_updates            | 4400       |\n",
      "|    policy_gradient_loss | -0.00609   |\n",
      "|    reward               | -1.5973903 |\n",
      "|    std                  | 1.8        |\n",
      "|    value_loss           | 305        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 8577        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009521176 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -0.7569095  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 8596         |\n",
      "|    total_timesteps      | 907264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133385435 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.1        |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.3         |\n",
      "|    n_updates            | 4420         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 0.87258303   |\n",
      "|    std                  | 1.81         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 8615        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025240283 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | 0.00181     |\n",
      "|    reward               | -0.51174855 |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 8635        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013529062 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.6        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | -0.12976632 |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 8654        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010555476 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    reward               | 6.4329844   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 8672        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026448587 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | 0.00186     |\n",
      "|    reward               | -4.385198   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8442377.62\n",
      "total_reward: 7442377.62\n",
      "total_cost: 80448.32\n",
      "total_trades: 53242\n",
      "Sharpe: 0.960\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 8691        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014069591 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -0.2840659  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 8710        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007523191 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | 18.368336   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 8729        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024727752 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.000902   |\n",
      "|    reward               | -2.0364277  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 69.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 8747        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019151729 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 0.47681895  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 8766        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009341257 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.5        |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | -6.9811697  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 453        |\n",
      "|    time_elapsed         | 8785       |\n",
      "|    total_timesteps      | 927744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01702591 |\n",
      "|    clip_fraction        | 0.0572     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.5      |\n",
      "|    explained_variance   | 0.569      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 110        |\n",
      "|    n_updates            | 4520       |\n",
      "|    policy_gradient_loss | -0.00342   |\n",
      "|    reward               | -1.5624907 |\n",
      "|    std                  | 1.83       |\n",
      "|    value_loss           | 206        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 8805        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020889223 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | -1.4589279  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 59.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 455         |\n",
      "|    time_elapsed         | 8824        |\n",
      "|    total_timesteps      | 931840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016374346 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.7        |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 1.7274897   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 8844        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010506285 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.1        |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    reward               | 1.4165455   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 8865        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017749816 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | -4.144788   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 458          |\n",
      "|    time_elapsed         | 8883         |\n",
      "|    total_timesteps      | 937984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077759046 |\n",
      "|    clip_fraction        | 0.0843       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.7        |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 4570         |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | -5.1552644   |\n",
      "|    std                  | 1.84         |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 8903        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016080093 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.000202   |\n",
      "|    reward               | -6.3460693  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 8922        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012975111 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | -3.309966   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 91.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 8942        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013790004 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    reward               | -2.2992382  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 94.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7960462.34\n",
      "total_reward: 6960462.34\n",
      "total_cost: 103381.49\n",
      "total_trades: 55392\n",
      "Sharpe: 1.029\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 462          |\n",
      "|    time_elapsed         | 8963         |\n",
      "|    total_timesteps      | 946176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013753736  |\n",
      "|    clip_fraction        | 0.0966       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.8        |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.7         |\n",
      "|    n_updates            | 4610         |\n",
      "|    policy_gradient_loss | -0.000369    |\n",
      "|    reward               | 0.0068908357 |\n",
      "|    std                  | 1.85         |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 8982        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010834461 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | 16.663338   |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 9001        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018597279 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32          |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.000866   |\n",
      "|    reward               | -0.10000786 |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 55          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 465        |\n",
      "|    time_elapsed         | 9021       |\n",
      "|    total_timesteps      | 952320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01093374 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.9      |\n",
      "|    explained_variance   | 0.446      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.2       |\n",
      "|    n_updates            | 4640       |\n",
      "|    policy_gradient_loss | -0.00394   |\n",
      "|    reward               | 0.04649249 |\n",
      "|    std                  | 1.86       |\n",
      "|    value_loss           | 97         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 9040        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011181198 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.8        |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | -0.70243233 |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 9058        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026098803 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.000341   |\n",
      "|    reward               | 2.8859906   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 9077        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013487639 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -1.7326583  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 76          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 9096        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019147988 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.1        |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.000573   |\n",
      "|    reward               | -0.42605054 |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 9116        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010872985 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | -1.7037507  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 471          |\n",
      "|    time_elapsed         | 9134         |\n",
      "|    total_timesteps      | 964608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.035525292  |\n",
      "|    clip_fraction        | 0.294        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -59.2        |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 4700         |\n",
      "|    policy_gradient_loss | -0.000404    |\n",
      "|    reward               | -0.057617348 |\n",
      "|    std                  | 1.87         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 9153        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012600571 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.9        |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | -0.6765671  |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 9172        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014046156 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -1.62e-05   |\n",
      "|    reward               | -1.772293   |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 474        |\n",
      "|    time_elapsed         | 9191       |\n",
      "|    total_timesteps      | 970752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02583275 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.3      |\n",
      "|    explained_variance   | 0.602      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.5       |\n",
      "|    n_updates            | 4730       |\n",
      "|    policy_gradient_loss | -0.00366   |\n",
      "|    reward               | 3.7994292  |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 32.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 9209        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017452331 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 0.03393106  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 61.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 9228        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010508252 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | 4.71989     |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5971098.68\n",
      "total_reward: 4971098.68\n",
      "total_cost: 134450.81\n",
      "total_trades: 56684\n",
      "Sharpe: 0.986\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 9247        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010365201 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    reward               | -1.0452324  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 9266        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020503936 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 1.0544113   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 9285        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010474181 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60          |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | -2.441687   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 84.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 9305        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013953522 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | 2.0473635   |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 91          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 9324        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017364068 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | 4.1252327   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 9344        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020789238 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | -0.63249326 |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 9363        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016592044 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.9        |\n",
      "|    n_updates            | 4820        |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | -13.484719  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 484         |\n",
      "|    time_elapsed         | 9382        |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018884279 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 2.7326326   |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 9401        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019640442 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.4        |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -1.5232253  |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 9420        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014754257 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 0.84412205  |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 487        |\n",
      "|    time_elapsed         | 9439       |\n",
      "|    total_timesteps      | 997376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01811602 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60        |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 64.2       |\n",
      "|    n_updates            | 4860       |\n",
      "|    policy_gradient_loss | -0.00481   |\n",
      "|    reward               | -1.6354955 |\n",
      "|    std                  | 1.93       |\n",
      "|    value_loss           | 115        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 9458        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0278756   |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.52        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    reward               | -0.26905861 |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 9477        |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015591335 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | 0.000266    |\n",
      "|    reward               | -0.51726866 |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 9496        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016018765 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.5        |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | -6.923557   |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7364724.83\n",
      "total_reward: 6364724.83\n",
      "total_cost: 159927.08\n",
      "total_trades: 59128\n",
      "Sharpe: 1.014\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 491        |\n",
      "|    time_elapsed         | 9515       |\n",
      "|    total_timesteps      | 1005568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02131518 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.1      |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.3       |\n",
      "|    n_updates            | 4900       |\n",
      "|    policy_gradient_loss | 0.000991   |\n",
      "|    reward               | 3.2792506  |\n",
      "|    std                  | 1.94       |\n",
      "|    value_loss           | 45.4       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 9534        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020506835 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.2        |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | 3.7282708   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 9553        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016000843 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    reward               | -0.01580158 |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 494         |\n",
      "|    time_elapsed         | 9572        |\n",
      "|    total_timesteps      | 1011712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012376282 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.0299      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 1.0815628   |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 495        |\n",
      "|    time_elapsed         | 9591       |\n",
      "|    total_timesteps      | 1013760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02023475 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.2      |\n",
      "|    explained_variance   | 0.747      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 4940       |\n",
      "|    policy_gradient_loss | -0.00502   |\n",
      "|    reward               | -1.6094998 |\n",
      "|    std                  | 1.94       |\n",
      "|    value_loss           | 17.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 9610        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014984477 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | 0.00305     |\n",
      "|    reward               | 0.51982033  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 9628         |\n",
      "|    total_timesteps      | 1017856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068781646 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.3        |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.4         |\n",
      "|    n_updates            | 4960         |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | 2.8999567    |\n",
      "|    std                  | 1.95         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 9648        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017187897 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 1.9565045   |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 9666        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018123288 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.6        |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | -1.1119144  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 82.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 9685        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018507097 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | -5.281672   |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 501        |\n",
      "|    time_elapsed         | 9704       |\n",
      "|    total_timesteps      | 1026048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01796411 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.4      |\n",
      "|    explained_variance   | 0.382      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 28.3       |\n",
      "|    n_updates            | 5000       |\n",
      "|    policy_gradient_loss | -0.00423   |\n",
      "|    reward               | -2.0368962 |\n",
      "|    std                  | 1.95       |\n",
      "|    value_loss           | 82.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 9723        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017752895 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | -1.2303724  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 503         |\n",
      "|    time_elapsed         | 9742        |\n",
      "|    total_timesteps      | 1030144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016224097 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | 0.96115553  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 9761        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019314919 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.5       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.000263   |\n",
      "|    reward               | -23.175816  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7928166.21\n",
      "total_reward: 6928166.21\n",
      "total_cost: 125160.92\n",
      "total_trades: 56561\n",
      "Sharpe: 1.005\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 505        |\n",
      "|    time_elapsed         | 9780       |\n",
      "|    total_timesteps      | 1034240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0227554  |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.6      |\n",
      "|    explained_variance   | 0.631      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.3       |\n",
      "|    n_updates            | 5040       |\n",
      "|    policy_gradient_loss | 0.00303    |\n",
      "|    reward               | -0.5939108 |\n",
      "|    std                  | 1.96       |\n",
      "|    value_loss           | 38.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 9800        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015991807 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | 0.3529151   |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 9819        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010348933 |\n",
      "|    clip_fraction        | 0.0889      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.4        |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | 2.2453141   |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 9837        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019577399 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | -1.2564573  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 9856        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013298013 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | 0.4442934   |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 9876        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013132628 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.3        |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | 0.15831594  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 9895        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013525072 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.4        |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 2.08203     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 9914        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034437664 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8           |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | 0.003       |\n",
      "|    reward               | 2.7065842   |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 9933        |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009036535 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.8       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    reward               | 0.28997344  |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 514        |\n",
      "|    time_elapsed         | 9952       |\n",
      "|    total_timesteps      | 1052672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01799407 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.8      |\n",
      "|    explained_variance   | 0.596      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 69.1       |\n",
      "|    n_updates            | 5130       |\n",
      "|    policy_gradient_loss | -0.00418   |\n",
      "|    reward               | 7.286772   |\n",
      "|    std                  | 1.98       |\n",
      "|    value_loss           | 151        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 9971        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028015815 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | 0.00773     |\n",
      "|    reward               | -3.8707957  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 74.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 9990        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036855835 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.9       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.8        |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | -2.7414453  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 10009       |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020326547 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.000594   |\n",
      "|    reward               | -2.6747947  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 10028       |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020595998 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | 1.26e-05    |\n",
      "|    reward               | 0.6199492   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8288688.19\n",
      "total_reward: 7288688.19\n",
      "total_cost: 140834.16\n",
      "total_trades: 58372\n",
      "Sharpe: 1.002\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 10047       |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015773676 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -0.22823203 |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 10067       |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016977975 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | -0.9445272  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 10086       |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018009081 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | 7.0638757   |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 10105       |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014247596 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    reward               | -1.1056995  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 523        |\n",
      "|    time_elapsed         | 10124      |\n",
      "|    total_timesteps      | 1071104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01374713 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.2      |\n",
      "|    explained_variance   | 0.402      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 106        |\n",
      "|    n_updates            | 5220       |\n",
      "|    policy_gradient_loss | -0.00417   |\n",
      "|    reward               | 0.56058383 |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 199        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 10143       |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012534787 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    reward               | 0.9773927   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 10162       |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014240398 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | -1.1645948  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 10181       |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025296377 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 273         |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | 0.57150674  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 10200       |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009731906 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.33183834 |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 528         |\n",
      "|    time_elapsed         | 10219       |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016187366 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.000522   |\n",
      "|    reward               | 1.9561162   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 10238       |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022177994 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | -0.3779785  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 10257       |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018403295 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.7        |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.50316614 |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 10277       |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011825098 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | -1.8158914  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 10296       |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016801715 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    reward               | 5.630806    |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8043700.99\n",
      "total_reward: 7043700.99\n",
      "total_cost: 147234.05\n",
      "total_trades: 59476\n",
      "Sharpe: 0.953\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 533          |\n",
      "|    time_elapsed         | 10315        |\n",
      "|    total_timesteps      | 1091584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126732085 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -61.5        |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 227          |\n",
      "|    n_updates            | 5320         |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    reward               | -0.8691974   |\n",
      "|    std                  | 2.03         |\n",
      "|    value_loss           | 309          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 10333       |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013429687 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.4        |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | -0.6002836  |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 10352       |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010443313 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | 3.5225377   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 10372       |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017737245 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.7       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 0.6226893   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 10390       |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012418163 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 341         |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -0.2435865  |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 356         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 10409       |\n",
      "|    total_timesteps      | 1101824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014234447 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | -7.8148994  |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 10428       |\n",
      "|    total_timesteps      | 1103872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016454984 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | 0.92200905  |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 10447       |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013533114 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 0.74194354  |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 10466       |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018634386 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.2        |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | -16.033947  |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 542         |\n",
      "|    time_elapsed         | 10485       |\n",
      "|    total_timesteps      | 1110016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032476094 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.6        |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | 0.00309     |\n",
      "|    reward               | 6.7890143   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 10504       |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018450571 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 1.9158819   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 10523       |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015373193 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.1        |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    reward               | -1.3801625  |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 545         |\n",
      "|    time_elapsed         | 10543       |\n",
      "|    total_timesteps      | 1116160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012154883 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | 12.03947    |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 546        |\n",
      "|    time_elapsed         | 10562      |\n",
      "|    total_timesteps      | 1118208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01729637 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.2      |\n",
      "|    explained_variance   | 0.648      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.5       |\n",
      "|    n_updates            | 5450       |\n",
      "|    policy_gradient_loss | -0.00406   |\n",
      "|    reward               | 0.7203162  |\n",
      "|    std                  | 2.08       |\n",
      "|    value_loss           | 44.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7837556.49\n",
      "total_reward: 6837556.49\n",
      "total_cost: 166908.69\n",
      "total_trades: 61733\n",
      "Sharpe: 1.026\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 547        |\n",
      "|    time_elapsed         | 10582      |\n",
      "|    total_timesteps      | 1120256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01205219 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.2      |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 175        |\n",
      "|    n_updates            | 5460       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    reward               | 4.6185718  |\n",
      "|    std                  | 2.08       |\n",
      "|    value_loss           | 236        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 10601       |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011869846 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | -3.3258355  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 10620       |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014863645 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 1.8814641   |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 10639       |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013131836 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -1.2960117  |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 10658        |\n",
      "|    total_timesteps      | 1128448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015039181  |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.4        |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 5500         |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    reward               | -0.045763962 |\n",
      "|    std                  | 2.09         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 552        |\n",
      "|    time_elapsed         | 10677      |\n",
      "|    total_timesteps      | 1130496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03120593 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.4      |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90.7       |\n",
      "|    n_updates            | 5510       |\n",
      "|    policy_gradient_loss | 0.0011     |\n",
      "|    reward               | 2.768668   |\n",
      "|    std                  | 2.1        |\n",
      "|    value_loss           | 144        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 10696       |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022577498 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.31        |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -0.65989757 |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 10715       |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013413835 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 0.14321642  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 555        |\n",
      "|    time_elapsed         | 10734      |\n",
      "|    total_timesteps      | 1136640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01660969 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.6      |\n",
      "|    explained_variance   | 0.504      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 94.6       |\n",
      "|    n_updates            | 5540       |\n",
      "|    policy_gradient_loss | -0.00556   |\n",
      "|    reward               | -1.5860442 |\n",
      "|    std                  | 2.11       |\n",
      "|    value_loss           | 167        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 10753       |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012374897 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | -1.9539808  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 50          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 10771       |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01732772  |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | -0.32979333 |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 85.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 10790       |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019505007 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | -0.20986815 |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 559          |\n",
      "|    time_elapsed         | 10808        |\n",
      "|    total_timesteps      | 1144832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102009475 |\n",
      "|    clip_fraction        | 0.0997       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.7        |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 5580         |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -2.1134827   |\n",
      "|    std                  | 2.12         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 10827       |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022095535 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    reward               | 2.394913    |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7276331.95\n",
      "total_reward: 6276331.95\n",
      "total_cost: 162062.31\n",
      "total_trades: 61104\n",
      "Sharpe: 0.989\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 561        |\n",
      "|    time_elapsed         | 10846      |\n",
      "|    total_timesteps      | 1148928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01394699 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.8      |\n",
      "|    explained_variance   | 0.185      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 69.4       |\n",
      "|    n_updates            | 5600       |\n",
      "|    policy_gradient_loss | -0.00465   |\n",
      "|    reward               | 0.157725   |\n",
      "|    std                  | 2.12       |\n",
      "|    value_loss           | 135        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 10865       |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011990018 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | 0.22634864  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 563          |\n",
      "|    time_elapsed         | 10884        |\n",
      "|    total_timesteps      | 1153024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016640777  |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -62.9        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 5620         |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | -0.050435647 |\n",
      "|    std                  | 2.13         |\n",
      "|    value_loss           | 35.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 564         |\n",
      "|    time_elapsed         | 10903       |\n",
      "|    total_timesteps      | 1155072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021418896 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 0.3086693   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 84.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 10922       |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018337399 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | -27.569965  |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 566        |\n",
      "|    time_elapsed         | 10941      |\n",
      "|    total_timesteps      | 1159168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01932508 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63        |\n",
      "|    explained_variance   | 0.487      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 40.9       |\n",
      "|    n_updates            | 5650       |\n",
      "|    policy_gradient_loss | -0.00684   |\n",
      "|    reward               | -1.9923643 |\n",
      "|    std                  | 2.14       |\n",
      "|    value_loss           | 77.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 567        |\n",
      "|    time_elapsed         | 10960      |\n",
      "|    total_timesteps      | 1161216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02357685 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.1      |\n",
      "|    explained_variance   | 0.448      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 5660       |\n",
      "|    policy_gradient_loss | -0.00825   |\n",
      "|    reward               | -4.3593774 |\n",
      "|    std                  | 2.14       |\n",
      "|    value_loss           | 30.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 10979       |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023504082 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.5        |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    reward               | 0.061254036 |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 98.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 10998       |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019661576 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | -1.7676215  |\n",
      "|    std                  | 2.15        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 11017       |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026019506 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | -2.5362463  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 11036       |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019257873 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 0.26574963  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 63.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 572         |\n",
      "|    time_elapsed         | 11055       |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010739049 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.00022    |\n",
      "|    reward               | -1.90405    |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 90.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 573        |\n",
      "|    time_elapsed         | 11074      |\n",
      "|    total_timesteps      | 1173504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0214976  |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.4      |\n",
      "|    explained_variance   | 0.497      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.2       |\n",
      "|    n_updates            | 5720       |\n",
      "|    policy_gradient_loss | 0.00484    |\n",
      "|    reward               | 0.29979086 |\n",
      "|    std                  | 2.17       |\n",
      "|    value_loss           | 34         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 574        |\n",
      "|    time_elapsed         | 11093      |\n",
      "|    total_timesteps      | 1175552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01817034 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.5      |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10         |\n",
      "|    n_updates            | 5730       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | -1.1977283 |\n",
      "|    std                  | 2.18       |\n",
      "|    value_loss           | 35.6       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3961251.22\n",
      "total_reward: 2961251.22\n",
      "total_cost: 182086.63\n",
      "total_trades: 61726\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 11114       |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013604051 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | -0.5065602  |\n",
      "|    std                  | 2.18        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 576        |\n",
      "|    time_elapsed         | 11134      |\n",
      "|    total_timesteps      | 1179648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.013785   |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.6      |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20         |\n",
      "|    n_updates            | 5750       |\n",
      "|    policy_gradient_loss | -0.00877   |\n",
      "|    reward               | -2.2604446 |\n",
      "|    std                  | 2.18       |\n",
      "|    value_loss           | 60.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 11154       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014069965 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.7         |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | 0.9112852   |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 11175       |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018494543 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | 0.00179     |\n",
      "|    reward               | -1.1881038  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 579        |\n",
      "|    time_elapsed         | 11194      |\n",
      "|    total_timesteps      | 1185792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01714369 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.7      |\n",
      "|    explained_variance   | 0.272      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 5780       |\n",
      "|    policy_gradient_loss | -0.00592   |\n",
      "|    reward               | 0.407061   |\n",
      "|    std                  | 2.19       |\n",
      "|    value_loss           | 47.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 11212       |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016518544 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.0878      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 0.39482528  |\n",
      "|    std                  | 2.19        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 11232       |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014516203 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | 2.3499112   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 582          |\n",
      "|    time_elapsed         | 11277        |\n",
      "|    total_timesteps      | 1191936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014226962  |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.8        |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.5          |\n",
      "|    n_updates            | 5810         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -0.016830064 |\n",
      "|    std                  | 2.2          |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 11296       |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011063521 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -1.5838981  |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 11315       |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017734498 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.45        |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -0.32930997 |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 585          |\n",
      "|    time_elapsed         | 11334        |\n",
      "|    total_timesteps      | 1198080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134606995 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63.9        |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 5840         |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    reward               | -0.07151474  |\n",
      "|    std                  | 2.21         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 586         |\n",
      "|    time_elapsed         | 11352       |\n",
      "|    total_timesteps      | 1200128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014283053 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    reward               | -3.2906566  |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 11372       |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019302765 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | 1.8554318   |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 11391       |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020097293 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 1.6106269   |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 11410       |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014316965 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64         |\n",
      "|    explained_variance   | 0.0918      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    reward               | -3.9891903  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 62.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4124980.50\n",
      "total_reward: 3124980.50\n",
      "total_cost: 164818.94\n",
      "total_trades: 60929\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 11429       |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017103396 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.0589      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | 2.4247906   |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 591         |\n",
      "|    time_elapsed         | 11448       |\n",
      "|    total_timesteps      | 1210368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016738946 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | -1.5918826  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 592          |\n",
      "|    time_elapsed         | 11468        |\n",
      "|    total_timesteps      | 1212416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012071627  |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.1        |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 5910         |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | -0.080998026 |\n",
      "|    std                  | 2.22         |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 593          |\n",
      "|    time_elapsed         | 11487        |\n",
      "|    total_timesteps      | 1214464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110314395 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.1        |\n",
      "|    explained_variance   | 0.0834       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 5920         |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | 0.36625326   |\n",
      "|    std                  | 2.23         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 11507       |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015459135 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | -4.5431867  |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 595          |\n",
      "|    time_elapsed         | 11526        |\n",
      "|    total_timesteps      | 1218560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127181765 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.2        |\n",
      "|    explained_variance   | 0.109        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.1         |\n",
      "|    n_updates            | 5940         |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -2.8358      |\n",
      "|    std                  | 2.23         |\n",
      "|    value_loss           | 52.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 11545       |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018071879 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | 0.7430528   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 11564       |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019522786 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.038       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | -0.25150418 |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 11582       |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028107282 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 3.0292745   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 599        |\n",
      "|    time_elapsed         | 11601      |\n",
      "|    total_timesteps      | 1226752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01589021 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.4      |\n",
      "|    explained_variance   | 0.0647     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 58.8       |\n",
      "|    n_updates            | 5980       |\n",
      "|    policy_gradient_loss | -0.00816   |\n",
      "|    reward               | 1.0702854  |\n",
      "|    std                  | 2.25       |\n",
      "|    value_loss           | 99.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 11620       |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015408147 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.0889      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    reward               | 4.818236    |\n",
      "|    std                  | 2.25        |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 11639       |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017496051 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.61        |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | -1.6550169  |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 105       |\n",
      "|    iterations           | 602       |\n",
      "|    time_elapsed         | 11659     |\n",
      "|    total_timesteps      | 1232896   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.016788  |\n",
      "|    clip_fraction        | 0.159     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -64.6     |\n",
      "|    explained_variance   | 0.165     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 30.4      |\n",
      "|    n_updates            | 6010      |\n",
      "|    policy_gradient_loss | -0.00842  |\n",
      "|    reward               | 0.8779246 |\n",
      "|    std                  | 2.26      |\n",
      "|    value_loss           | 43.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 11678       |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013755914 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    reward               | -3.125209   |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5864638.64\n",
      "total_reward: 4864638.64\n",
      "total_cost: 164714.90\n",
      "total_trades: 60748\n",
      "Sharpe: 0.975\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 604          |\n",
      "|    time_elapsed         | 11697        |\n",
      "|    total_timesteps      | 1236992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123395845 |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.6        |\n",
      "|    explained_variance   | -0.0134      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 6030         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 6.9834094    |\n",
      "|    std                  | 2.26         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 11717       |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020833723 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.2966743  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 11736       |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010638747 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 1.3373013   |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 83.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 11756       |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022728223 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 0.01323419  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 79.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 11775       |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015755076 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.45        |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 2.0154822   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 11794       |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018420983 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | -1.0754529  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 95.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 610         |\n",
      "|    time_elapsed         | 11814       |\n",
      "|    total_timesteps      | 1249280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011463301 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 6090        |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 1.8026278   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 11833       |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021830894 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.21        |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 1.0832512   |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 612        |\n",
      "|    time_elapsed         | 11852      |\n",
      "|    total_timesteps      | 1253376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01506791 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.9      |\n",
      "|    explained_variance   | 0.237      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 29.5       |\n",
      "|    n_updates            | 6110       |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    reward               | 1.9876415  |\n",
      "|    std                  | 2.28       |\n",
      "|    value_loss           | 85.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 613          |\n",
      "|    time_elapsed         | 11871        |\n",
      "|    total_timesteps      | 1255424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130014755 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -64.9        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.2         |\n",
      "|    n_updates            | 6120         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 4.5782943    |\n",
      "|    std                  | 2.29         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 11890       |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021457938 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 6130        |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    reward               | 0.22774209  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 11909       |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022685183 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | 0.9613896   |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 77.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 11928       |\n",
      "|    total_timesteps      | 1261568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013797905 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | 1.0464908   |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 11947       |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016556846 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65         |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.5        |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | 5.199847    |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5794126.44\n",
      "total_reward: 4794126.44\n",
      "total_cost: 137104.57\n",
      "total_trades: 58449\n",
      "Sharpe: 0.924\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 11966       |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011798417 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.28        |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | -0.76490086 |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 619        |\n",
      "|    time_elapsed         | 11986      |\n",
      "|    total_timesteps      | 1267712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01431684 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.1      |\n",
      "|    explained_variance   | 0.293      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.2       |\n",
      "|    n_updates            | 6180       |\n",
      "|    policy_gradient_loss | -0.00785   |\n",
      "|    reward               | 0.6813286  |\n",
      "|    std                  | 2.3        |\n",
      "|    value_loss           | 83         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 12006       |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009959204 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 0.39164776  |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 621        |\n",
      "|    time_elapsed         | 12027      |\n",
      "|    total_timesteps      | 1271808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01427515 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.2      |\n",
      "|    explained_variance   | 0.271      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.4       |\n",
      "|    n_updates            | 6200       |\n",
      "|    policy_gradient_loss | -0.00277   |\n",
      "|    reward               | 2.2699976  |\n",
      "|    std                  | 2.31       |\n",
      "|    value_loss           | 42.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 12047       |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014861185 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    reward               | 0.6539482   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 70.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 12066       |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010709782 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.8797257   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 12085       |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011226093 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.6        |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | 3.724634    |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 91.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 625         |\n",
      "|    time_elapsed         | 12105       |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016583785 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -1.2796181  |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 12124       |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019324187 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | -0.22405833 |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 96.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 12143       |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009943318 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 6260        |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    reward               | -1.537011   |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 70.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 12162       |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013530626 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.4       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    reward               | 4.04143     |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 629          |\n",
      "|    time_elapsed         | 12182        |\n",
      "|    total_timesteps      | 1288192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143799735 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -65.5        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 6280         |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    reward               | -0.2429394   |\n",
      "|    std                  | 2.33         |\n",
      "|    value_loss           | 80.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 12202       |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014664285 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.1        |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | -2.1230145  |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 12221       |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013942238 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | -0.19784431 |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 85.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4580991.08\n",
      "total_reward: 3580991.08\n",
      "total_cost: 148662.21\n",
      "total_trades: 59675\n",
      "Sharpe: 0.831\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 12240       |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020517498 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.5       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.59        |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | 1.6751579   |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 12258       |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016938161 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 0.023834603 |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 12277       |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015803786 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | -6.905684   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 635         |\n",
      "|    time_elapsed         | 12296       |\n",
      "|    total_timesteps      | 1300480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015568571 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.78        |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | 5.9016685   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 12315       |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009993064 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.7       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 1.1114088   |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 12333       |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017965555 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | -3.6921008  |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 12352       |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013997515 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | 3.9197178   |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 12371       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011351531 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.058494586 |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 12390       |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011723586 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 1.2531515   |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 87.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 12409       |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008214598 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    reward               | 1.8309717   |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 71.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 642        |\n",
      "|    time_elapsed         | 12428      |\n",
      "|    total_timesteps      | 1314816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01710991 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66        |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.58       |\n",
      "|    n_updates            | 6410       |\n",
      "|    policy_gradient_loss | -0.00117   |\n",
      "|    reward               | 1.6237456  |\n",
      "|    std                  | 2.37       |\n",
      "|    value_loss           | 16.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 12448       |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014405008 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.6        |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | 0.6691925   |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 12467       |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011248878 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | 0.29169253  |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 12485       |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012477855 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    reward               | -1.2806207  |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4840903.08\n",
      "total_reward: 3840903.08\n",
      "total_cost: 119068.44\n",
      "total_trades: 56242\n",
      "Sharpe: 0.863\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 12504       |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01899337  |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    reward               | -0.21054067 |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 12523       |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009221811 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | 1.1545552   |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 12542       |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013162002 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.2       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | 2.2738123   |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 12561       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016118402 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.97        |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | -2.8843553  |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 12580       |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014147399 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | 0.4152736   |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 12598       |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013282672 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 6500        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    reward               | -1.6035995  |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 12617       |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011613864 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    reward               | 3.0162907   |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 12636       |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018331116 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.13081948  |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 12655       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013277151 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    reward               | 22.2617     |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 12675       |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011500922 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    reward               | 0.70784944  |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 12694       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015662707 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.95        |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -1.2299137  |\n",
      "|    std                  | 2.42        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 12713       |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017081277 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 0.3244289   |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 12733       |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010059692 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 0.4519519   |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 12753       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012304181 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | -5.4193435  |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3474132.83\n",
      "total_reward: 2474132.83\n",
      "total_cost: 128478.48\n",
      "total_trades: 58022\n",
      "Sharpe: 0.715\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 12772       |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016940748 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | -0.47957516 |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 12791       |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011270405 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.1458473   |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 12810       |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015713273 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.7       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    reward               | 0.5412093   |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 12829       |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014457962 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.33        |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -1.9571029  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 12848       |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014375101 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.29        |\n",
      "|    n_updates            | 6630        |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | 0.59189165  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 665          |\n",
      "|    time_elapsed         | 12867        |\n",
      "|    total_timesteps      | 1361920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074599367 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -66.8        |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 6640         |\n",
      "|    policy_gradient_loss | -0.000851    |\n",
      "|    reward               | -3.040973    |\n",
      "|    std                  | 2.45         |\n",
      "|    value_loss           | 42.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 12886       |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016700448 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.89        |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | 0.731513    |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 12905       |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017875288 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.9       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 0.45936278  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 668        |\n",
      "|    time_elapsed         | 12924      |\n",
      "|    total_timesteps      | 1368064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01273985 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67        |\n",
      "|    explained_variance   | 0.227      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.3       |\n",
      "|    n_updates            | 6670       |\n",
      "|    policy_gradient_loss | -0.00433   |\n",
      "|    reward               | -3.4802635 |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 50.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 12943       |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011857096 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67         |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    reward               | 1.3575343   |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 12962       |\n",
      "|    total_timesteps      | 1372160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021852123 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.94        |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.89960593  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 12981       |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010636204 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | -0.31655046 |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 13000       |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010550121 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.1       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | -0.72080874 |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 13019       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017660195 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.35        |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -0.8424362  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3576282.36\n",
      "total_reward: 2576282.36\n",
      "total_cost: 149036.57\n",
      "total_trades: 59163\n",
      "Sharpe: 0.750\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 13037       |\n",
      "|    total_timesteps      | 1380352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016664868 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 1.1004415   |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 13056       |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010870996 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | 3.4944756   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 13075       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014490302 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -2.0366607  |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 677        |\n",
      "|    time_elapsed         | 13094      |\n",
      "|    total_timesteps      | 1386496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01708528 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.3      |\n",
      "|    explained_variance   | 0.191      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.5       |\n",
      "|    n_updates            | 6760       |\n",
      "|    policy_gradient_loss | -0.00542   |\n",
      "|    reward               | 0.64703214 |\n",
      "|    std                  | 2.49       |\n",
      "|    value_loss           | 45.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 13113       |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012749245 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | 1.4772745   |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 13131       |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012033099 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | -1.7119253  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 13150       |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019235052 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.0801      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | -2.8568633  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 681        |\n",
      "|    time_elapsed         | 13168      |\n",
      "|    total_timesteps      | 1394688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02017767 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.4      |\n",
      "|    explained_variance   | 0.305      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.7       |\n",
      "|    n_updates            | 6800       |\n",
      "|    policy_gradient_loss | -0.0039    |\n",
      "|    reward               | 1.7048438  |\n",
      "|    std                  | 2.49       |\n",
      "|    value_loss           | 35.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 13187       |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022793276 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    reward               | 0.86763287  |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 13206       |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013629079 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | 2.6272173   |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 13225       |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015643537 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 1.0865804   |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 13243       |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017387535 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.5       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    reward               | -0.3081299  |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 686        |\n",
      "|    time_elapsed         | 13262      |\n",
      "|    total_timesteps      | 1404928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01676443 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.6      |\n",
      "|    explained_variance   | 0.205      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.4       |\n",
      "|    n_updates            | 6850       |\n",
      "|    policy_gradient_loss | -0.00509   |\n",
      "|    reward               | 0.8205507  |\n",
      "|    std                  | 2.51       |\n",
      "|    value_loss           | 28.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 13281       |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021386724 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 0.48524716  |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3048218.04\n",
      "total_reward: 2048218.04\n",
      "total_cost: 169390.97\n",
      "total_trades: 61868\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 13300       |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018193178 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    reward               | 2.4718363   |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 13319       |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014826959 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | -0.8486133  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 690        |\n",
      "|    time_elapsed         | 13337      |\n",
      "|    total_timesteps      | 1413120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01583045 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.7      |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.35       |\n",
      "|    n_updates            | 6890       |\n",
      "|    policy_gradient_loss | -0.00753   |\n",
      "|    reward               | -2.6411238 |\n",
      "|    std                  | 2.52       |\n",
      "|    value_loss           | 16.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 13356       |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018714216 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | 0.8149873   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 13375       |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014777253 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    reward               | 0.9587323   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 13394       |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018239891 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -1.39672    |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 13412       |\n",
      "|    total_timesteps      | 1421312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021525335 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.7       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    reward               | -0.35772938 |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 13431       |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014029309 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -0.0676987  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 13450       |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013083198 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | -1.1881759  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 13469       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020406796 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.49        |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    reward               | 1.4103593   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 13488       |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029127952 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    reward               | -0.1519752  |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 699         |\n",
      "|    time_elapsed         | 13507       |\n",
      "|    total_timesteps      | 1431552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013606066 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | -4.409083   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 13525       |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016491596 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | -1.3546329  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 13544       |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014392149 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -3.5837405  |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 13563       |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010959426 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -0.4047496  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5161371.51\n",
      "total_reward: 4161371.51\n",
      "total_cost: 162288.17\n",
      "total_trades: 60420\n",
      "Sharpe: 0.964\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 106       |\n",
      "|    iterations           | 703       |\n",
      "|    time_elapsed         | 13582     |\n",
      "|    total_timesteps      | 1439744   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0194957 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -68.1     |\n",
      "|    explained_variance   | 0.255     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 14.5      |\n",
      "|    n_updates            | 7020      |\n",
      "|    policy_gradient_loss | -0.00229  |\n",
      "|    reward               | 0.156766  |\n",
      "|    std                  | 2.56      |\n",
      "|    value_loss           | 32.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 13601       |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022416757 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | 0.0865      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | -3.4023125  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 13619       |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018743547 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.2       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 0.55006933  |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 706        |\n",
      "|    time_elapsed         | 13638      |\n",
      "|    total_timesteps      | 1445888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01291226 |\n",
      "|    clip_fraction        | 0.0836     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.2      |\n",
      "|    explained_variance   | 0.181      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.3       |\n",
      "|    n_updates            | 7050       |\n",
      "|    policy_gradient_loss | -0.0045    |\n",
      "|    reward               | 0.4275293  |\n",
      "|    std                  | 2.57       |\n",
      "|    value_loss           | 35.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 13658       |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020895485 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | 0.49947977  |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 708        |\n",
      "|    time_elapsed         | 13676      |\n",
      "|    total_timesteps      | 1449984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01602354 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.4      |\n",
      "|    explained_variance   | 0.162      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.14       |\n",
      "|    n_updates            | 7070       |\n",
      "|    policy_gradient_loss | -0.00917   |\n",
      "|    reward               | 0.23068456 |\n",
      "|    std                  | 2.58       |\n",
      "|    value_loss           | 25         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 13695       |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010427073 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | 1.326746    |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 13714       |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013322238 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    reward               | -0.16093303 |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 13732       |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016445719 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | -0.96785575 |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 13752        |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01411337   |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.5        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 7110         |\n",
      "|    policy_gradient_loss | -0.000652    |\n",
      "|    reward               | -0.042896688 |\n",
      "|    std                  | 2.59         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 713         |\n",
      "|    time_elapsed         | 13771       |\n",
      "|    total_timesteps      | 1460224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010805825 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.5       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    reward               | 0.47162983  |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 13790       |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021229766 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.49        |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    reward               | -0.41027004 |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 13808       |\n",
      "|    total_timesteps      | 1464320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021816848 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | 0.71054745  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 13827       |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009380482 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.7       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -2.1038895  |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3159600.70\n",
      "total_reward: 2159600.70\n",
      "total_cost: 141789.54\n",
      "total_trades: 59203\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 717          |\n",
      "|    time_elapsed         | 13846        |\n",
      "|    total_timesteps      | 1468416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014109405  |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -68.8        |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.45         |\n",
      "|    n_updates            | 7160         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    reward               | -0.030411039 |\n",
      "|    std                  | 2.61         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 13865       |\n",
      "|    total_timesteps      | 1470464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020243583 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.52        |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | -0.77782    |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 13883       |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016658759 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    reward               | 11.773779   |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 13902       |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010840635 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | -2.11581    |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 64.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 13921       |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014220096 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.64        |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | -0.19425243 |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 13940       |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016405338 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | -1.5214196  |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 723         |\n",
      "|    time_elapsed         | 13958       |\n",
      "|    total_timesteps      | 1480704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015120469 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | 2.3858056   |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 13978       |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015069042 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.48        |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    reward               | 3.3999274   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 725        |\n",
      "|    time_elapsed         | 13997      |\n",
      "|    total_timesteps      | 1484800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01662801 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.1      |\n",
      "|    explained_variance   | 0.116      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27.7       |\n",
      "|    n_updates            | 7240       |\n",
      "|    policy_gradient_loss | -0.00862   |\n",
      "|    reward               | 1.2067779  |\n",
      "|    std                  | 2.65       |\n",
      "|    value_loss           | 34.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 14016       |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011494838 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 7250        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | 0.84520763  |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 14034       |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016405862 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.34        |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    reward               | 2.1691043   |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 728        |\n",
      "|    time_elapsed         | 14053      |\n",
      "|    total_timesteps      | 1490944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01639245 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.3      |\n",
      "|    explained_variance   | 0.321      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 7270       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    reward               | 0.3892318  |\n",
      "|    std                  | 2.66       |\n",
      "|    value_loss           | 30.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 14072       |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016986482 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -1.1174177  |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 14091       |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013205616 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.063       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    reward               | 5.7945776   |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4213532.55\n",
      "total_reward: 3213532.55\n",
      "total_cost: 206530.71\n",
      "total_trades: 63384\n",
      "Sharpe: 0.794\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 14109       |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032946616 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | 0.00085     |\n",
      "|    reward               | -0.35502425 |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 14128       |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014252037 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.4       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | 0.41639286  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 81.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 733         |\n",
      "|    time_elapsed         | 14148       |\n",
      "|    total_timesteps      | 1501184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014040841 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 2.282724    |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 74.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 14166       |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015559992 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -5.150109   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 14185       |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016207188 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -0.33787438 |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 84.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 14205       |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013311397 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.000432   |\n",
      "|    reward               | -0.34671175 |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 14226       |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017765295 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.0797      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.5        |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | 2.795219    |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 14246       |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020819813 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.86        |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | -0.6626302  |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 14266       |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018530075 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | 0.30525982  |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 83.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 740        |\n",
      "|    time_elapsed         | 14284      |\n",
      "|    total_timesteps      | 1515520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01372109 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.8      |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.2       |\n",
      "|    n_updates            | 7390       |\n",
      "|    policy_gradient_loss | -0.00721   |\n",
      "|    reward               | 2.9475951  |\n",
      "|    std                  | 2.71       |\n",
      "|    value_loss           | 82.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 14303       |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010555643 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.8       |\n",
      "|    explained_variance   | 0.000866    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | -0.38677815 |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 14322       |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017977152 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.15        |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | 0.98888814  |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 34.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 14340       |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011801977 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.5        |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | -8.458304   |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 14359       |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016513925 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.0548      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | -0.351035   |\n",
      "|    std                  | 2.73        |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6054043.25\n",
      "total_reward: 5054043.25\n",
      "total_cost: 209882.98\n",
      "total_trades: 63442\n",
      "Sharpe: 0.961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 14378       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023119062 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.24        |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 0.5687162   |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 14397       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015853008 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.2       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.6        |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | -0.4989697  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 14415       |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011992764 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -2.4792094  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 83.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 14434       |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018243073 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    reward               | -1.024858   |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 14453       |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017890146 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | -3.524976   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 14472       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010587141 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 2.8348532   |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 85.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 14491       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012072332 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | 0.0362      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | 0.014440912 |\n",
      "|    std                  | 2.77        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 752          |\n",
      "|    time_elapsed         | 14510        |\n",
      "|    total_timesteps      | 1540096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015757073  |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.5        |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.3         |\n",
      "|    n_updates            | 7510         |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    reward               | -0.077057734 |\n",
      "|    std                  | 2.78         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 753        |\n",
      "|    time_elapsed         | 14528      |\n",
      "|    total_timesteps      | 1542144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01887427 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.5      |\n",
      "|    explained_variance   | 0.118      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 48         |\n",
      "|    n_updates            | 7520       |\n",
      "|    policy_gradient_loss | -0.00911   |\n",
      "|    reward               | 0.31277952 |\n",
      "|    std                  | 2.78       |\n",
      "|    value_loss           | 125        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 14547       |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00998522  |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    reward               | 0.120924935 |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 755        |\n",
      "|    time_elapsed         | 14566      |\n",
      "|    total_timesteps      | 1546240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02243843 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.6      |\n",
      "|    explained_variance   | 0.219      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.7        |\n",
      "|    n_updates            | 7540       |\n",
      "|    policy_gradient_loss | -0.00687   |\n",
      "|    reward               | 0.65548456 |\n",
      "|    std                  | 2.79       |\n",
      "|    value_loss           | 18.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 14585       |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015552671 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.6       |\n",
      "|    explained_variance   | 0.0687      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    reward               | -0.81745976 |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 77          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 14604       |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013508368 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 0.7985791   |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 68.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 14623       |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033878595 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | 1.407711    |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6269518.27\n",
      "total_reward: 5269518.27\n",
      "total_cost: 250873.35\n",
      "total_trades: 66385\n",
      "Sharpe: 1.029\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 14641       |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020702146 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.8       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 0.65124816  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 760          |\n",
      "|    time_elapsed         | 14660        |\n",
      "|    total_timesteps      | 1556480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.020345293  |\n",
      "|    clip_fraction        | 0.207        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.9        |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.7         |\n",
      "|    n_updates            | 7590         |\n",
      "|    policy_gradient_loss | -0.00984     |\n",
      "|    reward               | -0.015276932 |\n",
      "|    std                  | 2.81         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 14679       |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013450719 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | -2.5767417  |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 64.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 14699       |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019674588 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.25        |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    reward               | 4.252507    |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 14719       |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009487101 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | -2.308903   |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 55.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 14738       |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016436089 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.9        |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | -0.1854971  |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 14758       |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013807193 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    reward               | -1.0745744  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 14776       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015910886 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | -0.17922519 |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 767        |\n",
      "|    time_elapsed         | 14795      |\n",
      "|    total_timesteps      | 1570816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01683131 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71        |\n",
      "|    explained_variance   | 0.367      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 7660       |\n",
      "|    policy_gradient_loss | -0.00705   |\n",
      "|    reward               | 21.748865  |\n",
      "|    std                  | 2.83       |\n",
      "|    value_loss           | 48         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 14814       |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016148748 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | -2.0702724  |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 14833       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019260556 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.62379795 |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 14852       |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012235396 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.0473775   |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 14871       |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015274761 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -1.208005   |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 14890       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021318726 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9           |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.3370662  |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4886176.57\n",
      "total_reward: 3886176.57\n",
      "total_cost: 269172.00\n",
      "total_trades: 67051\n",
      "Sharpe: 0.911\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 14909       |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016663503 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.48038647 |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 774          |\n",
      "|    time_elapsed         | 14927        |\n",
      "|    total_timesteps      | 1585152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106232865 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -71.2        |\n",
      "|    explained_variance   | 0.319        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 7730         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | 5.2152643    |\n",
      "|    std                  | 2.84         |\n",
      "|    value_loss           | 78.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 14946       |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015795283 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.0918      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | -1.5906545  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 14966       |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018590387 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -1.9645777  |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 777         |\n",
      "|    time_elapsed         | 14987       |\n",
      "|    total_timesteps      | 1591296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011068339 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.3       |\n",
      "|    explained_variance   | 0.0583      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | 0.89054656  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 95.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 15007       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009360586 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.2        |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | 0.92988837  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 95.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 15028       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023105748 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.84        |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | -1.123982   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 15049       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016489947 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.5       |\n",
      "|    explained_variance   | 0.0449      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | 0.86027443  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 15069       |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018750649 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.6       |\n",
      "|    explained_variance   | 0.038       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -3.0181031  |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 782         |\n",
      "|    time_elapsed         | 15089       |\n",
      "|    total_timesteps      | 1601536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017818352 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -2.1682663  |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 15108       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012287778 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | 0.3596184   |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 784        |\n",
      "|    time_elapsed         | 15127      |\n",
      "|    total_timesteps      | 1605632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0162834  |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.7      |\n",
      "|    explained_variance   | 0.0775     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 62.5       |\n",
      "|    n_updates            | 7830       |\n",
      "|    policy_gradient_loss | -0.00791   |\n",
      "|    reward               | 0.75303054 |\n",
      "|    std                  | 2.89       |\n",
      "|    value_loss           | 87.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 15145       |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017554365 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    reward               | 1.3657267   |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 84.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 15164       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018549751 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 1.2117125   |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3733526.60\n",
      "total_reward: 2733526.60\n",
      "total_cost: 211943.51\n",
      "total_trades: 64896\n",
      "Sharpe: 0.774\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 787         |\n",
      "|    time_elapsed         | 15183       |\n",
      "|    total_timesteps      | 1611776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016104007 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -1.3243876  |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 15202       |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020622652 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    reward               | 2.3931112   |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 73.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 15220       |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024978608 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.3715105  |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 15239       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016878314 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | 2.6394615   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 61.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 15258       |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018949337 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72         |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | 1.3187153   |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 792         |\n",
      "|    time_elapsed         | 15277       |\n",
      "|    total_timesteps      | 1622016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010228943 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | 3.7222176   |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 15295       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015882585 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.68597394 |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 15314       |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012121322 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    reward               | -0.17884555 |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 50.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 15333       |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015176833 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -0.07949831 |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 74.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 796         |\n",
      "|    time_elapsed         | 15352       |\n",
      "|    total_timesteps      | 1630208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013938338 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 0.36858565  |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 15371       |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020413782 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -0.25437716 |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 15389       |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018242128 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | 0.691697    |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 68.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 15408       |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017746866 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | 0.0606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | -0.07350003 |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 15427       |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023576818 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.6       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | -0.41051877 |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4638570.92\n",
      "total_reward: 3638570.92\n",
      "total_cost: 229924.39\n",
      "total_trades: 65276\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 15446       |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014571081 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -2.1772623  |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 56.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 802        |\n",
      "|    time_elapsed         | 15464      |\n",
      "|    total_timesteps      | 1642496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01528164 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.7      |\n",
      "|    explained_variance   | 0.0386     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.4       |\n",
      "|    n_updates            | 8010       |\n",
      "|    policy_gradient_loss | -0.0079    |\n",
      "|    reward               | -2.292291  |\n",
      "|    std                  | 2.99       |\n",
      "|    value_loss           | 118        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 15483       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023818402 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.08        |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    reward               | 0.7729472   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 15502       |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013700934 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.0736      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.5944214   |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 85.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 15521       |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013084017 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.8       |\n",
      "|    explained_variance   | 0.0128      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | 1.7924542   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 96.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 15541       |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011302946 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | 6.60615     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 55.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 15559       |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015375659 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.9       |\n",
      "|    explained_variance   | 0.08        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | 1.3519601   |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 15578       |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010933157 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.0911      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 2.8908331   |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 809         |\n",
      "|    time_elapsed         | 15596       |\n",
      "|    total_timesteps      | 1656832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017933527 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    reward               | 3.9731967   |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 15615       |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020631716 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | 2.2296138   |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 15634       |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013834546 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | -0.19175304 |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 15652       |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013079004 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.0643      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.7        |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | 2.4725902   |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 99.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 15671       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014785357 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.2       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.67        |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    reward               | 0.82237244  |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 15690       |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013638204 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 2.7273753   |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 15709       |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018960861 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | -1.0371934  |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4048302.78\n",
      "total_reward: 3048302.78\n",
      "total_cost: 156241.91\n",
      "total_trades: 60900\n",
      "Sharpe: 0.774\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 816         |\n",
      "|    time_elapsed         | 15728       |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014212195 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    reward               | -2.3701804  |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 817          |\n",
      "|    time_elapsed         | 15747        |\n",
      "|    total_timesteps      | 1673216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016927144  |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.4        |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 8160         |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | -0.028727353 |\n",
      "|    std                  | 3.07         |\n",
      "|    value_loss           | 57.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 818          |\n",
      "|    time_elapsed         | 15766        |\n",
      "|    total_timesteps      | 1675264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059214444 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.4        |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 8170         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    reward               | 0.6595772    |\n",
      "|    std                  | 3.07         |\n",
      "|    value_loss           | 87.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 15784       |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010685631 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | 1.3243316   |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 90.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 15803       |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018738994 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 8190        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 2.120426    |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 821        |\n",
      "|    time_elapsed         | 15822      |\n",
      "|    total_timesteps      | 1681408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01789082 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.4      |\n",
      "|    explained_variance   | 0.172      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38         |\n",
      "|    n_updates            | 8200       |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    reward               | 0.17933789 |\n",
      "|    std                  | 3.08       |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 15841       |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014391126 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.5        |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 4.0917935   |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 77.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 15860       |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016944572 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | 0.0901      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 8220        |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    reward               | 0.40514934  |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 824        |\n",
      "|    time_elapsed         | 15879      |\n",
      "|    total_timesteps      | 1687552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01497535 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.7      |\n",
      "|    explained_variance   | 0.126      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 47.1       |\n",
      "|    n_updates            | 8230       |\n",
      "|    policy_gradient_loss | -0.00537   |\n",
      "|    reward               | -0.4497273 |\n",
      "|    std                  | 3.1        |\n",
      "|    value_loss           | 104        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 15898       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011223339 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.2        |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -1.8325973  |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 826          |\n",
      "|    time_elapsed         | 15916        |\n",
      "|    total_timesteps      | 1691648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096527655 |\n",
      "|    clip_fraction        | 0.0969       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -73.8        |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 8250         |\n",
      "|    policy_gradient_loss | -0.00853     |\n",
      "|    reward               | 2.1840389    |\n",
      "|    std                  | 3.11         |\n",
      "|    value_loss           | 71           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 827        |\n",
      "|    time_elapsed         | 15935      |\n",
      "|    total_timesteps      | 1693696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01209623 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.8      |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.47       |\n",
      "|    n_updates            | 8260       |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | 4.6100745  |\n",
      "|    std                  | 3.12       |\n",
      "|    value_loss           | 19.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 15954       |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015986536 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.6        |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | 0.37025386  |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 15974       |\n",
      "|    total_timesteps      | 1697792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011570282 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.0957      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    reward               | 8.227648    |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5470944.31\n",
      "total_reward: 4470944.31\n",
      "total_cost: 190829.57\n",
      "total_trades: 61827\n",
      "Sharpe: 0.891\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 15993       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014342947 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.0521      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | -1.9850553  |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 831        |\n",
      "|    time_elapsed         | 16011      |\n",
      "|    total_timesteps      | 1701888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01145193 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.1      |\n",
      "|    explained_variance   | 0.062      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 73.4       |\n",
      "|    n_updates            | 8300       |\n",
      "|    policy_gradient_loss | -0.00888   |\n",
      "|    reward               | 1.9300535  |\n",
      "|    std                  | 3.15       |\n",
      "|    value_loss           | 146        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 832        |\n",
      "|    time_elapsed         | 16030      |\n",
      "|    total_timesteps      | 1703936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01208608 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.1      |\n",
      "|    explained_variance   | 0.184      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.7       |\n",
      "|    n_updates            | 8310       |\n",
      "|    policy_gradient_loss | -0.00883   |\n",
      "|    reward               | -4.0730004 |\n",
      "|    std                  | 3.15       |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 833         |\n",
      "|    time_elapsed         | 16049       |\n",
      "|    total_timesteps      | 1705984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011515387 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.6        |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | 0.37992018  |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 834        |\n",
      "|    time_elapsed         | 16068      |\n",
      "|    total_timesteps      | 1708032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01592832 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.2      |\n",
      "|    explained_variance   | 0.272      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.7       |\n",
      "|    n_updates            | 8330       |\n",
      "|    policy_gradient_loss | -0.00747   |\n",
      "|    reward               | -4.01765   |\n",
      "|    std                  | 3.16       |\n",
      "|    value_loss           | 27.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 835         |\n",
      "|    time_elapsed         | 16087       |\n",
      "|    total_timesteps      | 1710080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011320152 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.0687      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | 0.6068244   |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 16105       |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015907299 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.3       |\n",
      "|    explained_variance   | 0.0355      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.3        |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.2171165  |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 16124       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016659092 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.0436      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 5.54299     |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 16143       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009679755 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | 0.00458     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 3.4748292   |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 839          |\n",
      "|    time_elapsed         | 16163        |\n",
      "|    total_timesteps      | 1718272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122222435 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.5        |\n",
      "|    explained_variance   | 0.0134       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 8380         |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    reward               | 0.6786427    |\n",
      "|    std                  | 3.19         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 16182       |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012824602 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 2.32e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | 0.7263535   |\n",
      "|    std                  | 3.19        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 16201       |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014593728 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.0321      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.64859384 |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 16220       |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019222917 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.6       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | -2.5170732  |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 843          |\n",
      "|    time_elapsed         | 16240        |\n",
      "|    total_timesteps      | 1726464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011448339  |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -74.7        |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.2         |\n",
      "|    n_updates            | 8420         |\n",
      "|    policy_gradient_loss | -0.0081      |\n",
      "|    reward               | -0.115835786 |\n",
      "|    std                  | 3.21         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5033732.78\n",
      "total_reward: 4033732.78\n",
      "total_cost: 188960.64\n",
      "total_trades: 62266\n",
      "Sharpe: 0.832\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 16260       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016193368 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.0826      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 2.8415334   |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 16280       |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015040318 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    reward               | -1.0788685  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 846        |\n",
      "|    time_elapsed         | 16299      |\n",
      "|    total_timesteps      | 1732608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01502374 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.8      |\n",
      "|    explained_variance   | 0.00679    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.5       |\n",
      "|    n_updates            | 8450       |\n",
      "|    policy_gradient_loss | -0.00597   |\n",
      "|    reward               | 1.0241444  |\n",
      "|    std                  | 3.23       |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 16317       |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016832508 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | -0.0771     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | 1.2818193   |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 106       |\n",
      "|    iterations           | 848       |\n",
      "|    time_elapsed         | 16336     |\n",
      "|    total_timesteps      | 1736704   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0191185 |\n",
      "|    clip_fraction        | 0.204     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -75       |\n",
      "|    explained_variance   | 0.0425    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 31.5      |\n",
      "|    n_updates            | 8470      |\n",
      "|    policy_gradient_loss | -0.00937  |\n",
      "|    reward               | 1.7868326 |\n",
      "|    std                  | 3.24      |\n",
      "|    value_loss           | 124       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 849          |\n",
      "|    time_elapsed         | 16355        |\n",
      "|    total_timesteps      | 1738752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109974295 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75          |\n",
      "|    explained_variance   | 0.0541       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.3         |\n",
      "|    n_updates            | 8480         |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    reward               | -1.3875982   |\n",
      "|    std                  | 3.25         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 850         |\n",
      "|    time_elapsed         | 16374       |\n",
      "|    total_timesteps      | 1740800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011039906 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.00185     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.3        |\n",
      "|    n_updates            | 8490        |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | -7.5943265  |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 16392       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021751296 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.66        |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 0.084403895 |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 16412       |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010239742 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.0171      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.3        |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    reward               | -1.751159   |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 853          |\n",
      "|    time_elapsed         | 16431        |\n",
      "|    total_timesteps      | 1746944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133400615 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -75.2        |\n",
      "|    explained_variance   | 0.044        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 8520         |\n",
      "|    policy_gradient_loss | -0.00803     |\n",
      "|    reward               | 1.9247472    |\n",
      "|    std                  | 3.27         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 16450       |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013861852 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.51        |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | 1.0047574   |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 16470       |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013766142 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.0379      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    reward               | 0.93385905  |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 16491       |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010359004 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | -12.378878  |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 16510       |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012017901 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.0972      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    reward               | 4.2112727   |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3246099.69\n",
      "total_reward: 2246099.69\n",
      "total_cost: 169196.37\n",
      "total_trades: 61534\n",
      "Sharpe: 0.631\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 16528       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015607802 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.099       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.51        |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 3.006833    |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 16547       |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123659 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    reward               | -0.45225924 |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 860         |\n",
      "|    time_elapsed         | 16566       |\n",
      "|    total_timesteps      | 1761280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010588864 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 8590        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 3.0646527   |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 16585       |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017772129 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | -0.00257    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | 0.2685248   |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 862        |\n",
      "|    time_elapsed         | 16603      |\n",
      "|    total_timesteps      | 1765376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0146289  |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -75.7      |\n",
      "|    explained_variance   | 0.0307     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54.9       |\n",
      "|    n_updates            | 8610       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    reward               | -2.0304942 |\n",
      "|    std                  | 3.32       |\n",
      "|    value_loss           | 80.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 16622       |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013295496 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    reward               | 1.8706824   |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 66.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 864         |\n",
      "|    time_elapsed         | 16641       |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013507491 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | -0.116      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 8630        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -0.6161881  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 16660       |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010483714 |\n",
      "|    clip_fraction        | 0.0684      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.0851      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    reward               | -1.8360033  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 16678       |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011774567 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.8       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | 0.58511925  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 59.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 867         |\n",
      "|    time_elapsed         | 16697       |\n",
      "|    total_timesteps      | 1775616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009768933 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 8660        |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | -1.2299504  |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 16716       |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012289854 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | -0.095      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.34        |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -0.48828718 |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 16735       |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012452882 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.0297      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    reward               | 0.846017    |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 870         |\n",
      "|    time_elapsed         | 16753       |\n",
      "|    total_timesteps      | 1781760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012291687 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.00076     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 8690        |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 1.6931653   |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 16772       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011835964 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76         |\n",
      "|    explained_variance   | 0.0555      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | 2.1238432   |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3595498.00\n",
      "total_reward: 2595498.00\n",
      "total_cost: 155376.23\n",
      "total_trades: 61192\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 16791       |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012230447 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | -0.00158    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.5        |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | 1.869719    |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 16810       |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013881244 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 8720        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | -0.9173497  |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 874          |\n",
      "|    time_elapsed         | 16829        |\n",
      "|    total_timesteps      | 1789952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133928275 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.1        |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.5         |\n",
      "|    n_updates            | 8730         |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    reward               | -1.9851134   |\n",
      "|    std                  | 3.37         |\n",
      "|    value_loss           | 78           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 16847       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016486052 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.0249      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | -0.14242038 |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 16866       |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009745695 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | 1.5870547   |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 877          |\n",
      "|    time_elapsed         | 16885        |\n",
      "|    total_timesteps      | 1796096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012646731  |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.3        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 8760         |\n",
      "|    policy_gradient_loss | -0.00775     |\n",
      "|    reward               | -0.055647824 |\n",
      "|    std                  | 3.39         |\n",
      "|    value_loss           | 74.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 16904       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013972431 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.5569472  |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 879         |\n",
      "|    time_elapsed         | 16923       |\n",
      "|    total_timesteps      | 1800192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007590642 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 1.4118536   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 97.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 16943       |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011617458 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 2.156664    |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 16962       |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015627952 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | -2.1598318  |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 882        |\n",
      "|    time_elapsed         | 16980      |\n",
      "|    total_timesteps      | 1806336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01696075 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.3      |\n",
      "|    explained_variance   | 0.303      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.2       |\n",
      "|    n_updates            | 8810       |\n",
      "|    policy_gradient_loss | -0.00768   |\n",
      "|    reward               | 0.23544759 |\n",
      "|    std                  | 3.4        |\n",
      "|    value_loss           | 56         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 883          |\n",
      "|    time_elapsed         | 16999        |\n",
      "|    total_timesteps      | 1808384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116221495 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -76.4        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.6         |\n",
      "|    n_updates            | 8820         |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    reward               | 0.6744826    |\n",
      "|    std                  | 3.4          |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 884         |\n",
      "|    time_elapsed         | 17018       |\n",
      "|    total_timesteps      | 1810432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013711898 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | 4.45202     |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 17037       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011769779 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.0877      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | 2.9099002   |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3895550.71\n",
      "total_reward: 2895550.71\n",
      "total_cost: 242288.93\n",
      "total_trades: 65283\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 17056       |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014979557 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.4       |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | -2.2559524  |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 17075       |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026709113 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | -0.00859    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | 0.00154     |\n",
      "|    reward               | 5.4592276   |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 17095       |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014722765 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 1.3329674   |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 54.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 889         |\n",
      "|    time_elapsed         | 17114       |\n",
      "|    total_timesteps      | 1820672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016233746 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.4        |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.32135257 |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 86.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 17133       |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010272735 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.6        |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -0.6362191  |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 17152       |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012161322 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 8900        |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -0.52259415 |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 892        |\n",
      "|    time_elapsed         | 17171      |\n",
      "|    total_timesteps      | 1826816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01922039 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.7      |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14         |\n",
      "|    n_updates            | 8910       |\n",
      "|    policy_gradient_loss | -0.00734   |\n",
      "|    reward               | 1.1941044  |\n",
      "|    std                  | 3.45       |\n",
      "|    value_loss           | 25.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 17191       |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017598242 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.0272      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.1        |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | -1.62e-05   |\n",
      "|    reward               | 0.8005618   |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 894         |\n",
      "|    time_elapsed         | 17210       |\n",
      "|    total_timesteps      | 1830912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010531274 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -1.1896875  |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 17229       |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017391903 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.0322      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -2.8450506  |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 896         |\n",
      "|    time_elapsed         | 17248       |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013169039 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 8950        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | -0.7351112  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 17267       |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017900301 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.0252      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.4        |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    reward               | -10.915459  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 17286       |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014892474 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.0334      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | 0.7885261   |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 899        |\n",
      "|    time_elapsed         | 17305      |\n",
      "|    total_timesteps      | 1841152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01786961 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.1      |\n",
      "|    explained_variance   | 0.0369     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.23       |\n",
      "|    n_updates            | 8980       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | -2.20702   |\n",
      "|    std                  | 3.49       |\n",
      "|    value_loss           | 19.7       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3730074.57\n",
      "total_reward: 2730074.57\n",
      "total_cost: 163701.63\n",
      "total_trades: 60302\n",
      "Sharpe: 0.644\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 17324       |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012427106 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.00946    |\n",
      "|    reward               | 1.4855558   |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 97.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 17342       |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015155192 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.5        |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.00098    |\n",
      "|    reward               | -0.22304292 |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 17361       |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011747628 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | -0.0518     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | -1.2508765  |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 17380       |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015973605 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.4        |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | -1.4176619  |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 84.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 904          |\n",
      "|    time_elapsed         | 17399        |\n",
      "|    total_timesteps      | 1851392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052571204 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.2        |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.7         |\n",
      "|    n_updates            | 9030         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 0.15490784   |\n",
      "|    std                  | 3.51         |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 17418       |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014988339 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.0972      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    reward               | -0.34284407 |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 17437       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011824076 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.1        |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.25057542  |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 17456       |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011430644 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.3        |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    reward               | 1.4934297   |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 908          |\n",
      "|    time_elapsed         | 17474        |\n",
      "|    total_timesteps      | 1859584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135975685 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -77.4        |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 9070         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | 4.6811395    |\n",
      "|    std                  | 3.53         |\n",
      "|    value_loss           | 86.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 909         |\n",
      "|    time_elapsed         | 17493       |\n",
      "|    total_timesteps      | 1861632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018264007 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | -0.00952    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 9080        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    reward               | -1.8910372  |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 17512       |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013763767 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 9090        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -0.251673   |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 89          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 17531       |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014615319 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.6       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -3.051021   |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 17550       |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018136844 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | -0.0302     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | 1.7996922   |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 17568       |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012691855 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | 0.9493549   |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3760020.64\n",
      "total_reward: 2760020.64\n",
      "total_cost: 167564.85\n",
      "total_trades: 60073\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 914         |\n",
      "|    time_elapsed         | 17587       |\n",
      "|    total_timesteps      | 1871872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011437559 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 9130        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | 0.5891167   |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 66.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 17606       |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020410797 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | -0.54378504 |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 17626       |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014074308 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.9       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    reward               | -1.7345798  |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 917         |\n",
      "|    time_elapsed         | 17645       |\n",
      "|    total_timesteps      | 1878016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012377526 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.5        |\n",
      "|    n_updates            | 9160        |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | 0.71667475  |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 918         |\n",
      "|    time_elapsed         | 17664       |\n",
      "|    total_timesteps      | 1880064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022410095 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 9170        |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 0.38992032  |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 17683       |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012855085 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.1       |\n",
      "|    explained_variance   | 0.0029      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    reward               | -0.56780076 |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 17702       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015523582 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.3        |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.43354556  |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 921         |\n",
      "|    time_elapsed         | 17720       |\n",
      "|    total_timesteps      | 1886208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012172513 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.5        |\n",
      "|    n_updates            | 9200        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -3.9121442  |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 96.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 17739       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013680691 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | 1.1317854   |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 56.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 923         |\n",
      "|    time_elapsed         | 17759       |\n",
      "|    total_timesteps      | 1890304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016524533 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.0404      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | 3.4128418   |\n",
      "|    std                  | 3.64        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 17779       |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016050003 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 9230        |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | -2.6824412  |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 17800       |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012903906 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.0282      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    reward               | 0.25707507  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 17820       |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016747471 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.0681      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    reward               | 1.9361115   |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 927        |\n",
      "|    time_elapsed         | 17838      |\n",
      "|    total_timesteps      | 1898496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01602896 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.5      |\n",
      "|    explained_variance   | 0.098      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.2       |\n",
      "|    n_updates            | 9260       |\n",
      "|    policy_gradient_loss | -0.00677   |\n",
      "|    reward               | 2.9817417  |\n",
      "|    std                  | 3.67       |\n",
      "|    value_loss           | 70.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 928         |\n",
      "|    time_elapsed         | 17858       |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017511304 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.5       |\n",
      "|    explained_variance   | 0.0521      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 0.61225486  |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 84          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3808403.53\n",
      "total_reward: 2808403.53\n",
      "total_cost: 183360.56\n",
      "total_trades: 61211\n",
      "Sharpe: 0.717\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 17878       |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013220932 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.6       |\n",
      "|    explained_variance   | 0.0832      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 4.7105713   |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 17898       |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011500012 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.00335     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 0.7794099   |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 931         |\n",
      "|    time_elapsed         | 17917       |\n",
      "|    total_timesteps      | 1906688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00911124  |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -0.69079363 |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 76.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 932         |\n",
      "|    time_elapsed         | 17936       |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016083963 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.3        |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    reward               | -0.53237873 |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 91          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 933         |\n",
      "|    time_elapsed         | 17955       |\n",
      "|    total_timesteps      | 1910784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019236945 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.7       |\n",
      "|    explained_variance   | 0.0542      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    reward               | -3.685356   |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 17974       |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020479336 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.7377154   |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 72.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 17993       |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014628994 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 9340        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | 2.802149    |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 98.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 18011       |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013261361 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.0795      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -5.7407746  |\n",
      "|    std                  | 3.7         |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 18030       |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015234125 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.8       |\n",
      "|    explained_variance   | 0.0556      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | -0.48389527 |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 94.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 938         |\n",
      "|    time_elapsed         | 18049       |\n",
      "|    total_timesteps      | 1921024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011171281 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.9       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | -0.18442611 |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 939          |\n",
      "|    time_elapsed         | 18068        |\n",
      "|    total_timesteps      | 1923072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016533038  |\n",
      "|    clip_fraction        | 0.206        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -78.9        |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.2         |\n",
      "|    n_updates            | 9380         |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -0.023675127 |\n",
      "|    std                  | 3.72         |\n",
      "|    value_loss           | 69.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 18087       |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015988616 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    reward               | 1.4710511   |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 18107       |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011025558 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | -0.1152632  |\n",
      "|    std                  | 3.72        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 18126       |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011134657 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.2        |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 4.9575696   |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 80.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4281755.64\n",
      "total_reward: 3281755.64\n",
      "total_cost: 170044.58\n",
      "total_trades: 59651\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 18144       |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011772414 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | 0.77601445  |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 18163       |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014912138 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.1       |\n",
      "|    explained_variance   | 0.0611      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 9430        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 1.2873775   |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 945         |\n",
      "|    time_elapsed         | 18182       |\n",
      "|    total_timesteps      | 1935360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017388113 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.0402      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.3        |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 15.028219   |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 18201       |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011269409 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.028162291 |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 81.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 18220       |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013781978 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.0551      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 1.1333696   |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 948         |\n",
      "|    time_elapsed         | 18238       |\n",
      "|    total_timesteps      | 1941504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009755897 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.0671      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | 0.6812316   |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 18258       |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009327738 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -1.4847729  |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 79.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 18278       |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010874467 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | 1.012193    |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 18297       |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015670829 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 9500        |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 2.600692    |\n",
      "|    std                  | 3.78        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 952          |\n",
      "|    time_elapsed         | 18316        |\n",
      "|    total_timesteps      | 1949696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091914795 |\n",
      "|    clip_fraction        | 0.064        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -79.4        |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 9510         |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    reward               | 6.8661375    |\n",
      "|    std                  | 3.78         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 18335       |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014446894 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | -0.70425355 |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 18354       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011827115 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | 0.3976565   |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 18373       |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014279429 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.9        |\n",
      "|    n_updates            | 9540        |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    reward               | 0.56493354  |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 79.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 18393       |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008772431 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.6        |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 4.2772293   |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 98.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3780324.24\n",
      "total_reward: 2780324.24\n",
      "total_cost: 163233.90\n",
      "total_trades: 58715\n",
      "Sharpe: 0.638\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 18412       |\n",
      "|    total_timesteps      | 1959936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016227044 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 9560        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    reward               | 0.8772143   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 958         |\n",
      "|    time_elapsed         | 18430       |\n",
      "|    total_timesteps      | 1961984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011610074 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.0975      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.4        |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | 0.037373055 |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 18449       |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011514581 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.0544      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 9580        |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | -0.964912   |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 18469       |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010490959 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | -0.0356     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | 2.0234609   |\n",
      "|    std                  | 3.83        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 18488       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012069148 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.8       |\n",
      "|    explained_variance   | 0.00237     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.8        |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    reward               | -2.0632727  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 962         |\n",
      "|    time_elapsed         | 18508       |\n",
      "|    total_timesteps      | 1970176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011572786 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.2        |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | -0.387319   |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 18528       |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025206627 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    reward               | 1.7017778   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 18547       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011248836 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0792      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 0.4114167   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 18567       |\n",
      "|    total_timesteps      | 1976320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007203526 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | -0.22298068 |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 18587       |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007169249 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0724      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.1        |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    reward               | -0.8305088  |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 967         |\n",
      "|    time_elapsed         | 18606       |\n",
      "|    total_timesteps      | 1980416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018487327 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.091       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | 2.0412288   |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 18625       |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013047812 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.7        |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    reward               | -0.9705623  |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 969        |\n",
      "|    time_elapsed         | 18644      |\n",
      "|    total_timesteps      | 1984512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01177654 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80        |\n",
      "|    explained_variance   | 0.0607     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 159        |\n",
      "|    n_updates            | 9680       |\n",
      "|    policy_gradient_loss | -0.00782   |\n",
      "|    reward               | -15.920145 |\n",
      "|    std                  | 3.86       |\n",
      "|    value_loss           | 233        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 970        |\n",
      "|    time_elapsed         | 18663      |\n",
      "|    total_timesteps      | 1986560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01101259 |\n",
      "|    clip_fraction        | 0.0675     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.1      |\n",
      "|    explained_variance   | 0.184      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 36.7       |\n",
      "|    n_updates            | 9690       |\n",
      "|    policy_gradient_loss | -0.00493   |\n",
      "|    reward               | 1.5412971  |\n",
      "|    std                  | 3.86       |\n",
      "|    value_loss           | 74.9       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3702447.27\n",
      "total_reward: 2702447.27\n",
      "total_cost: 184438.58\n",
      "total_trades: 60454\n",
      "Sharpe: 0.607\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 18682       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024784356 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.0236      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.1        |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -2.770018   |\n",
      "|    std                  | 3.87        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 18701       |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013042374 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | 1.6206058   |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 973        |\n",
      "|    time_elapsed         | 18719      |\n",
      "|    total_timesteps      | 1992704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01976439 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -80.2      |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 118        |\n",
      "|    n_updates            | 9720       |\n",
      "|    policy_gradient_loss | 0.000582   |\n",
      "|    reward               | -10.456781 |\n",
      "|    std                  | 3.89       |\n",
      "|    value_loss           | 133        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 18739       |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024423454 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | -1.521543   |\n",
      "|    std                  | 3.9         |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 18757       |\n",
      "|    total_timesteps      | 1996800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013577167 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 9740        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    reward               | -0.6272742  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 18776       |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012390692 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.5        |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | -14.742069  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 977         |\n",
      "|    time_elapsed         | 18795       |\n",
      "|    total_timesteps      | 2000896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030283082 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | -0.014      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | 0.00352     |\n",
      "|    reward               | -1.9250131  |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 106       |\n",
      "|    iterations           | 978       |\n",
      "|    time_elapsed         | 18814     |\n",
      "|    total_timesteps      | 2002944   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.013486  |\n",
      "|    clip_fraction        | 0.11      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -80.6     |\n",
      "|    explained_variance   | 0.0384    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 25.8      |\n",
      "|    n_updates            | 9770      |\n",
      "|    policy_gradient_loss | -0.00546  |\n",
      "|    reward               | 1.0552212 |\n",
      "|    std                  | 3.93      |\n",
      "|    value_loss           | 139       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 18833       |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010218571 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.0221      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.8        |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.44572043 |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 18852       |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019683424 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | 3.2540474   |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 18871       |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024581565 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.0827      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 9800        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 0.5414266   |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 982         |\n",
      "|    time_elapsed         | 18890       |\n",
      "|    total_timesteps      | 2011136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632541 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.7       |\n",
      "|    explained_variance   | 0.0041      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -0.1494849  |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 18909       |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022533063 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.00289     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.1        |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | 0.00162     |\n",
      "|    reward               | 0.93512684  |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 18928       |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013747032 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.0439      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    reward               | -0.4161117  |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5215259.26\n",
      "total_reward: 4215259.26\n",
      "total_cost: 197689.66\n",
      "total_trades: 61477\n",
      "Sharpe: 0.778\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 18946       |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010905154 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.0609      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.33376196 |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 986         |\n",
      "|    time_elapsed         | 18965       |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013684217 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.00909     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.1        |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 0.030502753 |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 987         |\n",
      "|    time_elapsed         | 18985       |\n",
      "|    total_timesteps      | 2021376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014798704 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.0261      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 9860        |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.86610574  |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 19003       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013885145 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 0.99286276  |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 19022       |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009370268 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.0757      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 1.3247399   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 19041       |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007924451 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.1       |\n",
      "|    explained_variance   | 0.0839      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.9        |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    reward               | 1.2948304   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 19060       |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013590777 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | 1.8972026   |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 992          |\n",
      "|    time_elapsed         | 19080        |\n",
      "|    total_timesteps      | 2031616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077833235 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.2        |\n",
      "|    explained_variance   | 0.0325       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.4         |\n",
      "|    n_updates            | 9910         |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    reward               | -3.0320356   |\n",
      "|    std                  | 4.03         |\n",
      "|    value_loss           | 246          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 19101       |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009422126 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | 4.286481    |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 19121       |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014755489 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0709      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -0.6845971  |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 19140       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015694939 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    reward               | -2.3232734  |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 19159       |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010966981 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.000474   |\n",
      "|    reward               | 0.4489209   |\n",
      "|    std                  | 4.03        |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 997         |\n",
      "|    time_elapsed         | 19178       |\n",
      "|    total_timesteps      | 2041856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011897133 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0712      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | -20.627302  |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 257         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 19197       |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019954983 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | 0.000687    |\n",
      "|    reward               | -3.2506318  |\n",
      "|    std                  | 4.04        |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4448681.15\n",
      "total_reward: 3448681.15\n",
      "total_cost: 190769.16\n",
      "total_trades: 60683\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 19216       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008861318 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.4       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    reward               | -1.1782802  |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1000         |\n",
      "|    time_elapsed         | 19234        |\n",
      "|    total_timesteps      | 2048000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122671295 |\n",
      "|    clip_fraction        | 0.0997       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.4        |\n",
      "|    explained_variance   | 0.192        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 9990         |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 0.004889014  |\n",
      "|    std                  | 4.05         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1001       |\n",
      "|    time_elapsed         | 19253      |\n",
      "|    total_timesteps      | 2050048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0124235  |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.4      |\n",
      "|    explained_variance   | 0.132      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31         |\n",
      "|    n_updates            | 10000      |\n",
      "|    policy_gradient_loss | -0.00361   |\n",
      "|    reward               | -0.4188241 |\n",
      "|    std                  | 4.06       |\n",
      "|    value_loss           | 48.1       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 19272       |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011926855 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | 0.026644347 |\n",
      "|    std                  | 4.06        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1003         |\n",
      "|    time_elapsed         | 19291        |\n",
      "|    total_timesteps      | 2054144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066751204 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.5        |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 10020        |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    reward               | -0.62728226  |\n",
      "|    std                  | 4.06         |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1004        |\n",
      "|    time_elapsed         | 19310       |\n",
      "|    total_timesteps      | 2056192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016116846 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 10030       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 2.3119802   |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 19329       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015651587 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0701      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    reward               | 1.029148    |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1006        |\n",
      "|    time_elapsed         | 19347       |\n",
      "|    total_timesteps      | 2060288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011446427 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.5        |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | -1.258381   |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1007        |\n",
      "|    time_elapsed         | 19367       |\n",
      "|    total_timesteps      | 2062336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018163502 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.3        |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | 2.0283194   |\n",
      "|    std                  | 4.09        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 19387       |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014402721 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.7       |\n",
      "|    explained_variance   | 0.026       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -0.26982197 |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1009         |\n",
      "|    time_elapsed         | 19406        |\n",
      "|    total_timesteps      | 2066432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133667225 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -81.8        |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.8         |\n",
      "|    n_updates            | 10080        |\n",
      "|    policy_gradient_loss | -0.00904     |\n",
      "|    reward               | -0.7757179   |\n",
      "|    std                  | 4.11         |\n",
      "|    value_loss           | 90           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 19425       |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015921999 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | -15.841918  |\n",
      "|    std                  | 4.11        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1011       |\n",
      "|    time_elapsed         | 19444      |\n",
      "|    total_timesteps      | 2070528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01533931 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.8      |\n",
      "|    explained_variance   | 0.361      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 194        |\n",
      "|    n_updates            | 10100      |\n",
      "|    policy_gradient_loss | -0.00165   |\n",
      "|    reward               | -2.4785109 |\n",
      "|    std                  | 4.11       |\n",
      "|    value_loss           | 187        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 19464       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016017359 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.00374     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | -3.2887547  |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3870213.18\n",
      "total_reward: 2870213.18\n",
      "total_cost: 215796.54\n",
      "total_trades: 61347\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1013       |\n",
      "|    time_elapsed         | 19483      |\n",
      "|    total_timesteps      | 2074624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00796178 |\n",
      "|    clip_fraction        | 0.0592     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.9      |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 62.9       |\n",
      "|    n_updates            | 10120      |\n",
      "|    policy_gradient_loss | -0.00792   |\n",
      "|    reward               | -2.5400262 |\n",
      "|    std                  | 4.12       |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1014        |\n",
      "|    time_elapsed         | 19502       |\n",
      "|    total_timesteps      | 2076672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018633015 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.9       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.4        |\n",
      "|    n_updates            | 10130       |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | -2.925095   |\n",
      "|    std                  | 4.13        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 19522       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014265349 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82         |\n",
      "|    explained_variance   | 0.00335     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | 2.4877696   |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1016         |\n",
      "|    time_elapsed         | 19541        |\n",
      "|    total_timesteps      | 2080768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058713295 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -82.1        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 10150        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | -1.4512128   |\n",
      "|    std                  | 4.15         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1017        |\n",
      "|    time_elapsed         | 19560       |\n",
      "|    total_timesteps      | 2082816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010731581 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48          |\n",
      "|    n_updates            | 10160       |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | 3.700446    |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1018        |\n",
      "|    time_elapsed         | 19579       |\n",
      "|    total_timesteps      | 2084864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015998408 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.2       |\n",
      "|    explained_variance   | -0.0557     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 10170       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | -0.33924216 |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 19598       |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015250445 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | 1.9081203   |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 19617       |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011558043 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 0.15409462  |\n",
      "|    std                  | 4.19        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1021        |\n",
      "|    time_elapsed         | 19636       |\n",
      "|    total_timesteps      | 2091008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013948418 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.9        |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | 1.4292607   |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 97.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 19655       |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015297104 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    reward               | 0.8182763   |\n",
      "|    std                  | 4.22        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 19674       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013072711 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 0.4127454   |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 88.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1024        |\n",
      "|    time_elapsed         | 19693       |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016602049 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.6       |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 10230       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | 0.8395994   |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 95          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 19712       |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019964725 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.7       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -10.829794  |\n",
      "|    std                  | 4.24        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1026        |\n",
      "|    time_elapsed         | 19731       |\n",
      "|    total_timesteps      | 2101248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012369947 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.8       |\n",
      "|    explained_variance   | 0.0996      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    reward               | 0.118528135 |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 65.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3243757.57\n",
      "total_reward: 2243757.57\n",
      "total_cost: 201848.37\n",
      "total_trades: 61322\n",
      "Sharpe: 0.601\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 19750       |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010645554 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 10260       |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | 0.86675715  |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1028        |\n",
      "|    time_elapsed         | 19769       |\n",
      "|    total_timesteps      | 2105344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011077799 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.4        |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 0.13980667  |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 19788       |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013689195 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.0759      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.9         |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.72930497  |\n",
      "|    std                  | 4.28        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 19807       |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011904765 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | -0.8670144  |\n",
      "|    std                  | 4.29        |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1031         |\n",
      "|    time_elapsed         | 19826        |\n",
      "|    total_timesteps      | 2111488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141173545 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.1        |\n",
      "|    explained_variance   | 0.0498       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 10300        |\n",
      "|    policy_gradient_loss | -0.00894     |\n",
      "|    reward               | -1.0909535   |\n",
      "|    std                  | 4.29         |\n",
      "|    value_loss           | 95.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1032       |\n",
      "|    time_elapsed         | 19845      |\n",
      "|    total_timesteps      | 2113536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01269957 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.1      |\n",
      "|    explained_variance   | 0.256      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 10310      |\n",
      "|    policy_gradient_loss | -0.00787   |\n",
      "|    reward               | 0.11563367 |\n",
      "|    std                  | 4.3        |\n",
      "|    value_loss           | 27         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 19864       |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008117789 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.9        |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | 1.3565745   |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 85.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1034         |\n",
      "|    time_elapsed         | 19883        |\n",
      "|    total_timesteps      | 2117632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110890325 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -83.2        |\n",
      "|    explained_variance   | 0.192        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 10330        |\n",
      "|    policy_gradient_loss | -0.00849     |\n",
      "|    reward               | 16.126406    |\n",
      "|    std                  | 4.31         |\n",
      "|    value_loss           | 77.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 19902       |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022019194 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.2       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 0.13542737  |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1036        |\n",
      "|    time_elapsed         | 19921       |\n",
      "|    total_timesteps      | 2121728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010611106 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    reward               | -0.6593283  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 19939       |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008579576 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    reward               | 0.71391654  |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 71.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 19958       |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014355345 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 10370       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 0.6977077   |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1039        |\n",
      "|    time_elapsed         | 19977       |\n",
      "|    total_timesteps      | 2127872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014869725 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.3       |\n",
      "|    explained_variance   | 0.0754      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.62        |\n",
      "|    n_updates            | 10380       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | -0.55121577 |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 19996       |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016008295 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | -5.48e-05   |\n",
      "|    reward               | -0.9352052  |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1041        |\n",
      "|    time_elapsed         | 20015       |\n",
      "|    total_timesteps      | 2131968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007839853 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | -3.0309012  |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3643974.86\n",
      "total_reward: 2643974.86\n",
      "total_cost: 198283.71\n",
      "total_trades: 60248\n",
      "Sharpe: 0.651\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 20034       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017403547 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.0232      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | 0.08658209  |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 20053       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010915217 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -0.06305997 |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 20072       |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011962192 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.4       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.1        |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 1.7783308   |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 65.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1045        |\n",
      "|    time_elapsed         | 20091       |\n",
      "|    total_timesteps      | 2140160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010462251 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.5       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 0.92898923  |\n",
      "|    std                  | 4.36        |\n",
      "|    value_loss           | 66          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 20111       |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022691313 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.0563      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    reward               | 0.07049772  |\n",
      "|    std                  | 4.38        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1047        |\n",
      "|    time_elapsed         | 20132       |\n",
      "|    total_timesteps      | 2144256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013704318 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    reward               | -1.4060404  |\n",
      "|    std                  | 4.39        |\n",
      "|    value_loss           | 93.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 20151       |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003587626 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.8        |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | -2.3118072  |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 20170       |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017347574 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.0778      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    reward               | -0.7232015  |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1050        |\n",
      "|    time_elapsed         | 20189       |\n",
      "|    total_timesteps      | 2150400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014371949 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -1.9549346  |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 70.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 20208       |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010942422 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.8       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | 0.3830975   |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1052       |\n",
      "|    time_elapsed         | 20227      |\n",
      "|    total_timesteps      | 2154496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00787447 |\n",
      "|    clip_fraction        | 0.0694     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.9      |\n",
      "|    explained_variance   | 0.452      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 86.7       |\n",
      "|    n_updates            | 10510      |\n",
      "|    policy_gradient_loss | -0.00344   |\n",
      "|    reward               | -0.9325983 |\n",
      "|    std                  | 4.42       |\n",
      "|    value_loss           | 156        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 20246       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010669829 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.38        |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | 0.17215702  |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 20264       |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011741547 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.7095405   |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 95.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1055        |\n",
      "|    time_elapsed         | 20283       |\n",
      "|    total_timesteps      | 2160640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008853212 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 3.4101288   |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3223029.34\n",
      "total_reward: 2223029.34\n",
      "total_cost: 176312.85\n",
      "total_trades: 59568\n",
      "Sharpe: 0.597\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 20302       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014155682 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | -1.3632792  |\n",
      "|    std                  | 4.45        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1057        |\n",
      "|    time_elapsed         | 20322       |\n",
      "|    total_timesteps      | 2164736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711806 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 10560       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | -1.1511068  |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 20342       |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010600844 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -31.534018  |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1059         |\n",
      "|    time_elapsed         | 20363        |\n",
      "|    total_timesteps      | 2168832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048868023 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.1        |\n",
      "|    explained_variance   | 0.0676       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.1         |\n",
      "|    n_updates            | 10580        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.41844267  |\n",
      "|    std                  | 4.46         |\n",
      "|    value_loss           | 86.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1060        |\n",
      "|    time_elapsed         | 20382       |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009763692 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | 1.5815187   |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1061         |\n",
      "|    time_elapsed         | 20401        |\n",
      "|    total_timesteps      | 2172928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076139583 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.2        |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 10600        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | 0.60952276   |\n",
      "|    std                  | 4.48         |\n",
      "|    value_loss           | 58.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 20420       |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010466643 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.6        |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    reward               | -3.581098   |\n",
      "|    std                  | 4.48        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1063       |\n",
      "|    time_elapsed         | 20439      |\n",
      "|    total_timesteps      | 2177024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01372101 |\n",
      "|    clip_fraction        | 0.0763     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.3      |\n",
      "|    explained_variance   | 0.261      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.7       |\n",
      "|    n_updates            | 10620      |\n",
      "|    policy_gradient_loss | -0.0053    |\n",
      "|    reward               | -1.0981493 |\n",
      "|    std                  | 4.48       |\n",
      "|    value_loss           | 52         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 20458       |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006678273 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | 0.19186376  |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1065        |\n",
      "|    time_elapsed         | 20477       |\n",
      "|    total_timesteps      | 2181120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009159304 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    reward               | 3.254772    |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 91.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1066         |\n",
      "|    time_elapsed         | 20498        |\n",
      "|    total_timesteps      | 2183168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046639973 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -84.3        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 10650        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -1.3195499   |\n",
      "|    std                  | 4.49         |\n",
      "|    value_loss           | 75           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 20517       |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013742766 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.3       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | -0.5860562  |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 85.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1068        |\n",
      "|    time_elapsed         | 20536       |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016473126 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 10670       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | -2.255952   |\n",
      "|    std                  | 4.51        |\n",
      "|    value_loss           | 80.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 20554       |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015204825 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    reward               | -0.70301825 |\n",
      "|    std                  | 4.51        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3044613.62\n",
      "total_reward: 2044613.62\n",
      "total_cost: 181382.38\n",
      "total_trades: 60102\n",
      "Sharpe: 0.538\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1070        |\n",
      "|    time_elapsed         | 20573       |\n",
      "|    total_timesteps      | 2191360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018048529 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.5       |\n",
      "|    explained_variance   | 0.0541      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    reward               | 0.6125858   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 20592       |\n",
      "|    total_timesteps      | 2193408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004036245 |\n",
      "|    clip_fraction        | 0.00933     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 10700       |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 0.41673794  |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1072        |\n",
      "|    time_elapsed         | 20611       |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010206532 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.6       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    reward               | 5.4473057   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 87.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 20630       |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013332302 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.7       |\n",
      "|    explained_variance   | 0.0973      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | 1.4195632   |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1074       |\n",
      "|    time_elapsed         | 20649      |\n",
      "|    total_timesteps      | 2199552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01657327 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.7      |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.3       |\n",
      "|    n_updates            | 10730      |\n",
      "|    policy_gradient_loss | -0.0046    |\n",
      "|    reward               | 1.7242106  |\n",
      "|    std                  | 4.55       |\n",
      "|    value_loss           | 68.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1075        |\n",
      "|    time_elapsed         | 20670       |\n",
      "|    total_timesteps      | 2201600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014323713 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 0.3862667   |\n",
      "|    std                  | 4.56        |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 20689       |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012188476 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | -0.03905951 |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 20708       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013460634 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.0988      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | -0.6232665  |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 31.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 20731       |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011878159 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 0.19107118  |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1079         |\n",
      "|    time_elapsed         | 20749        |\n",
      "|    total_timesteps      | 2209792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071110576 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.1        |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.9         |\n",
      "|    n_updates            | 10780        |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    reward               | -0.7488569   |\n",
      "|    std                  | 4.62         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 20768       |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015380567 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.6124038  |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 20787       |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010360376 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | -1.7886096  |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 20807       |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012927098 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 5.911611    |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 20826       |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016327083 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    reward               | -2.456206   |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3642211.53\n",
      "total_reward: 2642211.53\n",
      "total_cost: 200477.79\n",
      "total_trades: 60680\n",
      "Sharpe: 0.612\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1084        |\n",
      "|    time_elapsed         | 20845       |\n",
      "|    total_timesteps      | 2220032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012898615 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 1.3357675   |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 20863       |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010555849 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.0792      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | -0.44610623 |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 20883       |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013248476 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | -6.418698   |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 74.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 20901       |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014323883 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.5       |\n",
      "|    explained_variance   | -0.0224     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    reward               | 3.4491827   |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1088         |\n",
      "|    time_elapsed         | 20920        |\n",
      "|    total_timesteps      | 2228224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055686356 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.6        |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.5         |\n",
      "|    n_updates            | 10870        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -2.301285    |\n",
      "|    std                  | 4.69         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1089        |\n",
      "|    time_elapsed         | 20940       |\n",
      "|    total_timesteps      | 2230272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007037202 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.2        |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | -2.5421185  |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 20958       |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016522361 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.6       |\n",
      "|    explained_variance   | 0.0568      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | -0.25178832 |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1091         |\n",
      "|    time_elapsed         | 20977        |\n",
      "|    total_timesteps      | 2234368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111534055 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -85.7        |\n",
      "|    explained_variance   | 0.1          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 10900        |\n",
      "|    policy_gradient_loss | -0.00949     |\n",
      "|    reward               | -0.8552975   |\n",
      "|    std                  | 4.72         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 20996       |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009315991 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.6        |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -1.3714868  |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 81.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 21015       |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009098906 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.1        |\n",
      "|    n_updates            | 10920       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.21494201 |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1094        |\n",
      "|    time_elapsed         | 21034       |\n",
      "|    total_timesteps      | 2240512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011272503 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.4         |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    reward               | 3.5393782   |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 21054       |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017420195 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.0573      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.7        |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    reward               | 0.011793254 |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1096       |\n",
      "|    time_elapsed         | 21073      |\n",
      "|    total_timesteps      | 2244608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01561329 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.9      |\n",
      "|    explained_variance   | 0.0388     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 143        |\n",
      "|    n_updates            | 10950      |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    reward               | -1.7665397 |\n",
      "|    std                  | 4.75       |\n",
      "|    value_loss           | 140        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1097        |\n",
      "|    time_elapsed         | 21093       |\n",
      "|    total_timesteps      | 2246656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011434339 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86         |\n",
      "|    explained_variance   | 0.0281      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | -0.5165937  |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 42.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3457963.38\n",
      "total_reward: 2457963.38\n",
      "total_cost: 202975.49\n",
      "total_trades: 59742\n",
      "Sharpe: 0.586\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1098       |\n",
      "|    time_elapsed         | 21113      |\n",
      "|    total_timesteps      | 2248704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01363025 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.1      |\n",
      "|    explained_variance   | 0.0624     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 54         |\n",
      "|    n_updates            | 10970      |\n",
      "|    policy_gradient_loss | -0.00784   |\n",
      "|    reward               | -1.4238471 |\n",
      "|    std                  | 4.78       |\n",
      "|    value_loss           | 116        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 21133       |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009125249 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 4.1002917   |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 21153       |\n",
      "|    total_timesteps      | 2252800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012554746 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.1       |\n",
      "|    explained_variance   | 0.0486      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.6        |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | 0.53164715  |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 21172       |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015276581 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.32        |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 5.7198753   |\n",
      "|    std                  | 4.79        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1102         |\n",
      "|    time_elapsed         | 21191        |\n",
      "|    total_timesteps      | 2256896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114071565 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.2        |\n",
      "|    explained_variance   | 0.213        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 11010        |\n",
      "|    policy_gradient_loss | -0.00753     |\n",
      "|    reward               | 1.0803639    |\n",
      "|    std                  | 4.79         |\n",
      "|    value_loss           | 93.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 21210       |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008884614 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    reward               | 2.2559204   |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 89.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 21229       |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012232565 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.2       |\n",
      "|    explained_variance   | 0.0839      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | 2.807126    |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 21248       |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009761855 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.5        |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -4.7162504  |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1106        |\n",
      "|    time_elapsed         | 21267       |\n",
      "|    total_timesteps      | 2265088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010150839 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | -0.00057    |\n",
      "|    reward               | -3.1916149  |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 87.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 21286       |\n",
      "|    total_timesteps      | 2267136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009635473 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.3       |\n",
      "|    explained_variance   | 0.0658      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    reward               | 1.1169097   |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1108        |\n",
      "|    time_elapsed         | 21306       |\n",
      "|    total_timesteps      | 2269184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012188096 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.4       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | -0.33145654 |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 69.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1109        |\n",
      "|    time_elapsed         | 21325       |\n",
      "|    total_timesteps      | 2271232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248124 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    reward               | 0.14099206  |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1110         |\n",
      "|    time_elapsed         | 21344        |\n",
      "|    total_timesteps      | 2273280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125274155 |\n",
      "|    clip_fraction        | 0.093        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -86.5        |\n",
      "|    explained_variance   | 0.0828       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 11090        |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    reward               | 2.3513758    |\n",
      "|    std                  | 4.85         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 21363       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011331247 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | -0.00463    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | -2.2471173  |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3273443.55\n",
      "total_reward: 2273443.55\n",
      "total_cost: 204480.02\n",
      "total_trades: 58966\n",
      "Sharpe: 0.571\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 21382       |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012615519 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.0716      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | 1.2070853   |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1113        |\n",
      "|    time_elapsed         | 21402       |\n",
      "|    total_timesteps      | 2279424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011312912 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.0553      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.8        |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | 1.3395438   |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 21424       |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011663744 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.00571     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | -1.5475403  |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 21442       |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012902379 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -0.27019984 |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1116        |\n",
      "|    time_elapsed         | 21461       |\n",
      "|    total_timesteps      | 2285568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011687464 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | 0.0838      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.7        |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 2.1119525   |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1117       |\n",
      "|    time_elapsed         | 21480      |\n",
      "|    total_timesteps      | 2287616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00986346 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.8      |\n",
      "|    explained_variance   | 0.0918     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 76.5       |\n",
      "|    n_updates            | 11160      |\n",
      "|    policy_gradient_loss | -0.00586   |\n",
      "|    reward               | 1.1480824  |\n",
      "|    std                  | 4.89       |\n",
      "|    value_loss           | 129        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 21499       |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012352499 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    reward               | 2.7907696   |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1119        |\n",
      "|    time_elapsed         | 21518       |\n",
      "|    total_timesteps      | 2291712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010050215 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.1        |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | 0.65453935  |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 21538       |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008374061 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.0839      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | -1.4839942  |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 21592       |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017302252 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.0931      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -2.8710034  |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 21613       |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013208274 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.0617      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -1.2385179  |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 21631       |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012888794 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.0621      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 17.35744    |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1124        |\n",
      "|    time_elapsed         | 21651       |\n",
      "|    total_timesteps      | 2301952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011762513 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.1       |\n",
      "|    explained_variance   | 0.0531      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | 0.74873644  |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1125       |\n",
      "|    time_elapsed         | 21670      |\n",
      "|    total_timesteps      | 2304000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01182127 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.1      |\n",
      "|    explained_variance   | 0.282      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.5       |\n",
      "|    n_updates            | 11240      |\n",
      "|    policy_gradient_loss | -0.00952   |\n",
      "|    reward               | 0.5160123  |\n",
      "|    std                  | 4.96       |\n",
      "|    value_loss           | 37.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3408345.65\n",
      "total_reward: 2408345.65\n",
      "total_cost: 215243.93\n",
      "total_trades: 59650\n",
      "Sharpe: 0.588\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 21689       |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012119187 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.2       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.4717163   |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1127        |\n",
      "|    time_elapsed         | 21707       |\n",
      "|    total_timesteps      | 2308096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010960778 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.3       |\n",
      "|    explained_variance   | 0.0775      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    reward               | 0.63788515  |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 95.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 21727       |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009366219 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    reward               | 3.8975945   |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1129        |\n",
      "|    time_elapsed         | 21745       |\n",
      "|    total_timesteps      | 2312192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010450108 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | -3.0325515  |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1130        |\n",
      "|    time_elapsed         | 21765       |\n",
      "|    total_timesteps      | 2314240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015404679 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 11290       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -1.0493577  |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1131        |\n",
      "|    time_elapsed         | 21785       |\n",
      "|    total_timesteps      | 2316288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015780047 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | -2.734766   |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 21804       |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012542069 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    reward               | 0.5706576   |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 90          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1133        |\n",
      "|    time_elapsed         | 21823       |\n",
      "|    total_timesteps      | 2320384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016089963 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 11320       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    reward               | -0.34011576 |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 87.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1134        |\n",
      "|    time_elapsed         | 21842       |\n",
      "|    total_timesteps      | 2322432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011961155 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.7       |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.1        |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | -2.9761956  |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1135         |\n",
      "|    time_elapsed         | 21862        |\n",
      "|    total_timesteps      | 2324480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00947986   |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -87.7        |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.75         |\n",
      "|    n_updates            | 11340        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    reward               | -0.014316154 |\n",
      "|    std                  | 5.06         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1136       |\n",
      "|    time_elapsed         | 21881      |\n",
      "|    total_timesteps      | 2326528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00770539 |\n",
      "|    clip_fraction        | 0.0398     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.8      |\n",
      "|    explained_variance   | 0.29       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.1       |\n",
      "|    n_updates            | 11350      |\n",
      "|    policy_gradient_loss | -0.00547   |\n",
      "|    reward               | 0.5656894  |\n",
      "|    std                  | 5.07       |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1137       |\n",
      "|    time_elapsed         | 21900      |\n",
      "|    total_timesteps      | 2328576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00486426 |\n",
      "|    clip_fraction        | 0.0104     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.8      |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 35.6       |\n",
      "|    n_updates            | 11360      |\n",
      "|    policy_gradient_loss | -0.00329   |\n",
      "|    reward               | -1.7380269 |\n",
      "|    std                  | 5.07       |\n",
      "|    value_loss           | 105        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1138        |\n",
      "|    time_elapsed         | 21919       |\n",
      "|    total_timesteps      | 2330624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009356057 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.0201      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | 3.1550772   |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 55.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 21937       |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009654732 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | 0.15205346  |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 91.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4197752.38\n",
      "total_reward: 3197752.38\n",
      "total_cost: 191954.21\n",
      "total_trades: 57571\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 21957       |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010314657 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.9       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | -3.878333   |\n",
      "|    std                  | 5.09        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1141         |\n",
      "|    time_elapsed         | 21976        |\n",
      "|    total_timesteps      | 2336768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075544957 |\n",
      "|    clip_fraction        | 0.054        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88          |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 11400        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    reward               | 2.4478157    |\n",
      "|    std                  | 5.1          |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 21994       |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012385823 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88         |\n",
      "|    explained_variance   | 0.0296      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -5.433567   |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1143        |\n",
      "|    time_elapsed         | 22013       |\n",
      "|    total_timesteps      | 2340864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013316309 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.2        |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    reward               | -1.3902345  |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 22032       |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009145717 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | 10.192861   |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1145       |\n",
      "|    time_elapsed         | 22051      |\n",
      "|    total_timesteps      | 2344960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01424617 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.2      |\n",
      "|    explained_variance   | 0.00342    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.9       |\n",
      "|    n_updates            | 11440      |\n",
      "|    policy_gradient_loss | -0.00374   |\n",
      "|    reward               | -0.7100999 |\n",
      "|    std                  | 5.14       |\n",
      "|    value_loss           | 48.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1146         |\n",
      "|    time_elapsed         | 22070        |\n",
      "|    total_timesteps      | 2347008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069109346 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.3        |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 11450        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -0.10190499  |\n",
      "|    std                  | 5.15         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1147         |\n",
      "|    time_elapsed         | 22089        |\n",
      "|    total_timesteps      | 2349056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018745079 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.3        |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.7         |\n",
      "|    n_updates            | 11460        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    reward               | 45.71766     |\n",
      "|    std                  | 5.15         |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 106           |\n",
      "|    iterations           | 1148          |\n",
      "|    time_elapsed         | 22109         |\n",
      "|    total_timesteps      | 2351104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077879784 |\n",
      "|    clip_fraction        | 0.00176       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -88.3         |\n",
      "|    explained_variance   | 0.242         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 65.4          |\n",
      "|    n_updates            | 11470         |\n",
      "|    policy_gradient_loss | -0.00108      |\n",
      "|    reward               | -2.9356549    |\n",
      "|    std                  | 5.15          |\n",
      "|    value_loss           | 145           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 22128       |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005195112 |\n",
      "|    clip_fraction        | 0.026       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | -0.0493     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | 1.3211023   |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 22146       |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003419478 |\n",
      "|    clip_fraction        | 0.00273     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | 0.7335369   |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1151        |\n",
      "|    time_elapsed         | 22165       |\n",
      "|    total_timesteps      | 2357248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010829633 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.0235      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83          |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -0.62709594 |\n",
      "|    std                  | 5.16        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1152         |\n",
      "|    time_elapsed         | 22184        |\n",
      "|    total_timesteps      | 2359296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136212725 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.4        |\n",
      "|    explained_variance   | 0.0177       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 11510        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    reward               | 8.342168     |\n",
      "|    std                  | 5.19         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1153         |\n",
      "|    time_elapsed         | 22202        |\n",
      "|    total_timesteps      | 2361344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076243337 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.5        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.2         |\n",
      "|    n_updates            | 11520        |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    reward               | -7.5852194   |\n",
      "|    std                  | 5.19         |\n",
      "|    value_loss           | 89.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1154         |\n",
      "|    time_elapsed         | 22221        |\n",
      "|    total_timesteps      | 2363392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052316613 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.5        |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.9         |\n",
      "|    n_updates            | 11530        |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    reward               | -3.9062247   |\n",
      "|    std                  | 5.2          |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4301785.54\n",
      "total_reward: 3301785.54\n",
      "total_cost: 188053.83\n",
      "total_trades: 58001\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1155        |\n",
      "|    time_elapsed         | 22240       |\n",
      "|    total_timesteps      | 2365440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011256717 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | -0.000329   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 11540       |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | -0.10419721 |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 22258       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011998141 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | 0.1627857   |\n",
      "|    std                  | 5.21        |\n",
      "|    value_loss           | 95.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1157        |\n",
      "|    time_elapsed         | 22277       |\n",
      "|    total_timesteps      | 2369536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010110691 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 1.1336058   |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 90.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1158        |\n",
      "|    time_elapsed         | 22296       |\n",
      "|    total_timesteps      | 2371584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012633622 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | 0.10494044  |\n",
      "|    std                  | 5.23        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1159         |\n",
      "|    time_elapsed         | 22315        |\n",
      "|    total_timesteps      | 2373632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067909677 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.7        |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 11580        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    reward               | 4.18903      |\n",
      "|    std                  | 5.23         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 22334       |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011878975 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | 1.4200832   |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 67.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 22353       |\n",
      "|    total_timesteps      | 2377728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009758202 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 11600       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | 0.45157593  |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 96.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 22373       |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024037557 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.000219    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | 2.2154112   |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 60.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1163        |\n",
      "|    time_elapsed         | 22392       |\n",
      "|    total_timesteps      | 2381824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012511595 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | -1.8611525  |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 22410        |\n",
      "|    total_timesteps      | 2383872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056767454 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -88.8        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.5         |\n",
      "|    n_updates            | 11630        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | -0.2825471   |\n",
      "|    std                  | 5.25         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 22430       |\n",
      "|    total_timesteps      | 2385920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013769092 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    reward               | 9.414788    |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 22449       |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011833779 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.0706      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    reward               | -1.0483581  |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1167        |\n",
      "|    time_elapsed         | 22467       |\n",
      "|    total_timesteps      | 2390016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008019654 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.2        |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | -1.0412712  |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 22486       |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007118335 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.5        |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    reward               | 6.781325    |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 224         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5195774.19\n",
      "total_reward: 4195774.19\n",
      "total_cost: 211514.54\n",
      "total_trades: 59862\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 22505       |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010939935 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 3.5426955   |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1170         |\n",
      "|    time_elapsed         | 22524        |\n",
      "|    total_timesteps      | 2396160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124496445 |\n",
      "|    clip_fraction        | 0.0885       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.1        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.9         |\n",
      "|    n_updates            | 11690        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | 2.2742164    |\n",
      "|    std                  | 5.29         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 22543       |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008033789 |\n",
      "|    clip_fraction        | 0.0684      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | -22.714695  |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1172         |\n",
      "|    time_elapsed         | 22562        |\n",
      "|    total_timesteps      | 2400256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096051935 |\n",
      "|    clip_fraction        | 0.0623       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.1        |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.7         |\n",
      "|    n_updates            | 11710        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -3.108342    |\n",
      "|    std                  | 5.3          |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 22581       |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010012329 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 5.2169566   |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1174         |\n",
      "|    time_elapsed         | 22600        |\n",
      "|    total_timesteps      | 2404352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114523955 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.1        |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.1         |\n",
      "|    n_updates            | 11730        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | -1.3404108   |\n",
      "|    std                  | 5.3          |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 22619       |\n",
      "|    total_timesteps      | 2406400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008996457 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 11740       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -3.4299097  |\n",
      "|    std                  | 5.31        |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1176        |\n",
      "|    time_elapsed         | 22638       |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012737251 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.00054     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.729659    |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1177         |\n",
      "|    time_elapsed         | 22656        |\n",
      "|    total_timesteps      | 2410496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099182855 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.3        |\n",
      "|    explained_variance   | 0.0146       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 11760        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | 1.048964     |\n",
      "|    std                  | 5.34         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1178       |\n",
      "|    time_elapsed         | 22675      |\n",
      "|    total_timesteps      | 2412544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00880934 |\n",
      "|    clip_fraction        | 0.0697     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.3      |\n",
      "|    explained_variance   | 0.514      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 75.8       |\n",
      "|    n_updates            | 11770      |\n",
      "|    policy_gradient_loss | -0.00918   |\n",
      "|    reward               | 2.4842677  |\n",
      "|    std                  | 5.35       |\n",
      "|    value_loss           | 131        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 22694       |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011032296 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    reward               | 1.4928167   |\n",
      "|    std                  | 5.35        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 22714       |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011800671 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.4       |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | -0.53581035 |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 22733       |\n",
      "|    total_timesteps      | 2418688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013231965 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | 0.20874687  |\n",
      "|    std                  | 5.37        |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1182        |\n",
      "|    time_elapsed         | 22752       |\n",
      "|    total_timesteps      | 2420736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011348745 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 11810       |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | -0.8314461  |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5538132.65\n",
      "total_reward: 4538132.65\n",
      "total_cost: 221980.47\n",
      "total_trades: 60036\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 22771       |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012592444 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.0243      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -5.0116897  |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1184         |\n",
      "|    time_elapsed         | 22790        |\n",
      "|    total_timesteps      | 2424832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043062055 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.6        |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.5         |\n",
      "|    n_updates            | 11830        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | -0.19848336  |\n",
      "|    std                  | 5.39         |\n",
      "|    value_loss           | 273          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 22809       |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011184666 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.5        |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    reward               | -4.4565616  |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1186        |\n",
      "|    time_elapsed         | 22828       |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008636415 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | -1.3736479  |\n",
      "|    std                  | 5.4         |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1187        |\n",
      "|    time_elapsed         | 22848       |\n",
      "|    total_timesteps      | 2430976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009271933 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    reward               | -1.1580477  |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1188         |\n",
      "|    time_elapsed         | 22867        |\n",
      "|    total_timesteps      | 2433024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072133867 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.7        |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.2         |\n",
      "|    n_updates            | 11870        |\n",
      "|    policy_gradient_loss | -0.00852     |\n",
      "|    reward               | -1.0912161   |\n",
      "|    std                  | 5.41         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1189        |\n",
      "|    time_elapsed         | 22886       |\n",
      "|    total_timesteps      | 2435072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010488038 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.5        |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -0.21078655 |\n",
      "|    std                  | 5.42        |\n",
      "|    value_loss           | 76.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 22905       |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013269648 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | -0.0918     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 1.7766739   |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1191        |\n",
      "|    time_elapsed         | 22924       |\n",
      "|    total_timesteps      | 2439168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009268379 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.9        |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -2.108087   |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1192         |\n",
      "|    time_elapsed         | 22943        |\n",
      "|    total_timesteps      | 2441216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093253255 |\n",
      "|    clip_fraction        | 0.0809       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -89.9        |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 11910        |\n",
      "|    policy_gradient_loss | -0.00792     |\n",
      "|    reward               | 1.0471684    |\n",
      "|    std                  | 5.44         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1193       |\n",
      "|    time_elapsed         | 22962      |\n",
      "|    total_timesteps      | 2443264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01347192 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.9      |\n",
      "|    explained_variance   | 0.0604     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 11920      |\n",
      "|    policy_gradient_loss | -0.00353   |\n",
      "|    reward               | 1.4343128  |\n",
      "|    std                  | 5.46       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1194         |\n",
      "|    time_elapsed         | 22981        |\n",
      "|    total_timesteps      | 2445312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136885485 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90          |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 11930        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    reward               | -2.3784933   |\n",
      "|    std                  | 5.46         |\n",
      "|    value_loss           | 78.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1195        |\n",
      "|    time_elapsed         | 23001       |\n",
      "|    total_timesteps      | 2447360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011250062 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 11940       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | 7.203639    |\n",
      "|    std                  | 5.47        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1196        |\n",
      "|    time_elapsed         | 23020       |\n",
      "|    total_timesteps      | 2449408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013517789 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90         |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 11950       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    reward               | -6.662922   |\n",
      "|    std                  | 5.48        |\n",
      "|    value_loss           | 49.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4780342.31\n",
      "total_reward: 3780342.31\n",
      "total_cost: 237572.87\n",
      "total_trades: 60049\n",
      "Sharpe: 0.724\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 23039       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009329969 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.3        |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | -0.54888237 |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 75.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1198         |\n",
      "|    time_elapsed         | 23058        |\n",
      "|    total_timesteps      | 2453504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099431975 |\n",
      "|    clip_fraction        | 0.0651       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -90.1        |\n",
      "|    explained_variance   | 0.0723       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 11970        |\n",
      "|    policy_gradient_loss | -0.00862     |\n",
      "|    reward               | -1.5039679   |\n",
      "|    std                  | 5.5          |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1199        |\n",
      "|    time_elapsed         | 23077       |\n",
      "|    total_timesteps      | 2455552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011366073 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.0826      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    reward               | -12.740858  |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 91.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 23096       |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013365235 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.044       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 3.0405788   |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 23114       |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008597315 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.2        |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    reward               | 1.292877    |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1202        |\n",
      "|    time_elapsed         | 23134       |\n",
      "|    total_timesteps      | 2461696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008647327 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | 3.0421963   |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 23152       |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010731701 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | -0.188      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 5.779817    |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 28          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1204        |\n",
      "|    time_elapsed         | 23171       |\n",
      "|    total_timesteps      | 2465792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008376536 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 12030       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | -1.9465435  |\n",
      "|    std                  | 5.54        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 23190       |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009277382 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -0.10005962 |\n",
      "|    std                  | 5.56        |\n",
      "|    value_loss           | 87.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 23209       |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009462592 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | 0.8208099   |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1207       |\n",
      "|    time_elapsed         | 23228      |\n",
      "|    total_timesteps      | 2471936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01451852 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.6      |\n",
      "|    explained_variance   | 0.0193     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.97       |\n",
      "|    n_updates            | 12060      |\n",
      "|    policy_gradient_loss | -0.00998   |\n",
      "|    reward               | 0.52983767 |\n",
      "|    std                  | 5.59       |\n",
      "|    value_loss           | 23.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 23247       |\n",
      "|    total_timesteps      | 2473984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010682694 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.6       |\n",
      "|    explained_variance   | 0.065       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.6997171  |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 94.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 23266       |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009502258 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.7       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | -8.121443   |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 23285       |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012253977 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.0449      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | -2.9019313  |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3108973.72\n",
      "total_reward: 2108973.72\n",
      "total_cost: 219836.82\n",
      "total_trades: 59372\n",
      "Sharpe: 0.579\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 23304       |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009139222 |\n",
      "|    clip_fraction        | 0.0597      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | 0.4673243   |\n",
      "|    std                  | 5.64        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1212        |\n",
      "|    time_elapsed         | 23323       |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004983942 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    reward               | 7.072176    |\n",
      "|    std                  | 5.64        |\n",
      "|    value_loss           | 77.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 23342       |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012426525 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | -0.13776898 |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 23362       |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016008541 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.9       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 4.214168    |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1215        |\n",
      "|    time_elapsed         | 23383       |\n",
      "|    total_timesteps      | 2488320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009070151 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.43971387 |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 23402       |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008275228 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | 1.3195431   |\n",
      "|    std                  | 5.67        |\n",
      "|    value_loss           | 94          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 23422       |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012685992 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.0847      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | 2.370308    |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 23441       |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005993612 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 4.5645666   |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 23460       |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010486629 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 0.6296554   |\n",
      "|    std                  | 5.7         |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 23479       |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009295922 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | 0.039       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | 2.7719347   |\n",
      "|    std                  | 5.71        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 23498       |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010773464 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -0.05167297 |\n",
      "|    std                  | 5.72        |\n",
      "|    value_loss           | 77.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 23518       |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009053817 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.3       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | 0.17647016  |\n",
      "|    std                  | 5.73        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 23538       |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007512969 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 12220       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -0.7408065  |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 97.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1224        |\n",
      "|    time_elapsed         | 23557       |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01057152  |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.50060385 |\n",
      "|    std                  | 5.74        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4478264.72\n",
      "total_reward: 3478264.72\n",
      "total_cost: 234125.78\n",
      "total_trades: 61216\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 23576       |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012417456 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 0.88330805  |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1226        |\n",
      "|    time_elapsed         | 23595       |\n",
      "|    total_timesteps      | 2510848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009507286 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 12250       |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | -3.8893757  |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1227        |\n",
      "|    time_elapsed         | 23615       |\n",
      "|    total_timesteps      | 2512896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01897769  |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.6       |\n",
      "|    explained_variance   | -0.00798    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 12260       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -0.26574567 |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 23635       |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010404218 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.7       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 12270       |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | 3.2561698   |\n",
      "|    std                  | 5.8         |\n",
      "|    value_loss           | 67.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1229         |\n",
      "|    time_elapsed         | 23654        |\n",
      "|    total_timesteps      | 2516992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092650745 |\n",
      "|    clip_fraction        | 0.059        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -91.7        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.4         |\n",
      "|    n_updates            | 12280        |\n",
      "|    policy_gradient_loss | -0.0092      |\n",
      "|    reward               | -0.46692264  |\n",
      "|    std                  | 5.81         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1230        |\n",
      "|    time_elapsed         | 23672       |\n",
      "|    total_timesteps      | 2519040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008186837 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    reward               | -0.3647374  |\n",
      "|    std                  | 5.82        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1231        |\n",
      "|    time_elapsed         | 23691       |\n",
      "|    total_timesteps      | 2521088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012625253 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.8       |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | 1.0333267   |\n",
      "|    std                  | 5.83        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 23711       |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010463517 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.6        |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 1.1759324   |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1233       |\n",
      "|    time_elapsed         | 23730      |\n",
      "|    total_timesteps      | 2525184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01046371 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92        |\n",
      "|    explained_variance   | 0.531      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 55.6       |\n",
      "|    n_updates            | 12320      |\n",
      "|    policy_gradient_loss | -0.00747   |\n",
      "|    reward               | -17.980442 |\n",
      "|    std                  | 5.85       |\n",
      "|    value_loss           | 114        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1234        |\n",
      "|    time_elapsed         | 23749       |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010345558 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | -0.404      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 12330       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | -1.3688239  |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 23768       |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010731952 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | -0.22879443 |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1236        |\n",
      "|    time_elapsed         | 23787       |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010269566 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.2        |\n",
      "|    n_updates            | 12350       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | 5.1998262   |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 23806        |\n",
      "|    total_timesteps      | 2533376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102667175 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.1        |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 12360        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    reward               | 3.8177443    |\n",
      "|    std                  | 5.89         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 23825       |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009958409 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 12370       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -1.7805179  |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 52.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5361136.59\n",
      "total_reward: 4361136.59\n",
      "total_cost: 237904.01\n",
      "total_trades: 62033\n",
      "Sharpe: 0.760\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1239         |\n",
      "|    time_elapsed         | 23844        |\n",
      "|    total_timesteps      | 2537472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068111774 |\n",
      "|    clip_fraction        | 0.0542       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.2        |\n",
      "|    explained_variance   | 0.0529       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.2         |\n",
      "|    n_updates            | 12380        |\n",
      "|    policy_gradient_loss | -0.00891     |\n",
      "|    reward               | -0.079197675 |\n",
      "|    std                  | 5.9          |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1240        |\n",
      "|    time_elapsed         | 23863       |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011176796 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.093       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -1.7932818  |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1241        |\n",
      "|    time_elapsed         | 23882       |\n",
      "|    total_timesteps      | 2541568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008953469 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | 0.0396      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 4.2995124   |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 23901       |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012700932 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.3       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 12410       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | 3.906407    |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 93.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1243        |\n",
      "|    time_elapsed         | 23920       |\n",
      "|    total_timesteps      | 2545664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013305269 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | -3.5361643  |\n",
      "|    std                  | 5.93        |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 23939       |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012992381 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.058       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    reward               | -1.0749624  |\n",
      "|    std                  | 5.94        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 23958       |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011641299 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 2.4194422   |\n",
      "|    std                  | 5.94        |\n",
      "|    value_loss           | 51.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1246        |\n",
      "|    time_elapsed         | 23976       |\n",
      "|    total_timesteps      | 2551808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008678853 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.4       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | -0.8920149  |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1247       |\n",
      "|    time_elapsed         | 23995      |\n",
      "|    total_timesteps      | 2553856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01104779 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.5      |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.7       |\n",
      "|    n_updates            | 12460      |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | -0.2850147 |\n",
      "|    std                  | 5.96       |\n",
      "|    value_loss           | 50.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 24014       |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015138311 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.6       |\n",
      "|    explained_variance   | 0.0495      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | -0.71537423 |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 24033       |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008894902 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    reward               | 0.5449208   |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1250         |\n",
      "|    time_elapsed         | 24053        |\n",
      "|    total_timesteps      | 2560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063502053 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.7        |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 12490        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | 1.6115372    |\n",
      "|    std                  | 6            |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 24072       |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016050838 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | -0.0234     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 12500       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | 3.2356791   |\n",
      "|    std                  | 6.03        |\n",
      "|    value_loss           | 24.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 24090       |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008168778 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.49        |\n",
      "|    n_updates            | 12510       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | 2.9157753   |\n",
      "|    std                  | 6.04        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1878342.14\n",
      "total_reward: 878342.14\n",
      "total_cost: 202949.78\n",
      "total_trades: 60171\n",
      "Sharpe: 0.369\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1253        |\n",
      "|    time_elapsed         | 24109       |\n",
      "|    total_timesteps      | 2566144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010260183 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 12520       |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -1.1218063  |\n",
      "|    std                  | 6.05        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 24128       |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011298718 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 12530       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    reward               | -0.91363317 |\n",
      "|    std                  | 6.06        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 24147       |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013576215 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 1.3054655   |\n",
      "|    std                  | 6.07        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1256        |\n",
      "|    time_elapsed         | 24166       |\n",
      "|    total_timesteps      | 2572288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013086287 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 12550       |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | 1.1789542   |\n",
      "|    std                  | 6.09        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 24185       |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010175703 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | -1.1271769  |\n",
      "|    std                  | 6.09        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1258        |\n",
      "|    time_elapsed         | 24204       |\n",
      "|    total_timesteps      | 2576384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010160477 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.0686      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.43        |\n",
      "|    n_updates            | 12570       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | -0.30806622 |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 24223       |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011070244 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 0.84763354  |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1260         |\n",
      "|    time_elapsed         | 24243        |\n",
      "|    total_timesteps      | 2580480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074095577 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.3        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 12590        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | 7.2266426    |\n",
      "|    std                  | 6.12         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 24262       |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009876046 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.3       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -1.2581217  |\n",
      "|    std                  | 6.14        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1262       |\n",
      "|    time_elapsed         | 24282      |\n",
      "|    total_timesteps      | 2584576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00966778 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.4      |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.86       |\n",
      "|    n_updates            | 12610      |\n",
      "|    policy_gradient_loss | -0.00968   |\n",
      "|    reward               | 0.16708049 |\n",
      "|    std                  | 6.15       |\n",
      "|    value_loss           | 18.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 24301       |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009254664 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | -0.17752835 |\n",
      "|    std                  | 6.16        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 24321       |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008046088 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | -4.756161   |\n",
      "|    std                  | 6.17        |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1265         |\n",
      "|    time_elapsed         | 24342        |\n",
      "|    total_timesteps      | 2590720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099983495 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.5        |\n",
      "|    explained_variance   | 0.0841       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.21         |\n",
      "|    n_updates            | 12640        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | -0.12085867  |\n",
      "|    std                  | 6.17         |\n",
      "|    value_loss           | 11.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 24361       |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013180561 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 12650       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    reward               | 6.483443    |\n",
      "|    std                  | 6.19        |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 24380       |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011423079 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.22        |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | 1.385873    |\n",
      "|    std                  | 6.19        |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2165449.27\n",
      "total_reward: 1165449.27\n",
      "total_cost: 201511.98\n",
      "total_trades: 59422\n",
      "Sharpe: 0.438\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1268        |\n",
      "|    time_elapsed         | 24399       |\n",
      "|    total_timesteps      | 2596864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012040428 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.0869      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.8865808  |\n",
      "|    std                  | 6.2         |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1269       |\n",
      "|    time_elapsed         | 24419      |\n",
      "|    total_timesteps      | 2598912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00776651 |\n",
      "|    clip_fraction        | 0.05       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.6      |\n",
      "|    explained_variance   | 0.563      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.77       |\n",
      "|    n_updates            | 12680      |\n",
      "|    policy_gradient_loss | -0.00687   |\n",
      "|    reward               | -1.1052864 |\n",
      "|    std                  | 6.21       |\n",
      "|    value_loss           | 21.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1270        |\n",
      "|    time_elapsed         | 24437       |\n",
      "|    total_timesteps      | 2600960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012386162 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 12690       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.6364305   |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1271         |\n",
      "|    time_elapsed         | 24457        |\n",
      "|    total_timesteps      | 2603008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109476885 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.8        |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 12700        |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    reward               | 0.61580944   |\n",
      "|    std                  | 6.23         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 24479       |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008519055 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.0546      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 0.4932317   |\n",
      "|    std                  | 6.24        |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 24499       |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009565522 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.9       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 1.3529843   |\n",
      "|    std                  | 6.25        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1274         |\n",
      "|    time_elapsed         | 24519        |\n",
      "|    total_timesteps      | 2609152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083986595 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -93.9        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 12730        |\n",
      "|    policy_gradient_loss | -0.00814     |\n",
      "|    reward               | -1.7496188   |\n",
      "|    std                  | 6.27         |\n",
      "|    value_loss           | 37.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1275        |\n",
      "|    time_elapsed         | 24538       |\n",
      "|    total_timesteps      | 2611200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009776197 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.86        |\n",
      "|    n_updates            | 12740       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    reward               | 0.94475937  |\n",
      "|    std                  | 6.29        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 24558       |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009370154 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.57        |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    reward               | 1.9477177   |\n",
      "|    std                  | 6.3         |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1277        |\n",
      "|    time_elapsed         | 24577       |\n",
      "|    total_timesteps      | 2615296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009630659 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.87        |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 0.7600981   |\n",
      "|    std                  | 6.3         |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1278        |\n",
      "|    time_elapsed         | 24596       |\n",
      "|    total_timesteps      | 2617344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009190585 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.0749      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 12770       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | 1.6939145   |\n",
      "|    std                  | 6.33        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 24615       |\n",
      "|    total_timesteps      | 2619392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009832213 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.67        |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 1.1798027   |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1280        |\n",
      "|    time_elapsed         | 24634       |\n",
      "|    total_timesteps      | 2621440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011261793 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 12790       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.7141993   |\n",
      "|    std                  | 6.37        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1281        |\n",
      "|    time_elapsed         | 24654       |\n",
      "|    total_timesteps      | 2623488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009749479 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 12800       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    reward               | 0.5852909   |\n",
      "|    std                  | 6.38        |\n",
      "|    value_loss           | 38.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3704520.56\n",
      "total_reward: 2704520.56\n",
      "total_cost: 258415.35\n",
      "total_trades: 61894\n",
      "Sharpe: 0.647\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1282       |\n",
      "|    time_elapsed         | 24673      |\n",
      "|    total_timesteps      | 2625536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01040031 |\n",
      "|    clip_fraction        | 0.0782     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.4      |\n",
      "|    explained_variance   | 0.14       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 12810      |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    reward               | 1.8206507  |\n",
      "|    std                  | 6.38       |\n",
      "|    value_loss           | 27.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1283         |\n",
      "|    time_elapsed         | 24692        |\n",
      "|    total_timesteps      | 2627584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075296196 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.4        |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.7         |\n",
      "|    n_updates            | 12820        |\n",
      "|    policy_gradient_loss | -0.00786     |\n",
      "|    reward               | -3.5110595   |\n",
      "|    std                  | 6.38         |\n",
      "|    value_loss           | 66.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1284        |\n",
      "|    time_elapsed         | 24711       |\n",
      "|    total_timesteps      | 2629632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009633813 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 12830       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    reward               | -12.1543665 |\n",
      "|    std                  | 6.38        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1285        |\n",
      "|    time_elapsed         | 24730       |\n",
      "|    total_timesteps      | 2631680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009587679 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 12840       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    reward               | 2.0644128   |\n",
      "|    std                  | 6.4         |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 24749       |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008569393 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 12850       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | 1.565407    |\n",
      "|    std                  | 6.41        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1287        |\n",
      "|    time_elapsed         | 24768       |\n",
      "|    total_timesteps      | 2635776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009914864 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    reward               | 0.6788908   |\n",
      "|    std                  | 6.42        |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 24787       |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010195553 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | -0.0167     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 12870       |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 11.09639    |\n",
      "|    std                  | 6.44        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1289         |\n",
      "|    time_elapsed         | 24808        |\n",
      "|    total_timesteps      | 2639872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140002165 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.7        |\n",
      "|    explained_variance   | 0.175        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 12880        |\n",
      "|    policy_gradient_loss | -0.00972     |\n",
      "|    reward               | -3.1814928   |\n",
      "|    std                  | 6.44         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1290         |\n",
      "|    time_elapsed         | 24827        |\n",
      "|    total_timesteps      | 2641920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076780254 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.7        |\n",
      "|    explained_variance   | 0.0927       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.3         |\n",
      "|    n_updates            | 12890        |\n",
      "|    policy_gradient_loss | -0.00965     |\n",
      "|    reward               | -0.085611984 |\n",
      "|    std                  | 6.45         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1291        |\n",
      "|    time_elapsed         | 24847       |\n",
      "|    total_timesteps      | 2643968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006979163 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.095       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 12900       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | 1.5641934   |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1292        |\n",
      "|    time_elapsed         | 24866       |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006505466 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44          |\n",
      "|    n_updates            | 12910       |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | 3.016729    |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 77.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 24885       |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011751188 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.0622      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | -4.239091   |\n",
      "|    std                  | 6.45        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1294        |\n",
      "|    time_elapsed         | 24903       |\n",
      "|    total_timesteps      | 2650112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009951001 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.0577      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | 0.42251125  |\n",
      "|    std                  | 6.46        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1295        |\n",
      "|    time_elapsed         | 24923       |\n",
      "|    total_timesteps      | 2652160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008430874 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.4        |\n",
      "|    n_updates            | 12940       |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    reward               | -0.9949102  |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6171902.97\n",
      "total_reward: 5171902.97\n",
      "total_cost: 240038.53\n",
      "total_trades: 61018\n",
      "Sharpe: 0.795\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 24942       |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010931078 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | -4.5356483  |\n",
      "|    std                  | 6.47        |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1297       |\n",
      "|    time_elapsed         | 24962      |\n",
      "|    total_timesteps      | 2656256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00867613 |\n",
      "|    clip_fraction        | 0.0673     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.9      |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 87         |\n",
      "|    n_updates            | 12960      |\n",
      "|    policy_gradient_loss | -0.0064    |\n",
      "|    reward               | 3.1955721  |\n",
      "|    std                  | 6.48       |\n",
      "|    value_loss           | 148        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 24982       |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011293684 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.9       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89          |\n",
      "|    n_updates            | 12970       |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    reward               | -0.23317944 |\n",
      "|    std                  | 6.49        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1299       |\n",
      "|    time_elapsed         | 25001      |\n",
      "|    total_timesteps      | 2660352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00867736 |\n",
      "|    clip_fraction        | 0.0946     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.9      |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.6       |\n",
      "|    n_updates            | 12980      |\n",
      "|    policy_gradient_loss | -0.00894   |\n",
      "|    reward               | -0.740756  |\n",
      "|    std                  | 6.49       |\n",
      "|    value_loss           | 76.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1300         |\n",
      "|    time_elapsed         | 25021        |\n",
      "|    total_timesteps      | 2662400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075975456 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95          |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.8         |\n",
      "|    n_updates            | 12990        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    reward               | -1.481328    |\n",
      "|    std                  | 6.51         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1301       |\n",
      "|    time_elapsed         | 25039      |\n",
      "|    total_timesteps      | 2664448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01047924 |\n",
      "|    clip_fraction        | 0.0733     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95        |\n",
      "|    explained_variance   | 0.316      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 90.2       |\n",
      "|    n_updates            | 13000      |\n",
      "|    policy_gradient_loss | -0.00965   |\n",
      "|    reward               | -10.425253 |\n",
      "|    std                  | 6.51       |\n",
      "|    value_loss           | 175        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1302        |\n",
      "|    time_elapsed         | 25059       |\n",
      "|    total_timesteps      | 2666496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018270988 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.2        |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 0.546063    |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 25078       |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011641411 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.214152   |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1304        |\n",
      "|    time_elapsed         | 25097       |\n",
      "|    total_timesteps      | 2670592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011180805 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.4        |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.1060172  |\n",
      "|    std                  | 6.53        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1305         |\n",
      "|    time_elapsed         | 25116        |\n",
      "|    total_timesteps      | 2672640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080917645 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.1        |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 98.8         |\n",
      "|    n_updates            | 13040        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | 1.0628356    |\n",
      "|    std                  | 6.54         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1306       |\n",
      "|    time_elapsed         | 25135      |\n",
      "|    total_timesteps      | 2674688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00975987 |\n",
      "|    clip_fraction        | 0.0829     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.1      |\n",
      "|    explained_variance   | 0.29       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.4       |\n",
      "|    n_updates            | 13050      |\n",
      "|    policy_gradient_loss | -0.00716   |\n",
      "|    reward               | 2.1717436  |\n",
      "|    std                  | 6.54       |\n",
      "|    value_loss           | 57.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 25154       |\n",
      "|    total_timesteps      | 2676736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010580066 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.6        |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 5.985911    |\n",
      "|    std                  | 6.56        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1308        |\n",
      "|    time_elapsed         | 25173       |\n",
      "|    total_timesteps      | 2678784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008415624 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 13070       |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | -1.0751648  |\n",
      "|    std                  | 6.58        |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 25193       |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009429122 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.3       |\n",
      "|    explained_variance   | 0.069       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    reward               | -3.1427975  |\n",
      "|    std                  | 6.59        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6043775.35\n",
      "total_reward: 5043775.35\n",
      "total_cost: 205374.10\n",
      "total_trades: 58800\n",
      "Sharpe: 0.770\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 25213       |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009084084 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.1        |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    reward               | -0.5925142  |\n",
      "|    std                  | 6.61        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1311         |\n",
      "|    time_elapsed         | 25231        |\n",
      "|    total_timesteps      | 2684928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084354095 |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.4        |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.4         |\n",
      "|    n_updates            | 13100        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | -0.5520058   |\n",
      "|    std                  | 6.62         |\n",
      "|    value_loss           | 194          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1312        |\n",
      "|    time_elapsed         | 25250       |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008988643 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | 0.0429      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 13110       |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    reward               | 5.0462537   |\n",
      "|    std                  | 6.63        |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1313         |\n",
      "|    time_elapsed         | 25270        |\n",
      "|    total_timesteps      | 2689024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135041475 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.6        |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 13120        |\n",
      "|    policy_gradient_loss | -0.00895     |\n",
      "|    reward               | 1.4926996    |\n",
      "|    std                  | 6.66         |\n",
      "|    value_loss           | 50.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1314        |\n",
      "|    time_elapsed         | 25288       |\n",
      "|    total_timesteps      | 2691072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008071229 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.7        |\n",
      "|    n_updates            | 13130       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    reward               | 1.040144    |\n",
      "|    std                  | 6.66        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 25307        |\n",
      "|    total_timesteps      | 2693120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00955057   |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -95.7        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 13140        |\n",
      "|    policy_gradient_loss | -0.00947     |\n",
      "|    reward               | -0.010545251 |\n",
      "|    std                  | 6.68         |\n",
      "|    value_loss           | 229          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 25326       |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013424464 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.1        |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | -15.954127  |\n",
      "|    std                  | 6.69        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 25346       |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011338496 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.8       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.6563962  |\n",
      "|    std                  | 6.71        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 25364       |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009602679 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -1.9387139  |\n",
      "|    std                  | 6.72        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1319        |\n",
      "|    time_elapsed         | 25383       |\n",
      "|    total_timesteps      | 2701312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00877409  |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.9       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.8        |\n",
      "|    n_updates            | 13180       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | -0.11241764 |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 25402       |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010648228 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | -2.6961439  |\n",
      "|    std                  | 6.74        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1321         |\n",
      "|    time_elapsed         | 25421        |\n",
      "|    total_timesteps      | 2705408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113848355 |\n",
      "|    clip_fraction        | 0.0777       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96          |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.5         |\n",
      "|    n_updates            | 13200        |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    reward               | 1.8547504    |\n",
      "|    std                  | 6.76         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1322         |\n",
      "|    time_elapsed         | 25440        |\n",
      "|    total_timesteps      | 2707456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074493815 |\n",
      "|    clip_fraction        | 0.0991       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.1        |\n",
      "|    explained_variance   | 0.288        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.7         |\n",
      "|    n_updates            | 13210        |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    reward               | 6.783051     |\n",
      "|    std                  | 6.76         |\n",
      "|    value_loss           | 230          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1323        |\n",
      "|    time_elapsed         | 25459       |\n",
      "|    total_timesteps      | 2709504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007579465 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -0.9051119  |\n",
      "|    std                  | 6.78        |\n",
      "|    value_loss           | 69.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5243969.51\n",
      "total_reward: 4243969.51\n",
      "total_cost: 184459.33\n",
      "total_trades: 56627\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 25478       |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012805931 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.2        |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    reward               | -0.6240847  |\n",
      "|    std                  | 6.79        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1325        |\n",
      "|    time_elapsed         | 25497       |\n",
      "|    total_timesteps      | 2713600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010483079 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.8        |\n",
      "|    n_updates            | 13240       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -12.923163  |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1326         |\n",
      "|    time_elapsed         | 25516        |\n",
      "|    total_timesteps      | 2715648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101611875 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.2        |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 13250        |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    reward               | 3.4742591    |\n",
      "|    std                  | 6.81         |\n",
      "|    value_loss           | 206          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 25534       |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010025607 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.92        |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | -0.9709618  |\n",
      "|    std                  | 6.83        |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 25553       |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006769269 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | 1.2620987   |\n",
      "|    std                  | 6.84        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1329         |\n",
      "|    time_elapsed         | 25572        |\n",
      "|    total_timesteps      | 2721792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035212846 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.4        |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.4         |\n",
      "|    n_updates            | 13280        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 4.6937284    |\n",
      "|    std                  | 6.85         |\n",
      "|    value_loss           | 192          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 25591       |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011952784 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | -4.386278   |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 25610       |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008789789 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | 2.3220463   |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1332         |\n",
      "|    time_elapsed         | 25630        |\n",
      "|    total_timesteps      | 2727936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064804433 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.6        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.7         |\n",
      "|    n_updates            | 13310        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | 2.616768     |\n",
      "|    std                  | 6.89         |\n",
      "|    value_loss           | 184          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1333        |\n",
      "|    time_elapsed         | 25648       |\n",
      "|    total_timesteps      | 2729984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007996985 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.7        |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | 6.0396028   |\n",
      "|    std                  | 6.9         |\n",
      "|    value_loss           | 81          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1334       |\n",
      "|    time_elapsed         | 25668      |\n",
      "|    total_timesteps      | 2732032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00971896 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.7      |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25.2       |\n",
      "|    n_updates            | 13330      |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    reward               | -2.821572  |\n",
      "|    std                  | 6.91       |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1335         |\n",
      "|    time_elapsed         | 25687        |\n",
      "|    total_timesteps      | 2734080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059670173 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.7        |\n",
      "|    explained_variance   | 0.136        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 13340        |\n",
      "|    policy_gradient_loss | -0.00849     |\n",
      "|    reward               | 0.5140649    |\n",
      "|    std                  | 6.92         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1336         |\n",
      "|    time_elapsed         | 25705        |\n",
      "|    total_timesteps      | 2736128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050931424 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.8        |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63           |\n",
      "|    n_updates            | 13350        |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    reward               | -7.7747335   |\n",
      "|    std                  | 6.93         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 25724       |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00617401  |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.8       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | -0.15111776 |\n",
      "|    std                  | 6.93        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5136432.47\n",
      "total_reward: 4136432.47\n",
      "total_cost: 201518.29\n",
      "total_trades: 57647\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1338         |\n",
      "|    time_elapsed         | 25744        |\n",
      "|    total_timesteps      | 2740224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074142567 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.8        |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.5         |\n",
      "|    n_updates            | 13370        |\n",
      "|    policy_gradient_loss | -0.00848     |\n",
      "|    reward               | -1.7214439   |\n",
      "|    std                  | 6.94         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1339         |\n",
      "|    time_elapsed         | 25763        |\n",
      "|    total_timesteps      | 2742272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050599184 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -96.8        |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 13380        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | -2.2516403   |\n",
      "|    std                  | 6.94         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1340       |\n",
      "|    time_elapsed         | 25781      |\n",
      "|    total_timesteps      | 2744320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00883491 |\n",
      "|    clip_fraction        | 0.0547     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.9      |\n",
      "|    explained_variance   | 0.568      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37.8       |\n",
      "|    n_updates            | 13390      |\n",
      "|    policy_gradient_loss | -0.00742   |\n",
      "|    reward               | 1.5830595  |\n",
      "|    std                  | 6.96       |\n",
      "|    value_loss           | 78.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 25800       |\n",
      "|    total_timesteps      | 2746368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012493574 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.9        |\n",
      "|    n_updates            | 13400       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -1.8624148  |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 97.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1342        |\n",
      "|    time_elapsed         | 25819       |\n",
      "|    total_timesteps      | 2748416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008498778 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87.4        |\n",
      "|    n_updates            | 13410       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 0.20974196  |\n",
      "|    std                  | 6.98        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1343        |\n",
      "|    time_elapsed         | 25838       |\n",
      "|    total_timesteps      | 2750464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006414569 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97         |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70          |\n",
      "|    n_updates            | 13420       |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    reward               | -0.6784795  |\n",
      "|    std                  | 6.99        |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 25857       |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011777514 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.1       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -1.0299733  |\n",
      "|    std                  | 7           |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1345         |\n",
      "|    time_elapsed         | 25878        |\n",
      "|    total_timesteps      | 2754560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060278717 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.1        |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.3         |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | -0.00794     |\n",
      "|    reward               | 0.10150231   |\n",
      "|    std                  | 7            |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1346         |\n",
      "|    time_elapsed         | 25899        |\n",
      "|    total_timesteps      | 2756608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076195737 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.1        |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 13450        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | -0.45445636  |\n",
      "|    std                  | 7.01         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1347       |\n",
      "|    time_elapsed         | 25919      |\n",
      "|    total_timesteps      | 2758656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00806951 |\n",
      "|    clip_fraction        | 0.0532     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.1      |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.8       |\n",
      "|    n_updates            | 13460      |\n",
      "|    policy_gradient_loss | -0.00743   |\n",
      "|    reward               | 0.33282655 |\n",
      "|    std                  | 7.02       |\n",
      "|    value_loss           | 58.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1348        |\n",
      "|    time_elapsed         | 25939       |\n",
      "|    total_timesteps      | 2760704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008852514 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | 0.69277185  |\n",
      "|    std                  | 7.03        |\n",
      "|    value_loss           | 99.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1349        |\n",
      "|    time_elapsed         | 25959       |\n",
      "|    total_timesteps      | 2762752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008613558 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 50.1        |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | -27.6352    |\n",
      "|    std                  | 7.03        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1350         |\n",
      "|    time_elapsed         | 25978        |\n",
      "|    total_timesteps      | 2764800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050303345 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.2        |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.6         |\n",
      "|    n_updates            | 13490        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | 3.4031434    |\n",
      "|    std                  | 7.04         |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1351        |\n",
      "|    time_elapsed         | 25997       |\n",
      "|    total_timesteps      | 2766848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011267712 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 13500       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | 0.39087132  |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5845215.85\n",
      "total_reward: 4845215.85\n",
      "total_cost: 183936.81\n",
      "total_trades: 56414\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1352        |\n",
      "|    time_elapsed         | 26017       |\n",
      "|    total_timesteps      | 2768896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006143029 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 13510       |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    reward               | 0.7824675   |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1353         |\n",
      "|    time_elapsed         | 26036        |\n",
      "|    total_timesteps      | 2770944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073332433 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 13520        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | -1.1928221   |\n",
      "|    std                  | 7.06         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 26055       |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012026941 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -0.42138317 |\n",
      "|    std                  | 7.09        |\n",
      "|    value_loss           | 65.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1355         |\n",
      "|    time_elapsed         | 26074        |\n",
      "|    total_timesteps      | 2775040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067983456 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.4        |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99           |\n",
      "|    n_updates            | 13540        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    reward               | -0.36340582  |\n",
      "|    std                  | 7.09         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 26093       |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009051634 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88          |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | -1.0150201  |\n",
      "|    std                  | 7.11        |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1357        |\n",
      "|    time_elapsed         | 26112       |\n",
      "|    total_timesteps      | 2779136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009534983 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 13560       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 0.5223787   |\n",
      "|    std                  | 7.11        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1358        |\n",
      "|    time_elapsed         | 26131       |\n",
      "|    total_timesteps      | 2781184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009913512 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 2.1165957   |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 90.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1359         |\n",
      "|    time_elapsed         | 26150        |\n",
      "|    total_timesteps      | 2783232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010323038  |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.6        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 13580        |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | -0.028704537 |\n",
      "|    std                  | 7.15         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1360       |\n",
      "|    time_elapsed         | 26168      |\n",
      "|    total_timesteps      | 2785280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00992804 |\n",
      "|    clip_fraction        | 0.0816     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.7      |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 66         |\n",
      "|    n_updates            | 13590      |\n",
      "|    policy_gradient_loss | -0.00915   |\n",
      "|    reward               | 2.080512   |\n",
      "|    std                  | 7.17       |\n",
      "|    value_loss           | 174        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 26188       |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013590658 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | -1.0194561  |\n",
      "|    std                  | 7.18        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1362        |\n",
      "|    time_elapsed         | 26207       |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008245277 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.3        |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | 1.4175088   |\n",
      "|    std                  | 7.19        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1363         |\n",
      "|    time_elapsed         | 26226        |\n",
      "|    total_timesteps      | 2791424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092872465 |\n",
      "|    clip_fraction        | 0.0768       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.9        |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.3         |\n",
      "|    n_updates            | 13620        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | -3.0290818   |\n",
      "|    std                  | 7.2          |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1364        |\n",
      "|    time_elapsed         | 26245       |\n",
      "|    total_timesteps      | 2793472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009246556 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 13630       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -0.78938156 |\n",
      "|    std                  | 7.22        |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 26264       |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010883074 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.8        |\n",
      "|    n_updates            | 13640       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    reward               | 1.5098239   |\n",
      "|    std                  | 7.23        |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5026878.01\n",
      "total_reward: 4026878.01\n",
      "total_cost: 196076.37\n",
      "total_trades: 56010\n",
      "Sharpe: 0.680\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1366         |\n",
      "|    time_elapsed         | 26283        |\n",
      "|    total_timesteps      | 2797568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117642265 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.9         |\n",
      "|    n_updates            | 13650        |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    reward               | -0.325761    |\n",
      "|    std                  | 7.24         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1367        |\n",
      "|    time_elapsed         | 26302       |\n",
      "|    total_timesteps      | 2799616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008430449 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.1        |\n",
      "|    n_updates            | 13660       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | 2.41635     |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1368        |\n",
      "|    time_elapsed         | 26321       |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009932062 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 2.042881    |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 26340       |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006887762 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 2.3849196   |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1370        |\n",
      "|    time_elapsed         | 26359       |\n",
      "|    total_timesteps      | 2805760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007633756 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 13690       |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    reward               | -3.2282882  |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 26378       |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011106063 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | -1.9370351  |\n",
      "|    std                  | 7.28        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1372        |\n",
      "|    time_elapsed         | 26398       |\n",
      "|    total_timesteps      | 2809856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009788903 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -1.4429966  |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 91.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1373       |\n",
      "|    time_elapsed         | 26417      |\n",
      "|    total_timesteps      | 2811904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00931311 |\n",
      "|    clip_fraction        | 0.0874     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.2      |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 70.5       |\n",
      "|    n_updates            | 13720      |\n",
      "|    policy_gradient_loss | -0.00717   |\n",
      "|    reward               | -9.81604   |\n",
      "|    std                  | 7.3        |\n",
      "|    value_loss           | 180        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 26436       |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009556605 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 13730       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 4.181035    |\n",
      "|    std                  | 7.32        |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 26455       |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009206755 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | -4.4081445  |\n",
      "|    std                  | 7.33        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 26474       |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009806206 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.9        |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 0.4309645   |\n",
      "|    std                  | 7.34        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1377         |\n",
      "|    time_elapsed         | 26494        |\n",
      "|    total_timesteps      | 2820096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090182675 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.4        |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 13760        |\n",
      "|    policy_gradient_loss | -0.00783     |\n",
      "|    reward               | 2.059777     |\n",
      "|    std                  | 7.35         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 26513       |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009567569 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | 0.6759382   |\n",
      "|    std                  | 7.36        |\n",
      "|    value_loss           | 63.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 26532       |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009292399 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.1        |\n",
      "|    n_updates            | 13780       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | -1.9064368  |\n",
      "|    std                  | 7.36        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1380         |\n",
      "|    time_elapsed         | 26551        |\n",
      "|    total_timesteps      | 2826240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073354635 |\n",
      "|    clip_fraction        | 0.0373       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.5        |\n",
      "|    explained_variance   | 0.0932       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 191          |\n",
      "|    n_updates            | 13790        |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    reward               | 2.6925797    |\n",
      "|    std                  | 7.37         |\n",
      "|    value_loss           | 410          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5587406.93\n",
      "total_reward: 4587406.93\n",
      "total_cost: 218365.04\n",
      "total_trades: 57664\n",
      "Sharpe: 0.715\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 26571       |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009963562 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.0753      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.9        |\n",
      "|    n_updates            | 13800       |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -2.3950994  |\n",
      "|    std                  | 7.37        |\n",
      "|    value_loss           | 99.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1382        |\n",
      "|    time_elapsed         | 26590       |\n",
      "|    total_timesteps      | 2830336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011092371 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.8        |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -1.0671014  |\n",
      "|    std                  | 7.38        |\n",
      "|    value_loss           | 84.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1383        |\n",
      "|    time_elapsed         | 26609       |\n",
      "|    total_timesteps      | 2832384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009947338 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 13820       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    reward               | 0.044519223 |\n",
      "|    std                  | 7.39        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1384         |\n",
      "|    time_elapsed         | 26629        |\n",
      "|    total_timesteps      | 2834432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097352695 |\n",
      "|    clip_fraction        | 0.0579       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 13830        |\n",
      "|    policy_gradient_loss | -0.00751     |\n",
      "|    reward               | -1.1378      |\n",
      "|    std                  | 7.41         |\n",
      "|    value_loss           | 98.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 26648       |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012538258 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -0.3862722  |\n",
      "|    std                  | 7.42        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1386         |\n",
      "|    time_elapsed         | 26667        |\n",
      "|    total_timesteps      | 2838528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066393954 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.7         |\n",
      "|    n_updates            | 13850        |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    reward               | 0.052489955  |\n",
      "|    std                  | 7.44         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1387        |\n",
      "|    time_elapsed         | 26686       |\n",
      "|    total_timesteps      | 2840576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007242729 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 13860       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | 0.7267366   |\n",
      "|    std                  | 7.46        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1388       |\n",
      "|    time_elapsed         | 26705      |\n",
      "|    total_timesteps      | 2842624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01582182 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.9      |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 13870      |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    reward               | 1.6060075  |\n",
      "|    std                  | 7.48       |\n",
      "|    value_loss           | 37.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 26725       |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007656972 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 13880       |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    reward               | -0.18548428 |\n",
      "|    std                  | 7.49        |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1390         |\n",
      "|    time_elapsed         | 26743        |\n",
      "|    total_timesteps      | 2846720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047384743 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.3         |\n",
      "|    n_updates            | 13890        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | -0.41471368  |\n",
      "|    std                  | 7.49         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1391         |\n",
      "|    time_elapsed         | 26763        |\n",
      "|    total_timesteps      | 2848768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057637636 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.103        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 13900        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | -0.85125726  |\n",
      "|    std                  | 7.5          |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 26782       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008870352 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 13910       |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | 1.8825966   |\n",
      "|    std                  | 7.51        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1393         |\n",
      "|    time_elapsed         | 26801        |\n",
      "|    total_timesteps      | 2852864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061449814 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65           |\n",
      "|    n_updates            | 13920        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    reward               | 0.6658784    |\n",
      "|    std                  | 7.52         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1394         |\n",
      "|    time_elapsed         | 26820        |\n",
      "|    total_timesteps      | 2854912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027084083 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.7         |\n",
      "|    n_updates            | 13930        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 2.0554068    |\n",
      "|    std                  | 7.52         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5194778.85\n",
      "total_reward: 4194778.85\n",
      "total_cost: 210869.05\n",
      "total_trades: 57604\n",
      "Sharpe: 0.692\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1395         |\n",
      "|    time_elapsed         | 26841        |\n",
      "|    total_timesteps      | 2856960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050428044 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 13940        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -0.93806595  |\n",
      "|    std                  | 7.54         |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1396         |\n",
      "|    time_elapsed         | 26861        |\n",
      "|    total_timesteps      | 2859008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050421506 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 13950        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | 2.5215526    |\n",
      "|    std                  | 7.55         |\n",
      "|    value_loss           | 88.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1397         |\n",
      "|    time_elapsed         | 26880        |\n",
      "|    total_timesteps      | 2861056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063438425 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.2         |\n",
      "|    n_updates            | 13960        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    reward               | 0.8921091    |\n",
      "|    std                  | 7.55         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 26899       |\n",
      "|    total_timesteps      | 2863104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006197814 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 13970       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | 1.1647824   |\n",
      "|    std                  | 7.56        |\n",
      "|    value_loss           | 88.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1399         |\n",
      "|    time_elapsed         | 26918        |\n",
      "|    total_timesteps      | 2865152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077719153 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.1         |\n",
      "|    n_updates            | 13980        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    reward               | 3.4105916    |\n",
      "|    std                  | 7.58         |\n",
      "|    value_loss           | 84.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 26937       |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007480333 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.6        |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | 0.75222504  |\n",
      "|    std                  | 7.58        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1401         |\n",
      "|    time_elapsed         | 26956        |\n",
      "|    total_timesteps      | 2869248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048554894 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.3        |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.7         |\n",
      "|    n_updates            | 14000        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | -0.8534031   |\n",
      "|    std                  | 7.59         |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1402        |\n",
      "|    time_elapsed         | 26975       |\n",
      "|    total_timesteps      | 2871296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007976317 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | -2.0194192  |\n",
      "|    std                  | 7.6         |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 26995       |\n",
      "|    total_timesteps      | 2873344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007007575 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.7        |\n",
      "|    n_updates            | 14020       |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    reward               | -1.3488932  |\n",
      "|    std                  | 7.6         |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1404         |\n",
      "|    time_elapsed         | 27013        |\n",
      "|    total_timesteps      | 2875392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069767735 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.4        |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 139          |\n",
      "|    n_updates            | 14030        |\n",
      "|    policy_gradient_loss | -0.00844     |\n",
      "|    reward               | -3.847292    |\n",
      "|    std                  | 7.61         |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1405         |\n",
      "|    time_elapsed         | 27033        |\n",
      "|    total_timesteps      | 2877440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073021306 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.5        |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.2         |\n",
      "|    n_updates            | 14040        |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    reward               | 14.931686    |\n",
      "|    std                  | 7.62         |\n",
      "|    value_loss           | 98.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1406        |\n",
      "|    time_elapsed         | 27051       |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007637137 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81          |\n",
      "|    n_updates            | 14050       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | -0.49357966 |\n",
      "|    std                  | 7.62        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1407         |\n",
      "|    time_elapsed         | 27071        |\n",
      "|    total_timesteps      | 2881536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055081546 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.5        |\n",
      "|    explained_variance   | 0.312        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.3         |\n",
      "|    n_updates            | 14060        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    reward               | 0.47664884   |\n",
      "|    std                  | 7.63         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1408        |\n",
      "|    time_elapsed         | 27090       |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002251412 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.1        |\n",
      "|    n_updates            | 14070       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    reward               | 0.4158079   |\n",
      "|    std                  | 7.63        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5738887.95\n",
      "total_reward: 4738887.95\n",
      "total_cost: 205942.94\n",
      "total_trades: 56840\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1409        |\n",
      "|    time_elapsed         | 27109       |\n",
      "|    total_timesteps      | 2885632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008749286 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    reward               | 2.8047807   |\n",
      "|    std                  | 7.65        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 27128       |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007917362 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.6        |\n",
      "|    n_updates            | 14090       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | -0.3602775  |\n",
      "|    std                  | 7.66        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 106       |\n",
      "|    iterations           | 1411      |\n",
      "|    time_elapsed         | 27147     |\n",
      "|    total_timesteps      | 2889728   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0053005 |\n",
      "|    clip_fraction        | 0.0184    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -99.7     |\n",
      "|    explained_variance   | 0.356     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 84.9      |\n",
      "|    n_updates            | 14100     |\n",
      "|    policy_gradient_loss | -0.00451  |\n",
      "|    reward               | 1.7600914 |\n",
      "|    std                  | 7.67      |\n",
      "|    value_loss           | 192       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1412        |\n",
      "|    time_elapsed         | 27167       |\n",
      "|    total_timesteps      | 2891776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008722038 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 14110       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -8.8209915  |\n",
      "|    std                  | 7.67        |\n",
      "|    value_loss           | 71.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 27185       |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011321305 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.5        |\n",
      "|    n_updates            | 14120       |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | 3.2839637   |\n",
      "|    std                  | 7.68        |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1414        |\n",
      "|    time_elapsed         | 27205       |\n",
      "|    total_timesteps      | 2895872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008797555 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 14130       |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    reward               | 0.51618296  |\n",
      "|    std                  | 7.69        |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1415        |\n",
      "|    time_elapsed         | 27224       |\n",
      "|    total_timesteps      | 2897920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005613747 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.1        |\n",
      "|    n_updates            | 14140       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | -0.8775424  |\n",
      "|    std                  | 7.69        |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 27244       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009749448 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | 2.2873495   |\n",
      "|    std                  | 7.73        |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1417         |\n",
      "|    time_elapsed         | 27263        |\n",
      "|    total_timesteps      | 2902016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076487307 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.9        |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.1         |\n",
      "|    n_updates            | 14160        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    reward               | -4.7734685   |\n",
      "|    std                  | 7.74         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1418        |\n",
      "|    time_elapsed         | 27282       |\n",
      "|    total_timesteps      | 2904064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007334712 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.3        |\n",
      "|    n_updates            | 14170       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | -12.501523  |\n",
      "|    std                  | 7.75        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1419        |\n",
      "|    time_elapsed         | 27301       |\n",
      "|    total_timesteps      | 2906112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010398779 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 14180       |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 0.5920199   |\n",
      "|    std                  | 7.75        |\n",
      "|    value_loss           | 49.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 27320       |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008472777 |\n",
      "|    clip_fraction        | 0.0406      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78          |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | 1.7308524   |\n",
      "|    std                  | 7.76        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1421        |\n",
      "|    time_elapsed         | 27340       |\n",
      "|    total_timesteps      | 2910208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006429962 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 14200       |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 8.277259    |\n",
      "|    std                  | 7.78        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1422         |\n",
      "|    time_elapsed         | 27359        |\n",
      "|    total_timesteps      | 2912256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073925294 |\n",
      "|    clip_fraction        | 0.0574       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.5         |\n",
      "|    n_updates            | 14210        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | 0.16223179   |\n",
      "|    std                  | 7.8          |\n",
      "|    value_loss           | 98.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5882845.80\n",
      "total_reward: 4882845.80\n",
      "total_cost: 246216.95\n",
      "total_trades: 59015\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 27379       |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010687422 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 14220       |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | -1.4998862  |\n",
      "|    std                  | 7.83        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1424         |\n",
      "|    time_elapsed         | 27398        |\n",
      "|    total_timesteps      | 2916352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051163854 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.5         |\n",
      "|    n_updates            | 14230        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    reward               | 3.8303204    |\n",
      "|    std                  | 7.84         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1425         |\n",
      "|    time_elapsed         | 27417        |\n",
      "|    total_timesteps      | 2918400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056120576 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.6         |\n",
      "|    n_updates            | 14240        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    reward               | 9.646548     |\n",
      "|    std                  | 7.85         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1426        |\n",
      "|    time_elapsed         | 27436       |\n",
      "|    total_timesteps      | 2920448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010524236 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    reward               | -1.5646036  |\n",
      "|    std                  | 7.86        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 27455       |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008628823 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    reward               | -0.5002701  |\n",
      "|    std                  | 7.88        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1428       |\n",
      "|    time_elapsed         | 27474      |\n",
      "|    total_timesteps      | 2924544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00663103 |\n",
      "|    clip_fraction        | 0.0207     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.312      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 38.8       |\n",
      "|    n_updates            | 14270      |\n",
      "|    policy_gradient_loss | -0.00634   |\n",
      "|    reward               | 2.5986695  |\n",
      "|    std                  | 7.89       |\n",
      "|    value_loss           | 144        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1429         |\n",
      "|    time_elapsed         | 27493        |\n",
      "|    total_timesteps      | 2926592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081358915 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.6         |\n",
      "|    n_updates            | 14280        |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    reward               | -5.753221    |\n",
      "|    std                  | 7.9          |\n",
      "|    value_loss           | 88.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 27512       |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008866651 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | 2.30452     |\n",
      "|    std                  | 7.9         |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1431        |\n",
      "|    time_elapsed         | 27531       |\n",
      "|    total_timesteps      | 2930688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007533688 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | -0.2818862  |\n",
      "|    std                  | 7.9         |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1432         |\n",
      "|    time_elapsed         | 27550        |\n",
      "|    total_timesteps      | 2932736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054572327 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.1         |\n",
      "|    n_updates            | 14310        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -2.0738056   |\n",
      "|    std                  | 7.91         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 27569       |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012915917 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 2.1939435   |\n",
      "|    std                  | 7.9         |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 27589       |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006841116 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.3        |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | 0.218376    |\n",
      "|    std                  | 7.91        |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1435         |\n",
      "|    time_elapsed         | 27609        |\n",
      "|    total_timesteps      | 2938880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019186026 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 14340        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -2.4647415   |\n",
      "|    std                  | 7.92         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1436       |\n",
      "|    time_elapsed         | 27630      |\n",
      "|    total_timesteps      | 2940928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00926646 |\n",
      "|    clip_fraction        | 0.0907     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.347      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30         |\n",
      "|    n_updates            | 14350      |\n",
      "|    policy_gradient_loss | -0.00959   |\n",
      "|    reward               | 1.9907353  |\n",
      "|    std                  | 7.92       |\n",
      "|    value_loss           | 77.7       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 2080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4639605.06\n",
      "total_reward: 3639605.06\n",
      "total_cost: 221796.20\n",
      "total_trades: 58026\n",
      "Sharpe: 0.654\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1437        |\n",
      "|    time_elapsed         | 27650       |\n",
      "|    total_timesteps      | 2942976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007969161 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.2        |\n",
      "|    n_updates            | 14360       |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | -1.5260731  |\n",
      "|    std                  | 7.94        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1438         |\n",
      "|    time_elapsed         | 27669        |\n",
      "|    total_timesteps      | 2945024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031779327 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 14370        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -20.753149   |\n",
      "|    std                  | 7.94         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 27688       |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010711324 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.3        |\n",
      "|    n_updates            | 14380       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    reward               | 1.2732456   |\n",
      "|    std                  | 7.97        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 27707       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011547996 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | 0.22141291  |\n",
      "|    std                  | 8.02        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1441        |\n",
      "|    time_elapsed         | 27726       |\n",
      "|    total_timesteps      | 2951168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008368883 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 0.12080117  |\n",
      "|    std                  | 8.03        |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1442        |\n",
      "|    time_elapsed         | 27745       |\n",
      "|    total_timesteps      | 2953216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006583329 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.3        |\n",
      "|    n_updates            | 14410       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    reward               | 1.3576683   |\n",
      "|    std                  | 8.04        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1443        |\n",
      "|    time_elapsed         | 27765       |\n",
      "|    total_timesteps      | 2955264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009083623 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    reward               | -3.0152924  |\n",
      "|    std                  | 8.05        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 27785       |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008387388 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    reward               | 1.563619    |\n",
      "|    std                  | 8.05        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1445        |\n",
      "|    time_elapsed         | 27804       |\n",
      "|    total_timesteps      | 2959360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007242548 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 14440       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | 7.300321    |\n",
      "|    std                  | 8.06        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1446        |\n",
      "|    time_elapsed         | 27823       |\n",
      "|    total_timesteps      | 2961408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006427786 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 14450       |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | 1.0770551   |\n",
      "|    std                  | 8.07        |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 27842       |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011079828 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 1.0408726   |\n",
      "|    std                  | 8.08        |\n",
      "|    value_loss           | 79.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 27861       |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007158818 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.1        |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | 0.4272292   |\n",
      "|    std                  | 8.08        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1449         |\n",
      "|    time_elapsed         | 27881        |\n",
      "|    total_timesteps      | 2967552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046843137 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.6         |\n",
      "|    n_updates            | 14480        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 4.4044228    |\n",
      "|    std                  | 8.09         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1450        |\n",
      "|    time_elapsed         | 27900       |\n",
      "|    total_timesteps      | 2969600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012274327 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    reward               | 1.6037561   |\n",
      "|    std                  | 8.12        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5284442.53\n",
      "total_reward: 4284442.53\n",
      "total_cost: 241309.99\n",
      "total_trades: 58766\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 27918       |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010037735 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.5        |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    reward               | 0.9411803   |\n",
      "|    std                  | 8.14        |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1452        |\n",
      "|    time_elapsed         | 27936       |\n",
      "|    total_timesteps      | 2973696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009566633 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.3        |\n",
      "|    n_updates            | 14510       |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | 0.3005985   |\n",
      "|    std                  | 8.15        |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1453        |\n",
      "|    time_elapsed         | 27955       |\n",
      "|    total_timesteps      | 2975744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010462677 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 14520       |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    reward               | 1.6198345   |\n",
      "|    std                  | 8.18        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1454         |\n",
      "|    time_elapsed         | 27973        |\n",
      "|    total_timesteps      | 2977792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077613425 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 14530        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | -1.255394    |\n",
      "|    std                  | 8.2          |\n",
      "|    value_loss           | 78.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1455        |\n",
      "|    time_elapsed         | 27991       |\n",
      "|    total_timesteps      | 2979840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009743608 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 14540       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    reward               | 1.645917    |\n",
      "|    std                  | 8.21        |\n",
      "|    value_loss           | 78          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1456        |\n",
      "|    time_elapsed         | 28012       |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011940537 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 14550       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -0.742078   |\n",
      "|    std                  | 8.24        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 28031       |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010186731 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.23        |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 0.90461     |\n",
      "|    std                  | 8.23        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1458        |\n",
      "|    time_elapsed         | 28049       |\n",
      "|    total_timesteps      | 2985984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004097872 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 14570       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | 0.7353288   |\n",
      "|    std                  | 8.24        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 28067       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004462058 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88          |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    reward               | -3.3518426  |\n",
      "|    std                  | 8.24        |\n",
      "|    value_loss           | 157         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1460         |\n",
      "|    time_elapsed         | 28087        |\n",
      "|    total_timesteps      | 2990080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075760223 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 14590        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 1.2616642    |\n",
      "|    std                  | 8.24         |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 28106       |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010133356 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 3.986365    |\n",
      "|    std                  | 8.25        |\n",
      "|    value_loss           | 67.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1462        |\n",
      "|    time_elapsed         | 28125       |\n",
      "|    total_timesteps      | 2994176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009773457 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 14610       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 22.730984   |\n",
      "|    std                  | 8.26        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1463        |\n",
      "|    time_elapsed         | 28143       |\n",
      "|    total_timesteps      | 2996224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009381244 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.2        |\n",
      "|    n_updates            | 14620       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | -0.81364036 |\n",
      "|    std                  | 8.26        |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1464        |\n",
      "|    time_elapsed         | 28161       |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009957157 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 14630       |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    reward               | 1.2837427   |\n",
      "|    std                  | 8.27        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5079906.65\n",
      "total_reward: 4079906.65\n",
      "total_cost: 250269.24\n",
      "total_trades: 59782\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1465         |\n",
      "|    time_elapsed         | 28180        |\n",
      "|    total_timesteps      | 3000320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071815304 |\n",
      "|    clip_fraction        | 0.0579       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.9         |\n",
      "|    n_updates            | 14640        |\n",
      "|    policy_gradient_loss | -0.008       |\n",
      "|    reward               | 1.2853981    |\n",
      "|    std                  | 8.28         |\n",
      "|    value_loss           | 166          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 28198       |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009546121 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.8        |\n",
      "|    n_updates            | 14650       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    reward               | 6.3126163   |\n",
      "|    std                  | 8.29        |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1467         |\n",
      "|    time_elapsed         | 28216        |\n",
      "|    total_timesteps      | 3004416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068042483 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 14660        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    reward               | 5.5774703    |\n",
      "|    std                  | 8.3          |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1468        |\n",
      "|    time_elapsed         | 28235       |\n",
      "|    total_timesteps      | 3006464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007428199 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 87          |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    reward               | -1.0680034  |\n",
      "|    std                  | 8.31        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1469        |\n",
      "|    time_elapsed         | 28253       |\n",
      "|    total_timesteps      | 3008512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002815512 |\n",
      "|    clip_fraction        | 0.00513     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 14680       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    reward               | 14.819551   |\n",
      "|    std                  | 8.32        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1470         |\n",
      "|    time_elapsed         | 28272        |\n",
      "|    total_timesteps      | 3010560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049094385 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 14690        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | -0.08662842  |\n",
      "|    std                  | 8.32         |\n",
      "|    value_loss           | 87.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1471         |\n",
      "|    time_elapsed         | 28290        |\n",
      "|    total_timesteps      | 3012608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059855515 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 14700        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 0.10772295   |\n",
      "|    std                  | 8.33         |\n",
      "|    value_loss           | 94.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1472        |\n",
      "|    time_elapsed         | 28308       |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004900524 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.3        |\n",
      "|    n_updates            | 14710       |\n",
      "|    policy_gradient_loss | -0.00573    |\n",
      "|    reward               | 0.29502645  |\n",
      "|    std                  | 8.34        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1473         |\n",
      "|    time_elapsed         | 28327        |\n",
      "|    total_timesteps      | 3016704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023212319 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 94.4         |\n",
      "|    n_updates            | 14720        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 1.8909045    |\n",
      "|    std                  | 8.34         |\n",
      "|    value_loss           | 181          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1474        |\n",
      "|    time_elapsed         | 28345       |\n",
      "|    total_timesteps      | 3018752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009544678 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 14730       |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    reward               | -0.5320437  |\n",
      "|    std                  | 8.37        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1475         |\n",
      "|    time_elapsed         | 28363        |\n",
      "|    total_timesteps      | 3020800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055755484 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.5         |\n",
      "|    n_updates            | 14740        |\n",
      "|    policy_gradient_loss | -0.00743     |\n",
      "|    reward               | -1.0125654   |\n",
      "|    std                  | 8.38         |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1476         |\n",
      "|    time_elapsed         | 28381        |\n",
      "|    total_timesteps      | 3022848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075817597 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.1         |\n",
      "|    n_updates            | 14750        |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    reward               | 2.593351     |\n",
      "|    std                  | 8.39         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1477        |\n",
      "|    time_elapsed         | 28400       |\n",
      "|    total_timesteps      | 3024896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011198964 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 14760       |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    reward               | -0.846999   |\n",
      "|    std                  | 8.42        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1478        |\n",
      "|    time_elapsed         | 28418       |\n",
      "|    total_timesteps      | 3026944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011573682 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.2        |\n",
      "|    n_updates            | 14770       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -2.4446278  |\n",
      "|    std                  | 8.44        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4356155.14\n",
      "total_reward: 3356155.14\n",
      "total_cost: 243502.29\n",
      "total_trades: 59435\n",
      "Sharpe: 0.631\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1479         |\n",
      "|    time_elapsed         | 28437        |\n",
      "|    total_timesteps      | 3028992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063101836 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.4         |\n",
      "|    n_updates            | 14780        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | 0.12400653   |\n",
      "|    std                  | 8.44         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1480        |\n",
      "|    time_elapsed         | 28455       |\n",
      "|    total_timesteps      | 3031040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005654062 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 59.9        |\n",
      "|    n_updates            | 14790       |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | -0.6244904  |\n",
      "|    std                  | 8.45        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 28474       |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013500966 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 14800       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.69747025  |\n",
      "|    std                  | 8.47        |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1482         |\n",
      "|    time_elapsed         | 28492        |\n",
      "|    total_timesteps      | 3035136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057788705 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.9         |\n",
      "|    n_updates            | 14810        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | 3.272521     |\n",
      "|    std                  | 8.47         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1483        |\n",
      "|    time_elapsed         | 28511       |\n",
      "|    total_timesteps      | 3037184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003920997 |\n",
      "|    clip_fraction        | 0.00811     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.7        |\n",
      "|    n_updates            | 14820       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -0.43446475 |\n",
      "|    std                  | 8.48        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1484        |\n",
      "|    time_elapsed         | 28529       |\n",
      "|    total_timesteps      | 3039232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005714721 |\n",
      "|    clip_fraction        | 0.0192      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 14830       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    reward               | -3.6983564  |\n",
      "|    std                  | 8.49        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1485        |\n",
      "|    time_elapsed         | 28548       |\n",
      "|    total_timesteps      | 3041280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007948622 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 14840       |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    reward               | 2.0734253   |\n",
      "|    std                  | 8.53        |\n",
      "|    value_loss           | 91.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1486         |\n",
      "|    time_elapsed         | 28566        |\n",
      "|    total_timesteps      | 3043328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014778376 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.7         |\n",
      "|    n_updates            | 14850        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    reward               | 11.072336    |\n",
      "|    std                  | 8.53         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1487        |\n",
      "|    time_elapsed         | 28584       |\n",
      "|    total_timesteps      | 3045376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010136507 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 14860       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 6.1728163   |\n",
      "|    std                  | 8.56        |\n",
      "|    value_loss           | 98.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 28603       |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009314226 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | 0.6742642   |\n",
      "|    std                  | 8.57        |\n",
      "|    value_loss           | 64.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1489        |\n",
      "|    time_elapsed         | 28622       |\n",
      "|    total_timesteps      | 3049472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007873372 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    reward               | 1.1756487   |\n",
      "|    std                  | 8.59        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1490        |\n",
      "|    time_elapsed         | 28640       |\n",
      "|    total_timesteps      | 3051520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008408379 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 94.1        |\n",
      "|    n_updates            | 14890       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | 4.7445827   |\n",
      "|    std                  | 8.6         |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1491        |\n",
      "|    time_elapsed         | 28658       |\n",
      "|    total_timesteps      | 3053568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010568849 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 14900       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -7.262673   |\n",
      "|    std                  | 8.64        |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1492        |\n",
      "|    time_elapsed         | 28677       |\n",
      "|    total_timesteps      | 3055616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00937373  |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 14910       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | -0.35361052 |\n",
      "|    std                  | 8.66        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1493        |\n",
      "|    time_elapsed         | 28696       |\n",
      "|    total_timesteps      | 3057664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010002791 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 14920       |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 7.1966743   |\n",
      "|    std                  | 8.67        |\n",
      "|    value_loss           | 95.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3898777.56\n",
      "total_reward: 2898777.56\n",
      "total_cost: 178692.49\n",
      "total_trades: 56228\n",
      "Sharpe: 0.578\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1494        |\n",
      "|    time_elapsed         | 28714       |\n",
      "|    total_timesteps      | 3059712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009180397 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 0.77912545  |\n",
      "|    std                  | 8.69        |\n",
      "|    value_loss           | 75          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1495        |\n",
      "|    time_elapsed         | 28732       |\n",
      "|    total_timesteps      | 3061760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009005884 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | -1.0257075  |\n",
      "|    std                  | 8.72        |\n",
      "|    value_loss           | 71          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1496        |\n",
      "|    time_elapsed         | 28751       |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009504392 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 14950       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | 0.26334593  |\n",
      "|    std                  | 8.72        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1497       |\n",
      "|    time_elapsed         | 28769      |\n",
      "|    total_timesteps      | 3065856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00793902 |\n",
      "|    clip_fraction        | 0.041      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 64         |\n",
      "|    n_updates            | 14960      |\n",
      "|    policy_gradient_loss | -0.00765   |\n",
      "|    reward               | -2.0335639 |\n",
      "|    std                  | 8.72       |\n",
      "|    value_loss           | 114        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 28787       |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007673531 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 14970       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 2.3780618   |\n",
      "|    std                  | 8.73        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 28806       |\n",
      "|    total_timesteps      | 3069952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006724318 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 14980       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -0.7068996  |\n",
      "|    std                  | 8.75        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1500         |\n",
      "|    time_elapsed         | 28824        |\n",
      "|    total_timesteps      | 3072000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069517773 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 14990        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    reward               | 2.7235055    |\n",
      "|    std                  | 8.75         |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1501        |\n",
      "|    time_elapsed         | 28843       |\n",
      "|    total_timesteps      | 3074048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009926895 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 15000       |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    reward               | -3.0471692  |\n",
      "|    std                  | 8.77        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1502         |\n",
      "|    time_elapsed         | 28862        |\n",
      "|    total_timesteps      | 3076096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069559375 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.1         |\n",
      "|    n_updates            | 15010        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | -0.105944715 |\n",
      "|    std                  | 8.79         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1503         |\n",
      "|    time_elapsed         | 28880        |\n",
      "|    total_timesteps      | 3078144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044308617 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.8         |\n",
      "|    n_updates            | 15020        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | -3.9243708   |\n",
      "|    std                  | 8.79         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1504         |\n",
      "|    time_elapsed         | 28899        |\n",
      "|    total_timesteps      | 3080192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050938595 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.3         |\n",
      "|    n_updates            | 15030        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | -4.420575    |\n",
      "|    std                  | 8.8          |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 28918       |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008759221 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 15040       |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | 0.47482726  |\n",
      "|    std                  | 8.79        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1506         |\n",
      "|    time_elapsed         | 28936        |\n",
      "|    total_timesteps      | 3084288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025707977 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.9         |\n",
      "|    n_updates            | 15050        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 1.8179444    |\n",
      "|    std                  | 8.8          |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1507         |\n",
      "|    time_elapsed         | 28956        |\n",
      "|    total_timesteps      | 3086336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034425275 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59           |\n",
      "|    n_updates            | 15060        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | -0.84265107  |\n",
      "|    std                  | 8.8          |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4411430.64\n",
      "total_reward: 3411430.64\n",
      "total_cost: 213147.48\n",
      "total_trades: 57827\n",
      "Sharpe: 0.636\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1508        |\n",
      "|    time_elapsed         | 28974       |\n",
      "|    total_timesteps      | 3088384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008067411 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 15070       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | -4.139344   |\n",
      "|    std                  | 8.8         |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1509        |\n",
      "|    time_elapsed         | 28993       |\n",
      "|    total_timesteps      | 3090432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007430381 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 15080       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    reward               | 2.9633682   |\n",
      "|    std                  | 8.82        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1510         |\n",
      "|    time_elapsed         | 29011        |\n",
      "|    total_timesteps      | 3092480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045019854 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.6         |\n",
      "|    n_updates            | 15090        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    reward               | 2.9084022    |\n",
      "|    std                  | 8.83         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1511         |\n",
      "|    time_elapsed         | 29030        |\n",
      "|    total_timesteps      | 3094528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066462723 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 15100        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 3.121301     |\n",
      "|    std                  | 8.84         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1512         |\n",
      "|    time_elapsed         | 29049        |\n",
      "|    total_timesteps      | 3096576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075863497 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 15110        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    reward               | -2.8851461   |\n",
      "|    std                  | 8.85         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1513         |\n",
      "|    time_elapsed         | 29067        |\n",
      "|    total_timesteps      | 3098624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059130923 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.7         |\n",
      "|    n_updates            | 15120        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    reward               | -0.09292579  |\n",
      "|    std                  | 8.86         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1514        |\n",
      "|    time_elapsed         | 29085       |\n",
      "|    total_timesteps      | 3100672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003161979 |\n",
      "|    clip_fraction        | 0.00337     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.4        |\n",
      "|    n_updates            | 15130       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 0.2229508   |\n",
      "|    std                  | 8.87        |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1515         |\n",
      "|    time_elapsed         | 29104        |\n",
      "|    total_timesteps      | 3102720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104210805 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.6         |\n",
      "|    n_updates            | 15140        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    reward               | 2.055532     |\n",
      "|    std                  | 8.9          |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1516         |\n",
      "|    time_elapsed         | 29122        |\n",
      "|    total_timesteps      | 3104768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067039505 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.2         |\n",
      "|    n_updates            | 15150        |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    reward               | 6.7200055    |\n",
      "|    std                  | 8.91         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1517         |\n",
      "|    time_elapsed         | 29140        |\n",
      "|    total_timesteps      | 3106816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036956132 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.3         |\n",
      "|    n_updates            | 15160        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    reward               | -3.0568285   |\n",
      "|    std                  | 8.91         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1518        |\n",
      "|    time_elapsed         | 29158       |\n",
      "|    total_timesteps      | 3108864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010292698 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 15170       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | -9.396217   |\n",
      "|    std                  | 8.92        |\n",
      "|    value_loss           | 81.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1519         |\n",
      "|    time_elapsed         | 29177        |\n",
      "|    total_timesteps      | 3110912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077004954 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.7         |\n",
      "|    n_updates            | 15180        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | -0.9932216   |\n",
      "|    std                  | 8.93         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 29197       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007304181 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 15190       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -0.27651674 |\n",
      "|    std                  | 8.93        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1521        |\n",
      "|    time_elapsed         | 29215       |\n",
      "|    total_timesteps      | 3115008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002895391 |\n",
      "|    clip_fraction        | 0.00259     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 15200       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | 6.0050325   |\n",
      "|    std                  | 8.93        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4866830.96\n",
      "total_reward: 3866830.96\n",
      "total_cost: 236897.74\n",
      "total_trades: 59750\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 29234       |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011266554 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    reward               | 0.64359784  |\n",
      "|    std                  | 8.96        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1523        |\n",
      "|    time_elapsed         | 29252       |\n",
      "|    total_timesteps      | 3119104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009208646 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.7        |\n",
      "|    n_updates            | 15220       |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | -0.30846983 |\n",
      "|    std                  | 8.97        |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1524         |\n",
      "|    time_elapsed         | 29270        |\n",
      "|    total_timesteps      | 3121152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062405393 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87           |\n",
      "|    n_updates            | 15230        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | -18.366035   |\n",
      "|    std                  | 8.97         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1525        |\n",
      "|    time_elapsed         | 29288       |\n",
      "|    total_timesteps      | 3123200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011617528 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 15240       |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | 0.49592257  |\n",
      "|    std                  | 9           |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1526         |\n",
      "|    time_elapsed         | 29307        |\n",
      "|    total_timesteps      | 3125248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067646047 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.4         |\n",
      "|    n_updates            | 15250        |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    reward               | 0.043024052  |\n",
      "|    std                  | 9.01         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1527         |\n",
      "|    time_elapsed         | 29325        |\n",
      "|    total_timesteps      | 3127296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021691981 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.5         |\n",
      "|    n_updates            | 15260        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 4.8646464    |\n",
      "|    std                  | 9            |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1528        |\n",
      "|    time_elapsed         | 29343       |\n",
      "|    total_timesteps      | 3129344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004807676 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.8        |\n",
      "|    n_updates            | 15270       |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | -3.2207112  |\n",
      "|    std                  | 9.02        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1529        |\n",
      "|    time_elapsed         | 29361       |\n",
      "|    total_timesteps      | 3131392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011508866 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 15280       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    reward               | -1.9160154  |\n",
      "|    std                  | 9.05        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1530         |\n",
      "|    time_elapsed         | 29380        |\n",
      "|    total_timesteps      | 3133440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052409777 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.5         |\n",
      "|    n_updates            | 15290        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    reward               | 3.2036388    |\n",
      "|    std                  | 9.06         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1531         |\n",
      "|    time_elapsed         | 29398        |\n",
      "|    total_timesteps      | 3135488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047539948 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.8         |\n",
      "|    n_updates            | 15300        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 11.97645     |\n",
      "|    std                  | 9.07         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1532         |\n",
      "|    time_elapsed         | 29417        |\n",
      "|    total_timesteps      | 3137536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044784164 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 15310        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    reward               | -1.5689842   |\n",
      "|    std                  | 9.07         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1533        |\n",
      "|    time_elapsed         | 29436       |\n",
      "|    total_timesteps      | 3139584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009515716 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 15320       |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    reward               | 1.9158578   |\n",
      "|    std                  | 9.08        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1534         |\n",
      "|    time_elapsed         | 29454        |\n",
      "|    total_timesteps      | 3141632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067343093 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.5         |\n",
      "|    n_updates            | 15330        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -0.001500525 |\n",
      "|    std                  | 9.09         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1535         |\n",
      "|    time_elapsed         | 29472        |\n",
      "|    total_timesteps      | 3143680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018845533 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 15340        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | -9.279413    |\n",
      "|    std                  | 9.09         |\n",
      "|    value_loss           | 85           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4184454.15\n",
      "total_reward: 3184454.15\n",
      "total_cost: 199123.12\n",
      "total_trades: 58318\n",
      "Sharpe: 0.602\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1536        |\n",
      "|    time_elapsed         | 29491       |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011933219 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 15350       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | -0.27898332 |\n",
      "|    std                  | 9.11        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1537        |\n",
      "|    time_elapsed         | 29509       |\n",
      "|    total_timesteps      | 3147776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009353165 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.2        |\n",
      "|    n_updates            | 15360       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 1.4181961   |\n",
      "|    std                  | 9.12        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1538         |\n",
      "|    time_elapsed         | 29528        |\n",
      "|    total_timesteps      | 3149824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099245105 |\n",
      "|    clip_fraction        | 0.0581       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.108        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.1         |\n",
      "|    n_updates            | 15370        |\n",
      "|    policy_gradient_loss | -0.00831     |\n",
      "|    reward               | 0.66504717   |\n",
      "|    std                  | 9.14         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1539        |\n",
      "|    time_elapsed         | 29546       |\n",
      "|    total_timesteps      | 3151872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011840622 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 15380       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 1.8109257   |\n",
      "|    std                  | 9.16        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1540        |\n",
      "|    time_elapsed         | 29565       |\n",
      "|    total_timesteps      | 3153920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009536572 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74          |\n",
      "|    n_updates            | 15390       |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | -1.8524671  |\n",
      "|    std                  | 9.18        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1541        |\n",
      "|    time_elapsed         | 29583       |\n",
      "|    total_timesteps      | 3155968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007658055 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 15400       |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | -2.1188116  |\n",
      "|    std                  | 9.19        |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1542         |\n",
      "|    time_elapsed         | 29601        |\n",
      "|    total_timesteps      | 3158016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067399126 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 15410        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | -6.736171    |\n",
      "|    std                  | 9.21         |\n",
      "|    value_loss           | 75.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1543       |\n",
      "|    time_elapsed         | 29620      |\n",
      "|    total_timesteps      | 3160064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00897933 |\n",
      "|    clip_fraction        | 0.0713     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.219      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33         |\n",
      "|    n_updates            | 15420      |\n",
      "|    policy_gradient_loss | -0.00761   |\n",
      "|    reward               | 0.7160996  |\n",
      "|    std                  | 9.23       |\n",
      "|    value_loss           | 93.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1544         |\n",
      "|    time_elapsed         | 29638        |\n",
      "|    total_timesteps      | 3162112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077867224 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.8         |\n",
      "|    n_updates            | 15430        |\n",
      "|    policy_gradient_loss | -0.00931     |\n",
      "|    reward               | 0.4426468    |\n",
      "|    std                  | 9.25         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1545        |\n",
      "|    time_elapsed         | 29657       |\n",
      "|    total_timesteps      | 3164160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002178039 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 92.1        |\n",
      "|    n_updates            | 15440       |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    reward               | 0.6284742   |\n",
      "|    std                  | 9.26        |\n",
      "|    value_loss           | 207         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1546        |\n",
      "|    time_elapsed         | 29675       |\n",
      "|    total_timesteps      | 3166208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006876941 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 15450       |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | 4.7363343   |\n",
      "|    std                  | 9.27        |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1547        |\n",
      "|    time_elapsed         | 29694       |\n",
      "|    total_timesteps      | 3168256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007389269 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 15460       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | 2.4561975   |\n",
      "|    std                  | 9.28        |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1548         |\n",
      "|    time_elapsed         | 29712        |\n",
      "|    total_timesteps      | 3170304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046248627 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56           |\n",
      "|    n_updates            | 15470        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | -4.123673    |\n",
      "|    std                  | 9.29         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 29731       |\n",
      "|    total_timesteps      | 3172352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007293811 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 15480       |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | 2.0355644   |\n",
      "|    std                  | 9.31        |\n",
      "|    value_loss           | 68.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4842722.19\n",
      "total_reward: 3842722.19\n",
      "total_cost: 209431.11\n",
      "total_trades: 60317\n",
      "Sharpe: 0.665\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1550       |\n",
      "|    time_elapsed         | 29750      |\n",
      "|    total_timesteps      | 3174400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00579148 |\n",
      "|    clip_fraction        | 0.0278     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.336      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 86.8       |\n",
      "|    n_updates            | 15490      |\n",
      "|    policy_gradient_loss | -0.00564   |\n",
      "|    reward               | -0.6045032 |\n",
      "|    std                  | 9.31       |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1551         |\n",
      "|    time_elapsed         | 29768        |\n",
      "|    total_timesteps      | 3176448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012613264 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52           |\n",
      "|    n_updates            | 15500        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | -25.9516     |\n",
      "|    std                  | 9.31         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1552         |\n",
      "|    time_elapsed         | 29787        |\n",
      "|    total_timesteps      | 3178496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053266105 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.5         |\n",
      "|    n_updates            | 15510        |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    reward               | 3.128554     |\n",
      "|    std                  | 9.32         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1553       |\n",
      "|    time_elapsed         | 29805      |\n",
      "|    total_timesteps      | 3180544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01036039 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.22       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.9       |\n",
      "|    n_updates            | 15520      |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    reward               | 4.5826497  |\n",
      "|    std                  | 9.34       |\n",
      "|    value_loss           | 40         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1554        |\n",
      "|    time_elapsed         | 29825       |\n",
      "|    total_timesteps      | 3182592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006066029 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 15530       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | -0.5442486  |\n",
      "|    std                  | 9.35        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1555         |\n",
      "|    time_elapsed         | 29846        |\n",
      "|    total_timesteps      | 3184640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029824951 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.8         |\n",
      "|    n_updates            | 15540        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | -5.144041    |\n",
      "|    std                  | 9.35         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1556        |\n",
      "|    time_elapsed         | 29865       |\n",
      "|    total_timesteps      | 3186688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012556475 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 15550       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -3.938184   |\n",
      "|    std                  | 9.38        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1557         |\n",
      "|    time_elapsed         | 29885        |\n",
      "|    total_timesteps      | 3188736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077003995 |\n",
      "|    clip_fraction        | 0.0505       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.4         |\n",
      "|    n_updates            | 15560        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -3.9128485   |\n",
      "|    std                  | 9.38         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1558        |\n",
      "|    time_elapsed         | 29904       |\n",
      "|    total_timesteps      | 3190784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008170618 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.7        |\n",
      "|    n_updates            | 15570       |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    reward               | 0.46442294  |\n",
      "|    std                  | 9.4         |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1559        |\n",
      "|    time_elapsed         | 29922       |\n",
      "|    total_timesteps      | 3192832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013505522 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.0731      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.3        |\n",
      "|    n_updates            | 15580       |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | 0.10340364  |\n",
      "|    std                  | 9.41        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 29941       |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008576504 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 15590       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.715585    |\n",
      "|    std                  | 9.41        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1561        |\n",
      "|    time_elapsed         | 29959       |\n",
      "|    total_timesteps      | 3196928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002365936 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.2        |\n",
      "|    n_updates            | 15600       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    reward               | 0.6353367   |\n",
      "|    std                  | 9.42        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1562        |\n",
      "|    time_elapsed         | 29978       |\n",
      "|    total_timesteps      | 3198976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002566933 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 15610       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | 3.374771    |\n",
      "|    std                  | 9.43        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1563        |\n",
      "|    time_elapsed         | 29997       |\n",
      "|    total_timesteps      | 3201024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00924797  |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 15620       |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    reward               | -0.57890975 |\n",
      "|    std                  | 9.41        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5155264.90\n",
      "total_reward: 4155264.90\n",
      "total_cost: 228864.31\n",
      "total_trades: 60651\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 30016       |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008974457 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.7        |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    reward               | 0.40161437  |\n",
      "|    std                  | 9.44        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1565       |\n",
      "|    time_elapsed         | 30036      |\n",
      "|    total_timesteps      | 3205120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00300781 |\n",
      "|    clip_fraction        | 0.00327    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -106       |\n",
      "|    explained_variance   | 0.241      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 108        |\n",
      "|    n_updates            | 15640      |\n",
      "|    policy_gradient_loss | -0.00402   |\n",
      "|    reward               | -3.098063  |\n",
      "|    std                  | 9.44       |\n",
      "|    value_loss           | 186        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1566        |\n",
      "|    time_elapsed         | 30054       |\n",
      "|    total_timesteps      | 3207168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008873399 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 15650       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.5409879  |\n",
      "|    std                  | 9.45        |\n",
      "|    value_loss           | 72.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1567        |\n",
      "|    time_elapsed         | 30073       |\n",
      "|    total_timesteps      | 3209216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008699875 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 15660       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -2.3300695  |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1568        |\n",
      "|    time_elapsed         | 30091       |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004007427 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 15670       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -0.8547759  |\n",
      "|    std                  | 9.49        |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1569         |\n",
      "|    time_elapsed         | 30109        |\n",
      "|    total_timesteps      | 3213312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016708047 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.5         |\n",
      "|    n_updates            | 15680        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -0.30948234  |\n",
      "|    std                  | 9.5          |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1570        |\n",
      "|    time_elapsed         | 30127       |\n",
      "|    total_timesteps      | 3215360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011388281 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 15690       |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    reward               | -0.90480447 |\n",
      "|    std                  | 9.53        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1571         |\n",
      "|    time_elapsed         | 30146        |\n",
      "|    total_timesteps      | 3217408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068528457 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.131        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 15700        |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    reward               | 0.6022655    |\n",
      "|    std                  | 9.56         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1572         |\n",
      "|    time_elapsed         | 30164        |\n",
      "|    total_timesteps      | 3219456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069045033 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.122        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.9         |\n",
      "|    n_updates            | 15710        |\n",
      "|    policy_gradient_loss | -0.00933     |\n",
      "|    reward               | 0.120817386  |\n",
      "|    std                  | 9.57         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1573         |\n",
      "|    time_elapsed         | 30182        |\n",
      "|    total_timesteps      | 3221504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085777985 |\n",
      "|    clip_fraction        | 0.0736       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.4         |\n",
      "|    n_updates            | 15720        |\n",
      "|    policy_gradient_loss | -0.00905     |\n",
      "|    reward               | -2.2103648   |\n",
      "|    std                  | 9.57         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1574         |\n",
      "|    time_elapsed         | 30201        |\n",
      "|    total_timesteps      | 3223552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067516565 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.2         |\n",
      "|    n_updates            | 15730        |\n",
      "|    policy_gradient_loss | -0.00876     |\n",
      "|    reward               | 1.6108879    |\n",
      "|    std                  | 9.58         |\n",
      "|    value_loss           | 96.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1575         |\n",
      "|    time_elapsed         | 30219        |\n",
      "|    total_timesteps      | 3225600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023567567 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.4         |\n",
      "|    n_updates            | 15740        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | -1.3169128   |\n",
      "|    std                  | 9.59         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1576         |\n",
      "|    time_elapsed         | 30238        |\n",
      "|    total_timesteps      | 3227648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103988405 |\n",
      "|    clip_fraction        | 0.0758       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.154        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.5         |\n",
      "|    n_updates            | 15750        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    reward               | 2.6640468    |\n",
      "|    std                  | 9.62         |\n",
      "|    value_loss           | 99.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1577        |\n",
      "|    time_elapsed         | 30256       |\n",
      "|    total_timesteps      | 3229696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009515445 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 15760       |\n",
      "|    policy_gradient_loss | -0.00874    |\n",
      "|    reward               | 0.6129174   |\n",
      "|    std                  | 9.63        |\n",
      "|    value_loss           | 68.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4596466.55\n",
      "total_reward: 3596466.55\n",
      "total_cost: 212025.79\n",
      "total_trades: 59713\n",
      "Sharpe: 0.666\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1578        |\n",
      "|    time_elapsed         | 30274       |\n",
      "|    total_timesteps      | 3231744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008273267 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 15770       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | -0.75532895 |\n",
      "|    std                  | 9.65        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1579         |\n",
      "|    time_elapsed         | 30293        |\n",
      "|    total_timesteps      | 3233792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044427696 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.16         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.3         |\n",
      "|    n_updates            | 15780        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | 10.77755     |\n",
      "|    std                  | 9.65         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1580        |\n",
      "|    time_elapsed         | 30311       |\n",
      "|    total_timesteps      | 3235840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009748437 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 15790       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | 0.6379616   |\n",
      "|    std                  | 9.69        |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1581         |\n",
      "|    time_elapsed         | 30329        |\n",
      "|    total_timesteps      | 3237888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059495023 |\n",
      "|    clip_fraction        | 0.042        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.3         |\n",
      "|    n_updates            | 15800        |\n",
      "|    policy_gradient_loss | -0.00745     |\n",
      "|    reward               | 1.7996645    |\n",
      "|    std                  | 9.72         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1582         |\n",
      "|    time_elapsed         | 30348        |\n",
      "|    total_timesteps      | 3239936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030304936 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 15810        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -3.6466904   |\n",
      "|    std                  | 9.72         |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1583        |\n",
      "|    time_elapsed         | 30366       |\n",
      "|    total_timesteps      | 3241984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008353586 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 15820       |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    reward               | -2.6223683  |\n",
      "|    std                  | 9.73        |\n",
      "|    value_loss           | 97.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1584        |\n",
      "|    time_elapsed         | 30385       |\n",
      "|    total_timesteps      | 3244032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011389979 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 15830       |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    reward               | -0.43997753 |\n",
      "|    std                  | 9.74        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1585        |\n",
      "|    time_elapsed         | 30404       |\n",
      "|    total_timesteps      | 3246080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008808479 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82          |\n",
      "|    n_updates            | 15840       |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    reward               | 1.1373595   |\n",
      "|    std                  | 9.76        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1586         |\n",
      "|    time_elapsed         | 30422        |\n",
      "|    total_timesteps      | 3248128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048147785 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.0485       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 15850        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | 0.1301149    |\n",
      "|    std                  | 9.78         |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1587        |\n",
      "|    time_elapsed         | 30440       |\n",
      "|    total_timesteps      | 3250176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010718789 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 15860       |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 0.18370605  |\n",
      "|    std                  | 9.79        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 30458       |\n",
      "|    total_timesteps      | 3252224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012025429 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.1        |\n",
      "|    n_updates            | 15870       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | -1.3970095  |\n",
      "|    std                  | 9.81        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1589        |\n",
      "|    time_elapsed         | 30476       |\n",
      "|    total_timesteps      | 3254272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005509533 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.6        |\n",
      "|    n_updates            | 15880       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 1.3784885   |\n",
      "|    std                  | 9.83        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1590        |\n",
      "|    time_elapsed         | 30495       |\n",
      "|    total_timesteps      | 3256320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010510598 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 15890       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | -1.627376   |\n",
      "|    std                  | 9.84        |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1591        |\n",
      "|    time_elapsed         | 30515       |\n",
      "|    total_timesteps      | 3258368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010362174 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.8        |\n",
      "|    n_updates            | 15900       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -3.3825471  |\n",
      "|    std                  | 9.86        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4933786.46\n",
      "total_reward: 3933786.46\n",
      "total_cost: 221386.55\n",
      "total_trades: 59207\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1592         |\n",
      "|    time_elapsed         | 30533        |\n",
      "|    total_timesteps      | 3260416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044756113 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74           |\n",
      "|    n_updates            | 15910        |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | -0.21955352  |\n",
      "|    std                  | 9.87         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1593         |\n",
      "|    time_elapsed         | 30551        |\n",
      "|    total_timesteps      | 3262464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069837663 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 15920        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | -0.55570465  |\n",
      "|    std                  | 9.87         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1594        |\n",
      "|    time_elapsed         | 30569       |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009160408 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.73        |\n",
      "|    n_updates            | 15930       |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | 0.91559553  |\n",
      "|    std                  | 9.88        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1595         |\n",
      "|    time_elapsed         | 30587        |\n",
      "|    total_timesteps      | 3266560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050376607 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.28         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69           |\n",
      "|    n_updates            | 15940        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | -0.069055684 |\n",
      "|    std                  | 9.88         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1596         |\n",
      "|    time_elapsed         | 30606        |\n",
      "|    total_timesteps      | 3268608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021194257 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.5         |\n",
      "|    n_updates            | 15950        |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    reward               | 4.2456255    |\n",
      "|    std                  | 9.89         |\n",
      "|    value_loss           | 180          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1597        |\n",
      "|    time_elapsed         | 30624       |\n",
      "|    total_timesteps      | 3270656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009815613 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | -5.139942   |\n",
      "|    std                  | 9.92        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1598        |\n",
      "|    time_elapsed         | 30643       |\n",
      "|    total_timesteps      | 3272704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009143179 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 15970       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    reward               | 1.3438749   |\n",
      "|    std                  | 9.94        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1599        |\n",
      "|    time_elapsed         | 30661       |\n",
      "|    total_timesteps      | 3274752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000831984 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52          |\n",
      "|    n_updates            | 15980       |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    reward               | -6.3780193  |\n",
      "|    std                  | 9.94        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1600        |\n",
      "|    time_elapsed         | 30680       |\n",
      "|    total_timesteps      | 3276800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005014375 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 15990       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -1.053767   |\n",
      "|    std                  | 9.95        |\n",
      "|    value_loss           | 78.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1601        |\n",
      "|    time_elapsed         | 30698       |\n",
      "|    total_timesteps      | 3278848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008913668 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 0.16257268  |\n",
      "|    std                  | 9.97        |\n",
      "|    value_loss           | 82          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1602         |\n",
      "|    time_elapsed         | 30717        |\n",
      "|    total_timesteps      | 3280896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004569114  |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 16010        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | -0.021195171 |\n",
      "|    std                  | 9.97         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1603        |\n",
      "|    time_elapsed         | 30735       |\n",
      "|    total_timesteps      | 3282944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004059963 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 185         |\n",
      "|    n_updates            | 16020       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | 24.65608    |\n",
      "|    std                  | 9.99        |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1604        |\n",
      "|    time_elapsed         | 30753       |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011917464 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | 2.0785682   |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1605         |\n",
      "|    time_elapsed         | 30772        |\n",
      "|    total_timesteps      | 3287040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071834056 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.5         |\n",
      "|    n_updates            | 16040        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | 0.88224375   |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1606         |\n",
      "|    time_elapsed         | 30790        |\n",
      "|    total_timesteps      | 3289088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028171116 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.3         |\n",
      "|    n_updates            | 16050        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | 2.2010262    |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4662638.75\n",
      "total_reward: 3662638.75\n",
      "total_cost: 188665.89\n",
      "total_trades: 57730\n",
      "Sharpe: 0.678\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1607         |\n",
      "|    time_elapsed         | 30808        |\n",
      "|    total_timesteps      | 3291136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015190743 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 16060        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 3.0594678    |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 61.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1608        |\n",
      "|    time_elapsed         | 30827       |\n",
      "|    total_timesteps      | 3293184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010873988 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 16070       |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    reward               | -2.3032644  |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 76.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1609         |\n",
      "|    time_elapsed         | 30845        |\n",
      "|    total_timesteps      | 3295232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051873685 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.5         |\n",
      "|    n_updates            | 16080        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 0.79711074   |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 98.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1610         |\n",
      "|    time_elapsed         | 30864        |\n",
      "|    total_timesteps      | 3297280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021099013 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.4         |\n",
      "|    n_updates            | 16090        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | -0.8629684   |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1611         |\n",
      "|    time_elapsed         | 30882        |\n",
      "|    total_timesteps      | 3299328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114257205 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 16100        |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    reward               | 1.9168106    |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1612         |\n",
      "|    time_elapsed         | 30900        |\n",
      "|    total_timesteps      | 3301376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042756433 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.4         |\n",
      "|    n_updates            | 16110        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | 0.84430206   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1613         |\n",
      "|    time_elapsed         | 30919        |\n",
      "|    total_timesteps      | 3303424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017294368 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.2         |\n",
      "|    n_updates            | 16120        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -8.848629    |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1614        |\n",
      "|    time_elapsed         | 30937       |\n",
      "|    total_timesteps      | 3305472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013360397 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.0433      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    reward               | 0.53528845  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1615        |\n",
      "|    time_elapsed         | 30955       |\n",
      "|    total_timesteps      | 3307520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008019468 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -0.34915712 |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 88.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1616         |\n",
      "|    time_elapsed         | 30973        |\n",
      "|    total_timesteps      | 3309568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072817607 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.133        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.00824     |\n",
      "|    reward               | -12.862894   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1617         |\n",
      "|    time_elapsed         | 30992        |\n",
      "|    total_timesteps      | 3311616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030211662 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.9         |\n",
      "|    n_updates            | 16160        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 0.51209825   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1618        |\n",
      "|    time_elapsed         | 31010       |\n",
      "|    total_timesteps      | 3313664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011364373 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.22        |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    reward               | 1.8831522   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1619        |\n",
      "|    time_elapsed         | 31028       |\n",
      "|    total_timesteps      | 3315712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006352204 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 16180       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | 2.6935973   |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1620         |\n",
      "|    time_elapsed         | 31047        |\n",
      "|    total_timesteps      | 3317760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043453868 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50           |\n",
      "|    n_updates            | 16190        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | 2.597373     |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5109873.30\n",
      "total_reward: 4109873.30\n",
      "total_cost: 208566.08\n",
      "total_trades: 57402\n",
      "Sharpe: 0.726\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1621       |\n",
      "|    time_elapsed         | 31065      |\n",
      "|    total_timesteps      | 3319808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00981915 |\n",
      "|    clip_fraction        | 0.0742     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 16200      |\n",
      "|    policy_gradient_loss | -0.00868   |\n",
      "|    reward               | -0.7597813 |\n",
      "|    std                  | 10.3       |\n",
      "|    value_loss           | 37.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1622         |\n",
      "|    time_elapsed         | 31083        |\n",
      "|    total_timesteps      | 3321856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059485766 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.8         |\n",
      "|    n_updates            | 16210        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | -3.812391    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1623         |\n",
      "|    time_elapsed         | 31102        |\n",
      "|    total_timesteps      | 3323904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049275625 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.3         |\n",
      "|    n_updates            | 16220        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    reward               | -3.6692727   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1624        |\n",
      "|    time_elapsed         | 31120       |\n",
      "|    total_timesteps      | 3325952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009490872 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 16230       |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    reward               | 1.8442467   |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 75.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 31139       |\n",
      "|    total_timesteps      | 3328000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008815326 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 16240       |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | 1.4498377   |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1626         |\n",
      "|    time_elapsed         | 31158        |\n",
      "|    total_timesteps      | 3330048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062774885 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.5         |\n",
      "|    n_updates            | 16250        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    reward               | -1.2603317   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1627        |\n",
      "|    time_elapsed         | 31176       |\n",
      "|    total_timesteps      | 3332096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007089588 |\n",
      "|    clip_fraction        | 0.0303      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.18        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 16260       |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    reward               | 0.9119086   |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1628        |\n",
      "|    time_elapsed         | 31194       |\n",
      "|    total_timesteps      | 3334144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00995226  |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.0304      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    reward               | -0.63152903 |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1629        |\n",
      "|    time_elapsed         | 31212       |\n",
      "|    total_timesteps      | 3336192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008471342 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.9174349   |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1630         |\n",
      "|    time_elapsed         | 31231        |\n",
      "|    total_timesteps      | 3338240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052502854 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.1         |\n",
      "|    n_updates            | 16290        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | -8.752216    |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 94.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1631         |\n",
      "|    time_elapsed         | 31249        |\n",
      "|    total_timesteps      | 3340288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041048587 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 16300        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | -2.8475838   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 66.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 31268       |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011034184 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    reward               | 0.49211857  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 82.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1633         |\n",
      "|    time_elapsed         | 31287        |\n",
      "|    total_timesteps      | 3344384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061817435 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 16320        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | 0.5890359    |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1634        |\n",
      "|    time_elapsed         | 31305       |\n",
      "|    total_timesteps      | 3346432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005661803 |\n",
      "|    clip_fraction        | 0.00825     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 16330       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | -0.16102189 |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4877542.83\n",
      "total_reward: 3877542.83\n",
      "total_cost: 216646.03\n",
      "total_trades: 58453\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1635        |\n",
      "|    time_elapsed         | 31324       |\n",
      "|    total_timesteps      | 3348480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011070947 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -4.5227394  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1636        |\n",
      "|    time_elapsed         | 31342       |\n",
      "|    total_timesteps      | 3350528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004099413 |\n",
      "|    clip_fraction        | 0.00718     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 16350       |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    reward               | -1.0254102  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1637         |\n",
      "|    time_elapsed         | 31360        |\n",
      "|    total_timesteps      | 3352576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034377058 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.9         |\n",
      "|    n_updates            | 16360        |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    reward               | -5.3102827   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 31378       |\n",
      "|    total_timesteps      | 3354624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011384826 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | -0.32762617 |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1639         |\n",
      "|    time_elapsed         | 31396        |\n",
      "|    total_timesteps      | 3356672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068952832 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.1         |\n",
      "|    n_updates            | 16380        |\n",
      "|    policy_gradient_loss | -0.00861     |\n",
      "|    reward               | 0.19876684   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 96.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 106        |\n",
      "|    iterations           | 1640       |\n",
      "|    time_elapsed         | 31415      |\n",
      "|    total_timesteps      | 3358720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00465753 |\n",
      "|    clip_fraction        | 0.0132     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -109       |\n",
      "|    explained_variance   | 0.433      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.5       |\n",
      "|    n_updates            | 16390      |\n",
      "|    policy_gradient_loss | -0.00511   |\n",
      "|    reward               | 13.373568  |\n",
      "|    std                  | 10.6       |\n",
      "|    value_loss           | 126        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1641         |\n",
      "|    time_elapsed         | 31433        |\n",
      "|    total_timesteps      | 3360768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017625701 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.4         |\n",
      "|    n_updates            | 16400        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 1.4617008    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1642        |\n",
      "|    time_elapsed         | 31452       |\n",
      "|    total_timesteps      | 3362816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008932503 |\n",
      "|    clip_fraction        | 0.0889      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0883      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 16410       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.7461307   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1643         |\n",
      "|    time_elapsed         | 31470        |\n",
      "|    total_timesteps      | 3364864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029479843 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.2         |\n",
      "|    n_updates            | 16420        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 0.6837894    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1644         |\n",
      "|    time_elapsed         | 31488        |\n",
      "|    total_timesteps      | 3366912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053218314 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52           |\n",
      "|    n_updates            | 16430        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | 5.184074     |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1645        |\n",
      "|    time_elapsed         | 31507       |\n",
      "|    total_timesteps      | 3368960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008153608 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    reward               | -2.5045297  |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1646        |\n",
      "|    time_elapsed         | 31525       |\n",
      "|    total_timesteps      | 3371008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007857598 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 16450       |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | -2.29373    |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1647         |\n",
      "|    time_elapsed         | 31543        |\n",
      "|    total_timesteps      | 3373056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039769113 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.169        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.4         |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | 4.320545     |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 99.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1648        |\n",
      "|    time_elapsed         | 31562       |\n",
      "|    total_timesteps      | 3375104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006143729 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 16470       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 1.0261132   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4681788.04\n",
      "total_reward: 3681788.04\n",
      "total_cost: 182876.87\n",
      "total_trades: 56561\n",
      "Sharpe: 0.697\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1649        |\n",
      "|    time_elapsed         | 31580       |\n",
      "|    total_timesteps      | 3377152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008146346 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | -0.5131257  |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 75.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1650         |\n",
      "|    time_elapsed         | 31598        |\n",
      "|    total_timesteps      | 3379200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017971303 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.291        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.9         |\n",
      "|    n_updates            | 16490        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -0.11782819  |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1651        |\n",
      "|    time_elapsed         | 31617       |\n",
      "|    total_timesteps      | 3381248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004962064 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    reward               | 6.703774    |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1652        |\n",
      "|    time_elapsed         | 31635       |\n",
      "|    total_timesteps      | 3383296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010891013 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0707      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -0.5200914  |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1653         |\n",
      "|    time_elapsed         | 31653        |\n",
      "|    total_timesteps      | 3385344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044187554 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 16520        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | -0.45178708  |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1654        |\n",
      "|    time_elapsed         | 31672       |\n",
      "|    total_timesteps      | 3387392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006498467 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0816      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 16530       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | 0.77302986  |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1655        |\n",
      "|    time_elapsed         | 31690       |\n",
      "|    total_timesteps      | 3389440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010170182 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | 0.8931859   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1656        |\n",
      "|    time_elapsed         | 31708       |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009672344 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 16550       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 6.4357085   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1657         |\n",
      "|    time_elapsed         | 31727        |\n",
      "|    total_timesteps      | 3393536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010388334 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.5         |\n",
      "|    n_updates            | 16560        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | 1.3052375    |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1658        |\n",
      "|    time_elapsed         | 31745       |\n",
      "|    total_timesteps      | 3395584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008381064 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 0.44385734  |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1659         |\n",
      "|    time_elapsed         | 31763        |\n",
      "|    total_timesteps      | 3397632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096550705 |\n",
      "|    clip_fraction        | 0.0663       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.182        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 16580        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 0.20659779   |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1660         |\n",
      "|    time_elapsed         | 31782        |\n",
      "|    total_timesteps      | 3399680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033337818 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | -0.8396856   |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1661         |\n",
      "|    time_elapsed         | 31800        |\n",
      "|    total_timesteps      | 3401728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049125934 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.2         |\n",
      "|    n_updates            | 16600        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    reward               | -2.049176    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1662        |\n",
      "|    time_elapsed         | 31820       |\n",
      "|    total_timesteps      | 3403776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009376412 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.0419      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -2.6346092  |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4811510.33\n",
      "total_reward: 3811510.33\n",
      "total_cost: 196008.87\n",
      "total_trades: 58379\n",
      "Sharpe: 0.708\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1663         |\n",
      "|    time_elapsed         | 31838        |\n",
      "|    total_timesteps      | 3405824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073222686 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 16620        |\n",
      "|    policy_gradient_loss | -0.00925     |\n",
      "|    reward               | 0.75810355   |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 96.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1664         |\n",
      "|    time_elapsed         | 31857        |\n",
      "|    total_timesteps      | 3407872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014000749 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.3         |\n",
      "|    n_updates            | 16630        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | -14.16965    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1665        |\n",
      "|    time_elapsed         | 31875       |\n",
      "|    total_timesteps      | 3409920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012162188 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.0653      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 16640       |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    reward               | 0.7765412   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 67.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1666        |\n",
      "|    time_elapsed         | 31894       |\n",
      "|    total_timesteps      | 3411968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008121806 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.83        |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | 2.4893086   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1667         |\n",
      "|    time_elapsed         | 31912        |\n",
      "|    total_timesteps      | 3414016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072395788 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.049        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.5         |\n",
      "|    n_updates            | 16660        |\n",
      "|    policy_gradient_loss | -0.00912     |\n",
      "|    reward               | -1.1507946   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1668        |\n",
      "|    time_elapsed         | 31931       |\n",
      "|    total_timesteps      | 3416064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006701638 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.0897      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 16670       |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    reward               | -7.2373004  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1669        |\n",
      "|    time_elapsed         | 31949       |\n",
      "|    total_timesteps      | 3418112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008815449 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 16680       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 0.46474427  |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1670         |\n",
      "|    time_elapsed         | 31968        |\n",
      "|    total_timesteps      | 3420160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040881755 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.0675       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.8         |\n",
      "|    n_updates            | 16690        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | -2.5548959   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1671        |\n",
      "|    time_elapsed         | 31986       |\n",
      "|    total_timesteps      | 3422208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008065322 |\n",
      "|    clip_fraction        | 0.034       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 16700       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 9.91244     |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1672         |\n",
      "|    time_elapsed         | 32005        |\n",
      "|    total_timesteps      | 3424256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070565715 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.8         |\n",
      "|    n_updates            | 16710        |\n",
      "|    policy_gradient_loss | -0.00985     |\n",
      "|    reward               | -0.44471583  |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 50.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1673        |\n",
      "|    time_elapsed         | 32024       |\n",
      "|    total_timesteps      | 3426304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008210532 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.096       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 16720       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | 0.7190722   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 82.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1674         |\n",
      "|    time_elapsed         | 32043        |\n",
      "|    total_timesteps      | 3428352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034774407 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.6         |\n",
      "|    n_updates            | 16730        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    reward               | 0.6531327    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 98           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1675         |\n",
      "|    time_elapsed         | 32062        |\n",
      "|    total_timesteps      | 3430400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046671117 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.103        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.9         |\n",
      "|    n_updates            | 16740        |\n",
      "|    policy_gradient_loss | -0.00764     |\n",
      "|    reward               | 1.9023837    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1676         |\n",
      "|    time_elapsed         | 32080        |\n",
      "|    total_timesteps      | 3432448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026544188 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.25         |\n",
      "|    n_updates            | 16750        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | -3.5600805   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4144228.22\n",
      "total_reward: 3144228.22\n",
      "total_cost: 182196.37\n",
      "total_trades: 57153\n",
      "Sharpe: 0.700\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 106          |\n",
      "|    iterations           | 1677         |\n",
      "|    time_elapsed         | 32098        |\n",
      "|    total_timesteps      | 3434496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033293609 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.5         |\n",
      "|    n_updates            | 16760        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | -0.009126977 |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 75.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 1678        |\n",
      "|    time_elapsed         | 32117       |\n",
      "|    total_timesteps      | 3436544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004605391 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 16770       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    reward               | 0.4727448   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 74.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1679        |\n",
      "|    time_elapsed         | 32135       |\n",
      "|    total_timesteps      | 3438592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007561177 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    reward               | 0.12221636  |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1680        |\n",
      "|    time_elapsed         | 32154       |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007503972 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 3.513298    |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 91.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1681         |\n",
      "|    time_elapsed         | 32172        |\n",
      "|    total_timesteps      | 3442688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036686745 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.1         |\n",
      "|    n_updates            | 16800        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -0.6335555   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 91.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1682        |\n",
      "|    time_elapsed         | 32192       |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001746239 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | -0.23913875 |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1683        |\n",
      "|    time_elapsed         | 32210       |\n",
      "|    total_timesteps      | 3446784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009275052 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.12        |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -2.2823548  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1684        |\n",
      "|    time_elapsed         | 32228       |\n",
      "|    total_timesteps      | 3448832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004939817 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 16830       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    reward               | -1.0112832  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1685         |\n",
      "|    time_elapsed         | 32246        |\n",
      "|    total_timesteps      | 3450880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030537404 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.0665       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.3         |\n",
      "|    n_updates            | 16840        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | -2.953858    |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 87.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1686        |\n",
      "|    time_elapsed         | 32265       |\n",
      "|    total_timesteps      | 3452928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004391916 |\n",
      "|    clip_fraction        | 0.00537     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 16850       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | -0.5881421  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1687        |\n",
      "|    time_elapsed         | 32283       |\n",
      "|    total_timesteps      | 3454976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007589744 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | 6.593391    |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 69.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1688        |\n",
      "|    time_elapsed         | 32302       |\n",
      "|    total_timesteps      | 3457024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422143 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.0489      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 16870       |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | 1.042281    |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 83.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1689        |\n",
      "|    time_elapsed         | 32320       |\n",
      "|    total_timesteps      | 3459072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005736967 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 16880       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | -3.5767329  |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1690         |\n",
      "|    time_elapsed         | 32338        |\n",
      "|    total_timesteps      | 3461120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069708596 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.6         |\n",
      "|    n_updates            | 16890        |\n",
      "|    policy_gradient_loss | -0.00873     |\n",
      "|    reward               | 1.5271153    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 59.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3867522.96\n",
      "total_reward: 2867522.96\n",
      "total_cost: 188120.60\n",
      "total_trades: 57259\n",
      "Sharpe: 0.673\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1691         |\n",
      "|    time_elapsed         | 32357        |\n",
      "|    total_timesteps      | 3463168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039056838 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67           |\n",
      "|    n_updates            | 16900        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | 0.42283475   |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 87.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1692        |\n",
      "|    time_elapsed         | 32375       |\n",
      "|    total_timesteps      | 3465216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005305319 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 16910       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 4.9276137   |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 71.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1693        |\n",
      "|    time_elapsed         | 32393       |\n",
      "|    total_timesteps      | 3467264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005743076 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.21        |\n",
      "|    n_updates            | 16920       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | -4.8255787  |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1694         |\n",
      "|    time_elapsed         | 32413        |\n",
      "|    total_timesteps      | 3469312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076281764 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.151        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 16930        |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    reward               | 0.58992124   |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 77.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1695        |\n",
      "|    time_elapsed         | 32432       |\n",
      "|    total_timesteps      | 3471360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008057967 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 16940       |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | -0.8677516  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1696         |\n",
      "|    time_elapsed         | 32450        |\n",
      "|    total_timesteps      | 3473408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061499747 |\n",
      "|    clip_fraction        | 0.0443       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 16950        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | 0.5269217    |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 30.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1697        |\n",
      "|    time_elapsed         | 32469       |\n",
      "|    total_timesteps      | 3475456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006704968 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 16960       |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | 0.31100208  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1698        |\n",
      "|    time_elapsed         | 32487       |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010042358 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.46077517  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 77.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1699         |\n",
      "|    time_elapsed         | 32506        |\n",
      "|    total_timesteps      | 3479552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032416056 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.151        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41           |\n",
      "|    n_updates            | 16980        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -4.1314583   |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 86.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1700        |\n",
      "|    time_elapsed         | 32525       |\n",
      "|    total_timesteps      | 3481600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010897636 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.17        |\n",
      "|    n_updates            | 16990       |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    reward               | 1.6298633   |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1701         |\n",
      "|    time_elapsed         | 32543        |\n",
      "|    total_timesteps      | 3483648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038258783 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.208        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 17000        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -0.35345307  |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 86.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1702         |\n",
      "|    time_elapsed         | 32562        |\n",
      "|    total_timesteps      | 3485696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047860807 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 17010        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | -1.4468218   |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 83.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1703        |\n",
      "|    time_elapsed         | 32580       |\n",
      "|    total_timesteps      | 3487744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008238293 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | 2.095916    |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1704        |\n",
      "|    time_elapsed         | 32599       |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004302481 |\n",
      "|    clip_fraction        | 0.00752     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 17030       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 1.7319465   |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1705         |\n",
      "|    time_elapsed         | 32618        |\n",
      "|    total_timesteps      | 3491840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031297214 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.4         |\n",
      "|    n_updates            | 17040        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | 5.4822564    |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4722254.16\n",
      "total_reward: 3722254.16\n",
      "total_cost: 190093.01\n",
      "total_trades: 58177\n",
      "Sharpe: 0.758\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 32636       |\n",
      "|    total_timesteps      | 3493888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004406543 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    reward               | -0.5572456  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1707        |\n",
      "|    time_elapsed         | 32655       |\n",
      "|    total_timesteps      | 3495936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008572727 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.68        |\n",
      "|    n_updates            | 17060       |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    reward               | -1.6211374  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1708         |\n",
      "|    time_elapsed         | 32673        |\n",
      "|    total_timesteps      | 3497984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061129266 |\n",
      "|    clip_fraction        | 0.0618       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.5         |\n",
      "|    n_updates            | 17070        |\n",
      "|    policy_gradient_loss | -0.00854     |\n",
      "|    reward               | -5.0932245   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 89.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1709         |\n",
      "|    time_elapsed         | 32692        |\n",
      "|    total_timesteps      | 3500032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016796519 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.1         |\n",
      "|    n_updates            | 17080        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 2.0185852    |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 81.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1710        |\n",
      "|    time_elapsed         | 32710       |\n",
      "|    total_timesteps      | 3502080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012387658 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 17090       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.83122987 |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1711        |\n",
      "|    time_elapsed         | 32729       |\n",
      "|    total_timesteps      | 3504128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008854637 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 17100       |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    reward               | 0.43136257  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1712        |\n",
      "|    time_elapsed         | 32747       |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003564031 |\n",
      "|    clip_fraction        | 0.00684     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 17110       |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    reward               | -0.4275782  |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1713          |\n",
      "|    time_elapsed         | 32765         |\n",
      "|    total_timesteps      | 3508224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045397386 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -112          |\n",
      "|    explained_variance   | 0.483         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.5          |\n",
      "|    n_updates            | 17120         |\n",
      "|    policy_gradient_loss | -0.00109      |\n",
      "|    reward               | -1.5101643    |\n",
      "|    std                  | 11.7          |\n",
      "|    value_loss           | 40.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1714        |\n",
      "|    time_elapsed         | 32783       |\n",
      "|    total_timesteps      | 3510272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007203175 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | 2.0409844   |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1715         |\n",
      "|    time_elapsed         | 32802        |\n",
      "|    total_timesteps      | 3512320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042839767 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.9         |\n",
      "|    n_updates            | 17140        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | -1.1358831   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 91.9         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1716       |\n",
      "|    time_elapsed         | 32820      |\n",
      "|    total_timesteps      | 3514368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00861275 |\n",
      "|    clip_fraction        | 0.0318     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -112       |\n",
      "|    explained_variance   | 0.242      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 43.6       |\n",
      "|    n_updates            | 17150      |\n",
      "|    policy_gradient_loss | -0.00625   |\n",
      "|    reward               | -6.0322022 |\n",
      "|    std                  | 11.7       |\n",
      "|    value_loss           | 76.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1717         |\n",
      "|    time_elapsed         | 32839        |\n",
      "|    total_timesteps      | 3516416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076348847 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 17160        |\n",
      "|    policy_gradient_loss | -0.008       |\n",
      "|    reward               | -0.4418911   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1718         |\n",
      "|    time_elapsed         | 32857        |\n",
      "|    total_timesteps      | 3518464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045065666 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.3         |\n",
      "|    n_updates            | 17170        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | 0.44192812   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 80.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1719        |\n",
      "|    time_elapsed         | 32876       |\n",
      "|    total_timesteps      | 3520512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003715364 |\n",
      "|    clip_fraction        | 0.0084      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62          |\n",
      "|    n_updates            | 17180       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 5.7260346   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 87.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4070036.83\n",
      "total_reward: 3070036.83\n",
      "total_cost: 202895.08\n",
      "total_trades: 59120\n",
      "Sharpe: 0.670\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 32895       |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006160777 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | 1.8050685   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 32913       |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007095985 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 17200       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | 0.6294553   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1722       |\n",
      "|    time_elapsed         | 32931      |\n",
      "|    total_timesteps      | 3526656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00822071 |\n",
      "|    clip_fraction        | 0.0586     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -112       |\n",
      "|    explained_variance   | 0.134      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 50.4       |\n",
      "|    n_updates            | 17210      |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    reward               | -0.1485556 |\n",
      "|    std                  | 11.8       |\n",
      "|    value_loss           | 105        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1723        |\n",
      "|    time_elapsed         | 32950       |\n",
      "|    total_timesteps      | 3528704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006910581 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -4.5629687  |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1724         |\n",
      "|    time_elapsed         | 32968        |\n",
      "|    total_timesteps      | 3530752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064698975 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.294        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 17230        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | -0.34085116  |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1725         |\n",
      "|    time_elapsed         | 32987        |\n",
      "|    total_timesteps      | 3532800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026598643 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.28         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.2         |\n",
      "|    n_updates            | 17240        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | 0.5573335    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 98.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1726         |\n",
      "|    time_elapsed         | 33005        |\n",
      "|    total_timesteps      | 3534848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046153497 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.1         |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | -2.644468    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 85.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1727         |\n",
      "|    time_elapsed         | 33023        |\n",
      "|    total_timesteps      | 3536896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022512968 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 17260        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | -3.1898663   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1728         |\n",
      "|    time_elapsed         | 33042        |\n",
      "|    total_timesteps      | 3538944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075422926 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 17270        |\n",
      "|    policy_gradient_loss | -0.00947     |\n",
      "|    reward               | 0.17869315   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 74.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1729        |\n",
      "|    time_elapsed         | 33060       |\n",
      "|    total_timesteps      | 3540992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007389621 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 17280       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | 2.6545146   |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 94.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1730         |\n",
      "|    time_elapsed         | 33079        |\n",
      "|    total_timesteps      | 3543040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019410859 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 17290        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | -0.64663976  |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 96.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1731         |\n",
      "|    time_elapsed         | 33097        |\n",
      "|    total_timesteps      | 3545088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037042284 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 17300        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 0.20745833   |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1732          |\n",
      "|    time_elapsed         | 33116         |\n",
      "|    total_timesteps      | 3547136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047508994 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -112          |\n",
      "|    explained_variance   | 0.289         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33.5          |\n",
      "|    n_updates            | 17310         |\n",
      "|    policy_gradient_loss | -0.000863     |\n",
      "|    reward               | 1.0206691     |\n",
      "|    std                  | 11.9          |\n",
      "|    value_loss           | 112           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1733        |\n",
      "|    time_elapsed         | 33134       |\n",
      "|    total_timesteps      | 3549184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008918235 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.00909     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | -3.6715422  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4069175.02\n",
      "total_reward: 3069175.02\n",
      "total_cost: 200826.34\n",
      "total_trades: 58438\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1734        |\n",
      "|    time_elapsed         | 33153       |\n",
      "|    total_timesteps      | 3551232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009398913 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | -0.0124     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 17330       |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -0.18554425 |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1735        |\n",
      "|    time_elapsed         | 33171       |\n",
      "|    total_timesteps      | 3553280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004016719 |\n",
      "|    clip_fraction        | 0.00762     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 17340       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | -1.3294612  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 79          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1736         |\n",
      "|    time_elapsed         | 33189        |\n",
      "|    total_timesteps      | 3555328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040246155 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.2         |\n",
      "|    n_updates            | 17350        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | -1.1088905   |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 89.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1737        |\n",
      "|    time_elapsed         | 33208       |\n",
      "|    total_timesteps      | 3557376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006496746 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 17360       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 0.8194205   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1738         |\n",
      "|    time_elapsed         | 33226        |\n",
      "|    total_timesteps      | 3559424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010906584 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.321        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 17370        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 0.54328364   |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 54.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1739        |\n",
      "|    time_elapsed         | 33245       |\n",
      "|    total_timesteps      | 3561472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002874859 |\n",
      "|    clip_fraction        | 0.00562     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | -0.40011656 |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 98.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1740          |\n",
      "|    time_elapsed         | 33264         |\n",
      "|    total_timesteps      | 3563520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050470326 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.327         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.2          |\n",
      "|    n_updates            | 17390         |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    reward               | 1.9698119     |\n",
      "|    std                  | 12            |\n",
      "|    value_loss           | 99.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1741        |\n",
      "|    time_elapsed         | 33283       |\n",
      "|    total_timesteps      | 3565568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009761476 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 8.797671    |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1742          |\n",
      "|    time_elapsed         | 33301         |\n",
      "|    total_timesteps      | 3567616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089984527 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.149         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.3          |\n",
      "|    n_updates            | 17410         |\n",
      "|    policy_gradient_loss | -0.00249      |\n",
      "|    reward               | -1.0987128    |\n",
      "|    std                  | 12            |\n",
      "|    value_loss           | 94.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1743         |\n",
      "|    time_elapsed         | 33320        |\n",
      "|    total_timesteps      | 3569664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016716953 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 17420        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | -20.386988   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1744        |\n",
      "|    time_elapsed         | 33339       |\n",
      "|    total_timesteps      | 3571712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004563058 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 17430       |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | 1.3648869   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1745        |\n",
      "|    time_elapsed         | 33357       |\n",
      "|    total_timesteps      | 3573760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003779603 |\n",
      "|    clip_fraction        | 0.00776     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 17440       |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    reward               | -0.0884422  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1746         |\n",
      "|    time_elapsed         | 33375        |\n",
      "|    total_timesteps      | 3575808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022679423 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | 0.6365455    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 79.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1747        |\n",
      "|    time_elapsed         | 33394       |\n",
      "|    total_timesteps      | 3577856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004801155 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.0804      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.6        |\n",
      "|    n_updates            | 17460       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 1.2266752   |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4392719.12\n",
      "total_reward: 3392719.12\n",
      "total_cost: 206894.46\n",
      "total_trades: 60008\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1748         |\n",
      "|    time_elapsed         | 33412        |\n",
      "|    total_timesteps      | 3579904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076855547 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.07         |\n",
      "|    n_updates            | 17470        |\n",
      "|    policy_gradient_loss | -0.00948     |\n",
      "|    reward               | -0.34113407  |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1749        |\n",
      "|    time_elapsed         | 33431       |\n",
      "|    total_timesteps      | 3581952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003384137 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 63.2        |\n",
      "|    n_updates            | 17480       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | -0.2000321  |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 84.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 33449       |\n",
      "|    total_timesteps      | 3584000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007458947 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.6        |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -7.060275   |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 95          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1751        |\n",
      "|    time_elapsed         | 33467       |\n",
      "|    total_timesteps      | 3586048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010153584 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | -2.411998   |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1752         |\n",
      "|    time_elapsed         | 33486        |\n",
      "|    total_timesteps      | 3588096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039603594 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 17510        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | 1.4942524    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 84.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1753         |\n",
      "|    time_elapsed         | 33504        |\n",
      "|    total_timesteps      | 3590144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049595563 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 17520        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | 28.083494    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 79.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1754         |\n",
      "|    time_elapsed         | 33523        |\n",
      "|    total_timesteps      | 3592192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029876614 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.7         |\n",
      "|    n_updates            | 17530        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -0.26551035  |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 81.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1755        |\n",
      "|    time_elapsed         | 33541       |\n",
      "|    total_timesteps      | 3594240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008467196 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 17540       |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    reward               | -1.4482831  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1756         |\n",
      "|    time_elapsed         | 33560        |\n",
      "|    total_timesteps      | 3596288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054562925 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.5         |\n",
      "|    n_updates            | 17550        |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    reward               | 0.07423972   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 86.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1757          |\n",
      "|    time_elapsed         | 33578         |\n",
      "|    total_timesteps      | 3598336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042916322 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.353         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53.7          |\n",
      "|    n_updates            | 17560         |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    reward               | 7.2559814     |\n",
      "|    std                  | 12.3          |\n",
      "|    value_loss           | 79.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1758        |\n",
      "|    time_elapsed         | 33596       |\n",
      "|    total_timesteps      | 3600384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007360948 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 17570       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | 1.181676    |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1759         |\n",
      "|    time_elapsed         | 33615        |\n",
      "|    total_timesteps      | 3602432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067515993 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 17580        |\n",
      "|    policy_gradient_loss | -0.0075      |\n",
      "|    reward               | -0.1049069   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 87.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1760        |\n",
      "|    time_elapsed         | 33633       |\n",
      "|    total_timesteps      | 3604480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004270737 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.3        |\n",
      "|    n_updates            | 17590       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    reward               | 0.5514152   |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 96.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1761        |\n",
      "|    time_elapsed         | 33652       |\n",
      "|    total_timesteps      | 3606528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006184386 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 17600       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 3.6301677   |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 58.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4459268.27\n",
      "total_reward: 3459268.27\n",
      "total_cost: 184267.63\n",
      "total_trades: 59278\n",
      "Sharpe: 0.711\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 33670       |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009172291 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    reward               | 1.7480141   |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1763         |\n",
      "|    time_elapsed         | 33689        |\n",
      "|    total_timesteps      | 3610624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032263517 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.0551       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 17620        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | 1.3658332    |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1764         |\n",
      "|    time_elapsed         | 33707        |\n",
      "|    total_timesteps      | 3612672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034555346 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.9         |\n",
      "|    n_updates            | 17630        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -0.9309362   |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 98.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 33726       |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009172073 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | 0.757892    |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1766        |\n",
      "|    time_elapsed         | 33744       |\n",
      "|    total_timesteps      | 3616768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007977806 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 17650       |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    reward               | 1.5683559   |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1767        |\n",
      "|    time_elapsed         | 33763       |\n",
      "|    total_timesteps      | 3618816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003132441 |\n",
      "|    clip_fraction        | 0.00288     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 17660       |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | 4.257823    |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1768          |\n",
      "|    time_elapsed         | 33781         |\n",
      "|    total_timesteps      | 3620864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005462924   |\n",
      "|    clip_fraction        | 0.0109        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.367         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.2          |\n",
      "|    n_updates            | 17670         |\n",
      "|    policy_gradient_loss | -0.00489      |\n",
      "|    reward               | -0.0019531914 |\n",
      "|    std                  | 12.4          |\n",
      "|    value_loss           | 46.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 33800       |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005376529 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    reward               | -4.5764914  |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1770         |\n",
      "|    time_elapsed         | 33819        |\n",
      "|    total_timesteps      | 3624960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015543702 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 17690        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | 0.0038065587 |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 65.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1771         |\n",
      "|    time_elapsed         | 33837        |\n",
      "|    total_timesteps      | 3627008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015755413 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.6         |\n",
      "|    n_updates            | 17700        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | -0.24563532  |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 95.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 33856       |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009659293 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.53        |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    reward               | -0.33910686 |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1773         |\n",
      "|    time_elapsed         | 33874        |\n",
      "|    total_timesteps      | 3631104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017342386 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 17720        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | -1.3078891   |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 76.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1774         |\n",
      "|    time_elapsed         | 33893        |\n",
      "|    total_timesteps      | 3633152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012549255 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.5         |\n",
      "|    n_updates            | 17730        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -4.498161    |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 69.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1775         |\n",
      "|    time_elapsed         | 33911        |\n",
      "|    total_timesteps      | 3635200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066311294 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 17740        |\n",
      "|    policy_gradient_loss | -0.00741     |\n",
      "|    reward               | 4.3645024    |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4163507.47\n",
      "total_reward: 3163507.47\n",
      "total_cost: 201242.52\n",
      "total_trades: 60112\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1776        |\n",
      "|    time_elapsed         | 33929       |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004153294 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -1.6904848  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 69.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1777         |\n",
      "|    time_elapsed         | 33948        |\n",
      "|    total_timesteps      | 3639296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059388727 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.0947       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.4         |\n",
      "|    n_updates            | 17760        |\n",
      "|    policy_gradient_loss | -0.00762     |\n",
      "|    reward               | 6.6356354    |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 88.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1778         |\n",
      "|    time_elapsed         | 33966        |\n",
      "|    total_timesteps      | 3641344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074595376 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 17770        |\n",
      "|    policy_gradient_loss | -0.0077      |\n",
      "|    reward               | 2.0205252    |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1779         |\n",
      "|    time_elapsed         | 33986        |\n",
      "|    total_timesteps      | 3643392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032559792 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.7         |\n",
      "|    n_updates            | 17780        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | -0.16583066  |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1780        |\n",
      "|    time_elapsed         | 34004       |\n",
      "|    total_timesteps      | 3645440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002991858 |\n",
      "|    clip_fraction        | 0.00244     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 17790       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | 0.669045    |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 83          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1781         |\n",
      "|    time_elapsed         | 34023        |\n",
      "|    total_timesteps      | 3647488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024766228 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 17800        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | 3.8606222    |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1782         |\n",
      "|    time_elapsed         | 34041        |\n",
      "|    total_timesteps      | 3649536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108372215 |\n",
      "|    clip_fraction        | 0.071        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.05         |\n",
      "|    n_updates            | 17810        |\n",
      "|    policy_gradient_loss | -0.00998     |\n",
      "|    reward               | 3.1524212    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1783         |\n",
      "|    time_elapsed         | 34060        |\n",
      "|    total_timesteps      | 3651584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032097292 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.6         |\n",
      "|    n_updates            | 17820        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | 0.56866556   |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 78.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1784         |\n",
      "|    time_elapsed         | 34079        |\n",
      "|    total_timesteps      | 3653632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011410598 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 17830        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -2.313284    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1785        |\n",
      "|    time_elapsed         | 34097       |\n",
      "|    total_timesteps      | 3655680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004633696 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    reward               | 1.3318818   |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 34116       |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009836974 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 0.74934536  |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 64.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1787         |\n",
      "|    time_elapsed         | 34135        |\n",
      "|    total_timesteps      | 3659776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044032536 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 17860        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    reward               | 2.5316324    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 89.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1788         |\n",
      "|    time_elapsed         | 34153        |\n",
      "|    total_timesteps      | 3661824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043697646 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.169        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 17870        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 1.5074443    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 89.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 34172       |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006697894 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.3         |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | 1.0650694   |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4770201.44\n",
      "total_reward: 3770201.44\n",
      "total_cost: 197640.16\n",
      "total_trades: 60465\n",
      "Sharpe: 0.747\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1790        |\n",
      "|    time_elapsed         | 34190       |\n",
      "|    total_timesteps      | 3665920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006070662 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 17890       |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    reward               | 1.1707916   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1791         |\n",
      "|    time_elapsed         | 34209        |\n",
      "|    total_timesteps      | 3667968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009135745 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41           |\n",
      "|    n_updates            | 17900        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 7.6074986    |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1792         |\n",
      "|    time_elapsed         | 34272        |\n",
      "|    total_timesteps      | 3670016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055692466 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 17910        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | -2.2653165   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1793        |\n",
      "|    time_elapsed         | 34290       |\n",
      "|    total_timesteps      | 3672064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007843888 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95          |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | -1.891219   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1794         |\n",
      "|    time_elapsed         | 34309        |\n",
      "|    total_timesteps      | 3674112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052467384 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.6         |\n",
      "|    n_updates            | 17930        |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    reward               | 0.04480274   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1795        |\n",
      "|    time_elapsed         | 34328       |\n",
      "|    total_timesteps      | 3676160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004324071 |\n",
      "|    clip_fraction        | 0.00703     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 1.1924483   |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 87.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1796       |\n",
      "|    time_elapsed         | 34346      |\n",
      "|    total_timesteps      | 3678208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00984818 |\n",
      "|    clip_fraction        | 0.0996     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.0801     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.8       |\n",
      "|    n_updates            | 17950      |\n",
      "|    policy_gradient_loss | -0.00847   |\n",
      "|    reward               | 1.9761021  |\n",
      "|    std                  | 12.9       |\n",
      "|    value_loss           | 22.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1797        |\n",
      "|    time_elapsed         | 34364       |\n",
      "|    total_timesteps      | 3680256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006671655 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70          |\n",
      "|    n_updates            | 17960       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | -0.8908453  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1798         |\n",
      "|    time_elapsed         | 34383        |\n",
      "|    total_timesteps      | 3682304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069622793 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.0937       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.6         |\n",
      "|    n_updates            | 17970        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | -11.889983   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 34401       |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006661645 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    reward               | 5.9188523   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1800         |\n",
      "|    time_elapsed         | 34420        |\n",
      "|    total_timesteps      | 3686400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058381734 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 17990        |\n",
      "|    policy_gradient_loss | -0.00839     |\n",
      "|    reward               | 0.92285657   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 80.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1801         |\n",
      "|    time_elapsed         | 34438        |\n",
      "|    total_timesteps      | 3688448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013878127 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.3         |\n",
      "|    n_updates            | 18000        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | -1.9052407   |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1802         |\n",
      "|    time_elapsed         | 34457        |\n",
      "|    total_timesteps      | 3690496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046223756 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 18010        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 1.002946     |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 34475       |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005826673 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 18020       |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    reward               | -4.228984   |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4490938.85\n",
      "total_reward: 3490938.85\n",
      "total_cost: 211733.81\n",
      "total_trades: 60540\n",
      "Sharpe: 0.715\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1804         |\n",
      "|    time_elapsed         | 34493        |\n",
      "|    total_timesteps      | 3694592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026428965 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.3         |\n",
      "|    n_updates            | 18030        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 0.013938317  |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 86.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1805         |\n",
      "|    time_elapsed         | 34512        |\n",
      "|    total_timesteps      | 3696640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010324193 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.3         |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    reward               | 2.4829178    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1806         |\n",
      "|    time_elapsed         | 34530        |\n",
      "|    total_timesteps      | 3698688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054699974 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 18050        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 0.07569677   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1807         |\n",
      "|    time_elapsed         | 34549        |\n",
      "|    total_timesteps      | 3700736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035523227 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.3         |\n",
      "|    n_updates            | 18060        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    reward               | -0.42003453  |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 90.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1808         |\n",
      "|    time_elapsed         | 34567        |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030336296 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.2         |\n",
      "|    n_updates            | 18070        |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | 5.1151013    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1809         |\n",
      "|    time_elapsed         | 34585        |\n",
      "|    total_timesteps      | 3704832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107583115 |\n",
      "|    clip_fraction        | 0.0781       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 18080        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    reward               | 3.781953     |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1810         |\n",
      "|    time_elapsed         | 34604        |\n",
      "|    total_timesteps      | 3706880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055804243 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.233        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 18090        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | 0.86754274   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 75.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1811         |\n",
      "|    time_elapsed         | 34622        |\n",
      "|    total_timesteps      | 3708928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034243728 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 18100        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 1.4256688    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 79.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1812         |\n",
      "|    time_elapsed         | 34641        |\n",
      "|    total_timesteps      | 3710976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022759596 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.8         |\n",
      "|    n_updates            | 18110        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 1.7217712    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1813        |\n",
      "|    time_elapsed         | 34659       |\n",
      "|    total_timesteps      | 3713024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005845286 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | -0.35158816 |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1814         |\n",
      "|    time_elapsed         | 34677        |\n",
      "|    total_timesteps      | 3715072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038684453 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.9         |\n",
      "|    n_updates            | 18130        |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    reward               | -0.72824883  |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 92.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1815       |\n",
      "|    time_elapsed         | 34696      |\n",
      "|    total_timesteps      | 3717120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00514449 |\n",
      "|    clip_fraction        | 0.0118     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.269      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 52.4       |\n",
      "|    n_updates            | 18140      |\n",
      "|    policy_gradient_loss | -0.0054    |\n",
      "|    reward               | -10.939231 |\n",
      "|    std                  | 13.2       |\n",
      "|    value_loss           | 91.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1816         |\n",
      "|    time_elapsed         | 34714        |\n",
      "|    total_timesteps      | 3719168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059318393 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 18150        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 1.1340675    |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1817        |\n",
      "|    time_elapsed         | 34732       |\n",
      "|    total_timesteps      | 3721216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006956612 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | 0.57715064  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 93.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1818         |\n",
      "|    time_elapsed         | 34751        |\n",
      "|    total_timesteps      | 3723264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010347096 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 18170        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    reward               | 2.6063356    |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 88.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4089506.35\n",
      "total_reward: 3089506.35\n",
      "total_cost: 241239.11\n",
      "total_trades: 62375\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1819          |\n",
      "|    time_elapsed         | 34769         |\n",
      "|    total_timesteps      | 3725312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031802963 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.219         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.7          |\n",
      "|    n_updates            | 18180         |\n",
      "|    policy_gradient_loss | -0.000554     |\n",
      "|    reward               | -1.3993336    |\n",
      "|    std                  | 13.2          |\n",
      "|    value_loss           | 81.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 34788       |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009737052 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    reward               | 0.76250136  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1821         |\n",
      "|    time_elapsed         | 34807        |\n",
      "|    total_timesteps      | 3729408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048387246 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.4         |\n",
      "|    n_updates            | 18200        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 0.7887992    |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 93.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1822         |\n",
      "|    time_elapsed         | 34825        |\n",
      "|    total_timesteps      | 3731456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044073137 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.0125       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.5         |\n",
      "|    n_updates            | 18210        |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    reward               | -2.8843935   |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1823        |\n",
      "|    time_elapsed         | 34843       |\n",
      "|    total_timesteps      | 3733504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008227866 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 18220       |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -2.2579415  |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1824         |\n",
      "|    time_elapsed         | 34861        |\n",
      "|    total_timesteps      | 3735552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066650845 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.0553       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.1         |\n",
      "|    n_updates            | 18230        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 1.6144289    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1825         |\n",
      "|    time_elapsed         | 34881        |\n",
      "|    total_timesteps      | 3737600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057331715 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.097        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.5         |\n",
      "|    n_updates            | 18240        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    reward               | 3.5257883    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1826        |\n",
      "|    time_elapsed         | 34899       |\n",
      "|    total_timesteps      | 3739648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003740964 |\n",
      "|    clip_fraction        | 0.00464     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 18250       |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    reward               | 0.5438738   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1827        |\n",
      "|    time_elapsed         | 34917       |\n",
      "|    total_timesteps      | 3741696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00734361  |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | -0.15881313 |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1828          |\n",
      "|    time_elapsed         | 34936         |\n",
      "|    total_timesteps      | 3743744       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090106553 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.119         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 93.5          |\n",
      "|    n_updates            | 18270         |\n",
      "|    policy_gradient_loss | -0.00246      |\n",
      "|    reward               | -2.3788562    |\n",
      "|    std                  | 13.5          |\n",
      "|    value_loss           | 99.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1829         |\n",
      "|    time_elapsed         | 34954        |\n",
      "|    total_timesteps      | 3745792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019149513 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.133        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.3         |\n",
      "|    n_updates            | 18280        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | 1.4121524    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1830         |\n",
      "|    time_elapsed         | 34973        |\n",
      "|    total_timesteps      | 3747840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077024573 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.97         |\n",
      "|    n_updates            | 18290        |\n",
      "|    policy_gradient_loss | -0.00818     |\n",
      "|    reward               | 0.44991454   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1831         |\n",
      "|    time_elapsed         | 34991        |\n",
      "|    total_timesteps      | 3749888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036733588 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43           |\n",
      "|    n_updates            | 18300        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | 1.2344967    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 72.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1832         |\n",
      "|    time_elapsed         | 35009        |\n",
      "|    total_timesteps      | 3751936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021992614 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.4         |\n",
      "|    n_updates            | 18310        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 3.266522     |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4356955.38\n",
      "total_reward: 3356955.38\n",
      "total_cost: 226169.13\n",
      "total_trades: 61249\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1833          |\n",
      "|    time_elapsed         | 35028         |\n",
      "|    total_timesteps      | 3753984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092428736 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.419         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.9          |\n",
      "|    n_updates            | 18320         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | 0.8619945     |\n",
      "|    std                  | 13.5          |\n",
      "|    value_loss           | 40.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1834        |\n",
      "|    time_elapsed         | 35046       |\n",
      "|    total_timesteps      | 3756032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001558617 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | -1.8586593  |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1835         |\n",
      "|    time_elapsed         | 35065        |\n",
      "|    total_timesteps      | 3758080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026653889 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 18340        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -1.7315156   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 81.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1836         |\n",
      "|    time_elapsed         | 35083        |\n",
      "|    total_timesteps      | 3760128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038013794 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.0161       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 18350        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    reward               | 0.27767986   |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 96.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 35102       |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008696217 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -1.6456372  |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1838         |\n",
      "|    time_elapsed         | 35120        |\n",
      "|    total_timesteps      | 3764224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050277356 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.0761       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.9         |\n",
      "|    n_updates            | 18370        |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    reward               | 1.4704313    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1839        |\n",
      "|    time_elapsed         | 35139       |\n",
      "|    total_timesteps      | 3766272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009867087 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.0879      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.1        |\n",
      "|    n_updates            | 18380       |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    reward               | 1.3685391   |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 99          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1840         |\n",
      "|    time_elapsed         | 35157        |\n",
      "|    total_timesteps      | 3768320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054633925 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 18390        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | 1.5811665    |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1841        |\n",
      "|    time_elapsed         | 35176       |\n",
      "|    total_timesteps      | 3770368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00554275  |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 18400       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -0.76896304 |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 99.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1842       |\n",
      "|    time_elapsed         | 35195      |\n",
      "|    total_timesteps      | 3772416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00828066 |\n",
      "|    clip_fraction        | 0.0674     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -116       |\n",
      "|    explained_variance   | 0.0604     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 64.6       |\n",
      "|    n_updates            | 18410      |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    reward               | -8.31862   |\n",
      "|    std                  | 13.7       |\n",
      "|    value_loss           | 133        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1843        |\n",
      "|    time_elapsed         | 35213       |\n",
      "|    total_timesteps      | 3774464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008210968 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.0573      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 18420       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | 0.1869235   |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1844        |\n",
      "|    time_elapsed         | 35231       |\n",
      "|    total_timesteps      | 3776512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010210962 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 18430       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    reward               | -0.15919238 |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1845        |\n",
      "|    time_elapsed         | 35250       |\n",
      "|    total_timesteps      | 3778560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009249583 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0546      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.6        |\n",
      "|    n_updates            | 18440       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.22768568  |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 95.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1846        |\n",
      "|    time_elapsed         | 35268       |\n",
      "|    total_timesteps      | 3780608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012410971 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 18450       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.4009125   |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4251634.88\n",
      "total_reward: 3251634.88\n",
      "total_cost: 188917.67\n",
      "total_trades: 59541\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1847         |\n",
      "|    time_elapsed         | 35287        |\n",
      "|    total_timesteps      | 3782656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008885786  |\n",
      "|    clip_fraction        | 0.0604       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 18460        |\n",
      "|    policy_gradient_loss | -0.00958     |\n",
      "|    reward               | -0.023328299 |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1848         |\n",
      "|    time_elapsed         | 35305        |\n",
      "|    total_timesteps      | 3784704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054418147 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.0672       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 18470        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -1.7529181   |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1849        |\n",
      "|    time_elapsed         | 35324       |\n",
      "|    total_timesteps      | 3786752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010667311 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0474      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 18480       |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | -1.8394408  |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1850         |\n",
      "|    time_elapsed         | 35342        |\n",
      "|    total_timesteps      | 3788800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073713916 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.0615       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 18490        |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    reward               | 0.4319278    |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 45.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1851         |\n",
      "|    time_elapsed         | 35361        |\n",
      "|    total_timesteps      | 3790848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032694195 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | -0.95535046  |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 70.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1852        |\n",
      "|    time_elapsed         | 35379       |\n",
      "|    total_timesteps      | 3792896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002263303 |\n",
      "|    clip_fraction        | 0.00146     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0833      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 98.5        |\n",
      "|    n_updates            | 18510       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    reward               | 2.3043551   |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1853         |\n",
      "|    time_elapsed         | 35398        |\n",
      "|    total_timesteps      | 3794944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060561374 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53           |\n",
      "|    n_updates            | 18520        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | 5.0687213    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1854        |\n",
      "|    time_elapsed         | 35417       |\n",
      "|    total_timesteps      | 3796992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010009573 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | -0.0175     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | -0.942252   |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1855        |\n",
      "|    time_elapsed         | 35435       |\n",
      "|    total_timesteps      | 3799040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007038068 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.3        |\n",
      "|    n_updates            | 18540       |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 0.40235606  |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1856         |\n",
      "|    time_elapsed         | 35453        |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077286395 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.0213       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.8         |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.00988     |\n",
      "|    reward               | -0.092064425 |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1857         |\n",
      "|    time_elapsed         | 35472        |\n",
      "|    total_timesteps      | 3803136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075087184 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 18560        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    reward               | 1.1338923    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1858        |\n",
      "|    time_elapsed         | 35490       |\n",
      "|    total_timesteps      | 3805184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005120863 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 18570       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 2.3598883   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1859        |\n",
      "|    time_elapsed         | 35509       |\n",
      "|    total_timesteps      | 3807232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006612604 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0657      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.4        |\n",
      "|    n_updates            | 18580       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    reward               | -0.39362064 |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 73          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1860        |\n",
      "|    time_elapsed         | 35527       |\n",
      "|    total_timesteps      | 3809280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012057615 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0333      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 18590       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    reward               | 1.5000155   |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 70.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3985695.83\n",
      "total_reward: 2985695.83\n",
      "total_cost: 174416.59\n",
      "total_trades: 59224\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1861        |\n",
      "|    time_elapsed         | 35546       |\n",
      "|    total_timesteps      | 3811328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006914026 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.32        |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    reward               | 1.1703581   |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1862        |\n",
      "|    time_elapsed         | 35565       |\n",
      "|    total_timesteps      | 3813376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007034861 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0609      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 18610       |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | 0.30945194  |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1863         |\n",
      "|    time_elapsed         | 35583        |\n",
      "|    total_timesteps      | 3815424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043332865 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.0455       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 18620        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -1.0638944   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1864         |\n",
      "|    time_elapsed         | 35601        |\n",
      "|    total_timesteps      | 3817472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060851453 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 18630        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | -0.07102537  |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1865         |\n",
      "|    time_elapsed         | 35620        |\n",
      "|    total_timesteps      | 3819520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060064187 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.192        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 18640        |\n",
      "|    policy_gradient_loss | -0.00905     |\n",
      "|    reward               | 0.88227785   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1866        |\n",
      "|    time_elapsed         | 35639       |\n",
      "|    total_timesteps      | 3821568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008091527 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 18650       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 16.297035   |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1867         |\n",
      "|    time_elapsed         | 35657        |\n",
      "|    total_timesteps      | 3823616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040648663 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 18660        |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    reward               | -0.14940087  |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1868        |\n",
      "|    time_elapsed         | 35676       |\n",
      "|    total_timesteps      | 3825664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005801443 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 18670       |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    reward               | 2.0953999   |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1869         |\n",
      "|    time_elapsed         | 35694        |\n",
      "|    total_timesteps      | 3827712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042262534 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.154        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.4         |\n",
      "|    n_updates            | 18680        |\n",
      "|    policy_gradient_loss | -0.00772     |\n",
      "|    reward               | -0.20031527  |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 51.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1870        |\n",
      "|    time_elapsed         | 35712       |\n",
      "|    total_timesteps      | 3829760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008091686 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.00108     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 18690       |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | -7.333128   |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1871         |\n",
      "|    time_elapsed         | 35731        |\n",
      "|    total_timesteps      | 3831808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056209783 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.02         |\n",
      "|    n_updates            | 18700        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 0.2468515    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1872         |\n",
      "|    time_elapsed         | 35749        |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035594478 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | 0.7275824    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1873        |\n",
      "|    time_elapsed         | 35768       |\n",
      "|    total_timesteps      | 3835904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004123928 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 18720       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | 2.7188256   |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1874         |\n",
      "|    time_elapsed         | 35787        |\n",
      "|    total_timesteps      | 3837952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034290566 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.0625       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 18730        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | 2.3734267    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4360813.52\n",
      "total_reward: 3360813.52\n",
      "total_cost: 191200.41\n",
      "total_trades: 59582\n",
      "Sharpe: 0.803\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1875         |\n",
      "|    time_elapsed         | 35805        |\n",
      "|    total_timesteps      | 3840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056896256 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.3         |\n",
      "|    n_updates            | 18740        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | 0.13049072   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 48.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1876        |\n",
      "|    time_elapsed         | 35824       |\n",
      "|    total_timesteps      | 3842048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006507766 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.0515      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 18750       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 1.1730584   |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1877         |\n",
      "|    time_elapsed         | 35843        |\n",
      "|    total_timesteps      | 3844096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096097225 |\n",
      "|    clip_fraction        | 0.0705       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.019        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 18760        |\n",
      "|    policy_gradient_loss | -0.00839     |\n",
      "|    reward               | -1.8069212   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1878        |\n",
      "|    time_elapsed         | 35861       |\n",
      "|    total_timesteps      | 3846144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006848001 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.18        |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 2.032412    |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 35879        |\n",
      "|    total_timesteps      | 3848192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056180134 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.101        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -0.00787     |\n",
      "|    reward               | -0.34998462  |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 39.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1880        |\n",
      "|    time_elapsed         | 35897       |\n",
      "|    total_timesteps      | 3850240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005961912 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 18790       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -2.1094396  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 54.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1881        |\n",
      "|    time_elapsed         | 35915       |\n",
      "|    total_timesteps      | 3852288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006975035 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 18800       |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.7382227   |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1882         |\n",
      "|    time_elapsed         | 35934        |\n",
      "|    total_timesteps      | 3854336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065401355 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 18810        |\n",
      "|    policy_gradient_loss | -0.00891     |\n",
      "|    reward               | -3.97063     |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1883        |\n",
      "|    time_elapsed         | 35952       |\n",
      "|    total_timesteps      | 3856384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006789612 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 18820       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    reward               | 0.10722054  |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1884         |\n",
      "|    time_elapsed         | 35971        |\n",
      "|    total_timesteps      | 3858432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059806667 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.0736       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 18830        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    reward               | 1.4392004    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 49           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1885        |\n",
      "|    time_elapsed         | 35989       |\n",
      "|    total_timesteps      | 3860480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009087199 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.6         |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | -0.49330935 |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1886         |\n",
      "|    time_elapsed         | 36008        |\n",
      "|    total_timesteps      | 3862528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042457096 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.158        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 18850        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | -0.6147862   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 54.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1887        |\n",
      "|    time_elapsed         | 36026       |\n",
      "|    total_timesteps      | 3864576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005134315 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.0804      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 18860       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | -2.1114671  |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 59.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1888        |\n",
      "|    time_elapsed         | 36045       |\n",
      "|    total_timesteps      | 3866624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005343765 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.0437      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | 0.4083872   |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4239644.34\n",
      "total_reward: 3239644.34\n",
      "total_cost: 222420.17\n",
      "total_trades: 61756\n",
      "Sharpe: 0.789\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1889         |\n",
      "|    time_elapsed         | 36063        |\n",
      "|    total_timesteps      | 3868672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007835859  |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 18880        |\n",
      "|    policy_gradient_loss | -0.00792     |\n",
      "|    reward               | -0.058921076 |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 35.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1890        |\n",
      "|    time_elapsed         | 36082       |\n",
      "|    total_timesteps      | 3870720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008089116 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 18890       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.4527928  |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 54.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1891         |\n",
      "|    time_elapsed         | 36100        |\n",
      "|    total_timesteps      | 3872768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051663173 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | -0.0555      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 18900        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | -0.8218094   |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 49.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1892        |\n",
      "|    time_elapsed         | 36119       |\n",
      "|    total_timesteps      | 3874816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005102507 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.075       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 18910       |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    reward               | 2.4353473   |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1893         |\n",
      "|    time_elapsed         | 36137        |\n",
      "|    total_timesteps      | 3876864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031885696 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.101        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 1.2436403    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1894         |\n",
      "|    time_elapsed         | 36155        |\n",
      "|    total_timesteps      | 3878912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043489677 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.208        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 18930        |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    reward               | 1.5084873    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1895         |\n",
      "|    time_elapsed         | 36173        |\n",
      "|    total_timesteps      | 3880960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038389121 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | -0.0579      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.04         |\n",
      "|    n_updates            | 18940        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -0.5947723   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 19.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1896        |\n",
      "|    time_elapsed         | 36192       |\n",
      "|    total_timesteps      | 3883008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005506496 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 18950       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -0.6346759  |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 36.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1897        |\n",
      "|    time_elapsed         | 36211       |\n",
      "|    total_timesteps      | 3885056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004194106 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.045       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 18960       |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    reward               | -0.8366403  |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1898         |\n",
      "|    time_elapsed         | 36230        |\n",
      "|    total_timesteps      | 3887104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073242104 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | -0.0465      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 18970        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | 1.4112643    |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1899        |\n",
      "|    time_elapsed         | 36249       |\n",
      "|    total_timesteps      | 3889152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008147686 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.083       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    reward               | -2.3098915  |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1900         |\n",
      "|    time_elapsed         | 36268        |\n",
      "|    total_timesteps      | 3891200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060612243 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 18990        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | 0.94419396   |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1901        |\n",
      "|    time_elapsed         | 36286       |\n",
      "|    total_timesteps      | 3893248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004417144 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 19000       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 0.58906096  |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1902        |\n",
      "|    time_elapsed         | 36305       |\n",
      "|    total_timesteps      | 3895296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009239441 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.0333      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 1.9021791   |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4013430.29\n",
      "total_reward: 3013430.29\n",
      "total_cost: 274434.08\n",
      "total_trades: 64390\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1903        |\n",
      "|    time_elapsed         | 36324       |\n",
      "|    total_timesteps      | 3897344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005848862 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.0676      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 19020       |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | 0.14466678  |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 54.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1904         |\n",
      "|    time_elapsed         | 36342        |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053529646 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 19030        |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    reward               | 0.04219218   |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 40.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1905       |\n",
      "|    time_elapsed         | 36360      |\n",
      "|    total_timesteps      | 3901440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00640695 |\n",
      "|    clip_fraction        | 0.0368     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -120       |\n",
      "|    explained_variance   | 0.0842     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.6       |\n",
      "|    n_updates            | 19040      |\n",
      "|    policy_gradient_loss | -0.00824   |\n",
      "|    reward               | -1.6696774 |\n",
      "|    std                  | 15.4       |\n",
      "|    value_loss           | 33.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1906        |\n",
      "|    time_elapsed         | 36379       |\n",
      "|    total_timesteps      | 3903488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004357836 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 19050       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | 1.801991    |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1907         |\n",
      "|    time_elapsed         | 36397        |\n",
      "|    total_timesteps      | 3905536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022512216 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.000544    |\n",
      "|    reward               | -24.614576   |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 97.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1908         |\n",
      "|    time_elapsed         | 36417        |\n",
      "|    total_timesteps      | 3907584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008038805 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.1         |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | -1.104181    |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 90.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 36435       |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010408098 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.0522      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.57        |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.6424492  |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1910         |\n",
      "|    time_elapsed         | 36453        |\n",
      "|    total_timesteps      | 3911680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066084275 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.16         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 19090        |\n",
      "|    policy_gradient_loss | -0.00843     |\n",
      "|    reward               | 0.70699716   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 55.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1911       |\n",
      "|    time_elapsed         | 36472      |\n",
      "|    total_timesteps      | 3913728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00415501 |\n",
      "|    clip_fraction        | 0.0451     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -120       |\n",
      "|    explained_variance   | 0.0316     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.6       |\n",
      "|    n_updates            | 19100      |\n",
      "|    policy_gradient_loss | -0.00327   |\n",
      "|    reward               | 0.37446827 |\n",
      "|    std                  | 15.5       |\n",
      "|    value_loss           | 99.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1912         |\n",
      "|    time_elapsed         | 36490        |\n",
      "|    total_timesteps      | 3915776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059879143 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.0888       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 19110        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | 0.117684424  |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1913         |\n",
      "|    time_elapsed         | 36509        |\n",
      "|    total_timesteps      | 3917824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042788982 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 19120        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | 2.2815504    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1914         |\n",
      "|    time_elapsed         | 36527        |\n",
      "|    total_timesteps      | 3919872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052381638 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 19130        |\n",
      "|    policy_gradient_loss | -0.00745     |\n",
      "|    reward               | 1.8867098    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1915        |\n",
      "|    time_elapsed         | 36546       |\n",
      "|    total_timesteps      | 3921920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005484758 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.0519      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | 0.90866774  |\n",
      "|    std                  | 15.5        |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1916        |\n",
      "|    time_elapsed         | 36565       |\n",
      "|    total_timesteps      | 3923968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007863248 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.08        |\n",
      "|    n_updates            | 19150       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.6129266  |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4955297.30\n",
      "total_reward: 3955297.30\n",
      "total_cost: 250364.13\n",
      "total_trades: 63193\n",
      "Sharpe: 0.833\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1917        |\n",
      "|    time_elapsed         | 36584       |\n",
      "|    total_timesteps      | 3926016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006270022 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 19160       |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    reward               | 2.4019227   |\n",
      "|    std                  | 15.6        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1918         |\n",
      "|    time_elapsed         | 36603        |\n",
      "|    total_timesteps      | 3928064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068626385 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.0641       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.3         |\n",
      "|    n_updates            | 19170        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | 0.49657667   |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 81.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1919         |\n",
      "|    time_elapsed         | 36622        |\n",
      "|    total_timesteps      | 3930112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068616765 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.58         |\n",
      "|    n_updates            | 19180        |\n",
      "|    policy_gradient_loss | -0.00718     |\n",
      "|    reward               | 0.928687     |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1920        |\n",
      "|    time_elapsed         | 36640       |\n",
      "|    total_timesteps      | 3932160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006087295 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 19190       |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    reward               | -0.70389086 |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1921         |\n",
      "|    time_elapsed         | 36659        |\n",
      "|    total_timesteps      | 3934208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023737794 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 19200        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 2.4546342    |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1922       |\n",
      "|    time_elapsed         | 36677      |\n",
      "|    total_timesteps      | 3936256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00395344 |\n",
      "|    clip_fraction        | 0.0126     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -120       |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.1       |\n",
      "|    n_updates            | 19210      |\n",
      "|    policy_gradient_loss | -0.00511   |\n",
      "|    reward               | 1.1218491  |\n",
      "|    std                  | 15.8       |\n",
      "|    value_loss           | 36.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1923        |\n",
      "|    time_elapsed         | 36695       |\n",
      "|    total_timesteps      | 3938304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008457946 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.0924      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | 0.43063536  |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1924        |\n",
      "|    time_elapsed         | 36714       |\n",
      "|    total_timesteps      | 3940352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004040831 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.115       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 19230       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -1.3038524  |\n",
      "|    std                  | 15.8        |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1925         |\n",
      "|    time_elapsed         | 36732        |\n",
      "|    total_timesteps      | 3942400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036373385 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.0498       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 19240        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    reward               | 1.556807     |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 55.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1926         |\n",
      "|    time_elapsed         | 36750        |\n",
      "|    total_timesteps      | 3944448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072750766 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.123        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.83         |\n",
      "|    n_updates            | 19250        |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    reward               | -0.7887654   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 19.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1927         |\n",
      "|    time_elapsed         | 36769        |\n",
      "|    total_timesteps      | 3946496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053218873 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | -0.2739469   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1928         |\n",
      "|    time_elapsed         | 36787        |\n",
      "|    total_timesteps      | 3948544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049158284 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 19270        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | 0.59050107   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 56.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1929         |\n",
      "|    time_elapsed         | 36805        |\n",
      "|    total_timesteps      | 3950592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052639465 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 19280        |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | -0.9617581   |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1930         |\n",
      "|    time_elapsed         | 36823        |\n",
      "|    total_timesteps      | 3952640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069279284 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.0477       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 19290        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    reward               | 0.70676327   |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1931         |\n",
      "|    time_elapsed         | 36842        |\n",
      "|    total_timesteps      | 3954688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020616078 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 19300        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | -6.7008023   |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4236546.44\n",
      "total_reward: 3236546.44\n",
      "total_cost: 251654.20\n",
      "total_trades: 64475\n",
      "Sharpe: 0.779\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1932        |\n",
      "|    time_elapsed         | 36860       |\n",
      "|    total_timesteps      | 3956736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005492523 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.0419      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 19310       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | 1.6909945   |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1933        |\n",
      "|    time_elapsed         | 36878       |\n",
      "|    total_timesteps      | 3958784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008641567 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 19320       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 0.102788545 |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1934         |\n",
      "|    time_elapsed         | 36897        |\n",
      "|    total_timesteps      | 3960832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030872799 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.101        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 19330        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | 0.27686384   |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 46.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1935       |\n",
      "|    time_elapsed         | 36915      |\n",
      "|    total_timesteps      | 3962880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0079135  |\n",
      "|    clip_fraction        | 0.0504     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -121       |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.1       |\n",
      "|    n_updates            | 19340      |\n",
      "|    policy_gradient_loss | -0.00949   |\n",
      "|    reward               | -0.3623937 |\n",
      "|    std                  | 16.1       |\n",
      "|    value_loss           | 50.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1936        |\n",
      "|    time_elapsed         | 36934       |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007986238 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | -0.000795   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.91        |\n",
      "|    n_updates            | 19350       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | -3.4344354  |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1937        |\n",
      "|    time_elapsed         | 36952       |\n",
      "|    total_timesteps      | 3966976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008401169 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.44        |\n",
      "|    n_updates            | 19360       |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | -2.9973752  |\n",
      "|    std                  | 16.2        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1938        |\n",
      "|    time_elapsed         | 36970       |\n",
      "|    total_timesteps      | 3969024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005178943 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 19370       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | -0.36569962 |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1939         |\n",
      "|    time_elapsed         | 36988        |\n",
      "|    total_timesteps      | 3971072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059342408 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 19380        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 0.6506038    |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1940         |\n",
      "|    time_elapsed         | 37007        |\n",
      "|    total_timesteps      | 3973120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031388034 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.332        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 19390        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 0.9651714    |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1941         |\n",
      "|    time_elapsed         | 37025        |\n",
      "|    total_timesteps      | 3975168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046517877 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.7         |\n",
      "|    n_updates            | 19400        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    reward               | -0.30772248  |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 49.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1942        |\n",
      "|    time_elapsed         | 37043       |\n",
      "|    total_timesteps      | 3977216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004517781 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 19410       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | -3.6939018  |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1943        |\n",
      "|    time_elapsed         | 37062       |\n",
      "|    total_timesteps      | 3979264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008699594 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | -0.00318    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | 0.4135121   |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1944         |\n",
      "|    time_elapsed         | 37080        |\n",
      "|    total_timesteps      | 3981312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035024988 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 19430        |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | -0.66856694  |\n",
      "|    std                  | 16.4         |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1945         |\n",
      "|    time_elapsed         | 37099        |\n",
      "|    total_timesteps      | 3983360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028506354 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.136        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 19440        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 3.3711655    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4284283.99\n",
      "total_reward: 3284283.99\n",
      "total_cost: 257006.52\n",
      "total_trades: 63747\n",
      "Sharpe: 0.798\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1946         |\n",
      "|    time_elapsed         | 37118        |\n",
      "|    total_timesteps      | 3985408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023905735 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.0883       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 19450        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 0.52356696   |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1947       |\n",
      "|    time_elapsed         | 37136      |\n",
      "|    total_timesteps      | 3987456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00431373 |\n",
      "|    clip_fraction        | 0.00918    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 19460      |\n",
      "|    policy_gradient_loss | -0.00612   |\n",
      "|    reward               | -0.9685196 |\n",
      "|    std                  | 16.5       |\n",
      "|    value_loss           | 29.3       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1948         |\n",
      "|    time_elapsed         | 37155        |\n",
      "|    total_timesteps      | 3989504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015243251 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.0993       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.5         |\n",
      "|    n_updates            | 19470        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | 0.8081033    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 59.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1949         |\n",
      "|    time_elapsed         | 37173        |\n",
      "|    total_timesteps      | 3991552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027029004 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.151        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 19480        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 1.7335719    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 53.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1950        |\n",
      "|    time_elapsed         | 37191       |\n",
      "|    total_timesteps      | 3993600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007683437 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | -0.12       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.18        |\n",
      "|    n_updates            | 19490       |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    reward               | -0.6986959  |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1951        |\n",
      "|    time_elapsed         | 37209       |\n",
      "|    total_timesteps      | 3995648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002969544 |\n",
      "|    clip_fraction        | 0.00547     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 19500       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | -0.824266   |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1952         |\n",
      "|    time_elapsed         | 37228        |\n",
      "|    total_timesteps      | 3997696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025643841 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.2         |\n",
      "|    n_updates            | 19510        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | -2.312746    |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1953         |\n",
      "|    time_elapsed         | 37246        |\n",
      "|    total_timesteps      | 3999744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031869495 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.0657       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.63         |\n",
      "|    n_updates            | 19520        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 0.12802748   |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1954         |\n",
      "|    time_elapsed         | 37265        |\n",
      "|    total_timesteps      | 4001792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063643707 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    reward               | -0.030703187 |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1955         |\n",
      "|    time_elapsed         | 37283        |\n",
      "|    total_timesteps      | 4003840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071507976 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.0695       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 19540        |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    reward               | -7.778622    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1956         |\n",
      "|    time_elapsed         | 37301        |\n",
      "|    total_timesteps      | 4005888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055642696 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | -0.0219      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 19550        |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    reward               | 4.1561837    |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 39           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1957         |\n",
      "|    time_elapsed         | 37320        |\n",
      "|    total_timesteps      | 4007936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072216056 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 19560        |\n",
      "|    policy_gradient_loss | -0.00843     |\n",
      "|    reward               | -1.5524685   |\n",
      "|    std                  | 16.7         |\n",
      "|    value_loss           | 19.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1958        |\n",
      "|    time_elapsed         | 37338       |\n",
      "|    total_timesteps      | 4009984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008197308 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.0926      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 19570       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.3810766  |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1959         |\n",
      "|    time_elapsed         | 37357        |\n",
      "|    total_timesteps      | 4012032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014549748 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 0.2994241    |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4417955.92\n",
      "total_reward: 3417955.92\n",
      "total_cost: 281693.12\n",
      "total_trades: 65701\n",
      "Sharpe: 0.820\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1960        |\n",
      "|    time_elapsed         | 37375       |\n",
      "|    total_timesteps      | 4014080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004996776 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 19590       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    reward               | 1.1990389   |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 1961       |\n",
      "|    time_elapsed         | 37394      |\n",
      "|    total_timesteps      | 4016128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00918765 |\n",
      "|    clip_fraction        | 0.0522     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.5       |\n",
      "|    n_updates            | 19600      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | -1.0260309 |\n",
      "|    std                  | 16.8       |\n",
      "|    value_loss           | 30         |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1962        |\n",
      "|    time_elapsed         | 37413       |\n",
      "|    total_timesteps      | 4018176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007276502 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 19610       |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    reward               | 1.8833609   |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1963         |\n",
      "|    time_elapsed         | 37431        |\n",
      "|    total_timesteps      | 4020224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038112924 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 19620        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | -0.1251231   |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1964        |\n",
      "|    time_elapsed         | 37449       |\n",
      "|    total_timesteps      | 4022272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004129916 |\n",
      "|    clip_fraction        | 0.00674     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.95        |\n",
      "|    n_updates            | 19630       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -0.6235313  |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1965         |\n",
      "|    time_elapsed         | 37468        |\n",
      "|    total_timesteps      | 4024320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019881893 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 19640        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 1.4191029    |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1966         |\n",
      "|    time_elapsed         | 37486        |\n",
      "|    total_timesteps      | 4026368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021069106 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.0941       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 19650        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 1.1543845    |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 57           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 37505       |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009927945 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.0493      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.45        |\n",
      "|    n_updates            | 19660       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    reward               | 1.3595521   |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1968         |\n",
      "|    time_elapsed         | 37523        |\n",
      "|    total_timesteps      | 4030464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071812384 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 19670        |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    reward               | -1.2338513   |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 43.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1969         |\n",
      "|    time_elapsed         | 37542        |\n",
      "|    total_timesteps      | 4032512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028512606 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -0.16970101  |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 48           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1970         |\n",
      "|    time_elapsed         | 37561        |\n",
      "|    total_timesteps      | 4034560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056955395 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.0574       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 19690        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | 0.14485365   |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1971        |\n",
      "|    time_elapsed         | 37579       |\n",
      "|    total_timesteps      | 4036608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007385319 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.0448      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 19700       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    reward               | 1.1795821   |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1972        |\n",
      "|    time_elapsed         | 37597       |\n",
      "|    total_timesteps      | 4038656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004905299 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 19710       |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | 0.017138345 |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1973         |\n",
      "|    time_elapsed         | 37616        |\n",
      "|    total_timesteps      | 4040704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020730759 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 19720        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -0.9470332   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 70.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4382646.81\n",
      "total_reward: 3382646.81\n",
      "total_cost: 216906.60\n",
      "total_trades: 61749\n",
      "Sharpe: 0.788\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 37634       |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008630001 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.76        |\n",
      "|    n_updates            | 19730       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 1.8799548   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 19.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1975         |\n",
      "|    time_elapsed         | 37652        |\n",
      "|    total_timesteps      | 4044800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033634459 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 19740        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -3.7860403   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1976         |\n",
      "|    time_elapsed         | 37671        |\n",
      "|    total_timesteps      | 4046848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028130966 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.101        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 19750        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | -1.4231676   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1977         |\n",
      "|    time_elapsed         | 37689        |\n",
      "|    total_timesteps      | 4048896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035037491 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 19760        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | -0.444895    |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1978         |\n",
      "|    time_elapsed         | 37708        |\n",
      "|    total_timesteps      | 4050944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037657125 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.294        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 19770        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    reward               | -1.0095063   |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1979        |\n",
      "|    time_elapsed         | 37726       |\n",
      "|    total_timesteps      | 4052992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002717983 |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 19780       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | -1.7701077  |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 59.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1980         |\n",
      "|    time_elapsed         | 37744        |\n",
      "|    total_timesteps      | 4055040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017568647 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 19790        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | 2.0931962    |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1981        |\n",
      "|    time_elapsed         | 37763       |\n",
      "|    total_timesteps      | 4057088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005849026 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 19800       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    reward               | -0.36654487 |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1982         |\n",
      "|    time_elapsed         | 37782        |\n",
      "|    total_timesteps      | 4059136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017264098 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.2         |\n",
      "|    n_updates            | 19810        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 0.7147085    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1983         |\n",
      "|    time_elapsed         | 37800        |\n",
      "|    total_timesteps      | 4061184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042360583 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | -5.304782    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 46.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1984         |\n",
      "|    time_elapsed         | 37819        |\n",
      "|    total_timesteps      | 4063232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040443935 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 19830        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    reward               | 3.2166426    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 34           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1985         |\n",
      "|    time_elapsed         | 37838        |\n",
      "|    total_timesteps      | 4065280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020394754 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 19840        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    reward               | 0.5387318    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1986         |\n",
      "|    time_elapsed         | 37856        |\n",
      "|    total_timesteps      | 4067328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017716754 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 19850        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.5884541   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1987         |\n",
      "|    time_elapsed         | 37875        |\n",
      "|    total_timesteps      | 4069376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057394737 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 19860        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    reward               | 0.8259153    |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 46.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4023702.06\n",
      "total_reward: 3023702.06\n",
      "total_cost: 157259.67\n",
      "total_trades: 57830\n",
      "Sharpe: 0.734\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1988        |\n",
      "|    time_elapsed         | 37893       |\n",
      "|    total_timesteps      | 4071424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008314522 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -1.1947675  |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1989        |\n",
      "|    time_elapsed         | 37912       |\n",
      "|    total_timesteps      | 4073472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003952535 |\n",
      "|    clip_fraction        | 0.00552     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 19880       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | 0.72488844  |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1990        |\n",
      "|    time_elapsed         | 37930       |\n",
      "|    total_timesteps      | 4075520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004775727 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 19890       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -3.4987295  |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1991        |\n",
      "|    time_elapsed         | 37948       |\n",
      "|    total_timesteps      | 4077568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009141147 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.95        |\n",
      "|    n_updates            | 19900       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | 0.48099527  |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1992        |\n",
      "|    time_elapsed         | 37967       |\n",
      "|    total_timesteps      | 4079616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005141343 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 19910       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 0.55667317  |\n",
      "|    std                  | 17.6        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1993         |\n",
      "|    time_elapsed         | 37985        |\n",
      "|    total_timesteps      | 4081664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027053405 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 19920        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | 0.6516345    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 60.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1994         |\n",
      "|    time_elapsed         | 38004        |\n",
      "|    total_timesteps      | 4083712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067256885 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 19930        |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    reward               | -5.7155657   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1995         |\n",
      "|    time_elapsed         | 38023        |\n",
      "|    total_timesteps      | 4085760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065307603 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 19940        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | -0.93201745  |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1996         |\n",
      "|    time_elapsed         | 38042        |\n",
      "|    total_timesteps      | 4087808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035129567 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.0826       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 19950        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | 3.028819     |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 72.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 1997          |\n",
      "|    time_elapsed         | 38061         |\n",
      "|    total_timesteps      | 4089856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063801574 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.108         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.5          |\n",
      "|    n_updates            | 19960         |\n",
      "|    policy_gradient_loss | -0.00277      |\n",
      "|    reward               | 4.027808      |\n",
      "|    std                  | 17.6          |\n",
      "|    value_loss           | 61            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1998        |\n",
      "|    time_elapsed         | 38079       |\n",
      "|    total_timesteps      | 4091904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011193503 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.0581      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.72        |\n",
      "|    n_updates            | 19970       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 2.0250952   |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 1999        |\n",
      "|    time_elapsed         | 38097       |\n",
      "|    total_timesteps      | 4093952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003443447 |\n",
      "|    clip_fraction        | 0.00532     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.095       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 19980       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | -4.9276457  |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2000        |\n",
      "|    time_elapsed         | 38116       |\n",
      "|    total_timesteps      | 4096000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004619167 |\n",
      "|    clip_fraction        | 0.00933     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 19990       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    reward               | 2.302894    |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2001        |\n",
      "|    time_elapsed         | 38134       |\n",
      "|    total_timesteps      | 4098048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005113549 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.58        |\n",
      "|    n_updates            | 20000       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | -1.6358457  |\n",
      "|    std                  | 17.7        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4020439.74\n",
      "total_reward: 3020439.74\n",
      "total_cost: 193369.62\n",
      "total_trades: 60123\n",
      "Sharpe: 0.784\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2002         |\n",
      "|    time_elapsed         | 38153        |\n",
      "|    total_timesteps      | 4100096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019506121 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.316        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 20010        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 1.8638762    |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2003         |\n",
      "|    time_elapsed         | 38171        |\n",
      "|    total_timesteps      | 4102144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036333904 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 20020        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 0.97566617   |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2004         |\n",
      "|    time_elapsed         | 38190        |\n",
      "|    total_timesteps      | 4104192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017952533 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.201        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.71         |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -1.5782093   |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2005        |\n",
      "|    time_elapsed         | 38208       |\n",
      "|    total_timesteps      | 4106240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008734155 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    reward               | 0.017381039 |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2006        |\n",
      "|    time_elapsed         | 38227       |\n",
      "|    total_timesteps      | 4108288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001839619 |\n",
      "|    clip_fraction        | 0.00264     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 20050       |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    reward               | -1.9290206  |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 56.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2007         |\n",
      "|    time_elapsed         | 38245        |\n",
      "|    total_timesteps      | 4110336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016429571 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.131        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 20060        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 1.4541677    |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 56           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2008         |\n",
      "|    time_elapsed         | 38264        |\n",
      "|    total_timesteps      | 4112384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011594195  |\n",
      "|    clip_fraction        | 0.0625       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.0666       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 20070        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    reward               | -0.090500176 |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2009         |\n",
      "|    time_elapsed         | 38282        |\n",
      "|    total_timesteps      | 4114432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038641524 |\n",
      "|    clip_fraction        | 0.00728      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 20080        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 0.6802755    |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2010        |\n",
      "|    time_elapsed         | 38300       |\n",
      "|    total_timesteps      | 4116480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003207527 |\n",
      "|    clip_fraction        | 0.00269     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.0856      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 20090       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -0.9974913  |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 75.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2011         |\n",
      "|    time_elapsed         | 38319        |\n",
      "|    total_timesteps      | 4118528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038221148 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 20100        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    reward               | -1.9437668   |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 43.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2012        |\n",
      "|    time_elapsed         | 38337       |\n",
      "|    total_timesteps      | 4120576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005166995 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 20110       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | 1.6213067   |\n",
      "|    std                  | 18          |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2013         |\n",
      "|    time_elapsed         | 38355        |\n",
      "|    total_timesteps      | 4122624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037774288 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 20120        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    reward               | -0.9319882   |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 43.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2014          |\n",
      "|    time_elapsed         | 38374         |\n",
      "|    total_timesteps      | 4124672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086715067 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.169         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18            |\n",
      "|    n_updates            | 20130         |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    reward               | 3.2741446     |\n",
      "|    std                  | 18            |\n",
      "|    value_loss           | 61.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2015         |\n",
      "|    time_elapsed         | 38393        |\n",
      "|    total_timesteps      | 4126720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071394965 |\n",
      "|    clip_fraction        | 0.0574       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.03         |\n",
      "|    n_updates            | 20140        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 0.93970114   |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 17           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4364877.08\n",
      "total_reward: 3364877.08\n",
      "total_cost: 167335.19\n",
      "total_trades: 58263\n",
      "Sharpe: 0.795\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2016         |\n",
      "|    time_elapsed         | 38411        |\n",
      "|    total_timesteps      | 4128768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038344818 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 20150        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 0.08804958   |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2017         |\n",
      "|    time_elapsed         | 38430        |\n",
      "|    total_timesteps      | 4130816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024523202 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 20160        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | -5.5930123   |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2018         |\n",
      "|    time_elapsed         | 38448        |\n",
      "|    total_timesteps      | 4132864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078751985 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.0661       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 20170        |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    reward               | -0.47904518  |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2019        |\n",
      "|    time_elapsed         | 38466       |\n",
      "|    total_timesteps      | 4134912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00312314  |\n",
      "|    clip_fraction        | 0.00337     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 20180       |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | -0.18820101 |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 35.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2020         |\n",
      "|    time_elapsed         | 38485        |\n",
      "|    total_timesteps      | 4136960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012635783 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -9.941031    |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2021          |\n",
      "|    time_elapsed         | 38503         |\n",
      "|    total_timesteps      | 4139008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080358726 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.157         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 33.8          |\n",
      "|    n_updates            | 20200         |\n",
      "|    policy_gradient_loss | -0.00294      |\n",
      "|    reward               | 0.19914405    |\n",
      "|    std                  | 18.1          |\n",
      "|    value_loss           | 57.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2022       |\n",
      "|    time_elapsed         | 38522      |\n",
      "|    total_timesteps      | 4141056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00630119 |\n",
      "|    clip_fraction        | 0.0157     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -125       |\n",
      "|    explained_variance   | 0.234      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 4.89       |\n",
      "|    n_updates            | 20210      |\n",
      "|    policy_gradient_loss | -0.0049    |\n",
      "|    reward               | 0.5258872  |\n",
      "|    std                  | 18.2       |\n",
      "|    value_loss           | 16.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2023        |\n",
      "|    time_elapsed         | 38541       |\n",
      "|    total_timesteps      | 4143104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002721991 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 20220       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    reward               | 1.2778214   |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2024        |\n",
      "|    time_elapsed         | 38559       |\n",
      "|    total_timesteps      | 4145152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001226983 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 20230       |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    reward               | -0.650531   |\n",
      "|    std                  | 18.2        |\n",
      "|    value_loss           | 53.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2025         |\n",
      "|    time_elapsed         | 38577        |\n",
      "|    total_timesteps      | 4147200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059226607 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.0753       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 20240        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | 3.1014569    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2026         |\n",
      "|    time_elapsed         | 38597        |\n",
      "|    total_timesteps      | 4149248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047449623 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 20250        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | -5.414749    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2027        |\n",
      "|    time_elapsed         | 38615       |\n",
      "|    total_timesteps      | 4151296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002046043 |\n",
      "|    clip_fraction        | 0.00171     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.0945      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 20260       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 0.99251455  |\n",
      "|    std                  | 18.3        |\n",
      "|    value_loss           | 57.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2028         |\n",
      "|    time_elapsed         | 38634        |\n",
      "|    total_timesteps      | 4153344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028775502 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.151        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 20270        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 2.9458039    |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 39.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2029        |\n",
      "|    time_elapsed         | 38652       |\n",
      "|    total_timesteps      | 4155392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009327251 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 20280       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 2.5008154   |\n",
      "|    std                  | 18.4        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4861881.42\n",
      "total_reward: 3861881.42\n",
      "total_cost: 173879.15\n",
      "total_trades: 58848\n",
      "Sharpe: 0.850\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2030         |\n",
      "|    time_elapsed         | 38671        |\n",
      "|    total_timesteps      | 4157440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047712983 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 20290        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | -0.61724883  |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 72.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2031         |\n",
      "|    time_elapsed         | 38689        |\n",
      "|    total_timesteps      | 4159488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036088398 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 20300        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    reward               | 2.622042     |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 57.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2032         |\n",
      "|    time_elapsed         | 38708        |\n",
      "|    total_timesteps      | 4161536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028064235 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | -0.331       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 20310        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | -1.1161816   |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2033         |\n",
      "|    time_elapsed         | 38726        |\n",
      "|    total_timesteps      | 4163584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024950411 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.5          |\n",
      "|    n_updates            | 20320        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 1.9265279    |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2034         |\n",
      "|    time_elapsed         | 38744        |\n",
      "|    total_timesteps      | 4165632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043818625 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 20330        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | 9.081627     |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2035        |\n",
      "|    time_elapsed         | 38763       |\n",
      "|    total_timesteps      | 4167680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005387543 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.096       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 20340       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 0.196787    |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2036         |\n",
      "|    time_elapsed         | 38781        |\n",
      "|    total_timesteps      | 4169728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037815622 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.123        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 20350        |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    reward               | 0.5787397    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2037         |\n",
      "|    time_elapsed         | 38799        |\n",
      "|    total_timesteps      | 4171776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037704473 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.167        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    reward               | 0.87415755   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 49.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2038         |\n",
      "|    time_elapsed         | 38817        |\n",
      "|    total_timesteps      | 4173824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058900774 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 20370        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | -0.60404     |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2039       |\n",
      "|    time_elapsed         | 38836      |\n",
      "|    total_timesteps      | 4175872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00632759 |\n",
      "|    clip_fraction        | 0.0146     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -125       |\n",
      "|    explained_variance   | 0.0613     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.94       |\n",
      "|    n_updates            | 20380      |\n",
      "|    policy_gradient_loss | -0.00528   |\n",
      "|    reward               | -1.8252149 |\n",
      "|    std                  | 18.5       |\n",
      "|    value_loss           | 24.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2040         |\n",
      "|    time_elapsed         | 38854        |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066630016 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.0838       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.6         |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.00853     |\n",
      "|    reward               | 0.603732     |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 54.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2041         |\n",
      "|    time_elapsed         | 38872        |\n",
      "|    total_timesteps      | 4179968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055909627 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 20400        |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    reward               | 0.99540395   |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 60.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2042        |\n",
      "|    time_elapsed         | 38890       |\n",
      "|    total_timesteps      | 4182016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007105591 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.0694      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    reward               | 0.7233744   |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2043        |\n",
      "|    time_elapsed         | 38908       |\n",
      "|    total_timesteps      | 4184064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004863058 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 20420       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | -1.7387071  |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2044        |\n",
      "|    time_elapsed         | 38927       |\n",
      "|    total_timesteps      | 4186112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004883839 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 20430       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | -12.434937  |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3696752.50\n",
      "total_reward: 2696752.50\n",
      "total_cost: 128131.06\n",
      "total_trades: 56694\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2045         |\n",
      "|    time_elapsed         | 38946        |\n",
      "|    total_timesteps      | 4188160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023211224 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.059        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 20440        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 1.3563211    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 53.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2046        |\n",
      "|    time_elapsed         | 38964       |\n",
      "|    total_timesteps      | 4190208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007249372 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.042       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.93        |\n",
      "|    n_updates            | 20450       |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    reward               | 0.03734651  |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2047         |\n",
      "|    time_elapsed         | 38983        |\n",
      "|    total_timesteps      | 4192256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038855828 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.143        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 20460        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | 0.53699565   |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 61.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2048        |\n",
      "|    time_elapsed         | 39001       |\n",
      "|    total_timesteps      | 4194304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004170365 |\n",
      "|    clip_fraction        | 0.00571     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 20470       |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | -3.090036   |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2049         |\n",
      "|    time_elapsed         | 39019        |\n",
      "|    total_timesteps      | 4196352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045121545 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 20480        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | -2.0767827   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2050         |\n",
      "|    time_elapsed         | 39038        |\n",
      "|    total_timesteps      | 4198400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016296466 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 20490        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | 4.702831     |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2051        |\n",
      "|    time_elapsed         | 39056       |\n",
      "|    total_timesteps      | 4200448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004055469 |\n",
      "|    clip_fraction        | 0.00796     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 20500       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -5.038647   |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2052         |\n",
      "|    time_elapsed         | 39075        |\n",
      "|    total_timesteps      | 4202496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037965705 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.6         |\n",
      "|    n_updates            | 20510        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | 2.0965314    |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2053        |\n",
      "|    time_elapsed         | 39093       |\n",
      "|    total_timesteps      | 4204544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422546 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 20520       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    reward               | 0.45455143  |\n",
      "|    std                  | 19.1        |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2054         |\n",
      "|    time_elapsed         | 39112        |\n",
      "|    total_timesteps      | 4206592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022815326 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 1.1452062    |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 46.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2055         |\n",
      "|    time_elapsed         | 39130        |\n",
      "|    total_timesteps      | 4208640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031874762 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 20540        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | -2.0219204   |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 64.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2056        |\n",
      "|    time_elapsed         | 39149       |\n",
      "|    total_timesteps      | 4210688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008473029 |\n",
      "|    clip_fraction        | 0.036       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.0705      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 20550       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    reward               | 2.1061954   |\n",
      "|    std                  | 19.1        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2057         |\n",
      "|    time_elapsed         | 39167        |\n",
      "|    total_timesteps      | 4212736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022209906 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.232        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 1.077296     |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 39.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2058       |\n",
      "|    time_elapsed         | 39187      |\n",
      "|    total_timesteps      | 4214784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00622005 |\n",
      "|    clip_fraction        | 0.0274     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -126       |\n",
      "|    explained_variance   | 0.16       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23         |\n",
      "|    n_updates            | 20570      |\n",
      "|    policy_gradient_loss | -0.00618   |\n",
      "|    reward               | 1.3959453  |\n",
      "|    std                  | 19.2       |\n",
      "|    value_loss           | 62.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 2520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4141005.82\n",
      "total_reward: 3141005.82\n",
      "total_cost: 148447.17\n",
      "total_trades: 58491\n",
      "Sharpe: 0.735\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2059         |\n",
      "|    time_elapsed         | 39205        |\n",
      "|    total_timesteps      | 4216832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048459778 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.07         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 20580        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    reward               | 5.156933     |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2060         |\n",
      "|    time_elapsed         | 39224        |\n",
      "|    total_timesteps      | 4218880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045439894 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 20590        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | 0.40641755   |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2061         |\n",
      "|    time_elapsed         | 39242        |\n",
      "|    total_timesteps      | 4220928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046599596 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 20600        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 0.8183976    |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2062        |\n",
      "|    time_elapsed         | 39261       |\n",
      "|    total_timesteps      | 4222976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002237849 |\n",
      "|    clip_fraction        | 0.000684    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 20610       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 0.4333947   |\n",
      "|    std                  | 19.2        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2063        |\n",
      "|    time_elapsed         | 39279       |\n",
      "|    total_timesteps      | 4225024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005463278 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.98        |\n",
      "|    n_updates            | 20620       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | -0.29956278 |\n",
      "|    std                  | 19.2        |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2064         |\n",
      "|    time_elapsed         | 39297        |\n",
      "|    total_timesteps      | 4227072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034246673 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.145        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 20630        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 1.0089511    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2065        |\n",
      "|    time_elapsed         | 39316       |\n",
      "|    total_timesteps      | 4229120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007252313 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 20640       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 0.4639548   |\n",
      "|    std                  | 19.3        |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2066         |\n",
      "|    time_elapsed         | 39334        |\n",
      "|    total_timesteps      | 4231168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055836253 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.067        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 20650        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | 1.5382987    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 40.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2067        |\n",
      "|    time_elapsed         | 39353       |\n",
      "|    total_timesteps      | 4233216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004761464 |\n",
      "|    clip_fraction        | 0.00811     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 20660       |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    reward               | -0.25699484 |\n",
      "|    std                  | 19.4        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2068         |\n",
      "|    time_elapsed         | 39371        |\n",
      "|    total_timesteps      | 4235264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032235086 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.252        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | -2.148844    |\n",
      "|    std                  | 19.4         |\n",
      "|    value_loss           | 55.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2069        |\n",
      "|    time_elapsed         | 39389       |\n",
      "|    total_timesteps      | 4237312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001940674 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 20680       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 0.6305408   |\n",
      "|    std                  | 19.4        |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2070         |\n",
      "|    time_elapsed         | 39408        |\n",
      "|    total_timesteps      | 4239360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014568677 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.193        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 20690        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -1.3783637   |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2071        |\n",
      "|    time_elapsed         | 39427       |\n",
      "|    total_timesteps      | 4241408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002766071 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 20700       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -0.3890766  |\n",
      "|    std                  | 19.5        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2072         |\n",
      "|    time_elapsed         | 39445        |\n",
      "|    total_timesteps      | 4243456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030625355 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.3         |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | 1.6210462    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 56.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4040428.47\n",
      "total_reward: 3040428.47\n",
      "total_cost: 118432.40\n",
      "total_trades: 56494\n",
      "Sharpe: 0.731\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2073         |\n",
      "|    time_elapsed         | 39464        |\n",
      "|    total_timesteps      | 4245504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060267826 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 20720        |\n",
      "|    policy_gradient_loss | -0.00879     |\n",
      "|    reward               | 2.3613095    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2074         |\n",
      "|    time_elapsed         | 39482        |\n",
      "|    total_timesteps      | 4247552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020925892 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 20730        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 2.6036015    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 33.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2075        |\n",
      "|    time_elapsed         | 39500       |\n",
      "|    total_timesteps      | 4249600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005757576 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 20740       |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | -0.10859475 |\n",
      "|    std                  | 19.6        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2076         |\n",
      "|    time_elapsed         | 39519        |\n",
      "|    total_timesteps      | 4251648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074787857 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.0664       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    reward               | 1.0168955    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 65.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2077         |\n",
      "|    time_elapsed         | 39538        |\n",
      "|    total_timesteps      | 4253696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038380546 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 20760        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    reward               | -1.7713569   |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2078         |\n",
      "|    time_elapsed         | 39556        |\n",
      "|    total_timesteps      | 4255744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035037904 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 20770        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 0.110409975  |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2079        |\n",
      "|    time_elapsed         | 39575       |\n",
      "|    total_timesteps      | 4257792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004718559 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 20780       |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | 0.79182297  |\n",
      "|    std                  | 19.7        |\n",
      "|    value_loss           | 61.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2080        |\n",
      "|    time_elapsed         | 39593       |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009812356 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 20790       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 2.0668018   |\n",
      "|    std                  | 19.8        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2081          |\n",
      "|    time_elapsed         | 39612         |\n",
      "|    total_timesteps      | 4261888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0048620356  |\n",
      "|    clip_fraction        | 0.0114        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.166         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.5          |\n",
      "|    n_updates            | 20800         |\n",
      "|    policy_gradient_loss | -0.00749      |\n",
      "|    reward               | -0.0004209446 |\n",
      "|    std                  | 19.8          |\n",
      "|    value_loss           | 52.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2082        |\n",
      "|    time_elapsed         | 39630       |\n",
      "|    total_timesteps      | 4263936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004184815 |\n",
      "|    clip_fraction        | 0.00757     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 20810       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    reward               | 5.0008073   |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 72.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2083        |\n",
      "|    time_elapsed         | 39649       |\n",
      "|    total_timesteps      | 4265984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004282243 |\n",
      "|    clip_fraction        | 0.00605     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 20820       |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | 2.4058206   |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2084         |\n",
      "|    time_elapsed         | 39667        |\n",
      "|    total_timesteps      | 4268032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031019915 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.12         |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | 1.240414     |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2085         |\n",
      "|    time_elapsed         | 39685        |\n",
      "|    total_timesteps      | 4270080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045914403 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 20840        |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    reward               | 0.8759821    |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2086         |\n",
      "|    time_elapsed         | 39704        |\n",
      "|    total_timesteps      | 4272128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033944007 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.131        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 20850        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | 0.857749     |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4357477.13\n",
      "total_reward: 3357477.13\n",
      "total_cost: 140446.39\n",
      "total_trades: 57456\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2087         |\n",
      "|    time_elapsed         | 39723        |\n",
      "|    total_timesteps      | 4274176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043449784 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.0957       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.06         |\n",
      "|    n_updates            | 20860        |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    reward               | -0.7826517   |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2088         |\n",
      "|    time_elapsed         | 39742        |\n",
      "|    total_timesteps      | 4276224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041298866 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | -0.040020533 |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2089         |\n",
      "|    time_elapsed         | 39760        |\n",
      "|    total_timesteps      | 4278272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044482467 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32           |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    reward               | 3.6529996    |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 66.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2090        |\n",
      "|    time_elapsed         | 39778       |\n",
      "|    total_timesteps      | 4280320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007066187 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 20890       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | 0.7757974   |\n",
      "|    std                  | 20.1        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2091        |\n",
      "|    time_elapsed         | 39796       |\n",
      "|    total_timesteps      | 4282368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006825379 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 20900       |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    reward               | -2.6292732  |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2092        |\n",
      "|    time_elapsed         | 39815       |\n",
      "|    total_timesteps      | 4284416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006780837 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 20910       |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    reward               | 0.9569515   |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2093        |\n",
      "|    time_elapsed         | 39834       |\n",
      "|    total_timesteps      | 4286464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007555993 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.4        |\n",
      "|    n_updates            | 20920       |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    reward               | -0.97593284 |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 51.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2094        |\n",
      "|    time_elapsed         | 39852       |\n",
      "|    total_timesteps      | 4288512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008430736 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 20930       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    reward               | -1.2284817  |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2095        |\n",
      "|    time_elapsed         | 39871       |\n",
      "|    total_timesteps      | 4290560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005257028 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 20940       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    reward               | -0.4817649  |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 49          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2096         |\n",
      "|    time_elapsed         | 39890        |\n",
      "|    total_timesteps      | 4292608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020686567 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 20950        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 2.9117012    |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 60.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2097         |\n",
      "|    time_elapsed         | 39908        |\n",
      "|    total_timesteps      | 4294656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029099742 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.122        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 20960        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | -0.5418253   |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2098         |\n",
      "|    time_elapsed         | 39927        |\n",
      "|    total_timesteps      | 4296704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023780866 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | 0.303058     |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2099         |\n",
      "|    time_elapsed         | 39945        |\n",
      "|    total_timesteps      | 4298752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014983201 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 20980        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 3.0908568    |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2100         |\n",
      "|    time_elapsed         | 39963        |\n",
      "|    total_timesteps      | 4300800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008473968 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.00641      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 20990        |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    reward               | -0.3232209   |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 62           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4054398.51\n",
      "total_reward: 3054398.51\n",
      "total_cost: 162096.61\n",
      "total_trades: 58246\n",
      "Sharpe: 0.750\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2101         |\n",
      "|    time_elapsed         | 39981        |\n",
      "|    total_timesteps      | 4302848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022709058 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.53         |\n",
      "|    n_updates            | 21000        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | -1.3165755   |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2102         |\n",
      "|    time_elapsed         | 40000        |\n",
      "|    total_timesteps      | 4304896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026384145 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 21010        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -1.4060746   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2103         |\n",
      "|    time_elapsed         | 40018        |\n",
      "|    total_timesteps      | 4306944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018237372 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 21020        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 0.2377991    |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 66.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2104        |\n",
      "|    time_elapsed         | 40036       |\n",
      "|    total_timesteps      | 4308992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003979626 |\n",
      "|    clip_fraction        | 0.00918     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 21030       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | -2.1161227  |\n",
      "|    std                  | 20.7        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2105         |\n",
      "|    time_elapsed         | 40055        |\n",
      "|    total_timesteps      | 4311040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028262534 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 21040        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | -1.0158508   |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 58.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2106         |\n",
      "|    time_elapsed         | 40073        |\n",
      "|    total_timesteps      | 4313088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036236313 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 21050        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    reward               | 1.6350428    |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 56.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2107        |\n",
      "|    time_elapsed         | 40092       |\n",
      "|    total_timesteps      | 4315136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003251802 |\n",
      "|    clip_fraction        | 0.00386     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | -0.0421     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 21060       |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | 6.892322    |\n",
      "|    std                  | 20.8        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2108         |\n",
      "|    time_elapsed         | 40110        |\n",
      "|    total_timesteps      | 4317184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049788514 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.328        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 21070        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | 3.1121066    |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2109         |\n",
      "|    time_elapsed         | 40128        |\n",
      "|    total_timesteps      | 4319232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038647668 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.173        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    reward               | -0.9836148   |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 65           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2110         |\n",
      "|    time_elapsed         | 40146        |\n",
      "|    total_timesteps      | 4321280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020435173 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | -2.4750965   |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 66.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2111        |\n",
      "|    time_elapsed         | 40164       |\n",
      "|    total_timesteps      | 4323328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008073932 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.04        |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    reward               | -0.45833683 |\n",
      "|    std                  | 21          |\n",
      "|    value_loss           | 14.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2112        |\n",
      "|    time_elapsed         | 40183       |\n",
      "|    total_timesteps      | 4325376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003079518 |\n",
      "|    clip_fraction        | 0.00317     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 21110       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | 2.5191143   |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2113        |\n",
      "|    time_elapsed         | 40202       |\n",
      "|    total_timesteps      | 4327424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003144893 |\n",
      "|    clip_fraction        | 0.00425     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 21120       |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | -0.4959195  |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2114        |\n",
      "|    time_elapsed         | 40220       |\n",
      "|    total_timesteps      | 4329472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004222572 |\n",
      "|    clip_fraction        | 0.00889     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.0361      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 21130       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | 0.23925991  |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4073598.86\n",
      "total_reward: 3073598.86\n",
      "total_cost: 206473.41\n",
      "total_trades: 60562\n",
      "Sharpe: 0.756\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2115        |\n",
      "|    time_elapsed         | 40241       |\n",
      "|    total_timesteps      | 4331520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002471635 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 21140       |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    reward               | 0.35921994  |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 40260       |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005168061 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 21150       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    reward               | 0.6080408   |\n",
      "|    std                  | 21.2        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2117         |\n",
      "|    time_elapsed         | 40278        |\n",
      "|    total_timesteps      | 4335616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036436226 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 21160        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | 0.10952675   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 46           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2118        |\n",
      "|    time_elapsed         | 40296       |\n",
      "|    total_timesteps      | 4337664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00445449  |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 21170       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | -0.16218208 |\n",
      "|    std                  | 21.3        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2119        |\n",
      "|    time_elapsed         | 40315       |\n",
      "|    total_timesteps      | 4339712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002338001 |\n",
      "|    clip_fraction        | 0.00181     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 21180       |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    reward               | 0.5176259   |\n",
      "|    std                  | 21.3        |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2120        |\n",
      "|    time_elapsed         | 40333       |\n",
      "|    total_timesteps      | 4341760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003823909 |\n",
      "|    clip_fraction        | 0.00845     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 21190       |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | 0.34911534  |\n",
      "|    std                  | 21.3        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2121         |\n",
      "|    time_elapsed         | 40352        |\n",
      "|    total_timesteps      | 4343808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016159856 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | -0.0072      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 21200        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 1.9325819    |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2122         |\n",
      "|    time_elapsed         | 40370        |\n",
      "|    total_timesteps      | 4345856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026619195 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -0.6870621   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2123         |\n",
      "|    time_elapsed         | 40389        |\n",
      "|    total_timesteps      | 4347904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023753084 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 21220        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | 1.3390836    |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2124        |\n",
      "|    time_elapsed         | 40408       |\n",
      "|    total_timesteps      | 4349952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006930014 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 21230       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    reward               | -5.0420938  |\n",
      "|    std                  | 21.4        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2125          |\n",
      "|    time_elapsed         | 40426         |\n",
      "|    total_timesteps      | 4352000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0034694793  |\n",
      "|    clip_fraction        | 0.0085        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.217         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.9          |\n",
      "|    n_updates            | 21240         |\n",
      "|    policy_gradient_loss | -0.0047       |\n",
      "|    reward               | -0.0029250358 |\n",
      "|    std                  | 21.5          |\n",
      "|    value_loss           | 32.1          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2126       |\n",
      "|    time_elapsed         | 40444      |\n",
      "|    total_timesteps      | 4354048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00285164 |\n",
      "|    clip_fraction        | 0.0019     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -129       |\n",
      "|    explained_variance   | 0.233      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 21250      |\n",
      "|    policy_gradient_loss | -0.00365   |\n",
      "|    reward               | 1.6541026  |\n",
      "|    std                  | 21.5       |\n",
      "|    value_loss           | 43         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2127         |\n",
      "|    time_elapsed         | 40462        |\n",
      "|    total_timesteps      | 4356096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023302482 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29           |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 1.3206241    |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 64.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2128        |\n",
      "|    time_elapsed         | 40481       |\n",
      "|    total_timesteps      | 4358144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004060778 |\n",
      "|    clip_fraction        | 0.00786     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.62        |\n",
      "|    n_updates            | 21270       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | 0.68253636  |\n",
      "|    std                  | 21.6        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4825389.37\n",
      "total_reward: 3825389.37\n",
      "total_cost: 249254.06\n",
      "total_trades: 62681\n",
      "Sharpe: 0.842\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2129        |\n",
      "|    time_elapsed         | 40499       |\n",
      "|    total_timesteps      | 4360192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004580726 |\n",
      "|    clip_fraction        | 0.00962     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 21280       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | -2.965211   |\n",
      "|    std                  | 21.6        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2130         |\n",
      "|    time_elapsed         | 40518        |\n",
      "|    total_timesteps      | 4362240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021664163 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 21290        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -10.023641   |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 51.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2131        |\n",
      "|    time_elapsed         | 40536       |\n",
      "|    total_timesteps      | 4364288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004322904 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | -0.00811    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 21300       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 0.73913795  |\n",
      "|    std                  | 21.7        |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2132        |\n",
      "|    time_elapsed         | 40555       |\n",
      "|    total_timesteps      | 4366336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005695013 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 21310       |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    reward               | -2.4710155  |\n",
      "|    std                  | 21.7        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2133         |\n",
      "|    time_elapsed         | 40573        |\n",
      "|    total_timesteps      | 4368384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047035716 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    reward               | -3.82219     |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2134        |\n",
      "|    time_elapsed         | 40593       |\n",
      "|    total_timesteps      | 4370432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001215816 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 21330       |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    reward               | -0.9245271  |\n",
      "|    std                  | 21.8        |\n",
      "|    value_loss           | 58.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2135        |\n",
      "|    time_elapsed         | 40611       |\n",
      "|    total_timesteps      | 4372480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008039309 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.8         |\n",
      "|    n_updates            | 21340       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.018752946 |\n",
      "|    std                  | 21.9        |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2136        |\n",
      "|    time_elapsed         | 40629       |\n",
      "|    total_timesteps      | 4374528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003575933 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 21350       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -0.5256564  |\n",
      "|    std                  | 21.9        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2137         |\n",
      "|    time_elapsed         | 40648        |\n",
      "|    total_timesteps      | 4376576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012209767 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    reward               | -2.693024    |\n",
      "|    std                  | 21.9         |\n",
      "|    value_loss           | 61           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2138        |\n",
      "|    time_elapsed         | 40666       |\n",
      "|    total_timesteps      | 4378624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003695432 |\n",
      "|    clip_fraction        | 0.00376     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.0477      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 21370       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -2.3442562  |\n",
      "|    std                  | 22          |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2139          |\n",
      "|    time_elapsed         | 40684         |\n",
      "|    total_timesteps      | 4380672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0076162284  |\n",
      "|    clip_fraction        | 0.0284        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.375         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.7          |\n",
      "|    n_updates            | 21380         |\n",
      "|    policy_gradient_loss | -0.00541      |\n",
      "|    reward               | 0.00088907365 |\n",
      "|    std                  | 22            |\n",
      "|    value_loss           | 30.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2140         |\n",
      "|    time_elapsed         | 40703        |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018101508 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 3.8355608    |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2141       |\n",
      "|    time_elapsed         | 40721      |\n",
      "|    total_timesteps      | 4384768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00163746 |\n",
      "|    clip_fraction        | 0.00337    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -130       |\n",
      "|    explained_variance   | 0.266      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.7       |\n",
      "|    n_updates            | 21400      |\n",
      "|    policy_gradient_loss | -0.00381   |\n",
      "|    reward               | -2.2742956 |\n",
      "|    std                  | 22.1       |\n",
      "|    value_loss           | 34.7       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2142         |\n",
      "|    time_elapsed         | 40740        |\n",
      "|    total_timesteps      | 4386816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025622286 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 21410        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -1.999364    |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4487092.52\n",
      "total_reward: 3487092.52\n",
      "total_cost: 191055.09\n",
      "total_trades: 59292\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2143         |\n",
      "|    time_elapsed         | 40759        |\n",
      "|    total_timesteps      | 4388864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017758085 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -0.4757791   |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2144         |\n",
      "|    time_elapsed         | 40777        |\n",
      "|    total_timesteps      | 4390912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025298744 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 21430        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | 1.4923748    |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 69.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2145         |\n",
      "|    time_elapsed         | 40797        |\n",
      "|    total_timesteps      | 4392960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058190045 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.55         |\n",
      "|    n_updates            | 21440        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 0.717042     |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2146        |\n",
      "|    time_elapsed         | 40815       |\n",
      "|    total_timesteps      | 4395008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002790481 |\n",
      "|    clip_fraction        | 0.00352     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 21450       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 1.3311623   |\n",
      "|    std                  | 22.2        |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2147         |\n",
      "|    time_elapsed         | 40834        |\n",
      "|    total_timesteps      | 4397056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037883432 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 21460        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 1.0843604    |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2148        |\n",
      "|    time_elapsed         | 40854       |\n",
      "|    total_timesteps      | 4399104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002443927 |\n",
      "|    clip_fraction        | 0.00337     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 21470       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | 0.52068114  |\n",
      "|    std                  | 22.3        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2149         |\n",
      "|    time_elapsed         | 40872        |\n",
      "|    total_timesteps      | 4401152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050959997 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.95         |\n",
      "|    n_updates            | 21480        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | 2.848623     |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2150         |\n",
      "|    time_elapsed         | 40891        |\n",
      "|    total_timesteps      | 4403200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016812521 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 21490        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 2.4331138    |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 43.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2151         |\n",
      "|    time_elapsed         | 40909        |\n",
      "|    total_timesteps      | 4405248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049300254 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 21500        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    reward               | 0.22184636   |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2152       |\n",
      "|    time_elapsed         | 40928      |\n",
      "|    total_timesteps      | 4407296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00832442 |\n",
      "|    clip_fraction        | 0.0465     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -130       |\n",
      "|    explained_variance   | 0.159      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.75       |\n",
      "|    n_updates            | 21510      |\n",
      "|    policy_gradient_loss | -0.00844   |\n",
      "|    reward               | 0.68369544 |\n",
      "|    std                  | 22.3       |\n",
      "|    value_loss           | 17         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2153         |\n",
      "|    time_elapsed         | 40946        |\n",
      "|    total_timesteps      | 4409344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034857583 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.319        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | -0.56865644  |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2154         |\n",
      "|    time_elapsed         | 40965        |\n",
      "|    total_timesteps      | 4411392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010775968 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 21530        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -6.973205    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 41.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2155         |\n",
      "|    time_elapsed         | 40983        |\n",
      "|    total_timesteps      | 4413440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046906807 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 21540        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | -3.131628    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2156        |\n",
      "|    time_elapsed         | 41002       |\n",
      "|    total_timesteps      | 4415488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005776509 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 21550       |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 0.11769357  |\n",
      "|    std                  | 22.5        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2157         |\n",
      "|    time_elapsed         | 41020        |\n",
      "|    total_timesteps      | 4417536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013315141 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.28         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | -24.285763   |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 60.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3947205.31\n",
      "total_reward: 2947205.31\n",
      "total_cost: 177537.01\n",
      "total_trades: 59458\n",
      "Sharpe: 0.742\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2158          |\n",
      "|    time_elapsed         | 41038         |\n",
      "|    total_timesteps      | 4419584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077464734 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.38          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.6          |\n",
      "|    n_updates            | 21570         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | 0.29031172    |\n",
      "|    std                  | 22.5          |\n",
      "|    value_loss           | 54.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2159         |\n",
      "|    time_elapsed         | 41057        |\n",
      "|    total_timesteps      | 4421632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044174194 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 21580        |\n",
      "|    policy_gradient_loss | -0.0081      |\n",
      "|    reward               | 0.79314303   |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2160         |\n",
      "|    time_elapsed         | 41075        |\n",
      "|    total_timesteps      | 4423680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013537616 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 21590        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 0.67526686   |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 53.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2161        |\n",
      "|    time_elapsed         | 41094       |\n",
      "|    total_timesteps      | 4425728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001620787 |\n",
      "|    clip_fraction        | 0.000537    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 21600       |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | -1.1300561  |\n",
      "|    std                  | 22.6        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2162         |\n",
      "|    time_elapsed         | 41112        |\n",
      "|    total_timesteps      | 4427776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016212952 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 21610        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 0.60754436   |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2163         |\n",
      "|    time_elapsed         | 41130        |\n",
      "|    total_timesteps      | 4429824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029124895 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 0.24260934   |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2164        |\n",
      "|    time_elapsed         | 41149       |\n",
      "|    total_timesteps      | 4431872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001474794 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 21630       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -0.8722449  |\n",
      "|    std                  | 22.7        |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2165        |\n",
      "|    time_elapsed         | 41167       |\n",
      "|    total_timesteps      | 4433920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002957398 |\n",
      "|    clip_fraction        | 0.00352     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 21640       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | 2.0776632   |\n",
      "|    std                  | 22.7        |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2166         |\n",
      "|    time_elapsed         | 41186        |\n",
      "|    total_timesteps      | 4435968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039586267 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 21650        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    reward               | 0.9044626    |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2167        |\n",
      "|    time_elapsed         | 41204       |\n",
      "|    total_timesteps      | 4438016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00247914  |\n",
      "|    clip_fraction        | 0.00146     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 21660       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    reward               | 0.068799645 |\n",
      "|    std                  | 22.7        |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2168         |\n",
      "|    time_elapsed         | 41222        |\n",
      "|    total_timesteps      | 4440064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012201868 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 21670        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 0.91820306   |\n",
      "|    std                  | 22.8         |\n",
      "|    value_loss           | 47.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2169        |\n",
      "|    time_elapsed         | 41241       |\n",
      "|    total_timesteps      | 4442112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004987794 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.55        |\n",
      "|    n_updates            | 21680       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | 0.50009453  |\n",
      "|    std                  | 22.8        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2170         |\n",
      "|    time_elapsed         | 41259        |\n",
      "|    total_timesteps      | 4444160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038670155 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 21690        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | 0.15977478   |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2171          |\n",
      "|    time_elapsed         | 41277         |\n",
      "|    total_timesteps      | 4446208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073666393 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.403         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.4          |\n",
      "|    n_updates            | 21700         |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    reward               | -2.9209929    |\n",
      "|    std                  | 22.9          |\n",
      "|    value_loss           | 50.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4397775.62\n",
      "total_reward: 3397775.62\n",
      "total_cost: 211395.87\n",
      "total_trades: 60879\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2172         |\n",
      "|    time_elapsed         | 41296        |\n",
      "|    total_timesteps      | 4448256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046594944 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 21710        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | -0.9405999   |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 37.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2173         |\n",
      "|    time_elapsed         | 41314        |\n",
      "|    total_timesteps      | 4450304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060480046 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.96         |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | 1.5853455    |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2174        |\n",
      "|    time_elapsed         | 41332       |\n",
      "|    total_timesteps      | 4452352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002680032 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 21730       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | -0.0120724  |\n",
      "|    std                  | 23          |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2175         |\n",
      "|    time_elapsed         | 41351        |\n",
      "|    total_timesteps      | 4454400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014116188 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.3         |\n",
      "|    n_updates            | 21740        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 1.0825531    |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 55.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2176        |\n",
      "|    time_elapsed         | 41369       |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003230804 |\n",
      "|    clip_fraction        | 0.00376     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 21750       |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -0.4233494  |\n",
      "|    std                  | 23.1        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2177       |\n",
      "|    time_elapsed         | 41388      |\n",
      "|    total_timesteps      | 4458496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00413231 |\n",
      "|    clip_fraction        | 0.0111     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -131       |\n",
      "|    explained_variance   | 0.469      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 24.6       |\n",
      "|    n_updates            | 21760      |\n",
      "|    policy_gradient_loss | -0.00658   |\n",
      "|    reward               | 2.2922528  |\n",
      "|    std                  | 23.1       |\n",
      "|    value_loss           | 48         |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2178          |\n",
      "|    time_elapsed         | 41406         |\n",
      "|    total_timesteps      | 4460544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068543473 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.23          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24.4          |\n",
      "|    n_updates            | 21770         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | -0.24437468   |\n",
      "|    std                  | 23.1          |\n",
      "|    value_loss           | 44.7          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2179        |\n",
      "|    time_elapsed         | 41425       |\n",
      "|    total_timesteps      | 4462592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005581776 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 21780       |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | 1.4195907   |\n",
      "|    std                  | 23.2        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2180         |\n",
      "|    time_elapsed         | 41443        |\n",
      "|    total_timesteps      | 4464640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029694359 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.95         |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | 1.8163539    |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2181         |\n",
      "|    time_elapsed         | 41462        |\n",
      "|    total_timesteps      | 4466688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015166873 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 21800        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | -0.656261    |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2182         |\n",
      "|    time_elapsed         | 41480        |\n",
      "|    total_timesteps      | 4468736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002313969 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 21810        |\n",
      "|    policy_gradient_loss | -0.000935    |\n",
      "|    reward               | 0.730373     |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2183         |\n",
      "|    time_elapsed         | 41498        |\n",
      "|    total_timesteps      | 4470784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037168616 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.51         |\n",
      "|    n_updates            | 21820        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -0.94926274  |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 20.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2184          |\n",
      "|    time_elapsed         | 41517         |\n",
      "|    total_timesteps      | 4472832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081441185 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.448         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.4          |\n",
      "|    n_updates            | 21830         |\n",
      "|    policy_gradient_loss | -0.00206      |\n",
      "|    reward               | 0.08610784    |\n",
      "|    std                  | 23.2          |\n",
      "|    value_loss           | 49.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2185         |\n",
      "|    time_elapsed         | 41535        |\n",
      "|    total_timesteps      | 4474880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012395061 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 21840        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 2.513956     |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 55.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4577251.43\n",
      "total_reward: 3577251.43\n",
      "total_cost: 212846.96\n",
      "total_trades: 61015\n",
      "Sharpe: 0.822\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2186         |\n",
      "|    time_elapsed         | 41553        |\n",
      "|    total_timesteps      | 4476928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038939198 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 21850        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    reward               | -2.1119242   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2187         |\n",
      "|    time_elapsed         | 41571        |\n",
      "|    total_timesteps      | 4478976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054259757 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    reward               | -1.3479697   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2188        |\n",
      "|    time_elapsed         | 41590       |\n",
      "|    total_timesteps      | 4481024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001100301 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 21870       |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    reward               | -0.663308   |\n",
      "|    std                  | 23.4        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2189         |\n",
      "|    time_elapsed         | 41608        |\n",
      "|    total_timesteps      | 4483072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008217824 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 21880        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    reward               | 2.5267818    |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2190         |\n",
      "|    time_elapsed         | 41626        |\n",
      "|    total_timesteps      | 4485120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072326395 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 21890        |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    reward               | -1.7131149   |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2191         |\n",
      "|    time_elapsed         | 41644        |\n",
      "|    total_timesteps      | 4487168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031817602 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.1         |\n",
      "|    n_updates            | 21900        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | -1.4767655   |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 56.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2192         |\n",
      "|    time_elapsed         | 41663        |\n",
      "|    total_timesteps      | 4489216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011308645 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 21910        |\n",
      "|    policy_gradient_loss | -0.000858    |\n",
      "|    reward               | 1.1510931    |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2193       |\n",
      "|    time_elapsed         | 41682      |\n",
      "|    total_timesteps      | 4491264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00341551 |\n",
      "|    clip_fraction        | 0.00645    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -132       |\n",
      "|    explained_variance   | 0.444      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.69       |\n",
      "|    n_updates            | 21920      |\n",
      "|    policy_gradient_loss | -0.00556   |\n",
      "|    reward               | 2.4645727  |\n",
      "|    std                  | 23.5       |\n",
      "|    value_loss           | 16.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2194         |\n",
      "|    time_elapsed         | 41700        |\n",
      "|    total_timesteps      | 4493312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034393123 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.1         |\n",
      "|    n_updates            | 21930        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | 0.8099094    |\n",
      "|    std                  | 23.5         |\n",
      "|    value_loss           | 43.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2195        |\n",
      "|    time_elapsed         | 41718       |\n",
      "|    total_timesteps      | 4495360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002070867 |\n",
      "|    clip_fraction        | 0.00166     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 21940       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    reward               | -1.3675022  |\n",
      "|    std                  | 23.6        |\n",
      "|    value_loss           | 52.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2196        |\n",
      "|    time_elapsed         | 41736       |\n",
      "|    total_timesteps      | 4497408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006149522 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 21950       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | 2.1186695   |\n",
      "|    std                  | 23.6        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2197         |\n",
      "|    time_elapsed         | 41755        |\n",
      "|    total_timesteps      | 4499456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023680737 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 21960        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | -2.5890138   |\n",
      "|    std                  | 23.6         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2198         |\n",
      "|    time_elapsed         | 41773        |\n",
      "|    total_timesteps      | 4501504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030499927 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 0.25959316   |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 55.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2199        |\n",
      "|    time_elapsed         | 41791       |\n",
      "|    total_timesteps      | 4503552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002143641 |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 21980       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | 1.9584478   |\n",
      "|    std                  | 23.7        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5197828.01\n",
      "total_reward: 4197828.01\n",
      "total_cost: 340066.84\n",
      "total_trades: 68086\n",
      "Sharpe: 0.877\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2200        |\n",
      "|    time_elapsed         | 41809       |\n",
      "|    total_timesteps      | 4505600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008806505 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 21990       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.20621012 |\n",
      "|    std                  | 23.8        |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2201        |\n",
      "|    time_elapsed         | 41827       |\n",
      "|    total_timesteps      | 4507648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004203258 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 22000       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    reward               | -1.1789827  |\n",
      "|    std                  | 23.8        |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2202         |\n",
      "|    time_elapsed         | 41845        |\n",
      "|    total_timesteps      | 4509696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009676113 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 22010        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -0.8794529   |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 48.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2203         |\n",
      "|    time_elapsed         | 41863        |\n",
      "|    total_timesteps      | 4511744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039572553 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 3.5084853    |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2204        |\n",
      "|    time_elapsed         | 41882       |\n",
      "|    total_timesteps      | 4513792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003363349 |\n",
      "|    clip_fraction        | 0.00347     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 22030       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 0.29430106  |\n",
      "|    std                  | 23.9        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2205         |\n",
      "|    time_elapsed         | 41900        |\n",
      "|    total_timesteps      | 4515840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028004316 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.1         |\n",
      "|    n_updates            | 22040        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | 2.088178     |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 57           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2206        |\n",
      "|    time_elapsed         | 41918       |\n",
      "|    total_timesteps      | 4517888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002797677 |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 22050       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | 0.15850556  |\n",
      "|    std                  | 24          |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2207        |\n",
      "|    time_elapsed         | 41938       |\n",
      "|    total_timesteps      | 4519936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004893156 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 22060       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | -1.6212401  |\n",
      "|    std                  | 24          |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2208        |\n",
      "|    time_elapsed         | 41956       |\n",
      "|    total_timesteps      | 4521984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004272623 |\n",
      "|    clip_fraction        | 0.0119      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 22070       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    reward               | 1.5298355   |\n",
      "|    std                  | 24.1        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2209        |\n",
      "|    time_elapsed         | 41974       |\n",
      "|    total_timesteps      | 4524032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001617692 |\n",
      "|    clip_fraction        | 0.00142     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.0682      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 22080       |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    reward               | 2.8263738   |\n",
      "|    std                  | 24.1        |\n",
      "|    value_loss           | 81          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2210         |\n",
      "|    time_elapsed         | 41993        |\n",
      "|    total_timesteps      | 4526080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024274583 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.57         |\n",
      "|    n_updates            | 22090        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | 1.5583829    |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2211         |\n",
      "|    time_elapsed         | 42011        |\n",
      "|    total_timesteps      | 4528128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033753244 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.66         |\n",
      "|    n_updates            | 22100        |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    reward               | 0.6911406    |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2212         |\n",
      "|    time_elapsed         | 42029        |\n",
      "|    total_timesteps      | 4530176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013188254 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 22110        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | 1.8224744    |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2213         |\n",
      "|    time_elapsed         | 42048        |\n",
      "|    total_timesteps      | 4532224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021027373 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 22120        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | -0.089795366 |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3610372.52\n",
      "total_reward: 2610372.52\n",
      "total_cost: 181470.23\n",
      "total_trades: 60076\n",
      "Sharpe: 0.686\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2214         |\n",
      "|    time_elapsed         | 42066        |\n",
      "|    total_timesteps      | 4534272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046316106 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.05         |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    reward               | -1.3331724   |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2215         |\n",
      "|    time_elapsed         | 42084        |\n",
      "|    total_timesteps      | 4536320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043448526 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 22140        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | -0.91770273  |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2216        |\n",
      "|    time_elapsed         | 42102       |\n",
      "|    total_timesteps      | 4538368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002130664 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 22150       |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | 0.7499522   |\n",
      "|    std                  | 24.5        |\n",
      "|    value_loss           | 41.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2217        |\n",
      "|    time_elapsed         | 42121       |\n",
      "|    total_timesteps      | 4540416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005509725 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.86        |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | 2.9290688   |\n",
      "|    std                  | 24.6        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2218        |\n",
      "|    time_elapsed         | 42139       |\n",
      "|    total_timesteps      | 4542464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002842147 |\n",
      "|    clip_fraction        | 0.00347     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 22170       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | 0.34733906  |\n",
      "|    std                  | 24.6        |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2219         |\n",
      "|    time_elapsed         | 42157        |\n",
      "|    total_timesteps      | 4544512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015531282 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | -0.43595952  |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2220         |\n",
      "|    time_elapsed         | 42175        |\n",
      "|    total_timesteps      | 4546560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044943737 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 22190        |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    reward               | -1.1009196   |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 43.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2221         |\n",
      "|    time_elapsed         | 42194        |\n",
      "|    total_timesteps      | 4548608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011625576 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 22200        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 0.15722245   |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2222          |\n",
      "|    time_elapsed         | 42212         |\n",
      "|    total_timesteps      | 4550656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091507816 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.429         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.2          |\n",
      "|    n_updates            | 22210         |\n",
      "|    policy_gradient_loss | -0.0024       |\n",
      "|    reward               | -0.16779652   |\n",
      "|    std                  | 24.7          |\n",
      "|    value_loss           | 44.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2223          |\n",
      "|    time_elapsed         | 42230         |\n",
      "|    total_timesteps      | 4552704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073720096 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.506         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.6          |\n",
      "|    n_updates            | 22220         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | 0.90701264    |\n",
      "|    std                  | 24.7          |\n",
      "|    value_loss           | 44            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2224        |\n",
      "|    time_elapsed         | 42248       |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005900438 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.13        |\n",
      "|    n_updates            | 22230       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | -1.5507637  |\n",
      "|    std                  | 24.7        |\n",
      "|    value_loss           | 15.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2225        |\n",
      "|    time_elapsed         | 42266       |\n",
      "|    total_timesteps      | 4556800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005611069 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 22240       |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | 0.018109113 |\n",
      "|    std                  | 24.7        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2226       |\n",
      "|    time_elapsed         | 42285      |\n",
      "|    total_timesteps      | 4558848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00221844 |\n",
      "|    clip_fraction        | 0.00161    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -133       |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 22250      |\n",
      "|    policy_gradient_loss | -0.00377   |\n",
      "|    reward               | 1.063785   |\n",
      "|    std                  | 24.8       |\n",
      "|    value_loss           | 43.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2227        |\n",
      "|    time_elapsed         | 42303       |\n",
      "|    total_timesteps      | 4560896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005126949 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 22260       |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    reward               | 2.8805733   |\n",
      "|    std                  | 24.8        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4111423.86\n",
      "total_reward: 3111423.86\n",
      "total_cost: 165426.04\n",
      "total_trades: 59837\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2228         |\n",
      "|    time_elapsed         | 42321        |\n",
      "|    total_timesteps      | 4562944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013863072 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 22270        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | -1.4438565   |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2229         |\n",
      "|    time_elapsed         | 42339        |\n",
      "|    total_timesteps      | 4564992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024432284 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 22280        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    reward               | 2.1203992    |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 51           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2230        |\n",
      "|    time_elapsed         | 42357       |\n",
      "|    total_timesteps      | 4567040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000635952 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 22290       |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    reward               | 2.2528174   |\n",
      "|    std                  | 24.8        |\n",
      "|    value_loss           | 45.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2231         |\n",
      "|    time_elapsed         | 42375        |\n",
      "|    total_timesteps      | 4569088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071856054 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.92         |\n",
      "|    n_updates            | 22300        |\n",
      "|    policy_gradient_loss | -0.00974     |\n",
      "|    reward               | 1.3082937    |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2232         |\n",
      "|    time_elapsed         | 42393        |\n",
      "|    total_timesteps      | 4571136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021843985 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 22310        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -0.69251513  |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2233          |\n",
      "|    time_elapsed         | 42412         |\n",
      "|    total_timesteps      | 4573184       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074804295 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.391         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 22320         |\n",
      "|    policy_gradient_loss | -0.00282      |\n",
      "|    reward               | 0.7731762     |\n",
      "|    std                  | 24.9          |\n",
      "|    value_loss           | 42.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2234         |\n",
      "|    time_elapsed         | 42431        |\n",
      "|    total_timesteps      | 4575232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040923087 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.316        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.96         |\n",
      "|    n_updates            | 22330        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | -1.3578836   |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2235        |\n",
      "|    time_elapsed         | 42449       |\n",
      "|    total_timesteps      | 4577280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002303796 |\n",
      "|    clip_fraction        | 0.00596     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 22340       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | -2.8005095  |\n",
      "|    std                  | 25          |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2236          |\n",
      "|    time_elapsed         | 42468         |\n",
      "|    total_timesteps      | 4579328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058947847 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.608         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.43          |\n",
      "|    n_updates            | 22350         |\n",
      "|    policy_gradient_loss | -0.00135      |\n",
      "|    reward               | -5.071216     |\n",
      "|    std                  | 25            |\n",
      "|    value_loss           | 38.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2237         |\n",
      "|    time_elapsed         | 42486        |\n",
      "|    total_timesteps      | 4581376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020707191 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.288        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 22360        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | -0.54170233  |\n",
      "|    std                  | 25           |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2238         |\n",
      "|    time_elapsed         | 42504        |\n",
      "|    total_timesteps      | 4583424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030135452 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 22370        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | 1.1516918    |\n",
      "|    std                  | 25.1         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2239         |\n",
      "|    time_elapsed         | 42522        |\n",
      "|    total_timesteps      | 4585472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019092226 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.76         |\n",
      "|    n_updates            | 22380        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | 3.9915016    |\n",
      "|    std                  | 25.1         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2240        |\n",
      "|    time_elapsed         | 42541       |\n",
      "|    total_timesteps      | 4587520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000886382 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 22390       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | -0.0239643  |\n",
      "|    std                  | 25.1        |\n",
      "|    value_loss           | 40.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2241         |\n",
      "|    time_elapsed         | 42559        |\n",
      "|    total_timesteps      | 4589568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054411488 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.03         |\n",
      "|    n_updates            | 22400        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | -0.21755637  |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 17           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4540361.53\n",
      "total_reward: 3540361.53\n",
      "total_cost: 195887.38\n",
      "total_trades: 62381\n",
      "Sharpe: 0.829\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2242         |\n",
      "|    time_elapsed         | 42577        |\n",
      "|    total_timesteps      | 4591616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047119614 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 22410        |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    reward               | 0.32272792   |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2243         |\n",
      "|    time_elapsed         | 42595        |\n",
      "|    total_timesteps      | 4593664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008962045 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 22420        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    reward               | 1.2293352    |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2244        |\n",
      "|    time_elapsed         | 42614       |\n",
      "|    total_timesteps      | 4595712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001382365 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.44        |\n",
      "|    n_updates            | 22430       |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | -0.5465949  |\n",
      "|    std                  | 25.2        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2245         |\n",
      "|    time_elapsed         | 42632        |\n",
      "|    total_timesteps      | 4597760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043217903 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 22440        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    reward               | -0.57064104  |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2246         |\n",
      "|    time_elapsed         | 42650        |\n",
      "|    total_timesteps      | 4599808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032851836 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 22450        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 13.219192    |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 47.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2247         |\n",
      "|    time_elapsed         | 42669        |\n",
      "|    total_timesteps      | 4601856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016010844 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 22460        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | 2.3193743    |\n",
      "|    std                  | 25.4         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2248        |\n",
      "|    time_elapsed         | 42687       |\n",
      "|    total_timesteps      | 4603904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006185755 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.99        |\n",
      "|    n_updates            | 22470       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | -0.39120775 |\n",
      "|    std                  | 25.5        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2249         |\n",
      "|    time_elapsed         | 42705        |\n",
      "|    total_timesteps      | 4605952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034990085 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 22480        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | 0.19444413   |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2250         |\n",
      "|    time_elapsed         | 42723        |\n",
      "|    total_timesteps      | 4608000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011673188 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 22490        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 2.249037     |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 44.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2251        |\n",
      "|    time_elapsed         | 42741       |\n",
      "|    total_timesteps      | 4610048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002256059 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 22500       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | -2.8357985  |\n",
      "|    std                  | 25.6        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2252        |\n",
      "|    time_elapsed         | 42760       |\n",
      "|    total_timesteps      | 4612096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004212985 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 22510       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    reward               | -6.921564   |\n",
      "|    std                  | 25.6        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2253         |\n",
      "|    time_elapsed         | 42778        |\n",
      "|    total_timesteps      | 4614144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001722866  |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 22520        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -0.009281749 |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2254          |\n",
      "|    time_elapsed         | 42796         |\n",
      "|    total_timesteps      | 4616192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024846537 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.484         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.7          |\n",
      "|    n_updates            | 22530         |\n",
      "|    policy_gradient_loss | -0.00112      |\n",
      "|    reward               | 11.445716     |\n",
      "|    std                  | 25.6          |\n",
      "|    value_loss           | 34.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2255         |\n",
      "|    time_elapsed         | 42815        |\n",
      "|    total_timesteps      | 4618240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073159244 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.67         |\n",
      "|    n_updates            | 22540        |\n",
      "|    policy_gradient_loss | -0.00843     |\n",
      "|    reward               | 0.5121281    |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3929913.12\n",
      "total_reward: 2929913.12\n",
      "total_cost: 155850.89\n",
      "total_trades: 59666\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2256          |\n",
      "|    time_elapsed         | 42832         |\n",
      "|    total_timesteps      | 4620288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030449303 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.48          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.1          |\n",
      "|    n_updates            | 22550         |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    reward               | -1.758681     |\n",
      "|    std                  | 25.7          |\n",
      "|    value_loss           | 46.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2257         |\n",
      "|    time_elapsed         | 42851        |\n",
      "|    total_timesteps      | 4622336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009252107 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 22560        |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    reward               | -0.09055677  |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2258        |\n",
      "|    time_elapsed         | 42869       |\n",
      "|    total_timesteps      | 4624384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001580009 |\n",
      "|    clip_fraction        | 0.00166     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.3         |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    reward               | -1.0293479  |\n",
      "|    std                  | 25.7        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2259         |\n",
      "|    time_elapsed         | 42888        |\n",
      "|    total_timesteps      | 4626432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031625386 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 22580        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | 0.5342532    |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 32.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2260         |\n",
      "|    time_elapsed         | 42906        |\n",
      "|    total_timesteps      | 4628480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011069055 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 22590        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -0.0968376   |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 39           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2261         |\n",
      "|    time_elapsed         | 42924        |\n",
      "|    total_timesteps      | 4630528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018137174 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 22600        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -1.7267209   |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2262         |\n",
      "|    time_elapsed         | 42942        |\n",
      "|    total_timesteps      | 4632576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069984184 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.47         |\n",
      "|    n_updates            | 22610        |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    reward               | 0.4186291    |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 22.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2263         |\n",
      "|    time_elapsed         | 42961        |\n",
      "|    total_timesteps      | 4634624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029719258 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 22620        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    reward               | -0.47589716  |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2264         |\n",
      "|    time_elapsed         | 42979        |\n",
      "|    total_timesteps      | 4636672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006830808 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 22630        |\n",
      "|    policy_gradient_loss | -3.21e-06    |\n",
      "|    reward               | 0.7426942    |\n",
      "|    std                  | 25.9         |\n",
      "|    value_loss           | 59.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2265         |\n",
      "|    time_elapsed         | 42997        |\n",
      "|    total_timesteps      | 4638720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053137047 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.72         |\n",
      "|    n_updates            | 22640        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | 1.6834788    |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 15.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2266        |\n",
      "|    time_elapsed         | 43015       |\n",
      "|    total_timesteps      | 4640768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004599083 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 22650       |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    reward               | 0.17887945  |\n",
      "|    std                  | 26          |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2267         |\n",
      "|    time_elapsed         | 43035        |\n",
      "|    total_timesteps      | 4642816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013264194 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 22660        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 1.8124268    |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 41.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2268        |\n",
      "|    time_elapsed         | 43053       |\n",
      "|    total_timesteps      | 4644864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002029905 |\n",
      "|    clip_fraction        | 0.00122     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 22670       |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | 0.2597009   |\n",
      "|    std                  | 26.1        |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2269         |\n",
      "|    time_elapsed         | 43072        |\n",
      "|    total_timesteps      | 4646912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055800425 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 22680        |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    reward               | 1.2967155    |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2270         |\n",
      "|    time_elapsed         | 43090        |\n",
      "|    total_timesteps      | 4648960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021274427 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 22690        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 0.5522353    |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4295684.91\n",
      "total_reward: 3295684.91\n",
      "total_cost: 275558.23\n",
      "total_trades: 65503\n",
      "Sharpe: 0.792\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2271         |\n",
      "|    time_elapsed         | 43109        |\n",
      "|    total_timesteps      | 4651008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023369852 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 22700        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | -1.6307476   |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2272         |\n",
      "|    time_elapsed         | 43127        |\n",
      "|    total_timesteps      | 4653056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044448394 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 22710        |\n",
      "|    policy_gradient_loss | -0.00736     |\n",
      "|    reward               | -2.1873      |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 19.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2273         |\n",
      "|    time_elapsed         | 43145        |\n",
      "|    total_timesteps      | 4655104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020506505 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 22720        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -0.868855    |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 30.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2274          |\n",
      "|    time_elapsed         | 43163         |\n",
      "|    total_timesteps      | 4657152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050312787 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.515         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.9          |\n",
      "|    n_updates            | 22730         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | -0.2504312    |\n",
      "|    std                  | 26.3          |\n",
      "|    value_loss           | 39.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2275         |\n",
      "|    time_elapsed         | 43182        |\n",
      "|    total_timesteps      | 4659200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048770704 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.74         |\n",
      "|    n_updates            | 22740        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | 1.281665     |\n",
      "|    std                  | 26.4         |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2276        |\n",
      "|    time_elapsed         | 43200       |\n",
      "|    total_timesteps      | 4661248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002145091 |\n",
      "|    clip_fraction        | 0.00156     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 22750       |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 1.6341095   |\n",
      "|    std                  | 26.4        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2277         |\n",
      "|    time_elapsed         | 43218        |\n",
      "|    total_timesteps      | 4663296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012919998 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 2.2051303    |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2278         |\n",
      "|    time_elapsed         | 43236        |\n",
      "|    total_timesteps      | 4665344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027966674 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 22770        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | -0.32723433  |\n",
      "|    std                  | 26.4         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2279         |\n",
      "|    time_elapsed         | 43255        |\n",
      "|    total_timesteps      | 4667392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024211244 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 22780        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 1.4610255    |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2280         |\n",
      "|    time_elapsed         | 43273        |\n",
      "|    total_timesteps      | 4669440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050231502 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 22790        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | 0.029049668  |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2281        |\n",
      "|    time_elapsed         | 43291       |\n",
      "|    total_timesteps      | 4671488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001186196 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 22800       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | -2.9954553  |\n",
      "|    std                  | 26.5        |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2282         |\n",
      "|    time_elapsed         | 43310        |\n",
      "|    total_timesteps      | 4673536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057787285 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.4          |\n",
      "|    n_updates            | 22810        |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    reward               | -0.68117225  |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2283         |\n",
      "|    time_elapsed         | 43328        |\n",
      "|    total_timesteps      | 4675584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038180894 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 22820        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | 1.3927968    |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2284         |\n",
      "|    time_elapsed         | 43346        |\n",
      "|    total_timesteps      | 4677632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010400359 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 22830        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | 2.786356     |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4248578.59\n",
      "total_reward: 3248578.59\n",
      "total_cost: 281890.54\n",
      "total_trades: 66512\n",
      "Sharpe: 0.786\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2285         |\n",
      "|    time_elapsed         | 43365        |\n",
      "|    total_timesteps      | 4679680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030739233 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.97         |\n",
      "|    n_updates            | 22840        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 1.9535686    |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2286         |\n",
      "|    time_elapsed         | 43384        |\n",
      "|    total_timesteps      | 4681728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036928428 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 22850        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    reward               | 0.6322357    |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2287         |\n",
      "|    time_elapsed         | 43402        |\n",
      "|    total_timesteps      | 4683776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044951867 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.66         |\n",
      "|    n_updates            | 22860        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    reward               | 0.012897616  |\n",
      "|    std                  | 26.7         |\n",
      "|    value_loss           | 33.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2288        |\n",
      "|    time_elapsed         | 43420       |\n",
      "|    total_timesteps      | 4685824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002141491 |\n",
      "|    clip_fraction        | 0.00176     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 22870       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | 0.009872827 |\n",
      "|    std                  | 26.8        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2289       |\n",
      "|    time_elapsed         | 43439      |\n",
      "|    total_timesteps      | 4687872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00641292 |\n",
      "|    clip_fraction        | 0.0245     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -136       |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.16       |\n",
      "|    n_updates            | 22880      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    reward               | 0.5571435  |\n",
      "|    std                  | 26.7       |\n",
      "|    value_loss           | 13.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2290         |\n",
      "|    time_elapsed         | 43457        |\n",
      "|    total_timesteps      | 4689920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023770868 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 22890        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 0.61062634   |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2291          |\n",
      "|    time_elapsed         | 43475         |\n",
      "|    total_timesteps      | 4691968       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073039514 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.617         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 22900         |\n",
      "|    policy_gradient_loss | -0.00236      |\n",
      "|    reward               | 0.042449497   |\n",
      "|    std                  | 26.8          |\n",
      "|    value_loss           | 36.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2292         |\n",
      "|    time_elapsed         | 43494        |\n",
      "|    total_timesteps      | 4694016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027906937 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 22910        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | -1.4965669   |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2293         |\n",
      "|    time_elapsed         | 43512        |\n",
      "|    total_timesteps      | 4696064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042924583 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.33         |\n",
      "|    n_updates            | 22920        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | -2.9161794   |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2294          |\n",
      "|    time_elapsed         | 43531         |\n",
      "|    total_timesteps      | 4698112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041560704 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.599         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.7          |\n",
      "|    n_updates            | 22930         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | 4.854578      |\n",
      "|    std                  | 26.9          |\n",
      "|    value_loss           | 42.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2295          |\n",
      "|    time_elapsed         | 43549         |\n",
      "|    total_timesteps      | 4700160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087613316 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.658         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.9          |\n",
      "|    n_updates            | 22940         |\n",
      "|    policy_gradient_loss | -0.00223      |\n",
      "|    reward               | -0.5754238    |\n",
      "|    std                  | 26.9          |\n",
      "|    value_loss           | 27.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2296         |\n",
      "|    time_elapsed         | 43568        |\n",
      "|    total_timesteps      | 4702208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051418627 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 22950        |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    reward               | -2.1566963   |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2297         |\n",
      "|    time_elapsed         | 43587        |\n",
      "|    total_timesteps      | 4704256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037672985 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 22960        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    reward               | 0.2959257    |\n",
      "|    std                  | 27           |\n",
      "|    value_loss           | 39.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2298       |\n",
      "|    time_elapsed         | 43605      |\n",
      "|    total_timesteps      | 4706304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00230105 |\n",
      "|    clip_fraction        | 0.000928   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -136       |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.5       |\n",
      "|    n_updates            | 22970      |\n",
      "|    policy_gradient_loss | -0.00451   |\n",
      "|    reward               | -2.5953867 |\n",
      "|    std                  | 27.1       |\n",
      "|    value_loss           | 35.4       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 2690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4338758.61\n",
      "total_reward: 3338758.61\n",
      "total_cost: 191020.05\n",
      "total_trades: 61878\n",
      "Sharpe: 0.777\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2299        |\n",
      "|    time_elapsed         | 43624       |\n",
      "|    total_timesteps      | 4708352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006955561 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 22980       |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | 2.3685696   |\n",
      "|    std                  | 27.2        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2300         |\n",
      "|    time_elapsed         | 43642        |\n",
      "|    total_timesteps      | 4710400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015072201 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.79         |\n",
      "|    n_updates            | 22990        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | -0.9679749   |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2301         |\n",
      "|    time_elapsed         | 43661        |\n",
      "|    total_timesteps      | 4712448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010572344 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 23000        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | -0.4228552   |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 53.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2302         |\n",
      "|    time_elapsed         | 43679        |\n",
      "|    total_timesteps      | 4714496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005587315 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 23010        |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    reward               | -3.356487    |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2303         |\n",
      "|    time_elapsed         | 43698        |\n",
      "|    total_timesteps      | 4716544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051125633 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.01         |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00926     |\n",
      "|    reward               | 2.0417566    |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2304        |\n",
      "|    time_elapsed         | 43717       |\n",
      "|    total_timesteps      | 4718592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005061727 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 23030       |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | -0.5588241  |\n",
      "|    std                  | 27.4        |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2305         |\n",
      "|    time_elapsed         | 43735        |\n",
      "|    total_timesteps      | 4720640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032610777 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 23040        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | -0.22775936  |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2306         |\n",
      "|    time_elapsed         | 43753        |\n",
      "|    total_timesteps      | 4722688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028061697 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.47         |\n",
      "|    n_updates            | 23050        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | 1.2941686    |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2307         |\n",
      "|    time_elapsed         | 43771        |\n",
      "|    total_timesteps      | 4724736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029892777 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 23060        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | -0.87094533  |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2308         |\n",
      "|    time_elapsed         | 43789        |\n",
      "|    total_timesteps      | 4726784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015912999 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 23070        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | 3.080663     |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2309         |\n",
      "|    time_elapsed         | 43808        |\n",
      "|    total_timesteps      | 4728832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018271732 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 23080        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | -7.0935855   |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 32.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2310         |\n",
      "|    time_elapsed         | 43827        |\n",
      "|    total_timesteps      | 4730880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036494755 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.83         |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    reward               | 1.5276486    |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 22.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2311        |\n",
      "|    time_elapsed         | 43845       |\n",
      "|    total_timesteps      | 4732928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002449612 |\n",
      "|    clip_fraction        | 0.00161     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 23100       |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | -0.47465783 |\n",
      "|    std                  | 27.7        |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2312         |\n",
      "|    time_elapsed         | 43863        |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009432336 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 23110        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | 2.0204103    |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 45.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4229861.68\n",
      "total_reward: 3229861.68\n",
      "total_cost: 167900.90\n",
      "total_trades: 60385\n",
      "Sharpe: 0.755\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2313         |\n",
      "|    time_elapsed         | 43881        |\n",
      "|    total_timesteps      | 4737024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033527168 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.63         |\n",
      "|    n_updates            | 23120        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | 0.22509438   |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 16           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2314         |\n",
      "|    time_elapsed         | 43900        |\n",
      "|    total_timesteps      | 4739072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033815536 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 23130        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    reward               | -2.29668     |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 39.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2315         |\n",
      "|    time_elapsed         | 43918        |\n",
      "|    total_timesteps      | 4741120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017255603 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 23140        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | -0.59729975  |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2316         |\n",
      "|    time_elapsed         | 43936        |\n",
      "|    total_timesteps      | 4743168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022485638 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 23150        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | 1.2873096    |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2317        |\n",
      "|    time_elapsed         | 43954       |\n",
      "|    total_timesteps      | 4745216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004499192 |\n",
      "|    clip_fraction        | 0.00796     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 23160       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    reward               | 1.9185776   |\n",
      "|    std                  | 28          |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2318         |\n",
      "|    time_elapsed         | 43973        |\n",
      "|    total_timesteps      | 4747264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032661739 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 23170        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.49078456   |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2319         |\n",
      "|    time_elapsed         | 43991        |\n",
      "|    total_timesteps      | 4749312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015520748 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 23180        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | 0.2938185    |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2320         |\n",
      "|    time_elapsed         | 44009        |\n",
      "|    total_timesteps      | 4751360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010511928 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 23190        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | -0.10764181  |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2321         |\n",
      "|    time_elapsed         | 44027        |\n",
      "|    total_timesteps      | 4753408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034784623 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 23200        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    reward               | -2.7175226   |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2322         |\n",
      "|    time_elapsed         | 44046        |\n",
      "|    total_timesteps      | 4755456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018262271 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.124        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 23210        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | 2.0712428    |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 107        |\n",
      "|    iterations           | 2323       |\n",
      "|    time_elapsed         | 44065      |\n",
      "|    total_timesteps      | 4757504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00634194 |\n",
      "|    clip_fraction        | 0.0202     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -137       |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.79       |\n",
      "|    n_updates            | 23220      |\n",
      "|    policy_gradient_loss | -0.00715   |\n",
      "|    reward               | 0.51300985 |\n",
      "|    std                  | 28.1       |\n",
      "|    value_loss           | 19.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2324         |\n",
      "|    time_elapsed         | 44084        |\n",
      "|    total_timesteps      | 4759552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030628275 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 23230        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 0.20365529   |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2325         |\n",
      "|    time_elapsed         | 44103        |\n",
      "|    total_timesteps      | 4761600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012577929 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 1.9781065    |\n",
      "|    std                  | 28.2         |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2326         |\n",
      "|    time_elapsed         | 44121        |\n",
      "|    total_timesteps      | 4763648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037647327 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 23250        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 2.884892     |\n",
      "|    std                  | 28.2         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3816363.06\n",
      "total_reward: 2816363.06\n",
      "total_cost: 191854.68\n",
      "total_trades: 62253\n",
      "Sharpe: 0.727\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2327        |\n",
      "|    time_elapsed         | 44139       |\n",
      "|    total_timesteps      | 4765696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003376768 |\n",
      "|    clip_fraction        | 0.00664     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.12        |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | 1.4925467   |\n",
      "|    std                  | 28.3        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2328         |\n",
      "|    time_elapsed         | 44157        |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033188988 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 2.1307123    |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2329         |\n",
      "|    time_elapsed         | 44176        |\n",
      "|    total_timesteps      | 4769792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006090987 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    reward               | -11.071446   |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 41           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2330        |\n",
      "|    time_elapsed         | 44194       |\n",
      "|    total_timesteps      | 4771840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004387802 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 23290       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | 2.199501    |\n",
      "|    std                  | 28.4        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2331        |\n",
      "|    time_elapsed         | 44212       |\n",
      "|    total_timesteps      | 4773888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002586857 |\n",
      "|    clip_fraction        | 0.00181     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 23300       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | -0.56369233 |\n",
      "|    std                  | 28.4        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2332         |\n",
      "|    time_elapsed         | 44231        |\n",
      "|    total_timesteps      | 4775936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004948322 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 23310        |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    reward               | -3.6199448   |\n",
      "|    std                  | 28.4         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2333         |\n",
      "|    time_elapsed         | 44250        |\n",
      "|    total_timesteps      | 4777984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022207452 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 23320        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | 2.7888734    |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 29.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2334         |\n",
      "|    time_elapsed         | 44269        |\n",
      "|    total_timesteps      | 4780032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053825704 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 23330        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    reward               | 0.79298145   |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 107           |\n",
      "|    iterations           | 2335          |\n",
      "|    time_elapsed         | 44288         |\n",
      "|    total_timesteps      | 4782080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071077736 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.596         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.6          |\n",
      "|    n_updates            | 23340         |\n",
      "|    policy_gradient_loss | -0.00189      |\n",
      "|    reward               | 8.32784       |\n",
      "|    std                  | 28.5          |\n",
      "|    value_loss           | 40.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2336         |\n",
      "|    time_elapsed         | 44306        |\n",
      "|    total_timesteps      | 4784128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015377696 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.5         |\n",
      "|    n_updates            | 23350        |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    reward               | 0.06953379   |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2337         |\n",
      "|    time_elapsed         | 44324        |\n",
      "|    total_timesteps      | 4786176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058901194 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.36         |\n",
      "|    n_updates            | 23360        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    reward               | 0.6876628    |\n",
      "|    std                  | 28.6         |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2338         |\n",
      "|    time_elapsed         | 44343        |\n",
      "|    total_timesteps      | 4788224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031102397 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 23370        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | -0.32203156  |\n",
      "|    std                  | 28.6         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2339        |\n",
      "|    time_elapsed         | 44361       |\n",
      "|    total_timesteps      | 4790272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004072711 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 23380       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | -0.19173837 |\n",
      "|    std                  | 28.7        |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2340         |\n",
      "|    time_elapsed         | 44379        |\n",
      "|    total_timesteps      | 4792320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019572927 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.03         |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 1.372755     |\n",
      "|    std                  | 28.7         |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3685238.18\n",
      "total_reward: 2685238.18\n",
      "total_cost: 164451.00\n",
      "total_trades: 59947\n",
      "Sharpe: 0.683\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2341        |\n",
      "|    time_elapsed         | 44398       |\n",
      "|    total_timesteps      | 4794368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004821988 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 23400       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -1.061398   |\n",
      "|    std                  | 28.8        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2342         |\n",
      "|    time_elapsed         | 44416        |\n",
      "|    total_timesteps      | 4796416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011386476 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 23410        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | -0.5382667   |\n",
      "|    std                  | 28.8         |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2343         |\n",
      "|    time_elapsed         | 44434        |\n",
      "|    total_timesteps      | 4798464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019539227 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15           |\n",
      "|    n_updates            | 23420        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 0.5082551    |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2344        |\n",
      "|    time_elapsed         | 44453       |\n",
      "|    total_timesteps      | 4800512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004119398 |\n",
      "|    clip_fraction        | 0.00923     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 23430       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | -0.4415324  |\n",
      "|    std                  | 29          |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2345         |\n",
      "|    time_elapsed         | 44472        |\n",
      "|    total_timesteps      | 4802560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019479096 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 23440        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -0.46381673  |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2346         |\n",
      "|    time_elapsed         | 44490        |\n",
      "|    total_timesteps      | 4804608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019375305 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 23450        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.67274934   |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2347         |\n",
      "|    time_elapsed         | 44508        |\n",
      "|    total_timesteps      | 4806656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033771864 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.98         |\n",
      "|    n_updates            | 23460        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 0.44737223   |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2348         |\n",
      "|    time_elapsed         | 44526        |\n",
      "|    total_timesteps      | 4808704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014412815 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 23470        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | -3.708614    |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2349         |\n",
      "|    time_elapsed         | 44545        |\n",
      "|    total_timesteps      | 4810752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022520223 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 23480        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 2.046247     |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 35.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2350         |\n",
      "|    time_elapsed         | 44563        |\n",
      "|    total_timesteps      | 4812800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020032935 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 23490        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | -0.59850746  |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 2351        |\n",
      "|    time_elapsed         | 44583       |\n",
      "|    total_timesteps      | 4814848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004568179 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.56        |\n",
      "|    n_updates            | 23500       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    reward               | -0.03734931 |\n",
      "|    std                  | 29.2        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 2352         |\n",
      "|    time_elapsed         | 44601        |\n",
      "|    total_timesteps      | 4816896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021750773 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.1         |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 0.39882296   |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2353         |\n",
      "|    time_elapsed         | 44619        |\n",
      "|    total_timesteps      | 4818944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010201974 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 23520        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 0.7481081    |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2354         |\n",
      "|    time_elapsed         | 44638        |\n",
      "|    total_timesteps      | 4820992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035464296 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.31         |\n",
      "|    n_updates            | 23530        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    reward               | 0.516118     |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 11.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3145566.05\n",
      "total_reward: 2145566.05\n",
      "total_cost: 223787.15\n",
      "total_trades: 63588\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2355         |\n",
      "|    time_elapsed         | 44656        |\n",
      "|    total_timesteps      | 4823040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019576447 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 23540        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | 0.24803062   |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2356         |\n",
      "|    time_elapsed         | 44674        |\n",
      "|    total_timesteps      | 4825088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015185724 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.83         |\n",
      "|    n_updates            | 23550        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -2.453526    |\n",
      "|    std                  | 29.4         |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2357         |\n",
      "|    time_elapsed         | 44693        |\n",
      "|    total_timesteps      | 4827136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029557846 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 23560        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 0.93050635   |\n",
      "|    std                  | 29.4         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2358         |\n",
      "|    time_elapsed         | 44711        |\n",
      "|    total_timesteps      | 4829184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029350524 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.43         |\n",
      "|    n_updates            | 23570        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 1.3017366    |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 19           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2359         |\n",
      "|    time_elapsed         | 44730        |\n",
      "|    total_timesteps      | 4831232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032765914 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 23580        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | -10.525279   |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 44748        |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016089324 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.02         |\n",
      "|    n_updates            | 23590        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 0.23800007   |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 27.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2361        |\n",
      "|    time_elapsed         | 44766       |\n",
      "|    total_timesteps      | 4835328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006067522 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.43        |\n",
      "|    n_updates            | 23600       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | -0.6328447  |\n",
      "|    std                  | 29.6        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2362        |\n",
      "|    time_elapsed         | 44784       |\n",
      "|    total_timesteps      | 4837376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002759654 |\n",
      "|    clip_fraction        | 0.00454     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.56        |\n",
      "|    n_updates            | 23610       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -0.38276136 |\n",
      "|    std                  | 29.6        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2363         |\n",
      "|    time_elapsed         | 44803        |\n",
      "|    total_timesteps      | 4839424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021069897 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 23620        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | 0.94564074   |\n",
      "|    std                  | 29.7         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2364        |\n",
      "|    time_elapsed         | 44821       |\n",
      "|    total_timesteps      | 4841472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004400443 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.42        |\n",
      "|    n_updates            | 23630       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | 0.29111773  |\n",
      "|    std                  | 29.7        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2365         |\n",
      "|    time_elapsed         | 44839        |\n",
      "|    total_timesteps      | 4843520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029835566 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.98         |\n",
      "|    n_updates            | 23640        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    reward               | 0.5360591    |\n",
      "|    std                  | 29.9         |\n",
      "|    value_loss           | 19.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2366         |\n",
      "|    time_elapsed         | 44858        |\n",
      "|    total_timesteps      | 4845568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011172718 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.67         |\n",
      "|    n_updates            | 23650        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -1.0496057   |\n",
      "|    std                  | 29.9         |\n",
      "|    value_loss           | 37.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2367         |\n",
      "|    time_elapsed         | 44876        |\n",
      "|    total_timesteps      | 4847616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023665554 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.31         |\n",
      "|    n_updates            | 23660        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    reward               | 0.3022741    |\n",
      "|    std                  | 29.9         |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2368         |\n",
      "|    time_elapsed         | 44895        |\n",
      "|    total_timesteps      | 4849664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045720395 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.44         |\n",
      "|    n_updates            | 23670        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | 1.8185741    |\n",
      "|    std                  | 29.9         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3019635.18\n",
      "total_reward: 2019635.18\n",
      "total_cost: 194889.16\n",
      "total_trades: 62143\n",
      "Sharpe: 0.588\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2369         |\n",
      "|    time_elapsed         | 44913        |\n",
      "|    total_timesteps      | 4851712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013428895 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 23680        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -0.3128795   |\n",
      "|    std                  | 30           |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2370         |\n",
      "|    time_elapsed         | 44933        |\n",
      "|    total_timesteps      | 4853760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010565124 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.3          |\n",
      "|    n_updates            | 23690        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -0.22563812  |\n",
      "|    std                  | 30           |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2371         |\n",
      "|    time_elapsed         | 44951        |\n",
      "|    total_timesteps      | 4855808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069403453 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.99         |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.00904     |\n",
      "|    reward               | 0.29580215   |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 10.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2372         |\n",
      "|    time_elapsed         | 44970        |\n",
      "|    total_timesteps      | 4857856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014286268 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 23710        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -0.4350303   |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2373         |\n",
      "|    time_elapsed         | 44988        |\n",
      "|    total_timesteps      | 4859904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018461307 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 23720        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | -0.2656066   |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 36.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2374         |\n",
      "|    time_elapsed         | 45007        |\n",
      "|    total_timesteps      | 4861952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011154464 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 23730        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -0.24448508  |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2375         |\n",
      "|    time_elapsed         | 45025        |\n",
      "|    total_timesteps      | 4864000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022563683 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.24         |\n",
      "|    n_updates            | 23740        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 1.6382167    |\n",
      "|    std                  | 30.2         |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2376        |\n",
      "|    time_elapsed         | 45044       |\n",
      "|    total_timesteps      | 4866048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001984947 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 23750       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -0.02086006 |\n",
      "|    std                  | 30.3        |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2377         |\n",
      "|    time_elapsed         | 45062        |\n",
      "|    total_timesteps      | 4868096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023218333 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 23760        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | -0.5999761   |\n",
      "|    std                  | 30.4         |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2378        |\n",
      "|    time_elapsed         | 45080       |\n",
      "|    total_timesteps      | 4870144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003256051 |\n",
      "|    clip_fraction        | 0.00405     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.39        |\n",
      "|    n_updates            | 23770       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | 0.7205202   |\n",
      "|    std                  | 30.5        |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2379         |\n",
      "|    time_elapsed         | 45098        |\n",
      "|    total_timesteps      | 4872192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016545752 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 23780        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | 0.49821705   |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2380         |\n",
      "|    time_elapsed         | 45117        |\n",
      "|    total_timesteps      | 4874240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010909546 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -0.58802825  |\n",
      "|    std                  | 30.6         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2381         |\n",
      "|    time_elapsed         | 45135        |\n",
      "|    total_timesteps      | 4876288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059182686 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 23800        |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    reward               | 0.9838373    |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2382         |\n",
      "|    time_elapsed         | 45154        |\n",
      "|    total_timesteps      | 4878336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015009597 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 23810        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 0.24181189   |\n",
      "|    std                  | 30.7         |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2383          |\n",
      "|    time_elapsed         | 45172         |\n",
      "|    total_timesteps      | 4880384       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075986586 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.473         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.9          |\n",
      "|    n_updates            | 23820         |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | -2.163739     |\n",
      "|    std                  | 30.7          |\n",
      "|    value_loss           | 39.8          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3684849.91\n",
      "total_reward: 2684849.91\n",
      "total_cost: 221420.26\n",
      "total_trades: 63714\n",
      "Sharpe: 0.699\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2384        |\n",
      "|    time_elapsed         | 45191       |\n",
      "|    total_timesteps      | 4882432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001594729 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 23830       |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    reward               | -1.5650218  |\n",
      "|    std                  | 30.8        |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2385         |\n",
      "|    time_elapsed         | 45209        |\n",
      "|    total_timesteps      | 4884480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023590806 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.4          |\n",
      "|    n_updates            | 23840        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | -0.5274517   |\n",
      "|    std                  | 30.8         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2386         |\n",
      "|    time_elapsed         | 45227        |\n",
      "|    total_timesteps      | 4886528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034894776 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.97         |\n",
      "|    n_updates            | 23850        |\n",
      "|    policy_gradient_loss | -0.00715     |\n",
      "|    reward               | -0.37296835  |\n",
      "|    std                  | 30.8         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2387         |\n",
      "|    time_elapsed         | 45246        |\n",
      "|    total_timesteps      | 4888576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013721864 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 23860        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -7.0723343   |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2388         |\n",
      "|    time_elapsed         | 45265        |\n",
      "|    total_timesteps      | 4890624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020759273 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.13         |\n",
      "|    n_updates            | 23870        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -2.0691106   |\n",
      "|    std                  | 31           |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2389        |\n",
      "|    time_elapsed         | 45284       |\n",
      "|    total_timesteps      | 4892672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003612619 |\n",
      "|    clip_fraction        | 0.00762     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 23880       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | -0.7601817  |\n",
      "|    std                  | 31.1        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2390         |\n",
      "|    time_elapsed         | 45302        |\n",
      "|    total_timesteps      | 4894720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008475991 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 23890        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 0.47303578   |\n",
      "|    std                  | 31.1         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2391        |\n",
      "|    time_elapsed         | 45320       |\n",
      "|    total_timesteps      | 4896768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001963084 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 23900       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | -0.06154776 |\n",
      "|    std                  | 31.1        |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2392         |\n",
      "|    time_elapsed         | 45339        |\n",
      "|    total_timesteps      | 4898816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062388023 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.13         |\n",
      "|    n_updates            | 23910        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    reward               | 0.49309355   |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2393         |\n",
      "|    time_elapsed         | 45357        |\n",
      "|    total_timesteps      | 4900864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006392897 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 23920        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    reward               | 0.65136874   |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2394         |\n",
      "|    time_elapsed         | 45376        |\n",
      "|    total_timesteps      | 4902912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008377768 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 23930        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | 0.5331296    |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2395         |\n",
      "|    time_elapsed         | 45394        |\n",
      "|    total_timesteps      | 4904960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028639706 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.68         |\n",
      "|    n_updates            | 23940        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | 0.024367375  |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2396         |\n",
      "|    time_elapsed         | 45412        |\n",
      "|    total_timesteps      | 4907008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024402994 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.86         |\n",
      "|    n_updates            | 23950        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | 0.5396478    |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 28.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2397         |\n",
      "|    time_elapsed         | 45431        |\n",
      "|    total_timesteps      | 4909056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012219803 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 23960        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | 3.0665135    |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3759885.38\n",
      "total_reward: 2759885.38\n",
      "total_cost: 170309.57\n",
      "total_trades: 60128\n",
      "Sharpe: 0.691\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2398         |\n",
      "|    time_elapsed         | 45449        |\n",
      "|    total_timesteps      | 4911104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011339153 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 23970        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | -2.3408554   |\n",
      "|    std                  | 31.4         |\n",
      "|    value_loss           | 36.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2399         |\n",
      "|    time_elapsed         | 45468        |\n",
      "|    total_timesteps      | 4913152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019431434 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.59         |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | 0.28491232   |\n",
      "|    std                  | 31.6         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2400         |\n",
      "|    time_elapsed         | 45486        |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012311453 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.79         |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | 4.8017535    |\n",
      "|    std                  | 31.6         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2401          |\n",
      "|    time_elapsed         | 45504         |\n",
      "|    total_timesteps      | 4917248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090710365 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.634         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.5          |\n",
      "|    n_updates            | 24000         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | -2.6789646    |\n",
      "|    std                  | 31.6          |\n",
      "|    value_loss           | 30.5          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2402        |\n",
      "|    time_elapsed         | 45522       |\n",
      "|    total_timesteps      | 4919296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005768007 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.89        |\n",
      "|    n_updates            | 24010       |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | -1.2271371  |\n",
      "|    std                  | 31.7        |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2403        |\n",
      "|    time_elapsed         | 45540       |\n",
      "|    total_timesteps      | 4921344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001368283 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 24020       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    reward               | -1.2836686  |\n",
      "|    std                  | 31.7        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2404         |\n",
      "|    time_elapsed         | 45558        |\n",
      "|    total_timesteps      | 4923392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003142242 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.371        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 24030        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | -0.15266083  |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2405        |\n",
      "|    time_elapsed         | 45577       |\n",
      "|    total_timesteps      | 4925440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003850733 |\n",
      "|    clip_fraction        | 0.00552     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -140        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 24040       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | 0.77380735  |\n",
      "|    std                  | 31.8        |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2406         |\n",
      "|    time_elapsed         | 45595        |\n",
      "|    total_timesteps      | 4927488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018381908 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.57         |\n",
      "|    n_updates            | 24050        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | -1.8723894   |\n",
      "|    std                  | 31.9         |\n",
      "|    value_loss           | 22.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2407         |\n",
      "|    time_elapsed         | 45613        |\n",
      "|    total_timesteps      | 4929536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017637576 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 24060        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | 0.88152933   |\n",
      "|    std                  | 31.9         |\n",
      "|    value_loss           | 37.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2408        |\n",
      "|    time_elapsed         | 45631       |\n",
      "|    total_timesteps      | 4931584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000339967 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 24070       |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    reward               | -1.0158879  |\n",
      "|    std                  | 32          |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2409        |\n",
      "|    time_elapsed         | 45650       |\n",
      "|    total_timesteps      | 4933632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003092256 |\n",
      "|    clip_fraction        | 0.00225     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.27        |\n",
      "|    n_updates            | 24080       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | 1.8801724   |\n",
      "|    std                  | 32          |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2410         |\n",
      "|    time_elapsed         | 45668        |\n",
      "|    total_timesteps      | 4935680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054989536 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.89         |\n",
      "|    n_updates            | 24090        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -0.058428075 |\n",
      "|    std                  | 32           |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2411         |\n",
      "|    time_elapsed         | 45687        |\n",
      "|    total_timesteps      | 4937728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011977355 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 24100        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -3.8547573   |\n",
      "|    std                  | 32           |\n",
      "|    value_loss           | 36.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4095151.87\n",
      "total_reward: 3095151.87\n",
      "total_cost: 187882.55\n",
      "total_trades: 62072\n",
      "Sharpe: 0.719\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2412        |\n",
      "|    time_elapsed         | 45705       |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005636064 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 24110       |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    reward               | 0.44697145  |\n",
      "|    std                  | 32.1        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2413         |\n",
      "|    time_elapsed         | 45724        |\n",
      "|    total_timesteps      | 4941824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011788995 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 24120        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 0.53338253   |\n",
      "|    std                  | 32.1         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2414          |\n",
      "|    time_elapsed         | 45742         |\n",
      "|    total_timesteps      | 4943872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070871325 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.442         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.5          |\n",
      "|    n_updates            | 24130         |\n",
      "|    policy_gradient_loss | -0.00214      |\n",
      "|    reward               | -0.5686693    |\n",
      "|    std                  | 32.2          |\n",
      "|    value_loss           | 41.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2415         |\n",
      "|    time_elapsed         | 45761        |\n",
      "|    total_timesteps      | 4945920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019640033 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | -0.8950721   |\n",
      "|    std                  | 32.2         |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2416         |\n",
      "|    time_elapsed         | 45779        |\n",
      "|    total_timesteps      | 4947968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029353881 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 24150        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | -0.52992904  |\n",
      "|    std                  | 32.2         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2417         |\n",
      "|    time_elapsed         | 45797        |\n",
      "|    total_timesteps      | 4950016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006660515 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 24160        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 1.734291     |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2418         |\n",
      "|    time_elapsed         | 45815        |\n",
      "|    total_timesteps      | 4952064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005935796 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 24170        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 0.36864015   |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2419         |\n",
      "|    time_elapsed         | 45833        |\n",
      "|    total_timesteps      | 4954112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040402804 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.9          |\n",
      "|    n_updates            | 24180        |\n",
      "|    policy_gradient_loss | -0.0081      |\n",
      "|    reward               | 0.051996242  |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 15.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2420         |\n",
      "|    time_elapsed         | 45851        |\n",
      "|    total_timesteps      | 4956160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023916014 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 24190        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | 1.108166     |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2421         |\n",
      "|    time_elapsed         | 45869        |\n",
      "|    total_timesteps      | 4958208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011748059 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 24200        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -1.4219022   |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2422         |\n",
      "|    time_elapsed         | 45888        |\n",
      "|    total_timesteps      | 4960256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009662206 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | -0.18707095  |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 30.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2423         |\n",
      "|    time_elapsed         | 45906        |\n",
      "|    total_timesteps      | 4962304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033343886 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 24220        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | -0.09889229  |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2424         |\n",
      "|    time_elapsed         | 45924        |\n",
      "|    total_timesteps      | 4964352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011202077 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 24230        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 1.9727039    |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2425         |\n",
      "|    time_elapsed         | 45942        |\n",
      "|    total_timesteps      | 4966400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035175132 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | -0.1486385   |\n",
      "|    std                  | 32.6         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3858322.81\n",
      "total_reward: 2858322.81\n",
      "total_cost: 150100.08\n",
      "total_trades: 59636\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2426        |\n",
      "|    time_elapsed         | 45960       |\n",
      "|    total_timesteps      | 4968448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004699666 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 24250       |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | 0.7226918   |\n",
      "|    std                  | 32.7        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2427        |\n",
      "|    time_elapsed         | 45978       |\n",
      "|    total_timesteps      | 4970496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000412678 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 24260       |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | -0.15532024 |\n",
      "|    std                  | 32.7        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2428          |\n",
      "|    time_elapsed         | 45996         |\n",
      "|    total_timesteps      | 4972544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074241986 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.622         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.4          |\n",
      "|    n_updates            | 24270         |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    reward               | 5.9060426     |\n",
      "|    std                  | 32.7          |\n",
      "|    value_loss           | 35.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2429         |\n",
      "|    time_elapsed         | 46015        |\n",
      "|    total_timesteps      | 4974592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016725836 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 24280        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | 0.27159092   |\n",
      "|    std                  | 32.7         |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2430         |\n",
      "|    time_elapsed         | 46034        |\n",
      "|    total_timesteps      | 4976640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051613655 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.06         |\n",
      "|    n_updates            | 24290        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    reward               | 1.5644615    |\n",
      "|    std                  | 32.8         |\n",
      "|    value_loss           | 20           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2431         |\n",
      "|    time_elapsed         | 46052        |\n",
      "|    total_timesteps      | 4978688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007457022 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 24300        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -0.117602415 |\n",
      "|    std                  | 32.8         |\n",
      "|    value_loss           | 28.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2432         |\n",
      "|    time_elapsed         | 46071        |\n",
      "|    total_timesteps      | 4980736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012302522 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 24310        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -1.2093693   |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2433         |\n",
      "|    time_elapsed         | 46089        |\n",
      "|    total_timesteps      | 4982784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074227536 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.93         |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    reward               | -0.5280441   |\n",
      "|    std                  | 32.8         |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2434         |\n",
      "|    time_elapsed         | 46108        |\n",
      "|    total_timesteps      | 4984832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012431063 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 24330        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | 0.4981913    |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2435          |\n",
      "|    time_elapsed         | 46126         |\n",
      "|    total_timesteps      | 4986880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064419396 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.641         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.5          |\n",
      "|    n_updates            | 24340         |\n",
      "|    policy_gradient_loss | -0.00215      |\n",
      "|    reward               | -0.007484301  |\n",
      "|    std                  | 32.9          |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2436         |\n",
      "|    time_elapsed         | 46144        |\n",
      "|    total_timesteps      | 4988928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018722146 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.71         |\n",
      "|    n_updates            | 24350        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | -0.16348776  |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2437         |\n",
      "|    time_elapsed         | 46162        |\n",
      "|    total_timesteps      | 4990976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026962077 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.63         |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | 1.364009     |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2438          |\n",
      "|    time_elapsed         | 46180         |\n",
      "|    total_timesteps      | 4993024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036852207 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.566         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.07          |\n",
      "|    n_updates            | 24370         |\n",
      "|    policy_gradient_loss | -0.00122      |\n",
      "|    reward               | -0.6455995    |\n",
      "|    std                  | 33            |\n",
      "|    value_loss           | 34.7          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2439        |\n",
      "|    time_elapsed         | 46199       |\n",
      "|    total_timesteps      | 4995072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002004943 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 24380       |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | 1.8969357   |\n",
      "|    std                  | 33.1        |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3606204.33\n",
      "total_reward: 2606204.33\n",
      "total_cost: 149294.18\n",
      "total_trades: 58875\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2440         |\n",
      "|    time_elapsed         | 46217        |\n",
      "|    total_timesteps      | 4997120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020355661 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.09         |\n",
      "|    n_updates            | 24390        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 0.15582469   |\n",
      "|    std                  | 33.1         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2441         |\n",
      "|    time_elapsed         | 46236        |\n",
      "|    total_timesteps      | 4999168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009766697 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 24400        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | -0.26911217  |\n",
      "|    std                  | 33.1         |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2442         |\n",
      "|    time_elapsed         | 46255        |\n",
      "|    total_timesteps      | 5001216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016898991 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 24410        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    reward               | -0.93551874  |\n",
      "|    std                  | 33.2         |\n",
      "|    value_loss           | 45.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2443         |\n",
      "|    time_elapsed         | 46273        |\n",
      "|    total_timesteps      | 5003264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001920956  |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.02         |\n",
      "|    n_updates            | 24420        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 0.0081287585 |\n",
      "|    std                  | 33.2         |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2444         |\n",
      "|    time_elapsed         | 46292        |\n",
      "|    total_timesteps      | 5005312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021624558 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 24430        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -1.0684451   |\n",
      "|    std                  | 33.3         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2445         |\n",
      "|    time_elapsed         | 46311        |\n",
      "|    total_timesteps      | 5007360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016450805 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.6         |\n",
      "|    n_updates            | 24440        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -0.80510616  |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 45.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2446         |\n",
      "|    time_elapsed         | 46330        |\n",
      "|    total_timesteps      | 5009408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013272241 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.5         |\n",
      "|    n_updates            | 24450        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 2.5218267    |\n",
      "|    std                  | 33.4         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2447         |\n",
      "|    time_elapsed         | 46348        |\n",
      "|    total_timesteps      | 5011456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027330345 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.88         |\n",
      "|    n_updates            | 24460        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    reward               | -0.0275707   |\n",
      "|    std                  | 33.5         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2448         |\n",
      "|    time_elapsed         | 46367        |\n",
      "|    total_timesteps      | 5013504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009080562 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 24470        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 19.667532    |\n",
      "|    std                  | 33.5         |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2449         |\n",
      "|    time_elapsed         | 46386        |\n",
      "|    total_timesteps      | 5015552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001334646  |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 24480        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.008725529 |\n",
      "|    std                  | 33.5         |\n",
      "|    value_loss           | 50.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2450         |\n",
      "|    time_elapsed         | 46404        |\n",
      "|    total_timesteps      | 5017600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018906965 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.91         |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 0.71343213   |\n",
      "|    std                  | 33.6         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2451        |\n",
      "|    time_elapsed         | 46422       |\n",
      "|    total_timesteps      | 5019648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001129241 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 24500       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | 1.2807398   |\n",
      "|    std                  | 33.6        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2452         |\n",
      "|    time_elapsed         | 46440        |\n",
      "|    total_timesteps      | 5021696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021041895 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 24510        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -2.815847    |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2453         |\n",
      "|    time_elapsed         | 46459        |\n",
      "|    total_timesteps      | 5023744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028708652 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 24520        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 2.2446716    |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3922501.46\n",
      "total_reward: 2922501.46\n",
      "total_cost: 145367.90\n",
      "total_trades: 59242\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2454         |\n",
      "|    time_elapsed         | 46477        |\n",
      "|    total_timesteps      | 5025792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.002895595  |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 24530        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | -0.011017584 |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2455         |\n",
      "|    time_elapsed         | 46495        |\n",
      "|    total_timesteps      | 5027840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023787753 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.7         |\n",
      "|    n_updates            | 24540        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | 2.4373229    |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2456        |\n",
      "|    time_elapsed         | 46513       |\n",
      "|    total_timesteps      | 5029888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002265695 |\n",
      "|    clip_fraction        | 0.00161     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 24550       |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    reward               | 3.2714136   |\n",
      "|    std                  | 33.9        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2457        |\n",
      "|    time_elapsed         | 46532       |\n",
      "|    total_timesteps      | 5031936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003956072 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.41        |\n",
      "|    n_updates            | 24560       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | -1.2900369  |\n",
      "|    std                  | 34          |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2458         |\n",
      "|    time_elapsed         | 46550        |\n",
      "|    total_timesteps      | 5033984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032881256 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 24570        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | -0.24607639  |\n",
      "|    std                  | 34.1         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2459          |\n",
      "|    time_elapsed         | 46569         |\n",
      "|    total_timesteps      | 5036032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078955584 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.585         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.4          |\n",
      "|    n_updates            | 24580         |\n",
      "|    policy_gradient_loss | -0.00203      |\n",
      "|    reward               | -2.6813974    |\n",
      "|    std                  | 34.1          |\n",
      "|    value_loss           | 43.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2460         |\n",
      "|    time_elapsed         | 46588        |\n",
      "|    total_timesteps      | 5038080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012095639 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 24590        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | -0.3427352   |\n",
      "|    std                  | 34.1         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2461         |\n",
      "|    time_elapsed         | 46606        |\n",
      "|    total_timesteps      | 5040128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015836268 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 24600        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -1.2633222   |\n",
      "|    std                  | 34.1         |\n",
      "|    value_loss           | 32.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2462         |\n",
      "|    time_elapsed         | 46624        |\n",
      "|    total_timesteps      | 5042176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016728926 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 24610        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 1.1753622    |\n",
      "|    std                  | 34.2         |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2463          |\n",
      "|    time_elapsed         | 46642         |\n",
      "|    total_timesteps      | 5044224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057442795 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.379         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.1          |\n",
      "|    n_updates            | 24620         |\n",
      "|    policy_gradient_loss | -0.00125      |\n",
      "|    reward               | -0.66445184   |\n",
      "|    std                  | 34.3          |\n",
      "|    value_loss           | 37.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2464         |\n",
      "|    time_elapsed         | 46660        |\n",
      "|    total_timesteps      | 5046272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029061753 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.58         |\n",
      "|    n_updates            | 24630        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    reward               | 4.0793457    |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 18           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2465         |\n",
      "|    time_elapsed         | 46678        |\n",
      "|    total_timesteps      | 5048320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023375791 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 24640        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | 0.7906798    |\n",
      "|    std                  | 34.4         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2466         |\n",
      "|    time_elapsed         | 46697        |\n",
      "|    total_timesteps      | 5050368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006681355 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 24650        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    reward               | 0.02199616   |\n",
      "|    std                  | 34.4         |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2467         |\n",
      "|    time_elapsed         | 46715        |\n",
      "|    total_timesteps      | 5052416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019114977 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.75         |\n",
      "|    n_updates            | 24660        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 0.12738454   |\n",
      "|    std                  | 34.5         |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3727988.21\n",
      "total_reward: 2727988.21\n",
      "total_cost: 156095.30\n",
      "total_trades: 60046\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2468         |\n",
      "|    time_elapsed         | 46733        |\n",
      "|    total_timesteps      | 5054464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039271223 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 24670        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    reward               | -0.2766001   |\n",
      "|    std                  | 34.6         |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2469         |\n",
      "|    time_elapsed         | 46752        |\n",
      "|    total_timesteps      | 5056512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018622635 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 24680        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -2.37423     |\n",
      "|    std                  | 34.6         |\n",
      "|    value_loss           | 34.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2470         |\n",
      "|    time_elapsed         | 46771        |\n",
      "|    total_timesteps      | 5058560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029865785 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 24690        |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    reward               | 0.8975868    |\n",
      "|    std                  | 34.7         |\n",
      "|    value_loss           | 26.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2471        |\n",
      "|    time_elapsed         | 46789       |\n",
      "|    total_timesteps      | 5060608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002555926 |\n",
      "|    clip_fraction        | 0.00303     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 24700       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    reward               | 0.9713947   |\n",
      "|    std                  | 34.9        |\n",
      "|    value_loss           | 26.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2472          |\n",
      "|    time_elapsed         | 46808         |\n",
      "|    total_timesteps      | 5062656       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048810395 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.727         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22.3          |\n",
      "|    n_updates            | 24710         |\n",
      "|    policy_gradient_loss | -0.00214      |\n",
      "|    reward               | 5.4634485     |\n",
      "|    std                  | 34.9          |\n",
      "|    value_loss           | 46.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2473         |\n",
      "|    time_elapsed         | 46828        |\n",
      "|    total_timesteps      | 5064704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010314654 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 24720        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | -5.44478     |\n",
      "|    std                  | 34.9         |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2474        |\n",
      "|    time_elapsed         | 46846       |\n",
      "|    total_timesteps      | 5066752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003622625 |\n",
      "|    clip_fraction        | 0.00688     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 24730       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    reward               | -2.8571193  |\n",
      "|    std                  | 35.1        |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2475        |\n",
      "|    time_elapsed         | 46864       |\n",
      "|    total_timesteps      | 5068800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002711809 |\n",
      "|    clip_fraction        | 0.00234     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 24740       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    reward               | -2.874719   |\n",
      "|    std                  | 35.2        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2476         |\n",
      "|    time_elapsed         | 46882        |\n",
      "|    total_timesteps      | 5070848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018309997 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 24750        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | -1.9958562   |\n",
      "|    std                  | 35.3         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2477         |\n",
      "|    time_elapsed         | 46901        |\n",
      "|    total_timesteps      | 5072896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028114049 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.14         |\n",
      "|    n_updates            | 24760        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.13746534   |\n",
      "|    std                  | 35.4         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2478         |\n",
      "|    time_elapsed         | 46919        |\n",
      "|    total_timesteps      | 5074944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022473899 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 24770        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -1.2819762   |\n",
      "|    std                  | 35.4         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2479         |\n",
      "|    time_elapsed         | 46937        |\n",
      "|    total_timesteps      | 5076992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011820949 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 24780        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 7.8253036    |\n",
      "|    std                  | 35.4         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2480        |\n",
      "|    time_elapsed         | 46956       |\n",
      "|    total_timesteps      | 5079040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001615893 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 24790       |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    reward               | -1.3397661  |\n",
      "|    std                  | 35.5        |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2481         |\n",
      "|    time_elapsed         | 46975        |\n",
      "|    total_timesteps      | 5081088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006543481 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 24800        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | 2.7452056    |\n",
      "|    std                  | 35.6         |\n",
      "|    value_loss           | 30.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4322483.28\n",
      "total_reward: 3322483.28\n",
      "total_cost: 177081.11\n",
      "total_trades: 61306\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2482         |\n",
      "|    time_elapsed         | 46993        |\n",
      "|    total_timesteps      | 5083136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013301722 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 24810        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 0.65161467   |\n",
      "|    std                  | 35.6         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2483         |\n",
      "|    time_elapsed         | 47011        |\n",
      "|    total_timesteps      | 5085184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006976706 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 24820        |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | 3.3125215    |\n",
      "|    std                  | 35.7         |\n",
      "|    value_loss           | 49.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2484         |\n",
      "|    time_elapsed         | 47029        |\n",
      "|    total_timesteps      | 5087232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021121013 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | -0.0859      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.47         |\n",
      "|    n_updates            | 24830        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | -0.15077685  |\n",
      "|    std                  | 35.7         |\n",
      "|    value_loss           | 20.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2485         |\n",
      "|    time_elapsed         | 47047        |\n",
      "|    total_timesteps      | 5089280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027899225 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 24840        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | 0.4277904    |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2486         |\n",
      "|    time_elapsed         | 47065        |\n",
      "|    total_timesteps      | 5091328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005748125 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 24850        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | 2.9265072    |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2487         |\n",
      "|    time_elapsed         | 47083        |\n",
      "|    total_timesteps      | 5093376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023756668 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 24860        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    reward               | 0.39401463   |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2488         |\n",
      "|    time_elapsed         | 47102        |\n",
      "|    total_timesteps      | 5095424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038011225 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.84         |\n",
      "|    n_updates            | 24870        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    reward               | 2.520711     |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2489        |\n",
      "|    time_elapsed         | 47120       |\n",
      "|    total_timesteps      | 5097472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001819494 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 24880       |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | -0.3174849  |\n",
      "|    std                  | 36          |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2490         |\n",
      "|    time_elapsed         | 47138        |\n",
      "|    total_timesteps      | 5099520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007699783 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 24890        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | 0.7827888    |\n",
      "|    std                  | 36           |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2491         |\n",
      "|    time_elapsed         | 47156        |\n",
      "|    total_timesteps      | 5101568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051681204 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.13         |\n",
      "|    n_updates            | 24900        |\n",
      "|    policy_gradient_loss | -0.00712     |\n",
      "|    reward               | 1.4805223    |\n",
      "|    std                  | 36.1         |\n",
      "|    value_loss           | 16.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2492         |\n",
      "|    time_elapsed         | 47174        |\n",
      "|    total_timesteps      | 5103616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017971206 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 24910        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 2.7869718    |\n",
      "|    std                  | 36.2         |\n",
      "|    value_loss           | 28           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2493         |\n",
      "|    time_elapsed         | 47193        |\n",
      "|    total_timesteps      | 5105664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009841574 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 24920        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 1.3203812    |\n",
      "|    std                  | 36.3         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2494         |\n",
      "|    time_elapsed         | 47211        |\n",
      "|    total_timesteps      | 5107712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019296911 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 24930        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | 1.40164      |\n",
      "|    std                  | 36.3         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2495        |\n",
      "|    time_elapsed         | 47230       |\n",
      "|    total_timesteps      | 5109760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003020452 |\n",
      "|    clip_fraction        | 0.00732     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.36        |\n",
      "|    n_updates            | 24940       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 2.2658648   |\n",
      "|    std                  | 36.5        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2496         |\n",
      "|    time_elapsed         | 47248        |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007435358 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 24950        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | -0.7223578   |\n",
      "|    std                  | 36.5         |\n",
      "|    value_loss           | 40.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3837256.71\n",
      "total_reward: 2837256.71\n",
      "total_cost: 182115.69\n",
      "total_trades: 61509\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2497         |\n",
      "|    time_elapsed         | 47266        |\n",
      "|    total_timesteps      | 5113856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014114758 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 24960        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -2.3629904   |\n",
      "|    std                  | 36.6         |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2498          |\n",
      "|    time_elapsed         | 47285         |\n",
      "|    total_timesteps      | 5115904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033108515 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.277         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.2          |\n",
      "|    n_updates            | 24970         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | 1.8240178     |\n",
      "|    std                  | 36.6          |\n",
      "|    value_loss           | 24.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2499         |\n",
      "|    time_elapsed         | 47304        |\n",
      "|    total_timesteps      | 5117952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025932463 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    reward               | -1.2924875   |\n",
      "|    std                  | 36.8         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2500         |\n",
      "|    time_elapsed         | 47322        |\n",
      "|    total_timesteps      | 5120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010474791 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 24990        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 3.1642601    |\n",
      "|    std                  | 36.8         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2501         |\n",
      "|    time_elapsed         | 47340        |\n",
      "|    total_timesteps      | 5122048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019687302 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.4          |\n",
      "|    n_updates            | 25000        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 2.038744     |\n",
      "|    std                  | 36.9         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2502         |\n",
      "|    time_elapsed         | 47358        |\n",
      "|    total_timesteps      | 5124096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018538613 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 25010        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | -0.86133516  |\n",
      "|    std                  | 36.9         |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2503          |\n",
      "|    time_elapsed         | 47377         |\n",
      "|    total_timesteps      | 5126144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040132023 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.478         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.9          |\n",
      "|    n_updates            | 25020         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | 3.031616      |\n",
      "|    std                  | 37            |\n",
      "|    value_loss           | 45.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2504        |\n",
      "|    time_elapsed         | 47395       |\n",
      "|    total_timesteps      | 5128192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001676481 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 25030       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    reward               | 1.1655695   |\n",
      "|    std                  | 37          |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2505         |\n",
      "|    time_elapsed         | 47413        |\n",
      "|    total_timesteps      | 5130240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026783356 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.72         |\n",
      "|    n_updates            | 25040        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | -0.2218123   |\n",
      "|    std                  | 37.1         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2506         |\n",
      "|    time_elapsed         | 47432        |\n",
      "|    total_timesteps      | 5132288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012867441 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 25050        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | -0.011807147 |\n",
      "|    std                  | 37.2         |\n",
      "|    value_loss           | 39.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2507         |\n",
      "|    time_elapsed         | 47450        |\n",
      "|    total_timesteps      | 5134336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018917118 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.72         |\n",
      "|    n_updates            | 25060        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 5.049573     |\n",
      "|    std                  | 37.3         |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2508         |\n",
      "|    time_elapsed         | 47469        |\n",
      "|    total_timesteps      | 5136384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022112941 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.53         |\n",
      "|    n_updates            | 25070        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | 0.76913047   |\n",
      "|    std                  | 37.3         |\n",
      "|    value_loss           | 21.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2509         |\n",
      "|    time_elapsed         | 47487        |\n",
      "|    total_timesteps      | 5138432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022557676 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 25080        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | 1.4491737    |\n",
      "|    std                  | 37.4         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2510          |\n",
      "|    time_elapsed         | 47505         |\n",
      "|    total_timesteps      | 5140480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031364788 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | -0.0698       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.7          |\n",
      "|    n_updates            | 25090         |\n",
      "|    policy_gradient_loss | -0.000966     |\n",
      "|    reward               | 12.201873     |\n",
      "|    std                  | 37.4          |\n",
      "|    value_loss           | 42.5          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3245560.36\n",
      "total_reward: 2245560.36\n",
      "total_cost: 177116.80\n",
      "total_trades: 60937\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2511        |\n",
      "|    time_elapsed         | 47523       |\n",
      "|    total_timesteps      | 5142528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003361601 |\n",
      "|    clip_fraction        | 0.00361     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -145        |\n",
      "|    explained_variance   | 0.0653      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.9         |\n",
      "|    n_updates            | 25100       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | -5.0194697  |\n",
      "|    std                  | 37.5        |\n",
      "|    value_loss           | 30.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2512         |\n",
      "|    time_elapsed         | 47542        |\n",
      "|    total_timesteps      | 5144576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063550575 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.12         |\n",
      "|    n_updates            | 25110        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    reward               | -1.1911132   |\n",
      "|    std                  | 37.6         |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2513         |\n",
      "|    time_elapsed         | 47560        |\n",
      "|    total_timesteps      | 5146624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008779855 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.56         |\n",
      "|    n_updates            | 25120        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 1.0261151    |\n",
      "|    std                  | 37.6         |\n",
      "|    value_loss           | 25           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2514          |\n",
      "|    time_elapsed         | 47579         |\n",
      "|    total_timesteps      | 5148672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090147444 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.309         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.1          |\n",
      "|    n_updates            | 25130         |\n",
      "|    policy_gradient_loss | -0.00219      |\n",
      "|    reward               | -1.3201258    |\n",
      "|    std                  | 37.7          |\n",
      "|    value_loss           | 39.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2515         |\n",
      "|    time_elapsed         | 47597        |\n",
      "|    total_timesteps      | 5150720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060415342 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.66         |\n",
      "|    n_updates            | 25140        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    reward               | 0.10738737   |\n",
      "|    std                  | 37.8         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2516         |\n",
      "|    time_elapsed         | 47615        |\n",
      "|    total_timesteps      | 5152768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015950454 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 25150        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -2.4292006   |\n",
      "|    std                  | 37.9         |\n",
      "|    value_loss           | 27.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2517         |\n",
      "|    time_elapsed         | 47634        |\n",
      "|    total_timesteps      | 5154816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009968834 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 25160        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 1.6458601    |\n",
      "|    std                  | 37.9         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2518         |\n",
      "|    time_elapsed         | 47653        |\n",
      "|    total_timesteps      | 5156864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029454827 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.62         |\n",
      "|    n_updates            | 25170        |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    reward               | -0.9509651   |\n",
      "|    std                  | 37.8         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2519         |\n",
      "|    time_elapsed         | 47671        |\n",
      "|    total_timesteps      | 5158912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030528842 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.29         |\n",
      "|    n_updates            | 25180        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    reward               | -2.3728094   |\n",
      "|    std                  | 38           |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2520         |\n",
      "|    time_elapsed         | 47689        |\n",
      "|    total_timesteps      | 5160960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006056854 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 25190        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 1.9066008    |\n",
      "|    std                  | 38           |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2521         |\n",
      "|    time_elapsed         | 47708        |\n",
      "|    total_timesteps      | 5163008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.002073762  |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 25200        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -0.055173986 |\n",
      "|    std                  | 38.1         |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2522         |\n",
      "|    time_elapsed         | 47726        |\n",
      "|    total_timesteps      | 5165056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057198466 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.66         |\n",
      "|    n_updates            | 25210        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    reward               | 0.5138935    |\n",
      "|    std                  | 38.2         |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2523         |\n",
      "|    time_elapsed         | 47744        |\n",
      "|    total_timesteps      | 5167104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012399332 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.6          |\n",
      "|    n_updates            | 25220        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -0.14518937  |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2524          |\n",
      "|    time_elapsed         | 47762         |\n",
      "|    total_timesteps      | 5169152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032725133 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.451         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 25230         |\n",
      "|    policy_gradient_loss | -0.00133      |\n",
      "|    reward               | -1.5543209    |\n",
      "|    std                  | 38.3          |\n",
      "|    value_loss           | 31.3          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3168534.79\n",
      "total_reward: 2168534.79\n",
      "total_cost: 171826.96\n",
      "total_trades: 60314\n",
      "Sharpe: 0.607\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2525         |\n",
      "|    time_elapsed         | 47781        |\n",
      "|    total_timesteps      | 5171200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033690888 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.05         |\n",
      "|    n_updates            | 25240        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 1.5693738    |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2526         |\n",
      "|    time_elapsed         | 47799        |\n",
      "|    total_timesteps      | 5173248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015964916 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.79         |\n",
      "|    n_updates            | 25250        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | 1.018211     |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2527          |\n",
      "|    time_elapsed         | 47817         |\n",
      "|    total_timesteps      | 5175296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037564654 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.585         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.66          |\n",
      "|    n_updates            | 25260         |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    reward               | -1.2216775    |\n",
      "|    std                  | 38.3          |\n",
      "|    value_loss           | 26.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2528         |\n",
      "|    time_elapsed         | 47836        |\n",
      "|    total_timesteps      | 5177344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026487461 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 25270        |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    reward               | 1.6445801    |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2529        |\n",
      "|    time_elapsed         | 47854       |\n",
      "|    total_timesteps      | 5179392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004076155 |\n",
      "|    clip_fraction        | 0.01        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.52        |\n",
      "|    n_updates            | 25280       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 0.46338838  |\n",
      "|    std                  | 38.4        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2530         |\n",
      "|    time_elapsed         | 47872        |\n",
      "|    total_timesteps      | 5181440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014008502 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 25290        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.73545825   |\n",
      "|    std                  | 38.4         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2531         |\n",
      "|    time_elapsed         | 47891        |\n",
      "|    total_timesteps      | 5183488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012324554 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 25300        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 0.67579865   |\n",
      "|    std                  | 38.4         |\n",
      "|    value_loss           | 30.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2532         |\n",
      "|    time_elapsed         | 47909        |\n",
      "|    total_timesteps      | 5185536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023855863 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.17         |\n",
      "|    n_updates            | 25310        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 0.7022295    |\n",
      "|    std                  | 38.4         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2533         |\n",
      "|    time_elapsed         | 47928        |\n",
      "|    total_timesteps      | 5187584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026423498 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.5          |\n",
      "|    n_updates            | 25320        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    reward               | 1.9110683    |\n",
      "|    std                  | 38.4         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2534         |\n",
      "|    time_elapsed         | 47946        |\n",
      "|    total_timesteps      | 5189632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009497857 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 25330        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -5.1614804   |\n",
      "|    std                  | 38.5         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2535         |\n",
      "|    time_elapsed         | 47965        |\n",
      "|    total_timesteps      | 5191680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039538965 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.82         |\n",
      "|    n_updates            | 25340        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -2.4395428   |\n",
      "|    std                  | 38.5         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2536         |\n",
      "|    time_elapsed         | 47984        |\n",
      "|    total_timesteps      | 5193728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030937288 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.73         |\n",
      "|    n_updates            | 25350        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    reward               | -0.2037123   |\n",
      "|    std                  | 38.6         |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2537         |\n",
      "|    time_elapsed         | 48003        |\n",
      "|    total_timesteps      | 5195776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011134315 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 25360        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | -0.3712712   |\n",
      "|    std                  | 38.7         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2538         |\n",
      "|    time_elapsed         | 48021        |\n",
      "|    total_timesteps      | 5197824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016451417 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 25370        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 0.92475426   |\n",
      "|    std                  | 38.7         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2844938.80\n",
      "total_reward: 1844938.80\n",
      "total_cost: 177300.03\n",
      "total_trades: 60742\n",
      "Sharpe: 0.567\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2539        |\n",
      "|    time_elapsed         | 48039       |\n",
      "|    total_timesteps      | 5199872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001884105 |\n",
      "|    clip_fraction        | 0.00122     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.12        |\n",
      "|    n_updates            | 25380       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    reward               | -0.22329134 |\n",
      "|    std                  | 38.8        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2540         |\n",
      "|    time_elapsed         | 48058        |\n",
      "|    total_timesteps      | 5201920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011153454 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.23         |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | 0.6909794    |\n",
      "|    std                  | 39           |\n",
      "|    value_loss           | 19.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2541         |\n",
      "|    time_elapsed         | 48076        |\n",
      "|    total_timesteps      | 5203968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004926749 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.53         |\n",
      "|    n_updates            | 25400        |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    reward               | 0.88040274   |\n",
      "|    std                  | 39           |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2542         |\n",
      "|    time_elapsed         | 48094        |\n",
      "|    total_timesteps      | 5206016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047133043 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.0243       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.31         |\n",
      "|    n_updates            | 25410        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    reward               | -1.9406487   |\n",
      "|    std                  | 39.1         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2543         |\n",
      "|    time_elapsed         | 48113        |\n",
      "|    total_timesteps      | 5208064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012066909 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 25420        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | -0.4708936   |\n",
      "|    std                  | 39.1         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2544         |\n",
      "|    time_elapsed         | 48131        |\n",
      "|    total_timesteps      | 5210112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006376193 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 25430        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | 1.5920503    |\n",
      "|    std                  | 39.2         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2545         |\n",
      "|    time_elapsed         | 48150        |\n",
      "|    total_timesteps      | 5212160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016182783 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.48         |\n",
      "|    n_updates            | 25440        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | -0.14385767  |\n",
      "|    std                  | 39.1         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2546         |\n",
      "|    time_elapsed         | 48168        |\n",
      "|    total_timesteps      | 5214208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032392642 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.44         |\n",
      "|    n_updates            | 25450        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | -0.89120466  |\n",
      "|    std                  | 39.2         |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2547         |\n",
      "|    time_elapsed         | 48186        |\n",
      "|    total_timesteps      | 5216256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005385292 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.68         |\n",
      "|    n_updates            | 25460        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    reward               | 1.3037243    |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2548         |\n",
      "|    time_elapsed         | 48204        |\n",
      "|    total_timesteps      | 5218304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013551683 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 25470        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | 1.8636639    |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2549         |\n",
      "|    time_elapsed         | 48223        |\n",
      "|    total_timesteps      | 5220352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054961015 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.97         |\n",
      "|    n_updates            | 25480        |\n",
      "|    policy_gradient_loss | -0.00889     |\n",
      "|    reward               | 0.5755945    |\n",
      "|    std                  | 39.5         |\n",
      "|    value_loss           | 14.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2550         |\n",
      "|    time_elapsed         | 48241        |\n",
      "|    total_timesteps      | 5222400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007440313 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | 0.4777869    |\n",
      "|    std                  | 39.5         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2551        |\n",
      "|    time_elapsed         | 48259       |\n",
      "|    total_timesteps      | 5224448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001526079 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 25500       |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | -1.3322638  |\n",
      "|    std                  | 39.6        |\n",
      "|    value_loss           | 39.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2552         |\n",
      "|    time_elapsed         | 48278        |\n",
      "|    total_timesteps      | 5226496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018608654 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.97         |\n",
      "|    n_updates            | 25510        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -0.65542525  |\n",
      "|    std                  | 39.7         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3032087.75\n",
      "total_reward: 2032087.75\n",
      "total_cost: 212871.37\n",
      "total_trades: 63159\n",
      "Sharpe: 0.586\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2553         |\n",
      "|    time_elapsed         | 48296        |\n",
      "|    total_timesteps      | 5228544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031378884 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.26         |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    reward               | -1.5671511   |\n",
      "|    std                  | 39.8         |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2554         |\n",
      "|    time_elapsed         | 48314        |\n",
      "|    total_timesteps      | 5230592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008485154 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.27         |\n",
      "|    n_updates            | 25530        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | 0.13225006   |\n",
      "|    std                  | 39.8         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2555         |\n",
      "|    time_elapsed         | 48332        |\n",
      "|    total_timesteps      | 5232640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021202662 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.359        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 25540        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | 0.60089535   |\n",
      "|    std                  | 39.9         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 2556       |\n",
      "|    time_elapsed         | 48351      |\n",
      "|    total_timesteps      | 5234688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00543481 |\n",
      "|    clip_fraction        | 0.0126     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -147       |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.59       |\n",
      "|    n_updates            | 25550      |\n",
      "|    policy_gradient_loss | -0.00696   |\n",
      "|    reward               | 0.8322238  |\n",
      "|    std                  | 40         |\n",
      "|    value_loss           | 9.48       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2557         |\n",
      "|    time_elapsed         | 48369        |\n",
      "|    total_timesteps      | 5236736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012189769 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 25560        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | -0.5657628   |\n",
      "|    std                  | 40           |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2558         |\n",
      "|    time_elapsed         | 48388        |\n",
      "|    total_timesteps      | 5238784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020427362 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.32         |\n",
      "|    n_updates            | 25570        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | 1.9958357    |\n",
      "|    std                  | 40           |\n",
      "|    value_loss           | 20.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2559         |\n",
      "|    time_elapsed         | 48406        |\n",
      "|    total_timesteps      | 5240832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022506178 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.61         |\n",
      "|    n_updates            | 25580        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | 0.64142907   |\n",
      "|    std                  | 40.1         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2560         |\n",
      "|    time_elapsed         | 48424        |\n",
      "|    total_timesteps      | 5242880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011573685 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4            |\n",
      "|    n_updates            | 25590        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | -0.4575888   |\n",
      "|    std                  | 40.1         |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2561         |\n",
      "|    time_elapsed         | 48442        |\n",
      "|    total_timesteps      | 5244928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005091289 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.63         |\n",
      "|    n_updates            | 25600        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 3.9566226    |\n",
      "|    std                  | 40.2         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2562          |\n",
      "|    time_elapsed         | 48460         |\n",
      "|    total_timesteps      | 5246976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054170704 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.528         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.3          |\n",
      "|    n_updates            | 25610         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | 0.37781507    |\n",
      "|    std                  | 40.2          |\n",
      "|    value_loss           | 33            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2563         |\n",
      "|    time_elapsed         | 48480        |\n",
      "|    total_timesteps      | 5249024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012514903 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.4          |\n",
      "|    n_updates            | 25620        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | -2.463918    |\n",
      "|    std                  | 40.3         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2564         |\n",
      "|    time_elapsed         | 48498        |\n",
      "|    total_timesteps      | 5251072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010086106 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.4          |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 1.4898384    |\n",
      "|    std                  | 40.3         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2565          |\n",
      "|    time_elapsed         | 48516         |\n",
      "|    total_timesteps      | 5253120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068632327 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.667         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.4          |\n",
      "|    n_updates            | 25640         |\n",
      "|    policy_gradient_loss | -0.00163      |\n",
      "|    reward               | 2.5195024     |\n",
      "|    std                  | 40.4          |\n",
      "|    value_loss           | 23.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2566         |\n",
      "|    time_elapsed         | 48534        |\n",
      "|    total_timesteps      | 5255168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046553193 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.98         |\n",
      "|    n_updates            | 25650        |\n",
      "|    policy_gradient_loss | -0.00855     |\n",
      "|    reward               | 0.5358282    |\n",
      "|    std                  | 40.5         |\n",
      "|    value_loss           | 15.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2776727.89\n",
      "total_reward: 1776727.89\n",
      "total_cost: 159164.95\n",
      "total_trades: 59805\n",
      "Sharpe: 0.557\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2567         |\n",
      "|    time_elapsed         | 48553        |\n",
      "|    total_timesteps      | 5257216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017552377 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.4          |\n",
      "|    n_updates            | 25660        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -0.85361063  |\n",
      "|    std                  | 40.5         |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2568         |\n",
      "|    time_elapsed         | 48571        |\n",
      "|    total_timesteps      | 5259264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009209226 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 25670        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | 0.49783468   |\n",
      "|    std                  | 40.6         |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2569         |\n",
      "|    time_elapsed         | 48589        |\n",
      "|    total_timesteps      | 5261312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011502141 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.91         |\n",
      "|    n_updates            | 25680        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | 0.49389905   |\n",
      "|    std                  | 40.7         |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2570         |\n",
      "|    time_elapsed         | 48609        |\n",
      "|    total_timesteps      | 5263360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019355507 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.8          |\n",
      "|    n_updates            | 25690        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | -2.269802    |\n",
      "|    std                  | 40.7         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2571         |\n",
      "|    time_elapsed         | 48627        |\n",
      "|    total_timesteps      | 5265408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011605406 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 25700        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | -0.08990418  |\n",
      "|    std                  | 40.8         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2572         |\n",
      "|    time_elapsed         | 48646        |\n",
      "|    total_timesteps      | 5267456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010461903 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.9         |\n",
      "|    n_updates            | 25710        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -1.2941345   |\n",
      "|    std                  | 40.9         |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2573        |\n",
      "|    time_elapsed         | 48665       |\n",
      "|    total_timesteps      | 5269504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004931083 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.4         |\n",
      "|    n_updates            | 25720       |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    reward               | 0.5797433   |\n",
      "|    std                  | 41.1        |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2574        |\n",
      "|    time_elapsed         | 48683       |\n",
      "|    total_timesteps      | 5271552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000774183 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 25730       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | 1.0193753   |\n",
      "|    std                  | 41.1        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2575        |\n",
      "|    time_elapsed         | 48701       |\n",
      "|    total_timesteps      | 5273600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001223495 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 25740       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | -1.6106464  |\n",
      "|    std                  | 41.2        |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2576        |\n",
      "|    time_elapsed         | 48720       |\n",
      "|    total_timesteps      | 5275648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001684132 |\n",
      "|    clip_fraction        | 0.000488    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 25750       |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | -0.8898507  |\n",
      "|    std                  | 41.2        |\n",
      "|    value_loss           | 26          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2577         |\n",
      "|    time_elapsed         | 48738        |\n",
      "|    total_timesteps      | 5277696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015153463 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.25         |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    reward               | 0.22146821   |\n",
      "|    std                  | 41.2         |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 2578       |\n",
      "|    time_elapsed         | 48756      |\n",
      "|    total_timesteps      | 5279744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00159309 |\n",
      "|    clip_fraction        | 0.000293   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -148       |\n",
      "|    explained_variance   | 0.286      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.97       |\n",
      "|    n_updates            | 25770      |\n",
      "|    policy_gradient_loss | -0.0023    |\n",
      "|    reward               | -0.4939779 |\n",
      "|    std                  | 41.3       |\n",
      "|    value_loss           | 23.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2579         |\n",
      "|    time_elapsed         | 48774        |\n",
      "|    total_timesteps      | 5281792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003357691 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 25780        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    reward               | -0.19808325  |\n",
      "|    std                  | 41.3         |\n",
      "|    value_loss           | 31.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2580        |\n",
      "|    time_elapsed         | 48792       |\n",
      "|    total_timesteps      | 5283840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003188947 |\n",
      "|    clip_fraction        | 0.00581     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.24        |\n",
      "|    n_updates            | 25790       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | 1.497986    |\n",
      "|    std                  | 41.5        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3250228.99\n",
      "total_reward: 2250228.99\n",
      "total_cost: 179582.02\n",
      "total_trades: 61245\n",
      "Sharpe: 0.635\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2581         |\n",
      "|    time_elapsed         | 48811        |\n",
      "|    total_timesteps      | 5285888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014636742 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.97         |\n",
      "|    n_updates            | 25800        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | -0.2798542   |\n",
      "|    std                  | 41.5         |\n",
      "|    value_loss           | 22.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2582         |\n",
      "|    time_elapsed         | 48829        |\n",
      "|    total_timesteps      | 5287936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009977947 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 25810        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | 0.19895394   |\n",
      "|    std                  | 41.6         |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2583         |\n",
      "|    time_elapsed         | 48848        |\n",
      "|    total_timesteps      | 5289984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018151016 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 25820        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -0.9739229   |\n",
      "|    std                  | 41.6         |\n",
      "|    value_loss           | 24           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2584         |\n",
      "|    time_elapsed         | 48866        |\n",
      "|    total_timesteps      | 5292032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007080587 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.85         |\n",
      "|    n_updates            | 25830        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | -0.4879054   |\n",
      "|    std                  | 41.7         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2585          |\n",
      "|    time_elapsed         | 48884         |\n",
      "|    total_timesteps      | 5294080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094612734 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.709         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.2          |\n",
      "|    n_updates            | 25840         |\n",
      "|    policy_gradient_loss | -0.00256      |\n",
      "|    reward               | -3.9550188    |\n",
      "|    std                  | 41.8          |\n",
      "|    value_loss           | 31.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2586         |\n",
      "|    time_elapsed         | 48903        |\n",
      "|    total_timesteps      | 5296128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012946166 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 25850        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 0.30635458   |\n",
      "|    std                  | 41.8         |\n",
      "|    value_loss           | 33.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2587         |\n",
      "|    time_elapsed         | 48921        |\n",
      "|    total_timesteps      | 5298176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014985374 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.95         |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | 0.799956     |\n",
      "|    std                  | 41.9         |\n",
      "|    value_loss           | 15.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2588          |\n",
      "|    time_elapsed         | 48939         |\n",
      "|    total_timesteps      | 5300224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043850578 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.614         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.7          |\n",
      "|    n_updates            | 25870         |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    reward               | 0.2958585     |\n",
      "|    std                  | 41.9          |\n",
      "|    value_loss           | 33.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2589         |\n",
      "|    time_elapsed         | 48958        |\n",
      "|    total_timesteps      | 5302272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006326076 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 25880        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | 5.269888     |\n",
      "|    std                  | 41.9         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2590         |\n",
      "|    time_elapsed         | 48976        |\n",
      "|    total_timesteps      | 5304320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043121395 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.78         |\n",
      "|    n_updates            | 25890        |\n",
      "|    policy_gradient_loss | -0.00826     |\n",
      "|    reward               | 3.12068      |\n",
      "|    std                  | 42.1         |\n",
      "|    value_loss           | 19.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2591        |\n",
      "|    time_elapsed         | 48995       |\n",
      "|    total_timesteps      | 5306368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001163491 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 25900       |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    reward               | 1.2127771   |\n",
      "|    std                  | 42.2        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2592         |\n",
      "|    time_elapsed         | 49013        |\n",
      "|    total_timesteps      | 5308416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014433032 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 25910        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | -3.0436778   |\n",
      "|    std                  | 42.3         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2593         |\n",
      "|    time_elapsed         | 49031        |\n",
      "|    total_timesteps      | 5310464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011592304 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 25920        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | -0.57223606  |\n",
      "|    std                  | 42.3         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2594         |\n",
      "|    time_elapsed         | 49050        |\n",
      "|    total_timesteps      | 5312512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027326557 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 25930        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | -0.54100794  |\n",
      "|    std                  | 42.4         |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2886361.60\n",
      "total_reward: 1886361.60\n",
      "total_cost: 177916.58\n",
      "total_trades: 60929\n",
      "Sharpe: 0.561\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2595         |\n",
      "|    time_elapsed         | 49069        |\n",
      "|    total_timesteps      | 5314560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014945518 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 25940        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | 0.12712215   |\n",
      "|    std                  | 42.5         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2596         |\n",
      "|    time_elapsed         | 49087        |\n",
      "|    total_timesteps      | 5316608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017514462 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 25950        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -0.5613263   |\n",
      "|    std                  | 42.5         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2597         |\n",
      "|    time_elapsed         | 49106        |\n",
      "|    total_timesteps      | 5318656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024690658 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.36         |\n",
      "|    n_updates            | 25960        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -0.3664654   |\n",
      "|    std                  | 42.6         |\n",
      "|    value_loss           | 13.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2598         |\n",
      "|    time_elapsed         | 49124        |\n",
      "|    total_timesteps      | 5320704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032996205 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.89         |\n",
      "|    n_updates            | 25970        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    reward               | -1.6270564   |\n",
      "|    std                  | 42.6         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2599         |\n",
      "|    time_elapsed         | 49143        |\n",
      "|    total_timesteps      | 5322752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010523841 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 25980        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    reward               | 3.7463374    |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 27.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2600         |\n",
      "|    time_elapsed         | 49161        |\n",
      "|    total_timesteps      | 5324800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013354211 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 25990        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | -2.682407    |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2601         |\n",
      "|    time_elapsed         | 49180        |\n",
      "|    total_timesteps      | 5326848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021072656 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.91         |\n",
      "|    n_updates            | 26000        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | 2.2363405    |\n",
      "|    std                  | 42.8         |\n",
      "|    value_loss           | 15.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2602          |\n",
      "|    time_elapsed         | 49198         |\n",
      "|    total_timesteps      | 5328896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078544545 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.575         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.7          |\n",
      "|    n_updates            | 26010         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | -1.5767651    |\n",
      "|    std                  | 42.8          |\n",
      "|    value_loss           | 32.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2603         |\n",
      "|    time_elapsed         | 49217        |\n",
      "|    total_timesteps      | 5330944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025260672 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.86         |\n",
      "|    n_updates            | 26020        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | 1.2220767    |\n",
      "|    std                  | 42.9         |\n",
      "|    value_loss           | 26.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2604         |\n",
      "|    time_elapsed         | 49236        |\n",
      "|    total_timesteps      | 5332992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027973806 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.06         |\n",
      "|    n_updates            | 26030        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | -0.8770249   |\n",
      "|    std                  | 43           |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2605         |\n",
      "|    time_elapsed         | 49255        |\n",
      "|    total_timesteps      | 5335040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017632265 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 26040        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 1.7036582    |\n",
      "|    std                  | 43           |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2606          |\n",
      "|    time_elapsed         | 49273         |\n",
      "|    total_timesteps      | 5337088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050716696 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.418         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.4          |\n",
      "|    n_updates            | 26050         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | -1.8433744    |\n",
      "|    std                  | 43            |\n",
      "|    value_loss           | 29.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2607         |\n",
      "|    time_elapsed         | 49292        |\n",
      "|    total_timesteps      | 5339136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028913822 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.79         |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | -1.78825     |\n",
      "|    std                  | 43.1         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2608         |\n",
      "|    time_elapsed         | 49310        |\n",
      "|    total_timesteps      | 5341184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016888345 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 0.26706898   |\n",
      "|    std                  | 43.2         |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2609          |\n",
      "|    time_elapsed         | 49329         |\n",
      "|    total_timesteps      | 5343232       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075484614 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.589         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.4          |\n",
      "|    n_updates            | 26080         |\n",
      "|    policy_gradient_loss | -0.00215      |\n",
      "|    reward               | -0.34675622   |\n",
      "|    std                  | 43.3          |\n",
      "|    value_loss           | 24            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2988541.33\n",
      "total_reward: 1988541.33\n",
      "total_cost: 179996.05\n",
      "total_trades: 61315\n",
      "Sharpe: 0.597\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2610         |\n",
      "|    time_elapsed         | 49347        |\n",
      "|    total_timesteps      | 5345280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024347561 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 26090        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | -0.4867533   |\n",
      "|    std                  | 43.4         |\n",
      "|    value_loss           | 20.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2611         |\n",
      "|    time_elapsed         | 49365        |\n",
      "|    total_timesteps      | 5347328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036393125 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | 0.02488692   |\n",
      "|    std                  | 43.6         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2612         |\n",
      "|    time_elapsed         | 49383        |\n",
      "|    total_timesteps      | 5349376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008404021 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 26110        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | 1.0791333    |\n",
      "|    std                  | 43.7         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2613         |\n",
      "|    time_elapsed         | 49402        |\n",
      "|    total_timesteps      | 5351424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013449974 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.64         |\n",
      "|    n_updates            | 26120        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 0.3771245    |\n",
      "|    std                  | 43.8         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2614         |\n",
      "|    time_elapsed         | 49420        |\n",
      "|    total_timesteps      | 5353472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048169657 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.259        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.44         |\n",
      "|    n_updates            | 26130        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    reward               | 0.72994673   |\n",
      "|    std                  | 43.8         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2615         |\n",
      "|    time_elapsed         | 49440        |\n",
      "|    total_timesteps      | 5355520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004443517 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.7         |\n",
      "|    n_updates            | 26140        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | -1.6021395   |\n",
      "|    std                  | 43.8         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2616          |\n",
      "|    time_elapsed         | 49458         |\n",
      "|    total_timesteps      | 5357568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026437422 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.595         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.9          |\n",
      "|    n_updates            | 26150         |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    reward               | 4.252312      |\n",
      "|    std                  | 43.8          |\n",
      "|    value_loss           | 29.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2617          |\n",
      "|    time_elapsed         | 49476         |\n",
      "|    total_timesteps      | 5359616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091768627 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.552         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.19          |\n",
      "|    n_updates            | 26160         |\n",
      "|    policy_gradient_loss | -0.00209      |\n",
      "|    reward               | 6.4735        |\n",
      "|    std                  | 43.9          |\n",
      "|    value_loss           | 32.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2618         |\n",
      "|    time_elapsed         | 49495        |\n",
      "|    total_timesteps      | 5361664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020554024 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.61         |\n",
      "|    n_updates            | 26170        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | -0.19411677  |\n",
      "|    std                  | 43.9         |\n",
      "|    value_loss           | 21.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2619          |\n",
      "|    time_elapsed         | 49513         |\n",
      "|    total_timesteps      | 5363712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062617485 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.617         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.2          |\n",
      "|    n_updates            | 26180         |\n",
      "|    policy_gradient_loss | -0.00168      |\n",
      "|    reward               | -1.7093049    |\n",
      "|    std                  | 44            |\n",
      "|    value_loss           | 37.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2620          |\n",
      "|    time_elapsed         | 49532         |\n",
      "|    total_timesteps      | 5365760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041777964 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.388         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21            |\n",
      "|    n_updates            | 26190         |\n",
      "|    policy_gradient_loss | -0.000568     |\n",
      "|    reward               | -0.6633628    |\n",
      "|    std                  | 44            |\n",
      "|    value_loss           | 47.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2621         |\n",
      "|    time_elapsed         | 49550        |\n",
      "|    total_timesteps      | 5367808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017098151 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.34         |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 1.0097301    |\n",
      "|    std                  | 44.1         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2622         |\n",
      "|    time_elapsed         | 49568        |\n",
      "|    total_timesteps      | 5369856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010264202 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.76         |\n",
      "|    n_updates            | 26210        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | 0.46392435   |\n",
      "|    std                  | 44.1         |\n",
      "|    value_loss           | 26.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2623          |\n",
      "|    time_elapsed         | 49586         |\n",
      "|    total_timesteps      | 5371904       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063228037 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.709         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 26220         |\n",
      "|    policy_gradient_loss | -0.00269      |\n",
      "|    reward               | 0.85864794    |\n",
      "|    std                  | 44.2          |\n",
      "|    value_loss           | 29.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2913298.37\n",
      "total_reward: 1913298.37\n",
      "total_cost: 158039.34\n",
      "total_trades: 59718\n",
      "Sharpe: 0.581\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2624         |\n",
      "|    time_elapsed         | 49605        |\n",
      "|    total_timesteps      | 5373952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020141639 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 26230        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | -0.4040819   |\n",
      "|    std                  | 44.3         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2625         |\n",
      "|    time_elapsed         | 49623        |\n",
      "|    total_timesteps      | 5376000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023999775 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.75         |\n",
      "|    n_updates            | 26240        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    reward               | 0.60089755   |\n",
      "|    std                  | 44.3         |\n",
      "|    value_loss           | 14.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2626        |\n",
      "|    time_elapsed         | 49703       |\n",
      "|    total_timesteps      | 5378048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003210897 |\n",
      "|    clip_fraction        | 0.00562     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 26250       |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    reward               | -4.142697   |\n",
      "|    std                  | 44.4        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2627          |\n",
      "|    time_elapsed         | 49722         |\n",
      "|    total_timesteps      | 5380096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044117437 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.318         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.6          |\n",
      "|    n_updates            | 26260         |\n",
      "|    policy_gradient_loss | -0.00169      |\n",
      "|    reward               | -0.10298065   |\n",
      "|    std                  | 44.5          |\n",
      "|    value_loss           | 41            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2628        |\n",
      "|    time_elapsed         | 49740       |\n",
      "|    total_timesteps      | 5382144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004252975 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.84        |\n",
      "|    n_updates            | 26270       |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    reward               | -1.3214433  |\n",
      "|    std                  | 44.6        |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2629          |\n",
      "|    time_elapsed         | 49759         |\n",
      "|    total_timesteps      | 5384192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029962923 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.465         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.7          |\n",
      "|    n_updates            | 26280         |\n",
      "|    policy_gradient_loss | -0.00135      |\n",
      "|    reward               | 0.100169465   |\n",
      "|    std                  | 44.6          |\n",
      "|    value_loss           | 37.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2630          |\n",
      "|    time_elapsed         | 49777         |\n",
      "|    total_timesteps      | 5386240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033337125 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.417         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.9          |\n",
      "|    n_updates            | 26290         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | 4.784258      |\n",
      "|    std                  | 44.6          |\n",
      "|    value_loss           | 43.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2631         |\n",
      "|    time_elapsed         | 49796        |\n",
      "|    total_timesteps      | 5388288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030490055 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.76         |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    reward               | 0.34900838   |\n",
      "|    std                  | 44.7         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2632        |\n",
      "|    time_elapsed         | 49814       |\n",
      "|    total_timesteps      | 5390336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002129089 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.1         |\n",
      "|    n_updates            | 26310       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | -3.6734715  |\n",
      "|    std                  | 44.8        |\n",
      "|    value_loss           | 18.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2633         |\n",
      "|    time_elapsed         | 49832        |\n",
      "|    total_timesteps      | 5392384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020899777 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 2.7993748    |\n",
      "|    std                  | 44.9         |\n",
      "|    value_loss           | 31           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2634         |\n",
      "|    time_elapsed         | 49850        |\n",
      "|    total_timesteps      | 5394432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017328162 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 26330        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.5017249    |\n",
      "|    std                  | 44.9         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2635        |\n",
      "|    time_elapsed         | 49869       |\n",
      "|    total_timesteps      | 5396480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001226511 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8           |\n",
      "|    n_updates            | 26340       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | -0.18492992 |\n",
      "|    std                  | 45          |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2636         |\n",
      "|    time_elapsed         | 49888        |\n",
      "|    total_timesteps      | 5398528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012809641 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.51         |\n",
      "|    n_updates            | 26350        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 0.7757437    |\n",
      "|    std                  | 45.1         |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2637         |\n",
      "|    time_elapsed         | 49906        |\n",
      "|    total_timesteps      | 5400576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012892827 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 26360        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -2.4047627   |\n",
      "|    std                  | 45.2         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3144065.32\n",
      "total_reward: 2144065.32\n",
      "total_cost: 235561.34\n",
      "total_trades: 65143\n",
      "Sharpe: 0.606\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2638         |\n",
      "|    time_elapsed         | 49925        |\n",
      "|    total_timesteps      | 5402624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041381083 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.7          |\n",
      "|    n_updates            | 26370        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -1.0609841   |\n",
      "|    std                  | 45.3         |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2639        |\n",
      "|    time_elapsed         | 49943       |\n",
      "|    total_timesteps      | 5404672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001513229 |\n",
      "|    clip_fraction        | 0.00151     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.49        |\n",
      "|    n_updates            | 26380       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | 1.918457    |\n",
      "|    std                  | 45.2        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2640         |\n",
      "|    time_elapsed         | 49961        |\n",
      "|    total_timesteps      | 5406720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014111298 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.3          |\n",
      "|    n_updates            | 26390        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | 0.0740017    |\n",
      "|    std                  | 45.3         |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2641        |\n",
      "|    time_elapsed         | 49979       |\n",
      "|    total_timesteps      | 5408768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002861782 |\n",
      "|    clip_fraction        | 0.00249     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 26400       |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    reward               | 1.6413374   |\n",
      "|    std                  | 45.3        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2642         |\n",
      "|    time_elapsed         | 49998        |\n",
      "|    total_timesteps      | 5410816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019419912 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 26410        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | 0.23819701   |\n",
      "|    std                  | 45.4         |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2643         |\n",
      "|    time_elapsed         | 50016        |\n",
      "|    total_timesteps      | 5412864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014550942 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.56         |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    reward               | 1.1885948    |\n",
      "|    std                  | 45.4         |\n",
      "|    value_loss           | 23.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2644         |\n",
      "|    time_elapsed         | 50035        |\n",
      "|    total_timesteps      | 5414912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008258653 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.99         |\n",
      "|    n_updates            | 26430        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | 3.1921086    |\n",
      "|    std                  | 45.5         |\n",
      "|    value_loss           | 29.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2645         |\n",
      "|    time_elapsed         | 50053        |\n",
      "|    total_timesteps      | 5416960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012627328 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.76         |\n",
      "|    n_updates            | 26440        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | 0.1786237    |\n",
      "|    std                  | 45.6         |\n",
      "|    value_loss           | 16.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2646         |\n",
      "|    time_elapsed         | 50072        |\n",
      "|    total_timesteps      | 5419008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009403387 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.99         |\n",
      "|    n_updates            | 26450        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 3.3654225    |\n",
      "|    std                  | 45.7         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2647         |\n",
      "|    time_elapsed         | 50090        |\n",
      "|    total_timesteps      | 5421056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002767303 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 26460        |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 2.9976695    |\n",
      "|    std                  | 45.7         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2648        |\n",
      "|    time_elapsed         | 50109       |\n",
      "|    total_timesteps      | 5423104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001884229 |\n",
      "|    clip_fraction        | 0.00146     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 26470       |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | -1.0133866  |\n",
      "|    std                  | 45.9        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2649          |\n",
      "|    time_elapsed         | 50128         |\n",
      "|    total_timesteps      | 5425152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054679695 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.62          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.1          |\n",
      "|    n_updates            | 26480         |\n",
      "|    policy_gradient_loss | -0.00178      |\n",
      "|    reward               | -0.17179145   |\n",
      "|    std                  | 45.9          |\n",
      "|    value_loss           | 24.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2650         |\n",
      "|    time_elapsed         | 50147        |\n",
      "|    total_timesteps      | 5427200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010366951 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.76         |\n",
      "|    n_updates            | 26490        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | -12.173148   |\n",
      "|    std                  | 46           |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2651         |\n",
      "|    time_elapsed         | 50165        |\n",
      "|    total_timesteps      | 5429248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004467007 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.03         |\n",
      "|    n_updates            | 26500        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | -0.31434172  |\n",
      "|    std                  | 46           |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3200668.13\n",
      "total_reward: 2200668.13\n",
      "total_cost: 315197.74\n",
      "total_trades: 68863\n",
      "Sharpe: 0.632\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2652        |\n",
      "|    time_elapsed         | 50184       |\n",
      "|    total_timesteps      | 5431296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003976642 |\n",
      "|    clip_fraction        | 0.00718     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 26510       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | 1.5416446   |\n",
      "|    std                  | 46.2        |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2653          |\n",
      "|    time_elapsed         | 50202         |\n",
      "|    total_timesteps      | 5433344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077658973 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.513         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.7          |\n",
      "|    n_updates            | 26520         |\n",
      "|    policy_gradient_loss | -0.00255      |\n",
      "|    reward               | 0.6347789     |\n",
      "|    std                  | 46.3          |\n",
      "|    value_loss           | 22.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2654         |\n",
      "|    time_elapsed         | 50221        |\n",
      "|    total_timesteps      | 5435392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016905203 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.21         |\n",
      "|    n_updates            | 26530        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | -0.8948698   |\n",
      "|    std                  | 46.3         |\n",
      "|    value_loss           | 20.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2655         |\n",
      "|    time_elapsed         | 50240        |\n",
      "|    total_timesteps      | 5437440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026019248 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.98         |\n",
      "|    n_updates            | 26540        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -0.31841826  |\n",
      "|    std                  | 46.5         |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2656         |\n",
      "|    time_elapsed         | 50259        |\n",
      "|    total_timesteps      | 5439488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010596886 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.78         |\n",
      "|    n_updates            | 26550        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -0.7519507   |\n",
      "|    std                  | 46.5         |\n",
      "|    value_loss           | 15.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2657        |\n",
      "|    time_elapsed         | 50278       |\n",
      "|    total_timesteps      | 5441536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004226904 |\n",
      "|    clip_fraction        | 0.00815     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -151        |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.91        |\n",
      "|    n_updates            | 26560       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | -0.12507433 |\n",
      "|    std                  | 46.6        |\n",
      "|    value_loss           | 24.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2658         |\n",
      "|    time_elapsed         | 50297        |\n",
      "|    total_timesteps      | 5443584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066922866 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.61         |\n",
      "|    n_updates            | 26570        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -4.06052     |\n",
      "|    std                  | 46.7         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2659         |\n",
      "|    time_elapsed         | 50316        |\n",
      "|    total_timesteps      | 5445632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017216865 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.28         |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | 2.4205196    |\n",
      "|    std                  | 46.8         |\n",
      "|    value_loss           | 14.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2660         |\n",
      "|    time_elapsed         | 50335        |\n",
      "|    total_timesteps      | 5447680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001995728  |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 26590        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -0.063466445 |\n",
      "|    std                  | 46.7         |\n",
      "|    value_loss           | 28.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2661          |\n",
      "|    time_elapsed         | 50353         |\n",
      "|    total_timesteps      | 5449728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039469462 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.497         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.5          |\n",
      "|    n_updates            | 26600         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | 3.9875853     |\n",
      "|    std                  | 46.7          |\n",
      "|    value_loss           | 25.5          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2662         |\n",
      "|    time_elapsed         | 50371        |\n",
      "|    total_timesteps      | 5451776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051004393 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.03         |\n",
      "|    n_updates            | 26610        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    reward               | 0.36127344   |\n",
      "|    std                  | 46.8         |\n",
      "|    value_loss           | 11.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2663         |\n",
      "|    time_elapsed         | 50389        |\n",
      "|    total_timesteps      | 5453824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015319022 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.05         |\n",
      "|    n_updates            | 26620        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | -0.23412809  |\n",
      "|    std                  | 46.9         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2664          |\n",
      "|    time_elapsed         | 50408         |\n",
      "|    total_timesteps      | 5455872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027718162 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.527         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.8          |\n",
      "|    n_updates            | 26630         |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    reward               | 3.614364      |\n",
      "|    std                  | 46.9          |\n",
      "|    value_loss           | 24.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2665         |\n",
      "|    time_elapsed         | 50426        |\n",
      "|    total_timesteps      | 5457920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014430179 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.98         |\n",
      "|    n_updates            | 26640        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 0.5616709    |\n",
      "|    std                  | 47           |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3397951.97\n",
      "total_reward: 2397951.97\n",
      "total_cost: 189243.00\n",
      "total_trades: 62194\n",
      "Sharpe: 0.664\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2666        |\n",
      "|    time_elapsed         | 50445       |\n",
      "|    total_timesteps      | 5459968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002097362 |\n",
      "|    clip_fraction        | 0.00142     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -152        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.53        |\n",
      "|    n_updates            | 26650       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 0.42616388  |\n",
      "|    std                  | 47.1        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2667         |\n",
      "|    time_elapsed         | 50463        |\n",
      "|    total_timesteps      | 5462016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006311028 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 26660        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | -0.1155409   |\n",
      "|    std                  | 47.1         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2668         |\n",
      "|    time_elapsed         | 50482        |\n",
      "|    total_timesteps      | 5464064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007576741 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 26670        |\n",
      "|    policy_gradient_loss | -0.000986    |\n",
      "|    reward               | 3.5246792    |\n",
      "|    std                  | 47.1         |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2669         |\n",
      "|    time_elapsed         | 50501        |\n",
      "|    total_timesteps      | 5466112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066645355 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.62         |\n",
      "|    n_updates            | 26680        |\n",
      "|    policy_gradient_loss | -0.00857     |\n",
      "|    reward               | 0.4509873    |\n",
      "|    std                  | 47.1         |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2670         |\n",
      "|    time_elapsed         | 50519        |\n",
      "|    total_timesteps      | 5468160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024446296 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.27         |\n",
      "|    n_updates            | 26690        |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | 1.3239989    |\n",
      "|    std                  | 47.1         |\n",
      "|    value_loss           | 20.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2671         |\n",
      "|    time_elapsed         | 50537        |\n",
      "|    total_timesteps      | 5470208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007358185 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.26         |\n",
      "|    n_updates            | 26700        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 2.3691378    |\n",
      "|    std                  | 47.2         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2672        |\n",
      "|    time_elapsed         | 50557       |\n",
      "|    total_timesteps      | 5472256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002031425 |\n",
      "|    clip_fraction        | 0.00244     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -152        |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.16        |\n",
      "|    n_updates            | 26710       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 1.2544446   |\n",
      "|    std                  | 47.2        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2673         |\n",
      "|    time_elapsed         | 50575        |\n",
      "|    total_timesteps      | 5474304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027065072 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.28         |\n",
      "|    n_updates            | 26720        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 3.7323544    |\n",
      "|    std                  | 47.4         |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2674         |\n",
      "|    time_elapsed         | 50593        |\n",
      "|    total_timesteps      | 5476352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005078949 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.1         |\n",
      "|    n_updates            | 26730        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | 1.1478504    |\n",
      "|    std                  | 47.5         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2675          |\n",
      "|    time_elapsed         | 50611         |\n",
      "|    total_timesteps      | 5478400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095816376 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.707         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.46          |\n",
      "|    n_updates            | 26740         |\n",
      "|    policy_gradient_loss | -0.00252      |\n",
      "|    reward               | -0.29540437   |\n",
      "|    std                  | 47.5          |\n",
      "|    value_loss           | 22.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2676         |\n",
      "|    time_elapsed         | 50630        |\n",
      "|    total_timesteps      | 5480448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015806973 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.79         |\n",
      "|    n_updates            | 26750        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 0.12694065   |\n",
      "|    std                  | 47.5         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2677         |\n",
      "|    time_elapsed         | 50648        |\n",
      "|    total_timesteps      | 5482496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015780575 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 26760        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -1.2317713   |\n",
      "|    std                  | 47.6         |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2678          |\n",
      "|    time_elapsed         | 50666         |\n",
      "|    total_timesteps      | 5484544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071446097 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.571         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.5          |\n",
      "|    n_updates            | 26770         |\n",
      "|    policy_gradient_loss | -0.00202      |\n",
      "|    reward               | -3.1051044    |\n",
      "|    std                  | 47.6          |\n",
      "|    value_loss           | 23.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2679         |\n",
      "|    time_elapsed         | 50685        |\n",
      "|    total_timesteps      | 5486592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024059564 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.76         |\n",
      "|    n_updates            | 26780        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | 0.39281443   |\n",
      "|    std                  | 47.8         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2655686.54\n",
      "total_reward: 1655686.54\n",
      "total_cost: 157278.15\n",
      "total_trades: 59726\n",
      "Sharpe: 0.537\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2680         |\n",
      "|    time_elapsed         | 50703        |\n",
      "|    total_timesteps      | 5488640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020836568 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.55         |\n",
      "|    n_updates            | 26790        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | -0.006257826 |\n",
      "|    std                  | 47.8         |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2681          |\n",
      "|    time_elapsed         | 50723         |\n",
      "|    total_timesteps      | 5490688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090374495 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.628         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.6          |\n",
      "|    n_updates            | 26800         |\n",
      "|    policy_gradient_loss | -0.00204      |\n",
      "|    reward               | 2.3147266     |\n",
      "|    std                  | 47.9          |\n",
      "|    value_loss           | 22.4          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2682          |\n",
      "|    time_elapsed         | 50742         |\n",
      "|    total_timesteps      | 5492736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088401017 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.574         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.27          |\n",
      "|    n_updates            | 26810         |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    reward               | -0.7134299    |\n",
      "|    std                  | 47.9          |\n",
      "|    value_loss           | 26.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2683         |\n",
      "|    time_elapsed         | 50760        |\n",
      "|    total_timesteps      | 5494784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010935256 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.51         |\n",
      "|    n_updates            | 26820        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | 2.3218527    |\n",
      "|    std                  | 47.9         |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2684         |\n",
      "|    time_elapsed         | 50779        |\n",
      "|    total_timesteps      | 5496832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005853949 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.72         |\n",
      "|    n_updates            | 26830        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | 0.36757755   |\n",
      "|    std                  | 48           |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2685          |\n",
      "|    time_elapsed         | 50797         |\n",
      "|    total_timesteps      | 5498880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081305485 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -152          |\n",
      "|    explained_variance   | 0.728         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.05          |\n",
      "|    n_updates            | 26840         |\n",
      "|    policy_gradient_loss | -0.00254      |\n",
      "|    reward               | -0.65929055   |\n",
      "|    std                  | 48            |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2686         |\n",
      "|    time_elapsed         | 50816        |\n",
      "|    total_timesteps      | 5500928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023519187 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.82         |\n",
      "|    n_updates            | 26850        |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    reward               | 0.5706584    |\n",
      "|    std                  | 48.1         |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2687         |\n",
      "|    time_elapsed         | 50834        |\n",
      "|    total_timesteps      | 5502976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038250093 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.8         |\n",
      "|    n_updates            | 26860        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    reward               | 0.2828043    |\n",
      "|    std                  | 48.2         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2688         |\n",
      "|    time_elapsed         | 50853        |\n",
      "|    total_timesteps      | 5505024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004971385 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 26870        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | 1.9557576    |\n",
      "|    std                  | 48.2         |\n",
      "|    value_loss           | 28.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2689         |\n",
      "|    time_elapsed         | 50871        |\n",
      "|    total_timesteps      | 5507072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012951042 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.39         |\n",
      "|    n_updates            | 26880        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | 0.23281044   |\n",
      "|    std                  | 48.3         |\n",
      "|    value_loss           | 21.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2690         |\n",
      "|    time_elapsed         | 50890        |\n",
      "|    total_timesteps      | 5509120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031505676 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.95         |\n",
      "|    n_updates            | 26890        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | 0.019016381  |\n",
      "|    std                  | 48.2         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2691         |\n",
      "|    time_elapsed         | 50908        |\n",
      "|    total_timesteps      | 5511168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012380197 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.97         |\n",
      "|    n_updates            | 26900        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -0.21024345  |\n",
      "|    std                  | 48.2         |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2692         |\n",
      "|    time_elapsed         | 50927        |\n",
      "|    total_timesteps      | 5513216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009268293 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.29         |\n",
      "|    n_updates            | 26910        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | -1.4997523   |\n",
      "|    std                  | 48.2         |\n",
      "|    value_loss           | 31.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2693         |\n",
      "|    time_elapsed         | 50945        |\n",
      "|    total_timesteps      | 5515264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027686695 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.29         |\n",
      "|    n_updates            | 26920        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 1.5571908    |\n",
      "|    std                  | 48.3         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3123034.58\n",
      "total_reward: 2123034.58\n",
      "total_cost: 216654.89\n",
      "total_trades: 63815\n",
      "Sharpe: 0.612\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2694         |\n",
      "|    time_elapsed         | 50963        |\n",
      "|    total_timesteps      | 5517312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018914614 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.19         |\n",
      "|    n_updates            | 26930        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | 1.2194971    |\n",
      "|    std                  | 48.4         |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2695         |\n",
      "|    time_elapsed         | 50981        |\n",
      "|    total_timesteps      | 5519360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018420372 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.99         |\n",
      "|    n_updates            | 26940        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 1.5973072    |\n",
      "|    std                  | 48.5         |\n",
      "|    value_loss           | 26.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2696         |\n",
      "|    time_elapsed         | 51000        |\n",
      "|    total_timesteps      | 5521408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008548241 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.18         |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | 0.022712646  |\n",
      "|    std                  | 48.4         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2697         |\n",
      "|    time_elapsed         | 51019        |\n",
      "|    total_timesteps      | 5523456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017342756 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.14         |\n",
      "|    n_updates            | 26960        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 1.8437592    |\n",
      "|    std                  | 48.6         |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2698         |\n",
      "|    time_elapsed         | 51038        |\n",
      "|    total_timesteps      | 5525504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016779983 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.83         |\n",
      "|    n_updates            | 26970        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | -1.3139205   |\n",
      "|    std                  | 48.7         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2699         |\n",
      "|    time_elapsed         | 51057        |\n",
      "|    total_timesteps      | 5527552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020822193 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.09         |\n",
      "|    n_updates            | 26980        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | -0.28516346  |\n",
      "|    std                  | 48.8         |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2700         |\n",
      "|    time_elapsed         | 51076        |\n",
      "|    total_timesteps      | 5529600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037063896 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.18         |\n",
      "|    n_updates            | 26990        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | 0.37374312   |\n",
      "|    std                  | 49           |\n",
      "|    value_loss           | 15.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2701         |\n",
      "|    time_elapsed         | 51095        |\n",
      "|    total_timesteps      | 5531648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008301906 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 27000        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | -1.469211    |\n",
      "|    std                  | 49.2         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2702         |\n",
      "|    time_elapsed         | 51114        |\n",
      "|    total_timesteps      | 5533696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011042266 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 27010        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | -0.25525156  |\n",
      "|    std                  | 49.2         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2703         |\n",
      "|    time_elapsed         | 51132        |\n",
      "|    total_timesteps      | 5535744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031431578 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.73         |\n",
      "|    n_updates            | 27020        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | 1.1244247    |\n",
      "|    std                  | 49.4         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2704        |\n",
      "|    time_elapsed         | 51151       |\n",
      "|    total_timesteps      | 5537792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003495718 |\n",
      "|    clip_fraction        | 0.00513     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 27030       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | 0.39681372  |\n",
      "|    std                  | 49.6        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2705          |\n",
      "|    time_elapsed         | 51169         |\n",
      "|    total_timesteps      | 5539840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053934625 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.715         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.38          |\n",
      "|    n_updates            | 27040         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | -0.16124572   |\n",
      "|    std                  | 49.6          |\n",
      "|    value_loss           | 24.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2706        |\n",
      "|    time_elapsed         | 51187       |\n",
      "|    total_timesteps      | 5541888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001138147 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.43        |\n",
      "|    n_updates            | 27050       |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    reward               | -5.063261   |\n",
      "|    std                  | 49.7        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2707        |\n",
      "|    time_elapsed         | 51205       |\n",
      "|    total_timesteps      | 5543936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002345869 |\n",
      "|    clip_fraction        | 0.0019      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -153        |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.49        |\n",
      "|    n_updates            | 27060       |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    reward               | 0.38328612  |\n",
      "|    std                  | 49.8        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3904418.11\n",
      "total_reward: 2904418.11\n",
      "total_cost: 248626.49\n",
      "total_trades: 65687\n",
      "Sharpe: 0.703\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2708         |\n",
      "|    time_elapsed         | 51223        |\n",
      "|    total_timesteps      | 5545984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007917377 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 27070        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -0.27448726  |\n",
      "|    std                  | 49.9         |\n",
      "|    value_loss           | 28.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2709          |\n",
      "|    time_elapsed         | 51242         |\n",
      "|    total_timesteps      | 5548032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042246465 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -153          |\n",
      "|    explained_variance   | 0.551         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.2          |\n",
      "|    n_updates            | 27080         |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    reward               | 0.3570678     |\n",
      "|    std                  | 49.9          |\n",
      "|    value_loss           | 39.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2710         |\n",
      "|    time_elapsed         | 51261        |\n",
      "|    total_timesteps      | 5550080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041731773 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.96         |\n",
      "|    n_updates            | 27090        |\n",
      "|    policy_gradient_loss | -0.00821     |\n",
      "|    reward               | -1.9981998   |\n",
      "|    std                  | 50           |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2711         |\n",
      "|    time_elapsed         | 51280        |\n",
      "|    total_timesteps      | 5552128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011433638 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -153         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 27100        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | -0.07338286  |\n",
      "|    std                  | 50.1         |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2712          |\n",
      "|    time_elapsed         | 51298         |\n",
      "|    total_timesteps      | 5554176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076780596 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.661         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.9          |\n",
      "|    n_updates            | 27110         |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    reward               | -8.578515     |\n",
      "|    std                  | 50.1          |\n",
      "|    value_loss           | 31.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2713         |\n",
      "|    time_elapsed         | 51316        |\n",
      "|    total_timesteps      | 5556224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005829942 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 27120        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -0.9325631   |\n",
      "|    std                  | 50.2         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2714        |\n",
      "|    time_elapsed         | 51335       |\n",
      "|    total_timesteps      | 5558272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001172961 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 27130       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | -1.2207758  |\n",
      "|    std                  | 50.3        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2715          |\n",
      "|    time_elapsed         | 51353         |\n",
      "|    total_timesteps      | 5560320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060373626 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.436         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 27140         |\n",
      "|    policy_gradient_loss | -0.0017       |\n",
      "|    reward               | -1.13339      |\n",
      "|    std                  | 50.3          |\n",
      "|    value_loss           | 23.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2716          |\n",
      "|    time_elapsed         | 51371         |\n",
      "|    total_timesteps      | 5562368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081212935 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.659         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.2          |\n",
      "|    n_updates            | 27150         |\n",
      "|    policy_gradient_loss | -0.0014       |\n",
      "|    reward               | -1.9828379    |\n",
      "|    std                  | 50.4          |\n",
      "|    value_loss           | 23.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2717        |\n",
      "|    time_elapsed         | 51389       |\n",
      "|    total_timesteps      | 5564416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004156162 |\n",
      "|    clip_fraction        | 0.00996     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 27160       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    reward               | -0.62704504 |\n",
      "|    std                  | 50.5        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2718          |\n",
      "|    time_elapsed         | 51408         |\n",
      "|    total_timesteps      | 5566464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029358102 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.509         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.1          |\n",
      "|    n_updates            | 27170         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    reward               | 2.0018744     |\n",
      "|    std                  | 50.5          |\n",
      "|    value_loss           | 31.3          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2719          |\n",
      "|    time_elapsed         | 51426         |\n",
      "|    total_timesteps      | 5568512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063519494 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.639         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.5          |\n",
      "|    n_updates            | 27180         |\n",
      "|    policy_gradient_loss | -0.00201      |\n",
      "|    reward               | -1.7812201    |\n",
      "|    std                  | 50.6          |\n",
      "|    value_loss           | 24.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2720         |\n",
      "|    time_elapsed         | 51444        |\n",
      "|    total_timesteps      | 5570560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019541355 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 27190        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | -3.2604887   |\n",
      "|    std                  | 50.8         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2721         |\n",
      "|    time_elapsed         | 51462        |\n",
      "|    total_timesteps      | 5572608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012966973 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.68         |\n",
      "|    n_updates            | 27200        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | -1.9899396   |\n",
      "|    std                  | 50.8         |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2722        |\n",
      "|    time_elapsed         | 51480       |\n",
      "|    total_timesteps      | 5574656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000868493 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 27210       |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | 3.3675566   |\n",
      "|    std                  | 50.8        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3010688.93\n",
      "total_reward: 2010688.93\n",
      "total_cost: 140707.61\n",
      "total_trades: 58920\n",
      "Sharpe: 0.587\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2723         |\n",
      "|    time_elapsed         | 51499        |\n",
      "|    total_timesteps      | 5576704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005839366 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.69         |\n",
      "|    n_updates            | 27220        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    reward               | -0.9518176   |\n",
      "|    std                  | 50.9         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2724        |\n",
      "|    time_elapsed         | 51517       |\n",
      "|    total_timesteps      | 5578752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002997776 |\n",
      "|    clip_fraction        | 0.00796     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 27230       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | 1.1003482   |\n",
      "|    std                  | 50.9        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2725          |\n",
      "|    time_elapsed         | 51535         |\n",
      "|    total_timesteps      | 5580800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086557725 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.355         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 22            |\n",
      "|    n_updates            | 27240         |\n",
      "|    policy_gradient_loss | -0.00211      |\n",
      "|    reward               | 1.6742761     |\n",
      "|    std                  | 51            |\n",
      "|    value_loss           | 55.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2726         |\n",
      "|    time_elapsed         | 51553        |\n",
      "|    total_timesteps      | 5582848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012269662 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.54         |\n",
      "|    n_updates            | 27250        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 0.9320992    |\n",
      "|    std                  | 51           |\n",
      "|    value_loss           | 29.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2727        |\n",
      "|    time_elapsed         | 51572       |\n",
      "|    total_timesteps      | 5584896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002566801 |\n",
      "|    clip_fraction        | 0.00137     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 27260       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | -0.63826776 |\n",
      "|    std                  | 51.1        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2728         |\n",
      "|    time_elapsed         | 51590        |\n",
      "|    total_timesteps      | 5586944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007745937 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.35         |\n",
      "|    n_updates            | 27270        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | -0.56405616  |\n",
      "|    std                  | 51           |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2729         |\n",
      "|    time_elapsed         | 51608        |\n",
      "|    total_timesteps      | 5588992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005462168 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.634        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.02         |\n",
      "|    n_updates            | 27280        |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    reward               | 3.2469811    |\n",
      "|    std                  | 51.1         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2730          |\n",
      "|    time_elapsed         | 51628         |\n",
      "|    total_timesteps      | 5591040       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016661137 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.424         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.58          |\n",
      "|    n_updates            | 27290         |\n",
      "|    policy_gradient_loss | -0.000612     |\n",
      "|    reward               | 1.2221218     |\n",
      "|    std                  | 51.2          |\n",
      "|    value_loss           | 26.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2731        |\n",
      "|    time_elapsed         | 51646       |\n",
      "|    total_timesteps      | 5593088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002078157 |\n",
      "|    clip_fraction        | 0.00181     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.89        |\n",
      "|    n_updates            | 27300       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 0.82013476  |\n",
      "|    std                  | 51.4        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 108        |\n",
      "|    iterations           | 2732       |\n",
      "|    time_elapsed         | 51664      |\n",
      "|    total_timesteps      | 5595136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00141149 |\n",
      "|    clip_fraction        | 0.000684   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -154       |\n",
      "|    explained_variance   | 0.66       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.11       |\n",
      "|    n_updates            | 27310      |\n",
      "|    policy_gradient_loss | -0.00321   |\n",
      "|    reward               | 0.53360486 |\n",
      "|    std                  | 51.5       |\n",
      "|    value_loss           | 18         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2733         |\n",
      "|    time_elapsed         | 51683        |\n",
      "|    total_timesteps      | 5597184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006284425 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 27320        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    reward               | -0.5041585   |\n",
      "|    std                  | 51.5         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2734        |\n",
      "|    time_elapsed         | 51702       |\n",
      "|    total_timesteps      | 5599232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004802963 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.7         |\n",
      "|    n_updates            | 27330       |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | 1.4823573   |\n",
      "|    std                  | 51.5        |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2735         |\n",
      "|    time_elapsed         | 51720        |\n",
      "|    total_timesteps      | 5601280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017931327 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 27340        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | -0.23315522  |\n",
      "|    std                  | 51.6         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2736          |\n",
      "|    time_elapsed         | 51739         |\n",
      "|    total_timesteps      | 5603328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095565565 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -154          |\n",
      "|    explained_variance   | 0.666         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.6           |\n",
      "|    n_updates            | 27350         |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    reward               | 2.4727495     |\n",
      "|    std                  | 51.6          |\n",
      "|    value_loss           | 27.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 3000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3034586.54\n",
      "total_reward: 2034586.54\n",
      "total_cost: 168161.39\n",
      "total_trades: 60103\n",
      "Sharpe: 0.606\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2737         |\n",
      "|    time_elapsed         | 51757        |\n",
      "|    total_timesteps      | 5605376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021775248 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.22         |\n",
      "|    n_updates            | 27360        |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    reward               | -0.10045689  |\n",
      "|    std                  | 51.7         |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2738         |\n",
      "|    time_elapsed         | 51775        |\n",
      "|    total_timesteps      | 5607424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016773604 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.83         |\n",
      "|    n_updates            | 27370        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -1.4446414   |\n",
      "|    std                  | 51.8         |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2739         |\n",
      "|    time_elapsed         | 51794        |\n",
      "|    total_timesteps      | 5609472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011788469 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -154         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.37         |\n",
      "|    n_updates            | 27380        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 9.093555     |\n",
      "|    std                  | 51.8         |\n",
      "|    value_loss           | 21.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2740        |\n",
      "|    time_elapsed         | 51812       |\n",
      "|    total_timesteps      | 5611520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002052376 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -154        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 27390       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | 0.61528915  |\n",
      "|    std                  | 51.9        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2741         |\n",
      "|    time_elapsed         | 51831        |\n",
      "|    total_timesteps      | 5613568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033933495 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.91         |\n",
      "|    n_updates            | 27400        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    reward               | -0.022152077 |\n",
      "|    std                  | 52           |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2742         |\n",
      "|    time_elapsed         | 51849        |\n",
      "|    total_timesteps      | 5615616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014599306 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.54         |\n",
      "|    n_updates            | 27410        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    reward               | 0.4904709    |\n",
      "|    std                  | 51.9         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2743          |\n",
      "|    time_elapsed         | 51867         |\n",
      "|    total_timesteps      | 5617664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071554387 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.519         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.8           |\n",
      "|    n_updates            | 27420         |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    reward               | -5.0504146    |\n",
      "|    std                  | 52            |\n",
      "|    value_loss           | 23.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2744         |\n",
      "|    time_elapsed         | 51886        |\n",
      "|    total_timesteps      | 5619712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018282344 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.72         |\n",
      "|    n_updates            | 27430        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 1.0729321    |\n",
      "|    std                  | 52.1         |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2745         |\n",
      "|    time_elapsed         | 51904        |\n",
      "|    total_timesteps      | 5621760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014557026 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.27         |\n",
      "|    n_updates            | 27440        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 0.26848528   |\n",
      "|    std                  | 52.1         |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2746         |\n",
      "|    time_elapsed         | 51922        |\n",
      "|    total_timesteps      | 5623808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031473022 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.23         |\n",
      "|    n_updates            | 27450        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 0.9463703    |\n",
      "|    std                  | 52.2         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2747          |\n",
      "|    time_elapsed         | 51941         |\n",
      "|    total_timesteps      | 5625856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077667146 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.621         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.5           |\n",
      "|    n_updates            | 27460         |\n",
      "|    policy_gradient_loss | -0.00238      |\n",
      "|    reward               | 0.045820426   |\n",
      "|    std                  | 52.3          |\n",
      "|    value_loss           | 22.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2748         |\n",
      "|    time_elapsed         | 51959        |\n",
      "|    total_timesteps      | 5627904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025716436 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.29         |\n",
      "|    n_updates            | 27470        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | 0.4179694    |\n",
      "|    std                  | 52.4         |\n",
      "|    value_loss           | 17.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2749          |\n",
      "|    time_elapsed         | 51977         |\n",
      "|    total_timesteps      | 5629952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064208877 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.549         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.1          |\n",
      "|    n_updates            | 27480         |\n",
      "|    policy_gradient_loss | -0.00263      |\n",
      "|    reward               | -0.31131223   |\n",
      "|    std                  | 52.4          |\n",
      "|    value_loss           | 31.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2750          |\n",
      "|    time_elapsed         | 51996         |\n",
      "|    total_timesteps      | 5632000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091182813 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.47          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 27490         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | -2.021176     |\n",
      "|    std                  | 52.4          |\n",
      "|    value_loss           | 24.9          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 3010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3503698.55\n",
      "total_reward: 2503698.55\n",
      "total_cost: 428054.35\n",
      "total_trades: 73272\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2751        |\n",
      "|    time_elapsed         | 52015       |\n",
      "|    total_timesteps      | 5634048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003579859 |\n",
      "|    clip_fraction        | 0.00859     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.62        |\n",
      "|    n_updates            | 27500       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | -0.1072481  |\n",
      "|    std                  | 52.6        |\n",
      "|    value_loss           | 9.63        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2752         |\n",
      "|    time_elapsed         | 52034        |\n",
      "|    total_timesteps      | 5636096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016181903 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.0888       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.6          |\n",
      "|    n_updates            | 27510        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 1.0047907    |\n",
      "|    std                  | 52.6         |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2753         |\n",
      "|    time_elapsed         | 52052        |\n",
      "|    total_timesteps      | 5638144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018002925 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 27520        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 2.651244     |\n",
      "|    std                  | 52.6         |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2754         |\n",
      "|    time_elapsed         | 52070        |\n",
      "|    total_timesteps      | 5640192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013166536 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 27530        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 0.42427298   |\n",
      "|    std                  | 52.7         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2755         |\n",
      "|    time_elapsed         | 52089        |\n",
      "|    total_timesteps      | 5642240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015511902 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.52         |\n",
      "|    n_updates            | 27540        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | -0.40194398  |\n",
      "|    std                  | 52.8         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2756         |\n",
      "|    time_elapsed         | 52107        |\n",
      "|    total_timesteps      | 5644288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015710411 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.89         |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | 2.1400235    |\n",
      "|    std                  | 52.8         |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2757        |\n",
      "|    time_elapsed         | 52126       |\n",
      "|    total_timesteps      | 5646336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002786642 |\n",
      "|    clip_fraction        | 0.00244     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 27560       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 0.049263965 |\n",
      "|    std                  | 52.8        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2758         |\n",
      "|    time_elapsed         | 52144        |\n",
      "|    total_timesteps      | 5648384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026635865 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.22         |\n",
      "|    n_updates            | 27570        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | -0.9581175   |\n",
      "|    std                  | 52.9         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2759        |\n",
      "|    time_elapsed         | 52163       |\n",
      "|    total_timesteps      | 5650432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000945139 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -155        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.53        |\n",
      "|    n_updates            | 27580       |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    reward               | -0.6892676  |\n",
      "|    std                  | 52.9        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2760         |\n",
      "|    time_elapsed         | 52181        |\n",
      "|    total_timesteps      | 5652480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014810711 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 27590        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | -0.929084    |\n",
      "|    std                  | 53.1         |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2761         |\n",
      "|    time_elapsed         | 52199        |\n",
      "|    total_timesteps      | 5654528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014798037 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.0391       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.14         |\n",
      "|    n_updates            | 27600        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 0.46138164   |\n",
      "|    std                  | 53.2         |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2762         |\n",
      "|    time_elapsed         | 52217        |\n",
      "|    total_timesteps      | 5656576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014241973 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.8          |\n",
      "|    n_updates            | 27610        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    reward               | 1.4433542    |\n",
      "|    std                  | 53.2         |\n",
      "|    value_loss           | 15.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2763         |\n",
      "|    time_elapsed         | 52235        |\n",
      "|    total_timesteps      | 5658624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015404907 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 27620        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | -8.49104     |\n",
      "|    std                  | 53.3         |\n",
      "|    value_loss           | 22.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2764          |\n",
      "|    time_elapsed         | 52254         |\n",
      "|    total_timesteps      | 5660672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024734598 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -155          |\n",
      "|    explained_variance   | 0.494         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.43          |\n",
      "|    n_updates            | 27630         |\n",
      "|    policy_gradient_loss | -0.00117      |\n",
      "|    reward               | -0.3535382    |\n",
      "|    std                  | 53.3          |\n",
      "|    value_loss           | 28.5          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 3020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3100116.53\n",
      "total_reward: 2100116.53\n",
      "total_cost: 257177.26\n",
      "total_trades: 66003\n",
      "Sharpe: 0.628\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2765         |\n",
      "|    time_elapsed         | 52272        |\n",
      "|    total_timesteps      | 5662720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022376399 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.24         |\n",
      "|    n_updates            | 27640        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | -0.8994347   |\n",
      "|    std                  | 53.4         |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2766         |\n",
      "|    time_elapsed         | 52290        |\n",
      "|    total_timesteps      | 5664768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012209001 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.86         |\n",
      "|    n_updates            | 27650        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -2.9553378   |\n",
      "|    std                  | 53.5         |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2767         |\n",
      "|    time_elapsed         | 52309        |\n",
      "|    total_timesteps      | 5666816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011925161 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -155         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 27660        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 5.7485113    |\n",
      "|    std                  | 53.6         |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2768         |\n",
      "|    time_elapsed         | 52328        |\n",
      "|    total_timesteps      | 5668864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025778108 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.63         |\n",
      "|    n_updates            | 27670        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | 4.146992     |\n",
      "|    std                  | 53.7         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2769         |\n",
      "|    time_elapsed         | 52346        |\n",
      "|    total_timesteps      | 5670912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006616507 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.74         |\n",
      "|    n_updates            | 27680        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | 1.4185278    |\n",
      "|    std                  | 53.7         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2770         |\n",
      "|    time_elapsed         | 52364        |\n",
      "|    total_timesteps      | 5672960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014591485 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.6          |\n",
      "|    n_updates            | 27690        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | 0.9902151    |\n",
      "|    std                  | 53.8         |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2771         |\n",
      "|    time_elapsed         | 52383        |\n",
      "|    total_timesteps      | 5675008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017695131 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.26         |\n",
      "|    n_updates            | 27700        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 0.06628172   |\n",
      "|    std                  | 53.9         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2772         |\n",
      "|    time_elapsed         | 52401        |\n",
      "|    total_timesteps      | 5677056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018660882 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.31         |\n",
      "|    n_updates            | 27710        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | 1.1395136    |\n",
      "|    std                  | 53.9         |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2773         |\n",
      "|    time_elapsed         | 52420        |\n",
      "|    total_timesteps      | 5679104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007380877 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.37         |\n",
      "|    n_updates            | 27720        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | -0.10649326  |\n",
      "|    std                  | 53.9         |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2774         |\n",
      "|    time_elapsed         | 52438        |\n",
      "|    total_timesteps      | 5681152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021402184 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 27730        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 0.11260111   |\n",
      "|    std                  | 54           |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2775         |\n",
      "|    time_elapsed         | 52456        |\n",
      "|    total_timesteps      | 5683200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023973153 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.741        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.32         |\n",
      "|    n_updates            | 27740        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | -0.11554106  |\n",
      "|    std                  | 54.2         |\n",
      "|    value_loss           | 12.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2776         |\n",
      "|    time_elapsed         | 52474        |\n",
      "|    total_timesteps      | 5685248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008499888 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.68         |\n",
      "|    n_updates            | 27750        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | 0.046462074  |\n",
      "|    std                  | 54.3         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2777          |\n",
      "|    time_elapsed         | 52492         |\n",
      "|    total_timesteps      | 5687296       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030512447 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.694         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.67          |\n",
      "|    n_updates            | 27760         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | 0.30091345    |\n",
      "|    std                  | 54.3          |\n",
      "|    value_loss           | 24.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2778         |\n",
      "|    time_elapsed         | 52511        |\n",
      "|    total_timesteps      | 5689344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008080408 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.0924       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.18         |\n",
      "|    n_updates            | 27770        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | -0.59835833  |\n",
      "|    std                  | 54.4         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 3030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3366591.30\n",
      "total_reward: 2366591.30\n",
      "total_cost: 221107.19\n",
      "total_trades: 63870\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2779         |\n",
      "|    time_elapsed         | 52529        |\n",
      "|    total_timesteps      | 5691392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032822576 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.63         |\n",
      "|    n_updates            | 27780        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | -0.34200963  |\n",
      "|    std                  | 54.5         |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2780          |\n",
      "|    time_elapsed         | 52547         |\n",
      "|    total_timesteps      | 5693440       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069168943 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.458         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 27790         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | 0.17553115    |\n",
      "|    std                  | 54.6          |\n",
      "|    value_loss           | 30            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2781         |\n",
      "|    time_elapsed         | 52565        |\n",
      "|    total_timesteps      | 5695488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011797589 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 27800        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    reward               | -0.33126286  |\n",
      "|    std                  | 54.6         |\n",
      "|    value_loss           | 28.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2782         |\n",
      "|    time_elapsed         | 52584        |\n",
      "|    total_timesteps      | 5697536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013753667 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.01         |\n",
      "|    n_updates            | 27810        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | 0.2726043    |\n",
      "|    std                  | 54.7         |\n",
      "|    value_loss           | 13.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2783         |\n",
      "|    time_elapsed         | 52602        |\n",
      "|    total_timesteps      | 5699584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031165807 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.58         |\n",
      "|    n_updates            | 27820        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | -2.460675    |\n",
      "|    std                  | 54.7         |\n",
      "|    value_loss           | 19.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2784        |\n",
      "|    time_elapsed         | 52621       |\n",
      "|    total_timesteps      | 5701632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001739984 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.48        |\n",
      "|    n_updates            | 27830       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | 20.359997   |\n",
      "|    std                  | 54.7        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2785         |\n",
      "|    time_elapsed         | 52639        |\n",
      "|    total_timesteps      | 5703680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016732267 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.45         |\n",
      "|    n_updates            | 27840        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -0.274091    |\n",
      "|    std                  | 54.8         |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2786          |\n",
      "|    time_elapsed         | 52657         |\n",
      "|    total_timesteps      | 5705728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058119453 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -156          |\n",
      "|    explained_variance   | 0.501         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.4          |\n",
      "|    n_updates            | 27850         |\n",
      "|    policy_gradient_loss | -0.0019       |\n",
      "|    reward               | 2.4692924     |\n",
      "|    std                  | 54.9          |\n",
      "|    value_loss           | 18.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2787         |\n",
      "|    time_elapsed         | 52675        |\n",
      "|    total_timesteps      | 5707776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014703094 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.03         |\n",
      "|    n_updates            | 27860        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 1.6093042    |\n",
      "|    std                  | 55           |\n",
      "|    value_loss           | 13.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2788         |\n",
      "|    time_elapsed         | 52694        |\n",
      "|    total_timesteps      | 5709824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017916672 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 27870        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | -3.9421206   |\n",
      "|    std                  | 55.1         |\n",
      "|    value_loss           | 29.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2789        |\n",
      "|    time_elapsed         | 52712       |\n",
      "|    total_timesteps      | 5711872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002206514 |\n",
      "|    clip_fraction        | 0.00225     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -156        |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 27880       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    reward               | 1.6381612   |\n",
      "|    std                  | 55.3        |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2790         |\n",
      "|    time_elapsed         | 52730        |\n",
      "|    total_timesteps      | 5713920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001158586  |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 27890        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | -0.035815768 |\n",
      "|    std                  | 55.4         |\n",
      "|    value_loss           | 29.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2791         |\n",
      "|    time_elapsed         | 52748        |\n",
      "|    total_timesteps      | 5715968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053218175 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 27900        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    reward               | 0.39917365   |\n",
      "|    std                  | 55.6         |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2792         |\n",
      "|    time_elapsed         | 52767        |\n",
      "|    total_timesteps      | 5718016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019481052 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -156         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.28         |\n",
      "|    n_updates            | 27910        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 2.1079159    |\n",
      "|    std                  | 55.7         |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 3040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2594821.06\n",
      "total_reward: 1594821.06\n",
      "total_cost: 175626.08\n",
      "total_trades: 60900\n",
      "Sharpe: 0.522\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2793         |\n",
      "|    time_elapsed         | 52785        |\n",
      "|    total_timesteps      | 5720064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022288223 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.74         |\n",
      "|    n_updates            | 27920        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | 0.2558887    |\n",
      "|    std                  | 55.7         |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2794         |\n",
      "|    time_elapsed         | 52803        |\n",
      "|    total_timesteps      | 5722112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022558384 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.64         |\n",
      "|    n_updates            | 27930        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -1.2512211   |\n",
      "|    std                  | 55.9         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2795         |\n",
      "|    time_elapsed         | 52822        |\n",
      "|    total_timesteps      | 5724160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010951657 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 27940        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 0.40362358   |\n",
      "|    std                  | 56           |\n",
      "|    value_loss           | 33.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2796         |\n",
      "|    time_elapsed         | 52840        |\n",
      "|    total_timesteps      | 5726208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020123355 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | -0.0232      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 27950        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | -0.24300212  |\n",
      "|    std                  | 56.1         |\n",
      "|    value_loss           | 27.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2797          |\n",
      "|    time_elapsed         | 52859         |\n",
      "|    total_timesteps      | 5728256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046704747 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.434         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.9          |\n",
      "|    n_updates            | 27960         |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    reward               | -0.071418315  |\n",
      "|    std                  | 56.1          |\n",
      "|    value_loss           | 35.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2798        |\n",
      "|    time_elapsed         | 52878       |\n",
      "|    total_timesteps      | 5730304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000358278 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 27970       |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    reward               | 0.72287184  |\n",
      "|    std                  | 56.2        |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2799         |\n",
      "|    time_elapsed         | 52897        |\n",
      "|    total_timesteps      | 5732352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035947785 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.21         |\n",
      "|    n_updates            | 27980        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | 1.1026201    |\n",
      "|    std                  | 56.4         |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2800         |\n",
      "|    time_elapsed         | 52915        |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012162245 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.18         |\n",
      "|    n_updates            | 27990        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 1.5537299    |\n",
      "|    std                  | 56.4         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2801          |\n",
      "|    time_elapsed         | 52934         |\n",
      "|    total_timesteps      | 5736448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060558674 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.71          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.62          |\n",
      "|    n_updates            | 28000         |\n",
      "|    policy_gradient_loss | -0.00268      |\n",
      "|    reward               | 0.23394777    |\n",
      "|    std                  | 56.6          |\n",
      "|    value_loss           | 25.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2802         |\n",
      "|    time_elapsed         | 52952        |\n",
      "|    total_timesteps      | 5738496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014853202 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 28010        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -2.547545    |\n",
      "|    std                  | 56.6         |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2803         |\n",
      "|    time_elapsed         | 52971        |\n",
      "|    total_timesteps      | 5740544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016215433 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.19         |\n",
      "|    n_updates            | 28020        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | -1.6043591   |\n",
      "|    std                  | 56.7         |\n",
      "|    value_loss           | 13.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2804         |\n",
      "|    time_elapsed         | 52990        |\n",
      "|    total_timesteps      | 5742592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011468824 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.29         |\n",
      "|    n_updates            | 28030        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -5.652222    |\n",
      "|    std                  | 56.8         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2805         |\n",
      "|    time_elapsed         | 53008        |\n",
      "|    total_timesteps      | 5744640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009395896 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.74         |\n",
      "|    n_updates            | 28040        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 0.9778787    |\n",
      "|    std                  | 56.8         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2806         |\n",
      "|    time_elapsed         | 53027        |\n",
      "|    total_timesteps      | 5746688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014293578 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.65         |\n",
      "|    n_updates            | 28050        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | -1.6251724   |\n",
      "|    std                  | 56.9         |\n",
      "|    value_loss           | 10.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 3050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3286904.08\n",
      "total_reward: 2286904.08\n",
      "total_cost: 251457.17\n",
      "total_trades: 66128\n",
      "Sharpe: 0.647\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2807         |\n",
      "|    time_elapsed         | 53046        |\n",
      "|    total_timesteps      | 5748736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017778818 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.44         |\n",
      "|    n_updates            | 28060        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | -1.274026    |\n",
      "|    std                  | 57.1         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2808          |\n",
      "|    time_elapsed         | 53064         |\n",
      "|    total_timesteps      | 5750784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072968024 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -157          |\n",
      "|    explained_variance   | 0.555         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.5          |\n",
      "|    n_updates            | 28070         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    reward               | 0.24219167    |\n",
      "|    std                  | 57.2          |\n",
      "|    value_loss           | 25.8          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2809        |\n",
      "|    time_elapsed         | 53083       |\n",
      "|    total_timesteps      | 5752832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002334944 |\n",
      "|    clip_fraction        | 0.00166     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -157        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.17        |\n",
      "|    n_updates            | 28080       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -0.71837556 |\n",
      "|    std                  | 57.3        |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2810         |\n",
      "|    time_elapsed         | 53102        |\n",
      "|    total_timesteps      | 5754880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012510723 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.89         |\n",
      "|    n_updates            | 28090        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    reward               | -2.0163941   |\n",
      "|    std                  | 57.4         |\n",
      "|    value_loss           | 15.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2811         |\n",
      "|    time_elapsed         | 53120        |\n",
      "|    total_timesteps      | 5756928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009577244 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -157         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 28100        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | 3.3824098    |\n",
      "|    std                  | 57.5         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2812         |\n",
      "|    time_elapsed         | 53139        |\n",
      "|    total_timesteps      | 5758976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010971026 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.85         |\n",
      "|    n_updates            | 28110        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -0.644022    |\n",
      "|    std                  | 57.7         |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2813         |\n",
      "|    time_elapsed         | 53158        |\n",
      "|    total_timesteps      | 5761024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016291556 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.2          |\n",
      "|    n_updates            | 28120        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 1.8551121    |\n",
      "|    std                  | 57.9         |\n",
      "|    value_loss           | 14.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2814         |\n",
      "|    time_elapsed         | 53177        |\n",
      "|    total_timesteps      | 5763072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008702355 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.31         |\n",
      "|    n_updates            | 28130        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 0.25085583   |\n",
      "|    std                  | 57.9         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2815         |\n",
      "|    time_elapsed         | 53195        |\n",
      "|    total_timesteps      | 5765120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005324322 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 28140        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | -1.6176198   |\n",
      "|    std                  | 57.9         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2816         |\n",
      "|    time_elapsed         | 53214        |\n",
      "|    total_timesteps      | 5767168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027399785 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.32         |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    reward               | 0.25923187   |\n",
      "|    std                  | 58           |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2817          |\n",
      "|    time_elapsed         | 53232         |\n",
      "|    total_timesteps      | 5769216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.000770182   |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.671         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.16          |\n",
      "|    n_updates            | 28160         |\n",
      "|    policy_gradient_loss | -0.00219      |\n",
      "|    reward               | -0.0039024227 |\n",
      "|    std                  | 58.1          |\n",
      "|    value_loss           | 17.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2818         |\n",
      "|    time_elapsed         | 53250        |\n",
      "|    total_timesteps      | 5771264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016237232 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.17         |\n",
      "|    n_updates            | 28170        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 4.588143     |\n",
      "|    std                  | 58.1         |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2819        |\n",
      "|    time_elapsed         | 53269       |\n",
      "|    total_timesteps      | 5773312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001122124 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.13        |\n",
      "|    n_updates            | 28180       |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | 1.1901791   |\n",
      "|    std                  | 58.2        |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2820         |\n",
      "|    time_elapsed         | 53287        |\n",
      "|    total_timesteps      | 5775360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013773317 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.5          |\n",
      "|    n_updates            | 28190        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | 2.0959158    |\n",
      "|    std                  | 58.4         |\n",
      "|    value_loss           | 12.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 3060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2895653.61\n",
      "total_reward: 1895653.61\n",
      "total_cost: 212128.55\n",
      "total_trades: 63728\n",
      "Sharpe: 0.595\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2821          |\n",
      "|    time_elapsed         | 53305         |\n",
      "|    total_timesteps      | 5777408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064267975 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.664         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.68          |\n",
      "|    n_updates            | 28200         |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    reward               | 1.6581141     |\n",
      "|    std                  | 58.4          |\n",
      "|    value_loss           | 17.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2822          |\n",
      "|    time_elapsed         | 53323         |\n",
      "|    total_timesteps      | 5779456       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081242144 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.742         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.71          |\n",
      "|    n_updates            | 28210         |\n",
      "|    policy_gradient_loss | -0.00268      |\n",
      "|    reward               | 1.2087873     |\n",
      "|    std                  | 58.5          |\n",
      "|    value_loss           | 20.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2823         |\n",
      "|    time_elapsed         | 53342        |\n",
      "|    total_timesteps      | 5781504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030735396 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.66         |\n",
      "|    n_updates            | 28220        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -1.4796364   |\n",
      "|    std                  | 58.7         |\n",
      "|    value_loss           | 12.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2824          |\n",
      "|    time_elapsed         | 53360         |\n",
      "|    total_timesteps      | 5783552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042272639 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.645         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.5           |\n",
      "|    n_updates            | 28230         |\n",
      "|    policy_gradient_loss | -0.00174      |\n",
      "|    reward               | 0.75886667    |\n",
      "|    std                  | 58.8          |\n",
      "|    value_loss           | 22.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2825          |\n",
      "|    time_elapsed         | 53379         |\n",
      "|    total_timesteps      | 5785600       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013293116 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.577         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.1          |\n",
      "|    n_updates            | 28240         |\n",
      "|    policy_gradient_loss | -0.000676     |\n",
      "|    reward               | -0.20224799   |\n",
      "|    std                  | 58.8          |\n",
      "|    value_loss           | 36.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2826          |\n",
      "|    time_elapsed         | 53397         |\n",
      "|    total_timesteps      | 5787648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021363661 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | -0.0623       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.5          |\n",
      "|    n_updates            | 28250         |\n",
      "|    policy_gradient_loss | -0.00118      |\n",
      "|    reward               | 0.89412034    |\n",
      "|    std                  | 58.8          |\n",
      "|    value_loss           | 25.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2827         |\n",
      "|    time_elapsed         | 53416        |\n",
      "|    total_timesteps      | 5789696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031018332 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.02         |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    reward               | -0.078911334 |\n",
      "|    std                  | 58.9         |\n",
      "|    value_loss           | 12.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2828        |\n",
      "|    time_elapsed         | 53435       |\n",
      "|    total_timesteps      | 5791744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000982963 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.13        |\n",
      "|    n_updates            | 28270       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | 3.7498028   |\n",
      "|    std                  | 59.1        |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2829          |\n",
      "|    time_elapsed         | 53453         |\n",
      "|    total_timesteps      | 5793792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063442363 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -158          |\n",
      "|    explained_variance   | 0.526         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14            |\n",
      "|    n_updates            | 28280         |\n",
      "|    policy_gradient_loss | -0.00261      |\n",
      "|    reward               | 0.5005127     |\n",
      "|    std                  | 59.2          |\n",
      "|    value_loss           | 30.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2830         |\n",
      "|    time_elapsed         | 53472        |\n",
      "|    total_timesteps      | 5795840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017046521 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.83         |\n",
      "|    n_updates            | 28290        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | -0.7784274   |\n",
      "|    std                  | 59.2         |\n",
      "|    value_loss           | 12           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2831         |\n",
      "|    time_elapsed         | 53490        |\n",
      "|    total_timesteps      | 5797888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010741117 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.26         |\n",
      "|    n_updates            | 28300        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | -0.122469485 |\n",
      "|    std                  | 59.4         |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2832        |\n",
      "|    time_elapsed         | 53508       |\n",
      "|    total_timesteps      | 5799936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002919873 |\n",
      "|    clip_fraction        | 0.0042      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -158        |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.88        |\n",
      "|    n_updates            | 28310       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | -0.45878664 |\n",
      "|    std                  | 59.5        |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2833         |\n",
      "|    time_elapsed         | 53526        |\n",
      "|    total_timesteps      | 5801984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009738527 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.0756       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.22         |\n",
      "|    n_updates            | 28320        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | 1.3225945    |\n",
      "|    std                  | 59.5         |\n",
      "|    value_loss           | 24.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2834         |\n",
      "|    time_elapsed         | 53545        |\n",
      "|    total_timesteps      | 5804032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008434669 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.29         |\n",
      "|    n_updates            | 28330        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | -1.2841653   |\n",
      "|    std                  | 59.5         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2835         |\n",
      "|    time_elapsed         | 53563        |\n",
      "|    total_timesteps      | 5806080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012575359 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -158         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.88         |\n",
      "|    n_updates            | 28340        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | -0.09738523  |\n",
      "|    std                  | 59.6         |\n",
      "|    value_loss           | 16.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 3070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3005835.88\n",
      "total_reward: 2005835.88\n",
      "total_cost: 194022.46\n",
      "total_trades: 62023\n",
      "Sharpe: 0.580\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2836        |\n",
      "|    time_elapsed         | 53581       |\n",
      "|    total_timesteps      | 5808128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001216783 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.71        |\n",
      "|    n_updates            | 28350       |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    reward               | -0.6117487  |\n",
      "|    std                  | 59.7        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2837          |\n",
      "|    time_elapsed         | 53600         |\n",
      "|    total_timesteps      | 5810176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053967745 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.55          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.58          |\n",
      "|    n_updates            | 28360         |\n",
      "|    policy_gradient_loss | -0.0017       |\n",
      "|    reward               | 0.4343517     |\n",
      "|    std                  | 59.7          |\n",
      "|    value_loss           | 14.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2838         |\n",
      "|    time_elapsed         | 53618        |\n",
      "|    total_timesteps      | 5812224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020073853 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.82         |\n",
      "|    n_updates            | 28370        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | -0.14490943  |\n",
      "|    std                  | 59.8         |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2839         |\n",
      "|    time_elapsed         | 53636        |\n",
      "|    total_timesteps      | 5814272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010938171 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.25         |\n",
      "|    n_updates            | 28380        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | 21.096846    |\n",
      "|    std                  | 59.8         |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2840         |\n",
      "|    time_elapsed         | 53654        |\n",
      "|    total_timesteps      | 5816320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037003825 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.1          |\n",
      "|    n_updates            | 28390        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | -0.54229885  |\n",
      "|    std                  | 59.9         |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2841         |\n",
      "|    time_elapsed         | 53672        |\n",
      "|    total_timesteps      | 5818368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009623853 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.6          |\n",
      "|    n_updates            | 28400        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | 1.745495     |\n",
      "|    std                  | 60           |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2842         |\n",
      "|    time_elapsed         | 53690        |\n",
      "|    total_timesteps      | 5820416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003158301 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 28410        |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    reward               | 0.9370832    |\n",
      "|    std                  | 60           |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2843        |\n",
      "|    time_elapsed         | 53708       |\n",
      "|    total_timesteps      | 5822464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001531493 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.56        |\n",
      "|    n_updates            | 28420       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | -0.49014956 |\n",
      "|    std                  | 60.2        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2844         |\n",
      "|    time_elapsed         | 53727        |\n",
      "|    total_timesteps      | 5824512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028035454 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.85         |\n",
      "|    n_updates            | 28430        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | -0.6802352   |\n",
      "|    std                  | 60.3         |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2845          |\n",
      "|    time_elapsed         | 53745         |\n",
      "|    total_timesteps      | 5826560       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028917025 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.511         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.2          |\n",
      "|    n_updates            | 28440         |\n",
      "|    policy_gradient_loss | -0.00119      |\n",
      "|    reward               | -1.1590259    |\n",
      "|    std                  | 60.3          |\n",
      "|    value_loss           | 25.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2846          |\n",
      "|    time_elapsed         | 53763         |\n",
      "|    total_timesteps      | 5828608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023513488 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.507         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.2          |\n",
      "|    n_updates            | 28450         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    reward               | -2.559151     |\n",
      "|    std                  | 60.3          |\n",
      "|    value_loss           | 31.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2847        |\n",
      "|    time_elapsed         | 53782       |\n",
      "|    total_timesteps      | 5830656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002733292 |\n",
      "|    clip_fraction        | 0.00337     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -159        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.58        |\n",
      "|    n_updates            | 28460       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | 0.29076025  |\n",
      "|    std                  | 60.7        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2848          |\n",
      "|    time_elapsed         | 53799         |\n",
      "|    total_timesteps      | 5832704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048461766 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.694         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.75          |\n",
      "|    n_updates            | 28470         |\n",
      "|    policy_gradient_loss | -0.00192      |\n",
      "|    reward               | 0.2909708     |\n",
      "|    std                  | 60.8          |\n",
      "|    value_loss           | 19.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2849          |\n",
      "|    time_elapsed         | 53817         |\n",
      "|    total_timesteps      | 5834752       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064427324 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.739         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.49          |\n",
      "|    n_updates            | 28480         |\n",
      "|    policy_gradient_loss | -0.00278      |\n",
      "|    reward               | 3.7189977     |\n",
      "|    std                  | 60.9          |\n",
      "|    value_loss           | 22            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 3080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2292981.62\n",
      "total_reward: 1292981.62\n",
      "total_cost: 118825.88\n",
      "total_trades: 56102\n",
      "Sharpe: 0.471\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2850         |\n",
      "|    time_elapsed         | 53836        |\n",
      "|    total_timesteps      | 5836800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009441428 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.88         |\n",
      "|    n_updates            | 28490        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 0.9811631    |\n",
      "|    std                  | 61.1         |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2851         |\n",
      "|    time_elapsed         | 53854        |\n",
      "|    total_timesteps      | 5838848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015534176 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.77         |\n",
      "|    n_updates            | 28500        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -0.13890058  |\n",
      "|    std                  | 61.2         |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2852          |\n",
      "|    time_elapsed         | 53871         |\n",
      "|    total_timesteps      | 5840896       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038165046 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.684         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.9          |\n",
      "|    n_updates            | 28510         |\n",
      "|    policy_gradient_loss | -0.00153      |\n",
      "|    reward               | -10.908232    |\n",
      "|    std                  | 61.2          |\n",
      "|    value_loss           | 19.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2853         |\n",
      "|    time_elapsed         | 53890        |\n",
      "|    total_timesteps      | 5842944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005764663 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.48         |\n",
      "|    n_updates            | 28520        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 0.0331828    |\n",
      "|    std                  | 61.2         |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2854         |\n",
      "|    time_elapsed         | 53908        |\n",
      "|    total_timesteps      | 5844992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026189538 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.24         |\n",
      "|    n_updates            | 28530        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    reward               | 0.08557753   |\n",
      "|    std                  | 61.4         |\n",
      "|    value_loss           | 10           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2855          |\n",
      "|    time_elapsed         | 53926         |\n",
      "|    total_timesteps      | 5847040       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066208193 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.686         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.7           |\n",
      "|    n_updates            | 28540         |\n",
      "|    policy_gradient_loss | -0.00238      |\n",
      "|    reward               | 1.0661594     |\n",
      "|    std                  | 61.4          |\n",
      "|    value_loss           | 16.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2856         |\n",
      "|    time_elapsed         | 53944        |\n",
      "|    total_timesteps      | 5849088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011290761 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.761        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.23         |\n",
      "|    n_updates            | 28550        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | 1.540933     |\n",
      "|    std                  | 61.5         |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2857          |\n",
      "|    time_elapsed         | 53963         |\n",
      "|    total_timesteps      | 5851136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069692434 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -159          |\n",
      "|    explained_variance   | 0.471         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.65          |\n",
      "|    n_updates            | 28560         |\n",
      "|    policy_gradient_loss | -0.00208      |\n",
      "|    reward               | -1.6126795    |\n",
      "|    std                  | 61.6          |\n",
      "|    value_loss           | 19.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2858         |\n",
      "|    time_elapsed         | 53981        |\n",
      "|    total_timesteps      | 5853184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003072924 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.52         |\n",
      "|    n_updates            | 28570        |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    reward               | -0.23841456  |\n",
      "|    std                  | 61.6         |\n",
      "|    value_loss           | 16.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2859         |\n",
      "|    time_elapsed         | 53999        |\n",
      "|    total_timesteps      | 5855232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015942848 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -159         |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.56         |\n",
      "|    n_updates            | 28580        |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | -4.0863547   |\n",
      "|    std                  | 61.7         |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2860         |\n",
      "|    time_elapsed         | 54017        |\n",
      "|    total_timesteps      | 5857280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025081383 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.15         |\n",
      "|    n_updates            | 28590        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | 2.239045     |\n",
      "|    std                  | 61.9         |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2861         |\n",
      "|    time_elapsed         | 54036        |\n",
      "|    total_timesteps      | 5859328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024575654 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.14         |\n",
      "|    n_updates            | 28600        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 0.046335045  |\n",
      "|    std                  | 61.9         |\n",
      "|    value_loss           | 11.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2862         |\n",
      "|    time_elapsed         | 54054        |\n",
      "|    total_timesteps      | 5861376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011203424 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.8          |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 0.13819696   |\n",
      "|    std                  | 62           |\n",
      "|    value_loss           | 19.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2863         |\n",
      "|    time_elapsed         | 54072        |\n",
      "|    total_timesteps      | 5863424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008516463 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 28620        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -0.82120156  |\n",
      "|    std                  | 62.1         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 3090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2534121.38\n",
      "total_reward: 1534121.38\n",
      "total_cost: 145083.10\n",
      "total_trades: 58474\n",
      "Sharpe: 0.523\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2864         |\n",
      "|    time_elapsed         | 54089        |\n",
      "|    total_timesteps      | 5865472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013417521 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.66         |\n",
      "|    n_updates            | 28630        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 0.049106732  |\n",
      "|    std                  | 62.2         |\n",
      "|    value_loss           | 11.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2865         |\n",
      "|    time_elapsed         | 54107        |\n",
      "|    total_timesteps      | 5867520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010784911 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.25         |\n",
      "|    n_updates            | 28640        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 0.14588858   |\n",
      "|    std                  | 62.4         |\n",
      "|    value_loss           | 14.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2866          |\n",
      "|    time_elapsed         | 54124         |\n",
      "|    total_timesteps      | 5869568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026932824 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.669         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.98          |\n",
      "|    n_updates            | 28650         |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    reward               | 1.3480779     |\n",
      "|    std                  | 62.4          |\n",
      "|    value_loss           | 24.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2867         |\n",
      "|    time_elapsed         | 54142        |\n",
      "|    total_timesteps      | 5871616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012106879 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.32         |\n",
      "|    n_updates            | 28660        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | -1.4016633   |\n",
      "|    std                  | 62.5         |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2868         |\n",
      "|    time_elapsed         | 54161        |\n",
      "|    total_timesteps      | 5873664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029323897 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.3          |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | -1.9758204   |\n",
      "|    std                  | 62.7         |\n",
      "|    value_loss           | 12           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2869         |\n",
      "|    time_elapsed         | 54179        |\n",
      "|    total_timesteps      | 5875712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008913486 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.38         |\n",
      "|    n_updates            | 28680        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -0.21310492  |\n",
      "|    std                  | 62.8         |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2870         |\n",
      "|    time_elapsed         | 54198        |\n",
      "|    total_timesteps      | 5877760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010122706 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 28690        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | 0.54291844   |\n",
      "|    std                  | 62.9         |\n",
      "|    value_loss           | 16.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2871         |\n",
      "|    time_elapsed         | 54215        |\n",
      "|    total_timesteps      | 5879808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043458776 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.53         |\n",
      "|    n_updates            | 28700        |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    reward               | 1.8806256    |\n",
      "|    std                  | 63.2         |\n",
      "|    value_loss           | 12.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2872          |\n",
      "|    time_elapsed         | 54233         |\n",
      "|    total_timesteps      | 5881856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041387966 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -160          |\n",
      "|    explained_variance   | 0.326         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 37.6          |\n",
      "|    n_updates            | 28710         |\n",
      "|    policy_gradient_loss | -0.0017       |\n",
      "|    reward               | 0.575657      |\n",
      "|    std                  | 63.3          |\n",
      "|    value_loss           | 45.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2873         |\n",
      "|    time_elapsed         | 54252        |\n",
      "|    total_timesteps      | 5883904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005466603 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.79         |\n",
      "|    n_updates            | 28720        |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    reward               | 3.366717     |\n",
      "|    std                  | 63.4         |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2874         |\n",
      "|    time_elapsed         | 54270        |\n",
      "|    total_timesteps      | 5885952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012823052 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.58         |\n",
      "|    n_updates            | 28730        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | -2.2572684   |\n",
      "|    std                  | 63.5         |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2875         |\n",
      "|    time_elapsed         | 54289        |\n",
      "|    total_timesteps      | 5888000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016228828 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.1          |\n",
      "|    n_updates            | 28740        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | -0.08171977  |\n",
      "|    std                  | 63.7         |\n",
      "|    value_loss           | 14.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2876         |\n",
      "|    time_elapsed         | 54308        |\n",
      "|    total_timesteps      | 5890048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007023999 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.86         |\n",
      "|    n_updates            | 28750        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 0.28066835   |\n",
      "|    std                  | 63.8         |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2877         |\n",
      "|    time_elapsed         | 54327        |\n",
      "|    total_timesteps      | 5892096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011186698 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.65         |\n",
      "|    n_updates            | 28760        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | -1.1146696   |\n",
      "|    std                  | 63.7         |\n",
      "|    value_loss           | 14.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 3100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2645460.86\n",
      "total_reward: 1645460.86\n",
      "total_cost: 169007.33\n",
      "total_trades: 60708\n",
      "Sharpe: 0.527\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2878         |\n",
      "|    time_elapsed         | 54346        |\n",
      "|    total_timesteps      | 5894144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024059336 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.13         |\n",
      "|    n_updates            | 28770        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | -0.8177514   |\n",
      "|    std                  | 63.8         |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2879         |\n",
      "|    time_elapsed         | 54364        |\n",
      "|    total_timesteps      | 5896192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004371606 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.97         |\n",
      "|    n_updates            | 28780        |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | -1.1196423   |\n",
      "|    std                  | 63.8         |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2880         |\n",
      "|    time_elapsed         | 54383        |\n",
      "|    total_timesteps      | 5898240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007326454 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -160         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.22         |\n",
      "|    n_updates            | 28790        |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    reward               | -0.61134416  |\n",
      "|    std                  | 63.9         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2881          |\n",
      "|    time_elapsed         | 54402         |\n",
      "|    total_timesteps      | 5900288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0014808206  |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.731         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.44          |\n",
      "|    n_updates            | 28800         |\n",
      "|    policy_gradient_loss | -0.0035       |\n",
      "|    reward               | -0.0045066057 |\n",
      "|    std                  | 64.1          |\n",
      "|    value_loss           | 14.1          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2882         |\n",
      "|    time_elapsed         | 54422        |\n",
      "|    total_timesteps      | 5902336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012741702 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.66         |\n",
      "|    n_updates            | 28810        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 1.000354     |\n",
      "|    std                  | 64           |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2883         |\n",
      "|    time_elapsed         | 54442        |\n",
      "|    total_timesteps      | 5904384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005076992 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.76         |\n",
      "|    n_updates            | 28820        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    reward               | -8.688134    |\n",
      "|    std                  | 64.2         |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2884        |\n",
      "|    time_elapsed         | 54461       |\n",
      "|    total_timesteps      | 5906432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001054014 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -161        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.95        |\n",
      "|    n_updates            | 28830       |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | 0.26906323  |\n",
      "|    std                  | 64.3        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2885         |\n",
      "|    time_elapsed         | 54480        |\n",
      "|    total_timesteps      | 5908480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016594965 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.3          |\n",
      "|    n_updates            | 28840        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    reward               | -1.4746131   |\n",
      "|    std                  | 64.3         |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2886         |\n",
      "|    time_elapsed         | 54499        |\n",
      "|    total_timesteps      | 5910528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007035255 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.24         |\n",
      "|    n_updates            | 28850        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | 0.23038772   |\n",
      "|    std                  | 64.3         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2887         |\n",
      "|    time_elapsed         | 54518        |\n",
      "|    total_timesteps      | 5912576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007063878 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.2         |\n",
      "|    n_updates            | 28860        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 0.5565954    |\n",
      "|    std                  | 64.5         |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2888         |\n",
      "|    time_elapsed         | 54536        |\n",
      "|    total_timesteps      | 5914624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012269386 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.34         |\n",
      "|    n_updates            | 28870        |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    reward               | 0.0030349244 |\n",
      "|    std                  | 64.6         |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2889         |\n",
      "|    time_elapsed         | 54555        |\n",
      "|    total_timesteps      | 5916672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008610486 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.42         |\n",
      "|    n_updates            | 28880        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 2.0940824    |\n",
      "|    std                  | 64.8         |\n",
      "|    value_loss           | 13.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2890          |\n",
      "|    time_elapsed         | 54574         |\n",
      "|    total_timesteps      | 5918720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044193806 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.769         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.85          |\n",
      "|    n_updates            | 28890         |\n",
      "|    policy_gradient_loss | -0.00183      |\n",
      "|    reward               | -3.9063811    |\n",
      "|    std                  | 64.8          |\n",
      "|    value_loss           | 19.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2891         |\n",
      "|    time_elapsed         | 54593        |\n",
      "|    total_timesteps      | 5920768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004991874 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.93         |\n",
      "|    n_updates            | 28900        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | 0.68984115   |\n",
      "|    std                  | 64.9         |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 3110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3648271.16\n",
      "total_reward: 2648271.16\n",
      "total_cost: 215024.34\n",
      "total_trades: 63856\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2892         |\n",
      "|    time_elapsed         | 54611        |\n",
      "|    total_timesteps      | 5922816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011506896 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.6          |\n",
      "|    n_updates            | 28910        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | -0.40794554  |\n",
      "|    std                  | 64.9         |\n",
      "|    value_loss           | 15           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2893          |\n",
      "|    time_elapsed         | 54630         |\n",
      "|    total_timesteps      | 5924864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013087611 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.549         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.7          |\n",
      "|    n_updates            | 28920         |\n",
      "|    policy_gradient_loss | -0.000648     |\n",
      "|    reward               | 1.8794655     |\n",
      "|    std                  | 65            |\n",
      "|    value_loss           | 39.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2894         |\n",
      "|    time_elapsed         | 54649        |\n",
      "|    total_timesteps      | 5926912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003339348 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 28930        |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | 0.54628164   |\n",
      "|    std                  | 65           |\n",
      "|    value_loss           | 30.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2895         |\n",
      "|    time_elapsed         | 54668        |\n",
      "|    total_timesteps      | 5928960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024069604 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.81         |\n",
      "|    n_updates            | 28940        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -0.23397125  |\n",
      "|    std                  | 65.2         |\n",
      "|    value_loss           | 11.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2896          |\n",
      "|    time_elapsed         | 54687         |\n",
      "|    total_timesteps      | 5931008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090806856 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.641         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6             |\n",
      "|    n_updates            | 28950         |\n",
      "|    policy_gradient_loss | -0.00321      |\n",
      "|    reward               | -1.5637114    |\n",
      "|    std                  | 65.4          |\n",
      "|    value_loss           | 19.4          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2897          |\n",
      "|    time_elapsed         | 54707         |\n",
      "|    total_timesteps      | 5933056       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082752114 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.518         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.33          |\n",
      "|    n_updates            | 28960         |\n",
      "|    policy_gradient_loss | -0.00253      |\n",
      "|    reward               | -0.07696419   |\n",
      "|    std                  | 65.4          |\n",
      "|    value_loss           | 27.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2898         |\n",
      "|    time_elapsed         | 54726        |\n",
      "|    total_timesteps      | 5935104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012510127 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.36         |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | 0.6035499    |\n",
      "|    std                  | 65.6         |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2899         |\n",
      "|    time_elapsed         | 54745        |\n",
      "|    total_timesteps      | 5937152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028439164 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.91         |\n",
      "|    n_updates            | 28980        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 1.4012678    |\n",
      "|    std                  | 65.6         |\n",
      "|    value_loss           | 11.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2900          |\n",
      "|    time_elapsed         | 54765         |\n",
      "|    total_timesteps      | 5939200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015576332 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.58          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.1          |\n",
      "|    n_updates            | 28990         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    reward               | 0.03308966    |\n",
      "|    std                  | 65.7          |\n",
      "|    value_loss           | 26.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2901         |\n",
      "|    time_elapsed         | 54784        |\n",
      "|    total_timesteps      | 5941248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008117899 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.63         |\n",
      "|    n_updates            | 29000        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    reward               | 0.071618155  |\n",
      "|    std                  | 65.8         |\n",
      "|    value_loss           | 16.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2902         |\n",
      "|    time_elapsed         | 54804        |\n",
      "|    total_timesteps      | 5943296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012164981 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.6          |\n",
      "|    n_updates            | 29010        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | 0.5489007    |\n",
      "|    std                  | 65.9         |\n",
      "|    value_loss           | 11           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2903        |\n",
      "|    time_elapsed         | 54823       |\n",
      "|    total_timesteps      | 5945344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001197478 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -161        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.34        |\n",
      "|    n_updates            | 29020       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 1.2800914   |\n",
      "|    std                  | 65.9        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2904          |\n",
      "|    time_elapsed         | 54842         |\n",
      "|    total_timesteps      | 5947392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068434555 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0.488         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.32          |\n",
      "|    n_updates            | 29030         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | 0.63695014    |\n",
      "|    std                  | 66.1          |\n",
      "|    value_loss           | 15.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2905         |\n",
      "|    time_elapsed         | 54861        |\n",
      "|    total_timesteps      | 5949440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014169369 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.08         |\n",
      "|    n_updates            | 29040        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | -0.5877982   |\n",
      "|    std                  | 66.3         |\n",
      "|    value_loss           | 14.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 3120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2374904.93\n",
      "total_reward: 1374904.93\n",
      "total_cost: 172962.71\n",
      "total_trades: 60110\n",
      "Sharpe: 0.480\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2906         |\n",
      "|    time_elapsed         | 54881        |\n",
      "|    total_timesteps      | 5951488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008229952 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.34         |\n",
      "|    n_updates            | 29050        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 0.20037824   |\n",
      "|    std                  | 66.4         |\n",
      "|    value_loss           | 15           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2907          |\n",
      "|    time_elapsed         | 54900         |\n",
      "|    total_timesteps      | 5953536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089609716 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.661         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 4.74          |\n",
      "|    n_updates            | 29060         |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    reward               | 0.2591621     |\n",
      "|    std                  | 66.5          |\n",
      "|    value_loss           | 14.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2908          |\n",
      "|    time_elapsed         | 54919         |\n",
      "|    total_timesteps      | 5955584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079106004 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.675         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.85          |\n",
      "|    n_updates            | 29070         |\n",
      "|    policy_gradient_loss | -0.00255      |\n",
      "|    reward               | 2.202668      |\n",
      "|    std                  | 66.6          |\n",
      "|    value_loss           | 17.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2909         |\n",
      "|    time_elapsed         | 54938        |\n",
      "|    total_timesteps      | 5957632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015092337 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.706        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.14         |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -0.19762984  |\n",
      "|    std                  | 66.8         |\n",
      "|    value_loss           | 10.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2910         |\n",
      "|    time_elapsed         | 54957        |\n",
      "|    total_timesteps      | 5959680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009000659 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.25         |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 0.7506345    |\n",
      "|    std                  | 66.9         |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2911          |\n",
      "|    time_elapsed         | 54976         |\n",
      "|    total_timesteps      | 5961728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036373717 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.641         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.3          |\n",
      "|    n_updates            | 29100         |\n",
      "|    policy_gradient_loss | -0.00109      |\n",
      "|    reward               | 0.07023285    |\n",
      "|    std                  | 66.9          |\n",
      "|    value_loss           | 18.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2912         |\n",
      "|    time_elapsed         | 54995        |\n",
      "|    total_timesteps      | 5963776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023183972 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.91         |\n",
      "|    n_updates            | 29110        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -0.4162018   |\n",
      "|    std                  | 67           |\n",
      "|    value_loss           | 8.93         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2913        |\n",
      "|    time_elapsed         | 55015       |\n",
      "|    total_timesteps      | 5965824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001207567 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -162        |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.74        |\n",
      "|    n_updates            | 29120       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    reward               | 0.47692767  |\n",
      "|    std                  | 67.2        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2914          |\n",
      "|    time_elapsed         | 55035         |\n",
      "|    total_timesteps      | 5967872       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082507276 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.695         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.87          |\n",
      "|    n_updates            | 29130         |\n",
      "|    policy_gradient_loss | -0.00223      |\n",
      "|    reward               | -2.1631804    |\n",
      "|    std                  | 67.3          |\n",
      "|    value_loss           | 27.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2915          |\n",
      "|    time_elapsed         | 55055         |\n",
      "|    total_timesteps      | 5969920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058945303 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.0116        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.18          |\n",
      "|    n_updates            | 29140         |\n",
      "|    policy_gradient_loss | -0.00146      |\n",
      "|    reward               | 0.501078      |\n",
      "|    std                  | 67.4          |\n",
      "|    value_loss           | 21.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2916         |\n",
      "|    time_elapsed         | 55074        |\n",
      "|    total_timesteps      | 5971968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013979429 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.8          |\n",
      "|    n_updates            | 29150        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -0.8777247   |\n",
      "|    std                  | 67.5         |\n",
      "|    value_loss           | 11.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2917         |\n",
      "|    time_elapsed         | 55093        |\n",
      "|    total_timesteps      | 5974016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006412577 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.81         |\n",
      "|    n_updates            | 29160        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 0.9747727    |\n",
      "|    std                  | 67.6         |\n",
      "|    value_loss           | 19.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2918          |\n",
      "|    time_elapsed         | 55113         |\n",
      "|    total_timesteps      | 5976064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031790565 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.649         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.69          |\n",
      "|    n_updates            | 29170         |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    reward               | -1.031807     |\n",
      "|    std                  | 67.7          |\n",
      "|    value_loss           | 16.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2919          |\n",
      "|    time_elapsed         | 55132         |\n",
      "|    total_timesteps      | 5978112       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089259096 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -162          |\n",
      "|    explained_variance   | 0.533         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.08          |\n",
      "|    n_updates            | 29180         |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    reward               | 0.5326577     |\n",
      "|    std                  | 67.8          |\n",
      "|    value_loss           | 9.75          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 3130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2920360.69\n",
      "total_reward: 1920360.69\n",
      "total_cost: 195996.09\n",
      "total_trades: 62169\n",
      "Sharpe: 0.591\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2920         |\n",
      "|    time_elapsed         | 55152        |\n",
      "|    total_timesteps      | 5980160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005835298 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.31         |\n",
      "|    n_updates            | 29190        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -1.7827383   |\n",
      "|    std                  | 67.9         |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2921         |\n",
      "|    time_elapsed         | 55171        |\n",
      "|    total_timesteps      | 5982208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008315593 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 29200        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | -0.02142128  |\n",
      "|    std                  | 67.9         |\n",
      "|    value_loss           | 21.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2922         |\n",
      "|    time_elapsed         | 55191        |\n",
      "|    total_timesteps      | 5984256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009883089 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.52         |\n",
      "|    n_updates            | 29210        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    reward               | 0.95989895   |\n",
      "|    std                  | 68           |\n",
      "|    value_loss           | 15.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2923        |\n",
      "|    time_elapsed         | 55211       |\n",
      "|    total_timesteps      | 5986304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001065973 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -162        |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.26        |\n",
      "|    n_updates            | 29220       |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    reward               | 0.7785437   |\n",
      "|    std                  | 68.1        |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2924         |\n",
      "|    time_elapsed         | 55230        |\n",
      "|    total_timesteps      | 5988352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008254185 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -162         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 29230        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    reward               | 3.9614084    |\n",
      "|    std                  | 68.3         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 2925        |\n",
      "|    time_elapsed         | 55249       |\n",
      "|    total_timesteps      | 5990400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000727419 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -162        |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.58        |\n",
      "|    n_updates            | 29240       |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | -0.5722441  |\n",
      "|    std                  | 68.4        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2926         |\n",
      "|    time_elapsed         | 55268        |\n",
      "|    total_timesteps      | 5992448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012974698 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.46         |\n",
      "|    n_updates            | 29250        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | -1.4506974   |\n",
      "|    std                  | 68.5         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2927         |\n",
      "|    time_elapsed         | 55287        |\n",
      "|    total_timesteps      | 5994496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015001926 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.54         |\n",
      "|    n_updates            | 29260        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.8866641    |\n",
      "|    std                  | 68.7         |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2928         |\n",
      "|    time_elapsed         | 55307        |\n",
      "|    total_timesteps      | 5996544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022882763 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.11         |\n",
      "|    n_updates            | 29270        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | -1.4289086   |\n",
      "|    std                  | 68.9         |\n",
      "|    value_loss           | 15.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 108           |\n",
      "|    iterations           | 2929          |\n",
      "|    time_elapsed         | 55326         |\n",
      "|    total_timesteps      | 5998592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083588145 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -163          |\n",
      "|    explained_variance   | 0.424         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.89          |\n",
      "|    n_updates            | 29280         |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    reward               | -2.4909592    |\n",
      "|    std                  | 69            |\n",
      "|    value_loss           | 16.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 2930         |\n",
      "|    time_elapsed         | 55346        |\n",
      "|    total_timesteps      | 6000640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010260588 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -163         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.62         |\n",
      "|    n_updates            | 29290        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -0.10386778  |\n",
      "|    std                  | 69.2         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=6000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [],
   "source": [
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tensorboard_log=\"2\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS,tensorboard_log='sac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='1',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)\n",
    "\n",
    "trained_ppo.save('12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>1.478412e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.478347e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.481373e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.474912e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.482114e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "331  2021-10-22   1.478412e+06\n",
       "332  2021-10-25   1.478347e+06\n",
       "333  2021-10-26   1.481373e+06\n",
       "334  2021-10-27   1.474912e+06\n",
       "335  2021-10-28   1.482114e+06"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BA</th>\n",
       "      <th>CAT</th>\n",
       "      <th>CRM</th>\n",
       "      <th>CSCO</th>\n",
       "      <th>CVX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>GS</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>V</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WMT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL  AMGN  AXP  BA  CAT  CRM  CSCO  CVX  DIS   GS  ...  MRK  \\\n",
       "date                                                            ...        \n",
       "2020-07-01     0     0  100   0    0    0    94    0  100  100  ...    0   \n",
       "2020-07-02     0     0  100   0    0    0    94    0  100  100  ...    0   \n",
       "2020-07-06     0     0  100   0    0    0    94    0  100  100  ...    0   \n",
       "2020-07-07     0     0  100   0    0    0    94    0  100  100  ...    0   \n",
       "2020-07-08     0     0  100   0    0    0    94    0  100  100  ...    0   \n",
       "\n",
       "            MSFT  NKE   PG  TRV  UNH  V   VZ  WBA  WMT  \n",
       "date                                                    \n",
       "2020-07-01   100    0  100  100    0  0  100    0  100  \n",
       "2020-07-02   100    0  100  100    0  0  100    0  100  \n",
       "2020-07-06   100    0  100  100    0  0  100    0  100  \n",
       "2020-07-07   100    0  100  100    0  0  100    0  100  \n",
       "2020-07-08   100    0  100  100    0  0  100    0  100  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.343263\n",
      "Cumulative returns     0.482114\n",
      "Annual volatility      0.139651\n",
      "Sharpe ratio           2.190283\n",
      "Calmar ratio           4.144584\n",
      "Stability              0.934858\n",
      "Max drawdown          -0.082822\n",
      "Omega ratio            1.442865\n",
      "Sortino ratio          3.361905\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.066702\n",
      "Daily value at risk   -0.016381\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-07-01'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-10-28'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>34.326%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>48.211%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>13.965%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-8.282%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.638%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.28</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.59</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.30</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.12</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.25</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.12%</td>\n",
       "      <td>-2.92%</td>\n",
       "      <td>4.29%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
