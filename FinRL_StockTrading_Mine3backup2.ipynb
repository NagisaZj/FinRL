{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)   \n",
    "* [RLlib Section](#7)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "ef0ba8d0-f57a-4c74-bb0b-46737762677d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-8i1_yu6g\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-8i1_yu6g\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5a06fizc/pyfolio_a7217f0bb5e740febfbf6fb40b942785\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5a06fizc/elegantrl_2c9dffb258c6419bb2f5c6a8409b99b2\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.1.5)\n",
      "Collecting stockstats\n",
      "  Downloading stockstats-0.3.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.67-py2.py3-none-any.whl (25 kB)\n",
      "Collecting elegantrl\n",
      "  Downloading elegantrl-0.3.2-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.17.3)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 65.2 MB/s \n",
      "\u001b[?25hCollecting ray[default]\n",
      "  Downloading ray-1.9.1-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 57.6 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting lz4\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 42.9 MB/s \n",
      "\u001b[?25hCollecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting gputil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "Collecting exchange_calendars\n",
      "  Downloading exchange_calendars-3.5.tar.gz (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 35.6 MB/s \n",
      "\u001b[?25hCollecting alpaca_trade_api\n",
      "  Downloading alpaca_trade_api-1.4.3-py3-none-any.whl (36 kB)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting jqdatasdk\n",
      "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 57.3 MB/s \n",
      "\u001b[?25hCollecting wrds\n",
      "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (3.6.4)\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (57.4.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.3) (0.37.0)\n",
      "Collecting pre-commit\n",
      "  Downloading pre_commit-2.16.0-py2.py3-none-any.whl (191 kB)\n",
      "\u001b[K     |████████████████████████████████| 191 kB 55.1 MB/s \n",
      "\u001b[?25hCollecting pybullet\n",
      "  Downloading pybullet-3.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (90.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 90.8 MB 244 bytes/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (1.10.0+cu111)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.3) (4.1.2.30)\n",
      "Collecting box2d-py\n",
      "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 50.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2018.9)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.11.2)\n",
      "Collecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.9.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.0.18)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.6.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.3) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.23.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (4.2.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.3) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.3) (1.1.0)\n",
      "Collecting websocket-client<2,>=0.56.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting PyYAML==5.4.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 52.7 MB/s \n",
      "\u001b[?25hCollecting msgpack==1.0.2\n",
      "  Downloading msgpack-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 60.4 MB/s \n",
      "\u001b[?25hCollecting aiohttp==3.7.4\n",
      "  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 55.5 MB/s \n",
      "\u001b[?25hCollecting websockets<10,>=8.0\n",
      "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (3.10.0.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 56.6 MB/s \n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 57.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->alpaca_trade_api->finrl==0.3.3) (21.2.0)\n",
      "Collecting ccxt\n",
      "  Downloading ccxt-1.65.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 68.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.65.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 28.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 21.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 59.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.64.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 70.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 25.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 60.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.63.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 26.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.85-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.84-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.83-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.82-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 67.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.81-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.80-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.79-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.78-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.77-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.76-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.75-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.74-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.73-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.72-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.71-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.70-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.69-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 73.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.68-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 24.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.67-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.66-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.65-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.64-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.63-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.62-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 53.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.61-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.60-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.59-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.58-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.57-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 30.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.56-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.55-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.54-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.53-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.52-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.51-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.50-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.49-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.48-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 32.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.47-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.46-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.45-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.44-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.43-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 50.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.42-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.41-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.40-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 48.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.39-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.38-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.37-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 35.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.36-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.35-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.34-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.33-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.32-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.31-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.30-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.29-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 31.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.28-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.27-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.26-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.25-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 29.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.24-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 36.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.23-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.22-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 57.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.21-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.20-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.19-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.18-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 40.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.17-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.16-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.15-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.14-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.13-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 56.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.12-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.11-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 14.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.10-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.9-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 34.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.8-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 37.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.7-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 41.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.6-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 55.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.4-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 51.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.3-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.62.1-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.100-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 65.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.99-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 45.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.98-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 39.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.97-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.96-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.95-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 33.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.94-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 43.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.93-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 46.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.92-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.91-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 47.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.90-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 54.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.89-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 44.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.88-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 49.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.87-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.86-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.85-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 59.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.84-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.83-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.82-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 56.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.81-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.80-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 35.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.79-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.78-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 20.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.77-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.76-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.75-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.74-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 34.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.73-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 41.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.72-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.71-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 36.0 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.70-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 37.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.69-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.68-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 60.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.67-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.66-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.65-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.7 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.64-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.5 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.63-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.62-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 42.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.61-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 49.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.60-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 57.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.59-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.3 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.58-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 44.6 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.57-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 50.4 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.56-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.8 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.55-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 45.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.54-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 51.9 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.53-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 43.2 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.52-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 47.1 MB/s \n",
      "\u001b[?25h  Downloading ccxt-1.61.51-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
      "\u001b[?25hCollecting aiodns>=1.1.1\n",
      "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 60.7 MB/s \n",
      "\u001b[?25hCollecting cryptography>=2.6.1\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
      "\u001b[?25hCollecting pycares>=4.0.0\n",
      "  Downloading pycares-4.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 44.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt->finrl==0.3.3) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt->finrl==0.3.3) (2.21)\n",
      "Collecting pyluach\n",
      "  Downloading pyluach-1.3.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.11.2)\n",
      "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.3) (0.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.3) (1.4.27)\n",
      "Collecting thriftpy2>=0.3.9\n",
      "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
      "\u001b[K     |████████████████████████████████| 361 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting pymysql>=0.7.6\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (4.8.2)\n",
      "Collecting ply<4.0,>=3.4\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.3) (3.6.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.3) (0.7.0)\n",
      "Collecting cfgv>=2.0.0\n",
      "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.3) (0.10.2)\n",
      "Collecting identify>=1.0.0\n",
      "  Downloading identify-2.4.1-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 7.2 MB/s \n",
      "\u001b[?25hCollecting virtualenv>=20.0.8\n",
      "  Downloading virtualenv-20.11.0-py2.py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 39.6 MB/s \n",
      "\u001b[?25hCollecting nodeenv>=0.11.1\n",
      "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.3) (3.4.0)\n",
      "Collecting distlib<1,>=0.3.1\n",
      "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
      "\u001b[K     |████████████████████████████████| 461 kB 32.3 MB/s \n",
      "\u001b[?25hCollecting platformdirs<3,>=2\n",
      "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (0.7.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.11.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (8.12.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.3) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (1.42.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (3.17.3)\n",
      "Collecting redis>=3.5.0\n",
      "  Downloading redis-4.1.0-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.12.0)\n",
      "Collecting aioredis<2\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 50.8 MB/s \n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 70.8 MB/s \n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (5.2.1)\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 7.1 MB/s \n",
      "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
      "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 213 kB/s \n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 53.5 MB/s \n",
      "\u001b[?25hCollecting hiredis\n",
      "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.3) (5.4.8)\n",
      "Collecting blessed>=1.17.1\n",
      "  Downloading blessed-1.19.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.8 MB/s \n",
      "\u001b[?25hCollecting deprecated>=1.2.3\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]->finrl==0.3.3) (21.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]->finrl==0.3.3) (1.13.3)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.3) (1.26.3)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.3) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.3) (0.8.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (2.7.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (7.1.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.3) (0.2.9)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.3) (3.1.1)\n",
      "Collecting int-date>=0.1.7\n",
      "  Downloading int_date-0.1.8-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 32.7 MB/s \n",
      "\u001b[?25hCollecting mock\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 45.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.3) (0.0.10)\n",
      "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat\n",
      "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for finrl: filename=finrl-0.3.3-py3-none-any.whl size=3885640 sha256=1667a85b9c8c0a7a8efbf04d5ebf154d5d1ea119a32e922d094820030ce0e7e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for elegantrl: filename=elegantrl-0.3.2-py3-none-any.whl size=168744 sha256=7773813204e1a2954730bd149444640d5155458fc82b6910ec4e661879797016\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75775 sha256=e3753b24d032afc5ef0b133c50557002ca9fed8416e2205e1547fc81af5c124a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ufkle1ru/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39777 sha256=6cc78a6b3f88187e2798221487acba0361bb1d094b6c82496348fb4c85f7686b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for exchange-calendars: filename=exchange_calendars-3.5-py3-none-any.whl size=179487 sha256=3d877d78e29a28c4b098f4a0b1d0106458d7f73b52f6c7a43d0757d55c11d44b\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/21/43/b6ae2605dd767f6cd5a5b0b70c93a9a75823e44b3ccb92bce7\n",
      "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=33dcd980f1b32f0582d029fcef126ae53327fb90724eee8c33bc3b4dbebda4b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
      "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940507 sha256=429244bf5fd89014c79f01bf0e4a59477258cd2b88978e3125b54f4bd62a88f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b831a9dba6682b3e0a7ae05d7c2ba465918426c72474917e56e0850ac8c73263\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
      "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat\n",
      "Installing collected packages: multidict, yarl, lxml, deprecated, async-timeout, redis, PyYAML, pycares, ply, platformdirs, opencensus-context, msgpack, hiredis, frozenlist, distlib, blessed, aiohttp, websockets, websocket-client, virtualenv, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, opencensus, nodeenv, mock, int-date, identify, gpustat, empyrical, cryptography, colorful, cfgv, box2d-py, aiosignal, aioredis, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed PyYAML-5.4.1 aiodns-3.0.0 aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 alpaca-trade-api-1.4.3 async-timeout-3.0.1 blessed-1.19.0 box2d-py-2.3.8 ccxt-1.61.51 cfgv-3.3.1 colorful-0.5.4 cryptography-36.0.1 deprecated-1.2.13 distlib-0.3.4 elegantrl-0.3.2 empyrical-0.5.5 exchange-calendars-3.5 finrl-0.3.3 frozenlist-1.2.0 gpustat-1.0.0b1 gputil-1.4.0 hiredis-2.0.0 identify-2.4.1 int-date-0.1.8 jqdatasdk-1.8.10 lxml-4.7.1 lz4-3.1.10 mock-4.0.3 msgpack-1.0.2 multidict-5.2.0 nodeenv-1.6.0 opencensus-0.8.0 opencensus-context-0.1.2 platformdirs-2.4.1 ply-3.11 pre-commit-2.16.0 psycopg2-binary-2.9.2 py-spy-0.3.11 pybullet-3.2.1 pycares-4.1.2 pyfolio-0.9.2+75.g4b901f6 pyluach-1.3.0 pymysql-1.0.2 ray-1.9.1 redis-4.1.0 stable-baselines3-1.3.0 stockstats-0.3.2 tensorboardX-2.4.1 thriftpy2-0.4.14 virtualenv-20.11.0 websocket-client-1.2.3 websockets-9.1 wrds-3.1.1 yarl-1.6.3 yfinance-0.1.67\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "10b08480-3a0c-4826-8e51-f94ce97ab84a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.tusharedownloader import TushareDownloader\n",
    "from finrl.finrl_meta.data_processors.processor_alpaca import AlpacaProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_wrds import WrdsProcessor\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading_conservative import StockTradingEnvCon\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot2 import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "5302d7c0-1c68-4c6e-b30e-b1395bdc109e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py TRAIN_START_DATE is a string\n",
    "config.TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "35dd8c5b-d58f-49b8-e4df-ae7e122448cd"
   },
   "outputs": [],
   "source": [
    "# from config.py TRAIN_END_DATE is a string\n",
    "# config.TRAIN_END_DATE\n",
    "# df2=TushareDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83c7f894-3757-473b-8afb-a904e6caabda",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-10-31',\n",
    "#                      ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "7a991dfe-f39c-40db-ec44-7c416cdce7dc"
   },
   "outputs": [],
   "source": [
    "# print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "5267773c-399c-4ec9-d4d5-13ab1e4cced0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94360, 9)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "210fade5-e912-40df-be99-4ad00bdb9d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100</td>\n",
       "      <td>BA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date       open       high        low      close  \\\n",
       "0           0  2008-12-31   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31  43.700001  45.099998  43.700001  30.628819   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  607541200  AAPL    2  \n",
       "1    6287200  AMGN    2  \n",
       "2    9625600   AXP    2  \n",
       "3    5443100    BA    2  \n",
       "4    6277400   CAT    2  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmKP-1ii3RLS",
    "outputId": "0708badb-77ef-4c86-f77c-6525f0e8934d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fe = FeatureEngineer(\n",
    "#                     use_technical_indicator=True,\n",
    "#                     tech_indicator_list = config.INDICATORS,\n",
    "#                     use_vix=True,\n",
    "#                     use_turbulence=True,\n",
    "#                     user_defined_feature = False)\n",
    "\n",
    "# processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Kixon2tR3RLT"
   },
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "grvhGJJII3Xn",
    "outputId": "733758c3-3552-4aa5-e1f9-789bd4ce0c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.070357</td>\n",
       "      <td>3.133571</td>\n",
       "      <td>3.047857</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>607541200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>2.606277</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>57.110001</td>\n",
       "      <td>58.220001</td>\n",
       "      <td>57.060001</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>6287200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>43.924454</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>AXP</td>\n",
       "      <td>17.969999</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>9625600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>14.908465</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>BA</td>\n",
       "      <td>41.590000</td>\n",
       "      <td>43.049999</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>5443100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>32.005894</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CAT</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.700001</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>6277400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>30.628819</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CRM</td>\n",
       "      <td>7.712500</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>7.707500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>5367600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>8.002500</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>16.180000</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.120001</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>37513700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>11.787783</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>CVX</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>74.629997</td>\n",
       "      <td>72.900002</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>9964300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>43.314438</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>DIS</td>\n",
       "      <td>22.570000</td>\n",
       "      <td>22.950001</td>\n",
       "      <td>22.520000</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>9012100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>19.538342</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>GS</td>\n",
       "      <td>82.239998</td>\n",
       "      <td>86.150002</td>\n",
       "      <td>81.120003</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>14894100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921925</td>\n",
       "      <td>2.455527</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>69.224182</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic       open       high        low      close  \\\n",
       "0           0  2008-12-31  AAPL   3.070357   3.133571   3.047857   2.606277   \n",
       "1           1  2008-12-31  AMGN  57.110001  58.220001  57.060001  43.924454   \n",
       "2           2  2008-12-31   AXP  17.969999  18.750000  17.910000  14.908465   \n",
       "3           3  2008-12-31    BA  41.590000  43.049999  41.500000  32.005894   \n",
       "4           4  2008-12-31   CAT  43.700001  45.099998  43.700001  30.628819   \n",
       "5           5  2008-12-31   CRM   7.712500   8.130000   7.707500   8.002500   \n",
       "6           6  2008-12-31  CSCO  16.180000  16.549999  16.120001  11.787783   \n",
       "7           7  2008-12-31   CVX  72.900002  74.629997  72.900002  43.314438   \n",
       "8           8  2008-12-31   DIS  22.570000  22.950001  22.520000  19.538342   \n",
       "9           9  2008-12-31    GS  82.239998  86.150002  81.120003  69.224182   \n",
       "\n",
       "        volume  day  macd   boll_ub   boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  607541200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "1    6287200.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "2    9625600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "3    5443100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "4    6277400.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "5    5367600.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "6   37513700.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "7    9964300.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "8    9012100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "9   14894100.0  2.0   0.0  2.921925  2.455527   100.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma   vix  turbulence  \n",
       "0      2.606277      2.606277  40.0         0.0  \n",
       "1     43.924454     43.924454  40.0         0.0  \n",
       "2     14.908465     14.908465  40.0         0.0  \n",
       "3     32.005894     32.005894  40.0         0.0  \n",
       "4     30.628819     30.628819  40.0         0.0  \n",
       "5      8.002500      8.002500  40.0         0.0  \n",
       "6     11.787783     11.787783  40.0         0.0  \n",
       "7     43.314438     43.314438  40.0         0.0  \n",
       "8     19.538342     19.538342  40.0         0.0  \n",
       "9     69.224182     69.224182  40.0         0.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full=pd.read_csv('./2.csv')\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01\n",
    "## Trade data split: 2020-07-01 to 2021-10-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "ca8d1a43-ffc3-4fc3-efa9-4de9a9065842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83897\n",
      "9744\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "p52zNCOhTtLR",
    "outputId": "b3ad3e10-376f-4186-f875-0331708c5e14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121795</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>UNH</td>\n",
       "      <td>288.570007</td>\n",
       "      <td>296.450012</td>\n",
       "      <td>287.660004</td>\n",
       "      <td>287.776794</td>\n",
       "      <td>2932900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>303.925869</td>\n",
       "      <td>271.251255</td>\n",
       "      <td>52.413046</td>\n",
       "      <td>-25.838431</td>\n",
       "      <td>1.846804</td>\n",
       "      <td>288.020689</td>\n",
       "      <td>281.001438</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121796</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>V</td>\n",
       "      <td>191.490005</td>\n",
       "      <td>193.750000</td>\n",
       "      <td>190.160004</td>\n",
       "      <td>190.737244</td>\n",
       "      <td>9040100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048786</td>\n",
       "      <td>198.750528</td>\n",
       "      <td>185.041391</td>\n",
       "      <td>53.021033</td>\n",
       "      <td>-51.550760</td>\n",
       "      <td>2.013358</td>\n",
       "      <td>191.485037</td>\n",
       "      <td>181.677683</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121797</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>VZ</td>\n",
       "      <td>54.919998</td>\n",
       "      <td>55.290001</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>50.376743</td>\n",
       "      <td>17414800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.437111</td>\n",
       "      <td>53.918425</td>\n",
       "      <td>48.729324</td>\n",
       "      <td>48.097044</td>\n",
       "      <td>-51.018262</td>\n",
       "      <td>8.508886</td>\n",
       "      <td>51.012123</td>\n",
       "      <td>51.464679</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121798</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WBA</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>42.580002</td>\n",
       "      <td>41.759998</td>\n",
       "      <td>39.035732</td>\n",
       "      <td>4782100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.083986</td>\n",
       "      <td>42.609305</td>\n",
       "      <td>36.487095</td>\n",
       "      <td>48.830181</td>\n",
       "      <td>-14.508130</td>\n",
       "      <td>1.500723</td>\n",
       "      <td>39.135190</td>\n",
       "      <td>38.935129</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>121799</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>WMT</td>\n",
       "      <td>119.220001</td>\n",
       "      <td>120.129997</td>\n",
       "      <td>118.540001</td>\n",
       "      <td>116.121765</td>\n",
       "      <td>6836400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.886569</td>\n",
       "      <td>119.473758</td>\n",
       "      <td>113.510454</td>\n",
       "      <td>48.159665</td>\n",
       "      <td>-69.938795</td>\n",
       "      <td>3.847271</td>\n",
       "      <td>117.787627</td>\n",
       "      <td>119.723273</td>\n",
       "      <td>30.43</td>\n",
       "      <td>12.918751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        date  tic        open        high         low  \\\n",
       "2892      121795  2020-06-30  UNH  288.570007  296.450012  287.660004   \n",
       "2892      121796  2020-06-30    V  191.490005  193.750000  190.160004   \n",
       "2892      121797  2020-06-30   VZ   54.919998   55.290001   54.360001   \n",
       "2892      121798  2020-06-30  WBA   42.119999   42.580002   41.759998   \n",
       "2892      121799  2020-06-30  WMT  119.220001  120.129997  118.540001   \n",
       "\n",
       "           close      volume  day      macd     boll_ub     boll_lb  \\\n",
       "2892  287.776794   2932900.0  1.0 -0.019475  303.925869  271.251255   \n",
       "2892  190.737244   9040100.0  1.0  1.048786  198.750528  185.041391   \n",
       "2892   50.376743  17414800.0  1.0 -0.437111   53.918425   48.729324   \n",
       "2892   39.035732   4782100.0  1.0 -0.083986   42.609305   36.487095   \n",
       "2892  116.121765   6836400.0  1.0 -0.886569  119.473758  113.510454   \n",
       "\n",
       "         rsi_30     cci_30     dx_30  close_30_sma  close_60_sma    vix  \\\n",
       "2892  52.413046 -25.838431  1.846804    288.020689    281.001438  30.43   \n",
       "2892  53.021033 -51.550760  2.013358    191.485037    181.677683  30.43   \n",
       "2892  48.097044 -51.018262  8.508886     51.012123     51.464679  30.43   \n",
       "2892  48.830181 -14.508130  1.500723     39.135190     38.935129  30.43   \n",
       "2892  48.159665 -69.938795  3.847271    117.787627    119.723273  30.43   \n",
       "\n",
       "      turbulence  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  \n",
       "2892   12.918751  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "72213585-39a3-4bff-c031-874ec0ca06f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "7f228183-abe3-4477-f574-3c9b25c62cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "1f54d044-e2d3-4a34-c041-e913d686654e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "e_train_gym_conservative = StockTradingEnvCon(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "deeaef07-afda-4ca1-fea8-99384224c7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "env_train_con, _ = e_train_gym_conservative.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "agent_con = DRLAgent(env = env_train_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "a90a7a60-21a5-47e1-b683-1f7cbb4b8bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "570d540f-abe9-402b-e0cc-f9b007228e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 67         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -1.41      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -72.8      |\n",
      "|    reward             | 0.19451597 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.68       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 68         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | -0.115     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -70.2      |\n",
      "|    reward             | -1.4624771 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.55       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -167     |\n",
      "|    reward             | 5.02583  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -30.9    |\n",
      "|    reward             | 5.606354 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 368       |\n",
      "|    reward             | -7.546301 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.0793    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 145       |\n",
      "|    reward             | 0.4507672 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 15        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -0.0998    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -78.4      |\n",
      "|    reward             | -2.1521304 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.52       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0.00557     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.80710465 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 70.3        |\n",
      "|    reward             | -0.11950674 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.94        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | -4.1389766 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -245     |\n",
      "|    reward             | 6.363784 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 38.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -63.1      |\n",
      "|    reward             | 0.07753525 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | -0.000831 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 48.9      |\n",
      "|    reward             | -4.088032 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 179       |\n",
      "|    reward             | 2.0626597 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | 4.8591986 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 21.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 85.1       |\n",
      "|    reward             | 0.85958314 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -141     |\n",
      "|    reward             | 5.65319  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | 1.1973313 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | 0.36287376 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | -0.0091     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -83.6       |\n",
      "|    reward             | -0.30971453 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 13.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 204       |\n",
      "|    reward             | 1.7650424 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -153       |\n",
      "|    reward             | -7.5710273 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -2.04e+03  |\n",
      "|    reward             | -14.886115 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3e+03      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 51        |\n",
      "|    reward             | 0.0559524 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -46.7     |\n",
      "|    reward             | -0.434364 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 5.71      |\n",
      "|    reward             | 4.8586307 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -0.4118847 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 328       |\n",
      "|    reward             | 1.0554261 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 66.3      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.88      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 2.3091433 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -20.7      |\n",
      "|    reward             | 0.38583377 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 43.7       |\n",
      "|    reward             | -0.3664559 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -38.8      |\n",
      "|    reward             | -0.4616701 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | 0.11014476 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -3.93     |\n",
      "|    reward             | 2.1390972 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 252        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 76.4       |\n",
      "|    reward             | 0.16336557 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -85.2     |\n",
      "|    reward             | 1.0221922 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 266       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | 1.1701288 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 33.2      |\n",
      "|    reward             | 2.4472284 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 41.3       |\n",
      "|    reward             | -1.2081411 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -0.481    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -5.13     |\n",
      "|    reward             | 1.3224076 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2         |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 295         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.25540048 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.837       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0.000881  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 1.3826902 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -64       |\n",
      "|    reward             | 3.9822705 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 63.9       |\n",
      "|    reward             | 0.95108056 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 324        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 86.2       |\n",
      "|    reward             | -2.1539907 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 102       |\n",
      "|    reward             | 4.8509326 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.00948     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | -105        |\n",
      "|    reward             | -0.22313617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -104        |\n",
      "|    reward             | -0.99914765 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 353        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -33.2      |\n",
      "|    reward             | 0.20132123 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | -7.57e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 46.2       |\n",
      "|    reward             | 0.26696855 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -83.4      |\n",
      "|    reward             | -1.8360271 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | 3.2874866 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 92.2      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3161472.69\n",
      "total_reward: 2161472.69\n",
      "total_cost: 19221.41\n",
      "total_trades: 41334\n",
      "Sharpe: 0.663\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -7.54     |\n",
      "|    reward             | 0.2828299 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.19252001 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.14        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 2.0577734 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.6       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -46.9       |\n",
      "|    reward             | -0.06746031 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.12        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.00117    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | 0.18157594 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 418       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0.0166    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | 0.6473793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.22656512 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.251      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 59.9       |\n",
      "|    reward             | -0.8028962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 439        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7693416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.89       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 446         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 20.2        |\n",
      "|    reward             | -0.10761352 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 454      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 203      |\n",
      "|    reward             | 3.869458 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 34.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -0.0428   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 110       |\n",
      "|    reward             | 1.2343621 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.67      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -2.028344 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.33169752 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.98       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 483      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.4    |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -869     |\n",
      "|    reward             | -8.09732 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 536      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 28.9       |\n",
      "|    reward             | 0.56556416 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -176       |\n",
      "|    reward             | -2.9329143 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 88.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 504        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 72.3       |\n",
      "|    reward             | 0.22214015 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 3.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -0.6425189 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -360        |\n",
      "|    reward             | -0.22756429 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 80.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -430        |\n",
      "|    reward             | -0.44158605 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 131         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 533        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 404        |\n",
      "|    reward             | -5.8487034 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -14.82644 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 832       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 548       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | 1.4826734 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.0473    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | 0.34629944 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 562       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -42       |\n",
      "|    reward             | -2.415951 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.0485888 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 42.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -207       |\n",
      "|    reward             | -3.2154734 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 56.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 257       |\n",
      "|    reward             | 5.370093  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -160       |\n",
      "|    reward             | 0.03019213 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 118        |\n",
      "|    reward             | -1.1561224 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 12.6       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -214        |\n",
      "|    reward             | -0.94865924 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 30.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 613       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 1.1797212 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 41.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 411        |\n",
      "|    reward             | -22.785406 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 627       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | 3.2164123 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 87          |\n",
      "|    reward             | -0.17441794 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.17        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 262         |\n",
      "|    reward             | -0.85795397 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 48.9        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 72.7       |\n",
      "|    reward             | -2.2230675 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 22.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 656       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -49.2     |\n",
      "|    reward             | 2.6728501 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 663      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -238     |\n",
      "|    reward             | 8.656925 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 86.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 670         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0.000219    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -187        |\n",
      "|    reward             | -0.62001467 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 55.6      |\n",
      "|    reward             | 1.1713017 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 1.3898315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -52.5     |\n",
      "|    reward             | -6.044222 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 69        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 67.7      |\n",
      "|    reward             | 1.8213228 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 706      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 177      |\n",
      "|    reward             | 8.957433 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 58.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 69          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.26523116 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.559       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 69         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | -0.00926   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | -0.6623605 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2YadjfnLwgt"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCDa78rqfO_a",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "y5D5PFUhMzSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Gt8eIQKYM4G3",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ppo/1_1\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 124       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.5073655 |\n",
      "----------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3946387.70\n",
      "total_reward: 2946387.70\n",
      "total_cost: 357438.48\n",
      "total_trades: 81024\n",
      "Sharpe: 0.793\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015788507 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00723     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 0.3435485   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 13.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012375185 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -1.1157341  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016662188 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00193    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.2809894   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017038994 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00886    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | 3.2505164   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01701039 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0063     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17         |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    reward               | 1.8685282  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 32.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486872 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0142    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 22.5       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    reward               | 0.39857626 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 46.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 116         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020911664 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0215     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 1.3883617   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7870/2360990771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_ppo = agent.train_model(model=model_ppo, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=3000000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             )\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_total_asset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_total_asset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_total_asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/zj/FinRL/finrl/finrl_meta/env_stock_trading/env_stocktrading.py\u001b[0m in \u001b[0;36m_get_date\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2037\u001b[0m         \u001b[0mCategories\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m         \"\"\"\n\u001b[0;32m-> 2039\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_hashtable_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_hashtable_algo\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_object_for_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mhtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mndtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_check_object_for_strings\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# including nulls because that is the only difference between\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# StringHashTable and ObjectHashtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0mndtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mndtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name=\"1\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "JSAHhV4Xc-bh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent_con = DRLAgent(env = env_train_con)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo2 = agent_con.get_model(\"ppo\",model_kwargs = PPO_PARAMS,tensorboard_log='ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "OSRxNYAxdKpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "Logging to ppo/4_2\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 119        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 17         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.66027504 |\n",
      "-----------------------------------\n",
      "day: 2892, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4707051.52\n",
      "total_reward: 3707051.52\n",
      "total_cost: 144199.94\n",
      "total_trades: 59794\n",
      "Sharpe: 0.843\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 116        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 35         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00836232 |\n",
      "|    clip_fraction        | 0.0751     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.2      |\n",
      "|    explained_variance   | 0.645      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.3       |\n",
      "|    n_updates            | 14660      |\n",
      "|    policy_gradient_loss | -0.00927   |\n",
      "|    reward               | 0.35074508 |\n",
      "|    std                  | 7.01       |\n",
      "|    value_loss           | 24         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 116          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071498877 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.2        |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 14670        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    reward               | -1.7450634   |\n",
      "|    std                  | 7.02         |\n",
      "|    value_loss           | 59.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 116          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049814684 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.3        |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 14680        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    reward               | -0.9762932   |\n",
      "|    std                  | 7.03         |\n",
      "|    value_loss           | 55.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010252999 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 14690       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    reward               | 0.28330052  |\n",
      "|    std                  | 7.04        |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008187547 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    reward               | 2.164796    |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 123        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00909102 |\n",
      "|    clip_fraction        | 0.0664     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.4      |\n",
      "|    explained_variance   | 0.525      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 27         |\n",
      "|    n_updates            | 14710      |\n",
      "|    policy_gradient_loss | -0.00806   |\n",
      "|    reward               | 0.8996356  |\n",
      "|    std                  | 7.06       |\n",
      "|    value_loss           | 63.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062469644 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.4        |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 14720        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | -0.09107769  |\n",
      "|    std                  | 7.06         |\n",
      "|    value_loss           | 45.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 159        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00960699 |\n",
      "|    clip_fraction        | 0.0581     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.5      |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.12       |\n",
      "|    n_updates            | 14730      |\n",
      "|    policy_gradient_loss | -0.00668   |\n",
      "|    reward               | 1.0925634  |\n",
      "|    std                  | 7.08       |\n",
      "|    value_loss           | 29         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009324803 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 14740       |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | 0.8975502   |\n",
      "|    std                  | 7.08        |\n",
      "|    value_loss           | 74.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007543003 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 14750       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | 0.8285881   |\n",
      "|    std                  | 7.08        |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103070205 |\n",
      "|    clip_fraction        | 0.091        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.5        |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 14760        |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    reward               | -1.021585    |\n",
      "|    std                  | 7.09         |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007282573 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 14770       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | 0.32790962  |\n",
      "|    std                  | 7.09        |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010617031 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 14780       |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    reward               | -0.13412422 |\n",
      "|    std                  | 7.1         |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009579152 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 14790       |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | 2.448655    |\n",
      "|    std                  | 7.11        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4594698.06\n",
      "total_reward: 3594698.06\n",
      "total_cost: 148138.06\n",
      "total_trades: 60016\n",
      "Sharpe: 0.820\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0134209   |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.6       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 14800       |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    reward               | -0.74143165 |\n",
      "|    std                  | 7.13        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009808006 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.7       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 14810       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | 0.6410361   |\n",
      "|    std                  | 7.14        |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003305939 |\n",
      "|    clip_fraction        | 0.00317     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 14820       |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    reward               | 0.31709123  |\n",
      "|    std                  | 7.15        |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012026918 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 14830       |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    reward               | -0.9448102  |\n",
      "|    std                  | 7.15        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010851831 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.156       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 14840       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | -0.66761416 |\n",
      "|    std                  | 7.16        |\n",
      "|    value_loss           | 68.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 375          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034465238 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -97.8        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 14850        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -4.146746    |\n",
      "|    std                  | 7.16         |\n",
      "|    value_loss           | 55.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010295881 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 14860       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | 0.81886286  |\n",
      "|    std                  | 7.17        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011865456 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | -0.7705994  |\n",
      "|    std                  | 7.18        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004455223 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    reward               | 1.5492172   |\n",
      "|    std                  | 7.19        |\n",
      "|    value_loss           | 47          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 445          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070307534 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98          |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 14890        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | -1.2126317   |\n",
      "|    std                  | 7.2          |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 463         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01168821  |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.33        |\n",
      "|    n_updates            | 14900       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    reward               | -0.10990807 |\n",
      "|    std                  | 7.22        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008326391 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 14910       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -1.0678415  |\n",
      "|    std                  | 7.22        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007572223 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 14920       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | -0.08699816 |\n",
      "|    std                  | 7.23        |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008719169 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | 1.50557     |\n",
      "|    std                  | 7.24        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4053982.54\n",
      "total_reward: 3053982.54\n",
      "total_cost: 139056.09\n",
      "total_trades: 59551\n",
      "Sharpe: 0.771\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008389753 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | 1.3548926   |\n",
      "|    std                  | 7.24        |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 553         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005656482 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 14950       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | 5.992053    |\n",
      "|    std                  | 7.24        |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006390235 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.1       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 14960       |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | -0.81934315 |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010088848 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 14970       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    reward               | -1.3846736  |\n",
      "|    std                  | 7.26        |\n",
      "|    value_loss           | 28.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 606          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071344795 |\n",
      "|    clip_fraction        | 0.0435       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.2        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 14980        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 1.0747913    |\n",
      "|    std                  | 7.27         |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010537174 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 14990       |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    reward               | -2.1748204  |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 61.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012828596 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.49        |\n",
      "|    n_updates            | 15000       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -4.370317   |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 659         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010183675 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 15010       |\n",
      "|    policy_gradient_loss | -0.00946    |\n",
      "|    reward               | 0.32441044  |\n",
      "|    std                  | 7.31        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 676         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010259016 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 15020       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -9.941013   |\n",
      "|    std                  | 7.32        |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 694         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006826455 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 15030       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    reward               | -1.9142956  |\n",
      "|    std                  | 7.32        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 712          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106089525 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.5        |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.6         |\n",
      "|    n_updates            | 15040        |\n",
      "|    policy_gradient_loss | -0.00985     |\n",
      "|    reward               | -1.4459485   |\n",
      "|    std                  | 7.34         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008367103 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 15050       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | 0.616323    |\n",
      "|    std                  | 7.35        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060535744 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.6        |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 15060        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | 0.9719906    |\n",
      "|    std                  | 7.35         |\n",
      "|    value_loss           | 49.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011690956 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 15070       |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | -0.71119666 |\n",
      "|    std                  | 7.37        |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4823858.99\n",
      "total_reward: 3823858.99\n",
      "total_cost: 131037.12\n",
      "total_trades: 59352\n",
      "Sharpe: 0.864\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 784        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00913436 |\n",
      "|    clip_fraction        | 0.0669     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.7      |\n",
      "|    explained_variance   | 0.205      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.1       |\n",
      "|    n_updates            | 15080      |\n",
      "|    policy_gradient_loss | -0.00683   |\n",
      "|    reward               | 0.1054809  |\n",
      "|    std                  | 7.38       |\n",
      "|    value_loss           | 72.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 801          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077756336 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.7        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 15090        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | 1.0411538    |\n",
      "|    std                  | 7.38         |\n",
      "|    value_loss           | 59.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 819         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006826613 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 15100       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    reward               | -4.2377696  |\n",
      "|    std                  | 7.39        |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 836         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011270281 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 15110       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 1.075229    |\n",
      "|    std                  | 7.4         |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 854         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004753698 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 15120       |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 1.4041377   |\n",
      "|    std                  | 7.4         |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 872        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01080124 |\n",
      "|    clip_fraction        | 0.09       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.8      |\n",
      "|    explained_variance   | 0.528      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.7       |\n",
      "|    n_updates            | 15130      |\n",
      "|    policy_gradient_loss | -0.00702   |\n",
      "|    reward               | -0.8489861 |\n",
      "|    std                  | 7.4        |\n",
      "|    value_loss           | 69.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 890         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010090569 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.41        |\n",
      "|    n_updates            | 15140       |\n",
      "|    policy_gradient_loss | -0.00819    |\n",
      "|    reward               | 1.1269264   |\n",
      "|    std                  | 7.43        |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 908         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008076852 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 15150       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.17927842  |\n",
      "|    std                  | 7.43        |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 925          |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029112839 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -98.9        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.4         |\n",
      "|    n_updates            | 15160        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -2.6742566   |\n",
      "|    std                  | 7.43         |\n",
      "|    value_loss           | 61.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 944         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007987587 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.7         |\n",
      "|    n_updates            | 15170       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    reward               | 3.652532    |\n",
      "|    std                  | 7.43        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 962         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009541746 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | 1.7214327   |\n",
      "|    std                  | 7.45        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 980         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007019992 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 15190       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    reward               | 0.8685791   |\n",
      "|    std                  | 7.46        |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 998         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003807434 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 15200       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    reward               | 0.57354134  |\n",
      "|    std                  | 7.46        |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 1016         |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077794157 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 15210        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    reward               | -0.2465239   |\n",
      "|    std                  | 7.47         |\n",
      "|    value_loss           | 34.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3688172.08\n",
      "total_reward: 2688172.08\n",
      "total_cost: 99794.91\n",
      "total_trades: 57529\n",
      "Sharpe: 0.704\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1034        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006625644 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 15220       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | 0.34006763  |\n",
      "|    std                  | 7.47        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 1051         |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050246967 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99          |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 15230        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 1.324365     |\n",
      "|    std                  | 7.47         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1069        |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011520406 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 15240       |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    reward               | 0.20638856  |\n",
      "|    std                  | 7.48        |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1088        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009641811 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 15250       |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | 0.95597404  |\n",
      "|    std                  | 7.49        |\n",
      "|    value_loss           | 55.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1106        |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005204113 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 15260       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | 0.78948843  |\n",
      "|    std                  | 7.5         |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 1124         |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031717727 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.1        |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.5         |\n",
      "|    n_updates            | 15270        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | 2.5977926    |\n",
      "|    std                  | 7.5          |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 1141         |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077350917 |\n",
      "|    clip_fraction        | 0.0834       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.2        |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.04         |\n",
      "|    n_updates            | 15280        |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    reward               | -0.2715654   |\n",
      "|    std                  | 7.52         |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1159        |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008863449 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 15290       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    reward               | -1.1609756  |\n",
      "|    std                  | 7.53        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1177        |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008455166 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 15300       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.4269687  |\n",
      "|    std                  | 7.53        |\n",
      "|    value_loss           | 43.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 1194        |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012012027 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 15310       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -1.5597495  |\n",
      "|    std                  | 7.56        |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1212        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010972094 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 15320       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.27682233 |\n",
      "|    std                  | 7.56        |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 1230        |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007889301 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 15330       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | -4.3398094  |\n",
      "|    std                  | 7.57        |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1249        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008590996 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 15340       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 1.928683    |\n",
      "|    std                  | 7.58        |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 1267        |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006673791 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 15350       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    reward               | -0.47052634 |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 37.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1284         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059218584 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.5        |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 15360        |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    reward               | -10.973903   |\n",
      "|    std                  | 7.59         |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3732113.96\n",
      "total_reward: 2732113.96\n",
      "total_cost: 85550.12\n",
      "total_trades: 56597\n",
      "Sharpe: 0.705\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1302        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008475034 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 15370       |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    reward               | -0.66036284 |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 1320        |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014536854 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 15380       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    reward               | -1.0882785  |\n",
      "|    std                  | 7.61        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1338        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006879155 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 15390       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | 1.1181928   |\n",
      "|    std                  | 7.63        |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 1356        |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008863329 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 15400       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | 0.6950992   |\n",
      "|    std                  | 7.63        |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 1373        |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009681135 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 15410       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    reward               | 1.6035095   |\n",
      "|    std                  | 7.64        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 1391        |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009560085 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.71        |\n",
      "|    n_updates            | 15420       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    reward               | 1.150006    |\n",
      "|    std                  | 7.65        |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1409         |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028260797 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.7        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.5         |\n",
      "|    n_updates            | 15430        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -0.3333138   |\n",
      "|    std                  | 7.65         |\n",
      "|    value_loss           | 53.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1426         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074986643 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.7        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 15440        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | -0.55347496  |\n",
      "|    std                  | 7.66         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1444        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008273515 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.05        |\n",
      "|    n_updates            | 15450       |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    reward               | 0.49249834  |\n",
      "|    std                  | 7.67        |\n",
      "|    value_loss           | 23.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 1462         |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039440747 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 15460        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | -0.43631455  |\n",
      "|    std                  | 7.67         |\n",
      "|    value_loss           | 48.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 1479         |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062330537 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29           |\n",
      "|    n_updates            | 15470        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | -0.8668414   |\n",
      "|    std                  | 7.68         |\n",
      "|    value_loss           | 62.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 1497        |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011001058 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.12        |\n",
      "|    n_updates            | 15480       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    reward               | 1.0351821   |\n",
      "|    std                  | 7.68        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 1515        |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006527364 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | -0.08312318 |\n",
      "|    std                  | 7.68        |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 1532         |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070779272 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 15500        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    reward               | 4.433605     |\n",
      "|    std                  | 7.69         |\n",
      "|    value_loss           | 67.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6441395.25\n",
      "total_reward: 5441395.25\n",
      "total_cost: 122775.97\n",
      "total_trades: 59096\n",
      "Sharpe: 0.978\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1550         |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047510685 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -99.8        |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 15510        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | 2.906273     |\n",
      "|    std                  | 7.69         |\n",
      "|    value_loss           | 63.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 1568        |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009714081 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 15520       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    reward               | -0.53630716 |\n",
      "|    std                  | 7.7         |\n",
      "|    value_loss           | 74.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1586        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008457305 |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 15530       |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | -0.16700184 |\n",
      "|    std                  | 7.7         |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 1604        |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005726177 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 15540       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 0.42211387  |\n",
      "|    std                  | 7.7         |\n",
      "|    value_loss           | 97.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1622        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015014429 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.9       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 15550       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | -0.24087979 |\n",
      "|    std                  | 7.73        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 1640         |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062520355 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.4         |\n",
      "|    n_updates            | 15560        |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    reward               | -1.5063503   |\n",
      "|    std                  | 7.73         |\n",
      "|    value_loss           | 85.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1658         |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028147046 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.4         |\n",
      "|    n_updates            | 15570        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | -3.4410765   |\n",
      "|    std                  | 7.74         |\n",
      "|    value_loss           | 96.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1676        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010109898 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 15580       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    reward               | -1.3942302  |\n",
      "|    std                  | 7.73        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1694        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010075847 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.6        |\n",
      "|    n_updates            | 15590       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -0.1627802  |\n",
      "|    std                  | 7.74        |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1712        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008390958 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 15600       |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    reward               | -3.020192   |\n",
      "|    std                  | 7.76        |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1730        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010621894 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 15610       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | 0.8703191   |\n",
      "|    std                  | 7.79        |\n",
      "|    value_loss           | 57.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 1748        |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012602238 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 15620       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.347871   |\n",
      "|    std                  | 7.79        |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1766        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009704161 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -1.9105264  |\n",
      "|    std                  | 7.81        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1783        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009137318 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 15640       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    reward               | 5.66087     |\n",
      "|    std                  | 7.81        |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4403530.40\n",
      "total_reward: 3403530.40\n",
      "total_cost: 97161.43\n",
      "total_trades: 57042\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1801        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009988157 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 15650       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    reward               | -0.07079129 |\n",
      "|    std                  | 7.83        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1819        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008487471 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 15660       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -0.8927292  |\n",
      "|    std                  | 7.85        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 1837        |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007916022 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 15670       |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    reward               | 3.8207088   |\n",
      "|    std                  | 7.86        |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1855        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006558977 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 15680       |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    reward               | 0.60132056  |\n",
      "|    std                  | 7.86        |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1873        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008022307 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 15690       |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    reward               | -1.5264509  |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1890        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008358894 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 15700       |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | -0.88752997 |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 1908        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009075714 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 15710       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 1.0268484   |\n",
      "|    std                  | 7.88        |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 1926        |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010781036 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 15720       |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    reward               | -0.3598956  |\n",
      "|    std                  | 7.86        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 1944         |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038139867 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -100         |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 15730        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    reward               | 0.123485625  |\n",
      "|    std                  | 7.87         |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 1962         |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050314693 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 15740        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    reward               | 5.4403152    |\n",
      "|    std                  | 7.87         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 1980         |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028559729 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 15750        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 4.088642     |\n",
      "|    std                  | 7.87         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 1998         |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063609085 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 15760        |\n",
      "|    policy_gradient_loss | -0.0087      |\n",
      "|    reward               | -0.40407562  |\n",
      "|    std                  | 7.87         |\n",
      "|    value_loss           | 38.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 2016         |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077959346 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.8         |\n",
      "|    n_updates            | 15770        |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    reward               | 0.30947936   |\n",
      "|    std                  | 7.88         |\n",
      "|    value_loss           | 58.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 2034        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007410104 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 15780       |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    reward               | 1.802908    |\n",
      "|    std                  | 7.88        |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4296196.88\n",
      "total_reward: 3296196.88\n",
      "total_cost: 87400.73\n",
      "total_trades: 56788\n",
      "Sharpe: 0.797\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 2052        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010707474 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 15790       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | -1.6828418  |\n",
      "|    std                  | 7.92        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 2069        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008127196 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 15800       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    reward               | -1.6564292  |\n",
      "|    std                  | 7.92        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 2087         |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020424193 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 15810        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    reward               | -5.385377    |\n",
      "|    std                  | 7.93         |\n",
      "|    value_loss           | 52.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 2105        |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008448652 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 15820       |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    reward               | 0.7984838   |\n",
      "|    std                  | 7.95        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 2123        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004113888 |\n",
      "|    clip_fraction        | 0.00957     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 15830       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 0.78520757  |\n",
      "|    std                  | 7.95        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 2140        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000972063 |\n",
      "|    clip_fraction        | 0.000488    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 15840       |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    reward               | -3.2736301  |\n",
      "|    std                  | 7.95        |\n",
      "|    value_loss           | 53.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 2158        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009916818 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 15850       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | 0.097484194 |\n",
      "|    std                  | 7.96        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 2176        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008961432 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 15860       |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | 0.2131836   |\n",
      "|    std                  | 7.98        |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 2194         |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052232365 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 15870        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | 2.0709233    |\n",
      "|    std                  | 7.98         |\n",
      "|    value_loss           | 43           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 2212         |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075347126 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.8         |\n",
      "|    n_updates            | 15880        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 2.8400707    |\n",
      "|    std                  | 7.98         |\n",
      "|    value_loss           | 46.8         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 2230       |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01180134 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.12       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 15890      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    reward               | 4.7804947  |\n",
      "|    std                  | 8.01       |\n",
      "|    value_loss           | 22.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 2248        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008886814 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 15900       |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    reward               | -0.8702669  |\n",
      "|    std                  | 8.02        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 2266        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008592164 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 15910       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    reward               | -3.0107806  |\n",
      "|    std                  | 8.04        |\n",
      "|    value_loss           | 62.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 2283        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008367345 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 15920       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | 4.7375736   |\n",
      "|    std                  | 8.06        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4522972.22\n",
      "total_reward: 3522972.22\n",
      "total_cost: 100802.41\n",
      "total_trades: 57365\n",
      "Sharpe: 0.827\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 2302        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00904124  |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 15930       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -0.75273246 |\n",
      "|    std                  | 8.07        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 2319         |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061041224 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 15940        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    reward               | -0.6475526   |\n",
      "|    std                  | 8.08         |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 2337         |\n",
      "|    total_timesteps      | 268288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038550908 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 15950        |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    reward               | -2.4297173   |\n",
      "|    std                  | 8.08         |\n",
      "|    value_loss           | 94.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 2355        |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010087922 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.82        |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    reward               | 1.0125015   |\n",
      "|    std                  | 8.09        |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 2373         |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051795635 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.3         |\n",
      "|    n_updates            | 15970        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    reward               | 1.5513754    |\n",
      "|    std                  | 8.1          |\n",
      "|    value_loss           | 42.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 2391         |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062633893 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.28         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.2         |\n",
      "|    n_updates            | 15980        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 0.12602645   |\n",
      "|    std                  | 8.1          |\n",
      "|    value_loss           | 77.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 2409        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003650768 |\n",
      "|    clip_fraction        | 0.00293     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 15990       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | -1.1320659  |\n",
      "|    std                  | 8.11        |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 2427        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008664658 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | 2.0779645   |\n",
      "|    std                  | 8.12        |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 2444         |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030283015 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -101         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 16010        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | -1.0158559   |\n",
      "|    std                  | 8.13         |\n",
      "|    value_loss           | 49           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 2462        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008999687 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 16020       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -0.6702093  |\n",
      "|    std                  | 8.14        |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 2480        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011455354 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.53        |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -1.9597323  |\n",
      "|    std                  | 8.14        |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 2498         |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042091594 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 16040        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 0.6726967    |\n",
      "|    std                  | 8.15         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 2516        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005292433 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.1        |\n",
      "|    n_updates            | 16050       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    reward               | 5.411787    |\n",
      "|    std                  | 8.16        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 2534        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010272318 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 16060       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 0.21803756  |\n",
      "|    std                  | 8.2         |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6685738.09\n",
      "total_reward: 5685738.09\n",
      "total_cost: 83903.70\n",
      "total_trades: 56153\n",
      "Sharpe: 1.010\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 2551        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009943932 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 16070       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | 0.3143046   |\n",
      "|    std                  | 8.22        |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 2569        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008373765 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.5        |\n",
      "|    n_updates            | 16080       |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    reward               | 0.54913855  |\n",
      "|    std                  | 8.23        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 2587        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009223059 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 16090       |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    reward               | -3.7280304  |\n",
      "|    std                  | 8.23        |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 2605         |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097213425 |\n",
      "|    clip_fraction        | 0.0604       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.1         |\n",
      "|    n_updates            | 16100        |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    reward               | 1.4789978    |\n",
      "|    std                  | 8.24         |\n",
      "|    value_loss           | 66.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 2622         |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034803522 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 16110        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | -0.80983603  |\n",
      "|    std                  | 8.26         |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 2639       |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00604141 |\n",
      "|    clip_fraction        | 0.0275     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | 0.464      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 55.4       |\n",
      "|    n_updates            | 16120      |\n",
      "|    policy_gradient_loss | -0.0046    |\n",
      "|    reward               | 2.8957918  |\n",
      "|    std                  | 8.26       |\n",
      "|    value_loss           | 132        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 2657        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008584123 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    reward               | 0.67018723  |\n",
      "|    std                  | 8.27        |\n",
      "|    value_loss           | 44.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 2674         |\n",
      "|    total_timesteps      | 307200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024548296 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.7         |\n",
      "|    n_updates            | 16140        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 0.29357782   |\n",
      "|    std                  | 8.28         |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 2692         |\n",
      "|    total_timesteps      | 309248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014389828 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.3         |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    reward               | -1.4074218   |\n",
      "|    std                  | 8.28         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 2710        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009423416 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 16160       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | -1.4851211  |\n",
      "|    std                  | 8.28        |\n",
      "|    value_loss           | 54.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 2727        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008341616 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | -0.54527307 |\n",
      "|    std                  | 8.27        |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 2744        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009775858 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 16180       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.0067899  |\n",
      "|    std                  | 8.27        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 2762         |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074941167 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 16190        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    reward               | -4.1784754   |\n",
      "|    std                  | 8.27         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2779        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013030226 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 16200       |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    reward               | -0.5879572  |\n",
      "|    std                  | 8.28        |\n",
      "|    value_loss           | 25.7        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6584181.84\n",
      "total_reward: 5584181.84\n",
      "total_cost: 122898.52\n",
      "total_trades: 58535\n",
      "Sharpe: 0.933\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 157          |\n",
      "|    time_elapsed         | 2797         |\n",
      "|    total_timesteps      | 321536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035326076 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.5         |\n",
      "|    n_updates            | 16210        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | -0.91863996  |\n",
      "|    std                  | 8.27         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 2815        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002708348 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 73.8        |\n",
      "|    n_updates            | 16220       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | -10.911574  |\n",
      "|    std                  | 8.28        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 2833         |\n",
      "|    total_timesteps      | 325632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091199335 |\n",
      "|    clip_fraction        | 0.0869       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 16230        |\n",
      "|    policy_gradient_loss | -0.00813     |\n",
      "|    reward               | -3.6384945   |\n",
      "|    std                  | 8.28         |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 2850         |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076574786 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 16240        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    reward               | 0.70867205   |\n",
      "|    std                  | 8.29         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 2868         |\n",
      "|    total_timesteps      | 329728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026179668 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 16250        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    reward               | 27.613003    |\n",
      "|    std                  | 8.29         |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 162          |\n",
      "|    time_elapsed         | 2886         |\n",
      "|    total_timesteps      | 331776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033809012 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 208          |\n",
      "|    n_updates            | 16260        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    reward               | -0.35461816  |\n",
      "|    std                  | 8.29         |\n",
      "|    value_loss           | 290          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 2904        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005703955 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.228      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    reward               | 1.6905451   |\n",
      "|    std                  | 8.3         |\n",
      "|    value_loss           | 84.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 164          |\n",
      "|    time_elapsed         | 2922         |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020909929 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.1         |\n",
      "|    n_updates            | 16280        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 0.112832494  |\n",
      "|    std                  | 8.3          |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 2940         |\n",
      "|    total_timesteps      | 337920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025436534 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 16290        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 2.5673077    |\n",
      "|    std                  | 8.3          |\n",
      "|    value_loss           | 227          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 2958         |\n",
      "|    total_timesteps      | 339968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073278816 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 16300        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | 5.3299084    |\n",
      "|    std                  | 8.32         |\n",
      "|    value_loss           | 62           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 2976        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007031429 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 1.0588735   |\n",
      "|    std                  | 8.33        |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 2994        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005452938 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 93.4        |\n",
      "|    n_updates            | 16320       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | -0.694336   |\n",
      "|    std                  | 8.33        |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 3012        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005386534 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.4        |\n",
      "|    n_updates            | 16330       |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | -3.97113    |\n",
      "|    std                  | 8.33        |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 3030         |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077559743 |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 16340        |\n",
      "|    policy_gradient_loss | -0.007       |\n",
      "|    reward               | -1.836913    |\n",
      "|    std                  | 8.35         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7710863.61\n",
      "total_reward: 6710863.61\n",
      "total_cost: 116594.54\n",
      "total_trades: 58348\n",
      "Sharpe: 0.965\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 3048         |\n",
      "|    total_timesteps      | 350208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053440747 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.1         |\n",
      "|    n_updates            | 16350        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | -0.6838121   |\n",
      "|    std                  | 8.36         |\n",
      "|    value_loss           | 221          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 3066        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007612952 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 16360       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 3.0758815   |\n",
      "|    std                  | 8.36        |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 3084        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011845943 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | 0.09217166  |\n",
      "|    std                  | 8.36        |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 3102         |\n",
      "|    total_timesteps      | 356352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063089966 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 16380        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 0.6317138    |\n",
      "|    std                  | 8.36         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 3120         |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075023137 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 16390        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | -3.4048197   |\n",
      "|    std                  | 8.36         |\n",
      "|    value_loss           | 268          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 176          |\n",
      "|    time_elapsed         | 3138         |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076051317 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67           |\n",
      "|    n_updates            | 16400        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | -1.6794652   |\n",
      "|    std                  | 8.36         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 3155         |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099501535 |\n",
      "|    clip_fraction        | 0.0678       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 16410        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    reward               | 1.035271     |\n",
      "|    std                  | 8.38         |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 3174         |\n",
      "|    total_timesteps      | 364544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061498587 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 16420        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    reward               | -0.9922281   |\n",
      "|    std                  | 8.39         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 3193         |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070571275 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 254          |\n",
      "|    n_updates            | 16430        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | 0.0032532134 |\n",
      "|    std                  | 8.39         |\n",
      "|    value_loss           | 289          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 3211        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009446131 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | 1.3861378   |\n",
      "|    std                  | 8.41        |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 3230        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003913535 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 16450       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | -0.26445273 |\n",
      "|    std                  | 8.41        |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 3249         |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031900508 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -5.5932074   |\n",
      "|    std                  | 8.41         |\n",
      "|    value_loss           | 230          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 3267        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007824998 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 16470       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | 0.06462791  |\n",
      "|    std                  | 8.42        |\n",
      "|    value_loss           | 53.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 3285         |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026632284 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.5         |\n",
      "|    n_updates            | 16480        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -1.4547523   |\n",
      "|    std                  | 8.43         |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 3303        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002365875 |\n",
      "|    clip_fraction        | 0.00347     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 76.3        |\n",
      "|    n_updates            | 16490       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 9.418129    |\n",
      "|    std                  | 8.43        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7295957.40\n",
      "total_reward: 6295957.40\n",
      "total_cost: 108562.12\n",
      "total_trades: 57430\n",
      "Sharpe: 1.000\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 3321        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007845797 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.2        |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    reward               | -2.2196126  |\n",
      "|    std                  | 8.44        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 3339         |\n",
      "|    total_timesteps      | 382976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103587955 |\n",
      "|    clip_fraction        | 0.0791       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 16510        |\n",
      "|    policy_gradient_loss | -0.00905     |\n",
      "|    reward               | -0.37278637  |\n",
      "|    std                  | 8.45         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 3357         |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037821168 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 16520        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | 0.8929447    |\n",
      "|    std                  | 8.46         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 3375         |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020157904 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 136          |\n",
      "|    n_updates            | 16530        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | -9.00373     |\n",
      "|    std                  | 8.46         |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 3392        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012345699 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 2.8557422   |\n",
      "|    std                  | 8.51        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 3410         |\n",
      "|    total_timesteps      | 391168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039217947 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.5         |\n",
      "|    n_updates            | 16550        |\n",
      "|    policy_gradient_loss | -0.00773     |\n",
      "|    reward               | 0.43581134   |\n",
      "|    std                  | 8.52         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 3429        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006172394 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | -9.354512   |\n",
      "|    std                  | 8.53        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 3449        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009402903 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    reward               | -0.8161733  |\n",
      "|    std                  | 8.54        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 3467         |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012277292  |\n",
      "|    clip_fraction        | 0.0999       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 16580        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    reward               | -0.052989647 |\n",
      "|    std                  | 8.57         |\n",
      "|    value_loss           | 73.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 3485         |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070238532 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    reward               | 0.38682923   |\n",
      "|    std                  | 8.57         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 3503        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005956526 |\n",
      "|    clip_fraction        | 0.0252      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.1        |\n",
      "|    n_updates            | 16600       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 1.4004405   |\n",
      "|    std                  | 8.58        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 197        |\n",
      "|    time_elapsed         | 3521       |\n",
      "|    total_timesteps      | 403456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00931551 |\n",
      "|    clip_fraction        | 0.0847     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | -0.136     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 16610      |\n",
      "|    policy_gradient_loss | -0.00531   |\n",
      "|    reward               | -0.9148957 |\n",
      "|    std                  | 8.6        |\n",
      "|    value_loss           | 25.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 3539        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006647734 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | 0.17604443  |\n",
      "|    std                  | 8.61        |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 3557       |\n",
      "|    total_timesteps      | 407552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00723063 |\n",
      "|    clip_fraction        | 0.0655     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.539      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30         |\n",
      "|    n_updates            | 16630      |\n",
      "|    policy_gradient_loss | -0.00782   |\n",
      "|    reward               | 1.0119203  |\n",
      "|    std                  | 8.63       |\n",
      "|    value_loss           | 84.3       |\n",
      "----------------------------------------\n",
      "day: 2892, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5554832.79\n",
      "total_reward: 4554832.79\n",
      "total_cost: 93524.30\n",
      "total_trades: 56199\n",
      "Sharpe: 0.924\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 3575        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008026937 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 16640       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 2.7129717   |\n",
      "|    std                  | 8.64        |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 3593        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009053966 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | -0.35410732 |\n",
      "|    std                  | 8.67        |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 3611        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007050285 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 16660       |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    reward               | -10.920803  |\n",
      "|    std                  | 8.67        |\n",
      "|    value_loss           | 77.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 3629        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004737483 |\n",
      "|    clip_fraction        | 0.00835     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.7        |\n",
      "|    n_updates            | 16670       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | -0.8327844  |\n",
      "|    std                  | 8.68        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 3647        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01135448  |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 16680       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -0.07293929 |\n",
      "|    std                  | 8.67        |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 3666         |\n",
      "|    total_timesteps      | 419840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025016791 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.5         |\n",
      "|    n_updates            | 16690        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | 2.0021641    |\n",
      "|    std                  | 8.68         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 3684        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007548468 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.8        |\n",
      "|    n_updates            | 16700       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | -0.2332789  |\n",
      "|    std                  | 8.7         |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 3702         |\n",
      "|    total_timesteps      | 423936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103880875 |\n",
      "|    clip_fraction        | 0.0966       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 16710        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | -2.8300147   |\n",
      "|    std                  | 8.71         |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 3720         |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040332684 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -103         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.8         |\n",
      "|    n_updates            | 16720        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | -1.6105583   |\n",
      "|    std                  | 8.71         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 3738        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004277901 |\n",
      "|    clip_fraction        | 0.00786     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.6        |\n",
      "|    n_updates            | 16730       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 2.3344502   |\n",
      "|    std                  | 8.72        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 3756         |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030293227 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.6         |\n",
      "|    n_updates            | 16740        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -1.1848325   |\n",
      "|    std                  | 8.73         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 3775        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009206165 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 16750       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    reward               | 2.8766713   |\n",
      "|    std                  | 8.75        |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 212          |\n",
      "|    time_elapsed         | 3793         |\n",
      "|    total_timesteps      | 434176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060988646 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 245          |\n",
      "|    n_updates            | 16760        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    reward               | 0.045179695  |\n",
      "|    std                  | 8.76         |\n",
      "|    value_loss           | 273          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 213          |\n",
      "|    time_elapsed         | 3811         |\n",
      "|    total_timesteps      | 436224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043673986 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 16770        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | -0.34759936  |\n",
      "|    std                  | 8.77         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6315885.70\n",
      "total_reward: 5315885.70\n",
      "total_cost: 114351.24\n",
      "total_trades: 57647\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 3829        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010297499 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.223       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    reward               | -2.2385385  |\n",
      "|    std                  | 8.79        |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 215          |\n",
      "|    time_elapsed         | 3847         |\n",
      "|    total_timesteps      | 440320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032867908 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.9         |\n",
      "|    n_updates            | 16790        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | 0.57242215   |\n",
      "|    std                  | 8.79         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 3865        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001645524 |\n",
      "|    clip_fraction        | 0.00381     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 16800       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | 0.97644895  |\n",
      "|    std                  | 8.8         |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 3883        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004294609 |\n",
      "|    clip_fraction        | 0.00942     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | 3.1058702   |\n",
      "|    std                  | 8.8         |\n",
      "|    value_loss           | 80.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 3901        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003341036 |\n",
      "|    clip_fraction        | 0.00513     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.3        |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 1.1990201   |\n",
      "|    std                  | 8.81        |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 219           |\n",
      "|    time_elapsed         | 3920          |\n",
      "|    total_timesteps      | 448512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079201965 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -104          |\n",
      "|    explained_variance   | 0.533         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.9          |\n",
      "|    n_updates            | 16830         |\n",
      "|    policy_gradient_loss | -0.000819     |\n",
      "|    reward               | -0.10814363   |\n",
      "|    std                  | 8.81          |\n",
      "|    value_loss           | 144           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 3937         |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012500248 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.8         |\n",
      "|    n_updates            | 16840        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 4.3567467    |\n",
      "|    std                  | 8.82         |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 3956        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00744514  |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 16850       |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | -0.36428177 |\n",
      "|    std                  | 8.82        |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 3974        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006123184 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.5        |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | -0.37738472 |\n",
      "|    std                  | 8.82        |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 3992         |\n",
      "|    total_timesteps      | 456704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033937027 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 16870        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | 3.8989656    |\n",
      "|    std                  | 8.83         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 4010        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007783154 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 16880       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    reward               | 1.9341412   |\n",
      "|    std                  | 8.84        |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 225          |\n",
      "|    time_elapsed         | 4028         |\n",
      "|    total_timesteps      | 460800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066621285 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.6         |\n",
      "|    n_updates            | 16890        |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    reward               | 1.6922923    |\n",
      "|    std                  | 8.85         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 226           |\n",
      "|    time_elapsed         | 4046          |\n",
      "|    total_timesteps      | 462848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045109302 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -104          |\n",
      "|    explained_variance   | 0.372         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 89.2          |\n",
      "|    n_updates            | 16900         |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    reward               | 13.139852     |\n",
      "|    std                  | 8.85          |\n",
      "|    value_loss           | 184           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 227           |\n",
      "|    time_elapsed         | 4064          |\n",
      "|    total_timesteps      | 464896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076536305 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -104          |\n",
      "|    explained_variance   | 0.13          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 39.8          |\n",
      "|    n_updates            | 16910         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | -2.5761347    |\n",
      "|    std                  | 8.85          |\n",
      "|    value_loss           | 153           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6008367.93\n",
      "total_reward: 5008367.93\n",
      "total_cost: 99663.33\n",
      "total_trades: 56471\n",
      "Sharpe: 0.929\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 4082        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010240283 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.56        |\n",
      "|    n_updates            | 16920       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.2496465   |\n",
      "|    std                  | 8.87        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 4100         |\n",
      "|    total_timesteps      | 468992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019689621 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43           |\n",
      "|    n_updates            | 16930        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -0.1683485   |\n",
      "|    std                  | 8.87         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 230          |\n",
      "|    time_elapsed         | 4118         |\n",
      "|    total_timesteps      | 471040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015609437 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.8         |\n",
      "|    n_updates            | 16940        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | 3.1361365    |\n",
      "|    std                  | 8.88         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 4136        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011086199 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    reward               | -8.570965   |\n",
      "|    std                  | 8.91        |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 232          |\n",
      "|    time_elapsed         | 4154         |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014245708 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.2         |\n",
      "|    n_updates            | 16960        |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    reward               | 0.5239861    |\n",
      "|    std                  | 8.91         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 4171         |\n",
      "|    total_timesteps      | 477184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036897953 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.4         |\n",
      "|    n_updates            | 16970        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | -2.1397552   |\n",
      "|    std                  | 8.92         |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 4189         |\n",
      "|    total_timesteps      | 479232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047874935 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 16980        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | 1.8643278    |\n",
      "|    std                  | 8.94         |\n",
      "|    value_loss           | 62.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 235          |\n",
      "|    time_elapsed         | 4207         |\n",
      "|    total_timesteps      | 481280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102618225 |\n",
      "|    clip_fraction        | 0.095        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 16990        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    reward               | -1.7507387   |\n",
      "|    std                  | 8.96         |\n",
      "|    value_loss           | 45.5         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 236        |\n",
      "|    time_elapsed         | 4225       |\n",
      "|    total_timesteps      | 483328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00703015 |\n",
      "|    clip_fraction        | 0.0383     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | 0.477      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 45.1       |\n",
      "|    n_updates            | 17000      |\n",
      "|    policy_gradient_loss | -0.00537   |\n",
      "|    reward               | 0.9878292  |\n",
      "|    std                  | 8.96       |\n",
      "|    value_loss           | 83.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 237          |\n",
      "|    time_elapsed         | 4242         |\n",
      "|    total_timesteps      | 485376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020189309 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 17010        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | 0.8881949    |\n",
      "|    std                  | 8.97         |\n",
      "|    value_loss           | 87.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 4260        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012018478 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | -0.43697774 |\n",
      "|    std                  | 8.96        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 4277         |\n",
      "|    total_timesteps      | 489472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043925187 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -104         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.4         |\n",
      "|    n_updates            | 17030        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    reward               | 0.5553548    |\n",
      "|    std                  | 8.98         |\n",
      "|    value_loss           | 58.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 4295        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005311949 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.351       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 17040       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    reward               | -2.8751755  |\n",
      "|    std                  | 8.99        |\n",
      "|    value_loss           | 71.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 4312        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007165729 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | -0.34426957 |\n",
      "|    std                  | 9.01        |\n",
      "|    value_loss           | 46.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4734219.28\n",
      "total_reward: 3734219.28\n",
      "total_cost: 67921.05\n",
      "total_trades: 54243\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 4330        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011206803 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 17060       |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    reward               | -1.6816291  |\n",
      "|    std                  | 9.02        |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 4347        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012034798 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 17070       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 0.039864607 |\n",
      "|    std                  | 9.04        |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 4365        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008070613 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | 0.48324618  |\n",
      "|    std                  | 9.05        |\n",
      "|    value_loss           | 72.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 4383        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009973206 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.93        |\n",
      "|    n_updates            | 17090       |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    reward               | -1.210317   |\n",
      "|    std                  | 9.09        |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 246          |\n",
      "|    time_elapsed         | 4400         |\n",
      "|    total_timesteps      | 503808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048240186 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.4         |\n",
      "|    n_updates            | 17100        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    reward               | 1.179161     |\n",
      "|    std                  | 9.1          |\n",
      "|    value_loss           | 74.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 4418         |\n",
      "|    total_timesteps      | 505856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058688186 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 17110        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | 8.208202     |\n",
      "|    std                  | 9.1          |\n",
      "|    value_loss           | 84.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 248        |\n",
      "|    time_elapsed         | 4436       |\n",
      "|    total_timesteps      | 507904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00812762 |\n",
      "|    clip_fraction        | 0.0418     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.482      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 20.6       |\n",
      "|    n_updates            | 17120      |\n",
      "|    policy_gradient_loss | -0.00729   |\n",
      "|    reward               | -1.4730754 |\n",
      "|    std                  | 9.13       |\n",
      "|    value_loss           | 45.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 249        |\n",
      "|    time_elapsed         | 4453       |\n",
      "|    total_timesteps      | 509952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00797726 |\n",
      "|    clip_fraction        | 0.049      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.594      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.1       |\n",
      "|    n_updates            | 17130      |\n",
      "|    policy_gradient_loss | -0.00777   |\n",
      "|    reward               | 0.5337524  |\n",
      "|    std                  | 9.15       |\n",
      "|    value_loss           | 49.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 250          |\n",
      "|    time_elapsed         | 4471         |\n",
      "|    total_timesteps      | 512000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036427674 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.9         |\n",
      "|    n_updates            | 17140        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -2.4413786   |\n",
      "|    std                  | 9.15         |\n",
      "|    value_loss           | 81.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 4488         |\n",
      "|    total_timesteps      | 514048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041521536 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 17150        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 5.0970926    |\n",
      "|    std                  | 9.16         |\n",
      "|    value_loss           | 81.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 4506        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007782094 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 17160       |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    reward               | -0.3619165  |\n",
      "|    std                  | 9.17        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 253          |\n",
      "|    time_elapsed         | 4523         |\n",
      "|    total_timesteps      | 518144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038667629 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 17170        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.38189003   |\n",
      "|    std                  | 9.19         |\n",
      "|    value_loss           | 91.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 254          |\n",
      "|    time_elapsed         | 4541         |\n",
      "|    total_timesteps      | 520192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058126925 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.3         |\n",
      "|    n_updates            | 17180        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    reward               | -0.400773    |\n",
      "|    std                  | 9.2          |\n",
      "|    value_loss           | 86.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 4558        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008178295 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 4.01986     |\n",
      "|    std                  | 9.2         |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4993048.74\n",
      "total_reward: 3993048.74\n",
      "total_cost: 84067.29\n",
      "total_trades: 55803\n",
      "Sharpe: 0.872\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 256          |\n",
      "|    time_elapsed         | 4576         |\n",
      "|    total_timesteps      | 524288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070588314 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 17200        |\n",
      "|    policy_gradient_loss | -0.00839     |\n",
      "|    reward               | 4.3158464    |\n",
      "|    std                  | 9.22         |\n",
      "|    value_loss           | 68.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 257          |\n",
      "|    time_elapsed         | 4594         |\n",
      "|    total_timesteps      | 526336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026637912 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.9         |\n",
      "|    n_updates            | 17210        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    reward               | 3.194417     |\n",
      "|    std                  | 9.23         |\n",
      "|    value_loss           | 84.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 4612        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009946627 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | 1.3851604   |\n",
      "|    std                  | 9.24        |\n",
      "|    value_loss           | 58.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 259          |\n",
      "|    time_elapsed         | 4629         |\n",
      "|    total_timesteps      | 530432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099247275 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.6         |\n",
      "|    n_updates            | 17230        |\n",
      "|    policy_gradient_loss | -0.00965     |\n",
      "|    reward               | 0.5136014    |\n",
      "|    std                  | 9.27         |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 4647        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00501467  |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 17240       |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | -0.33626762 |\n",
      "|    std                  | 9.28        |\n",
      "|    value_loss           | 86.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 261          |\n",
      "|    time_elapsed         | 4665         |\n",
      "|    total_timesteps      | 534528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077731656 |\n",
      "|    clip_fraction        | 0.0831       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    reward               | 2.6977336    |\n",
      "|    std                  | 9.3          |\n",
      "|    value_loss           | 82.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 4682       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01037422 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.313      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 17260      |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    reward               | 0.895798   |\n",
      "|    std                  | 9.33       |\n",
      "|    value_loss           | 28.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 4700        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004887148 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | 0.24858706  |\n",
      "|    std                  | 9.34        |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 264          |\n",
      "|    time_elapsed         | 4718         |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012644471 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -105         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.1         |\n",
      "|    n_updates            | 17280        |\n",
      "|    policy_gradient_loss | -0.000921    |\n",
      "|    reward               | -2.905427    |\n",
      "|    std                  | 9.34         |\n",
      "|    value_loss           | 82.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 4736        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015918102 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 17290       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -6.1620274  |\n",
      "|    std                  | 9.36        |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 4753        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010479698 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.4954556   |\n",
      "|    std                  | 9.36        |\n",
      "|    value_loss           | 54.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 4771        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008778283 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | -0.70876974 |\n",
      "|    std                  | 9.38        |\n",
      "|    value_loss           | 99.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 4789        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009728169 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 69.1        |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | 0.06474524  |\n",
      "|    std                  | 9.39        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 4807        |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011671927 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.77        |\n",
      "|    n_updates            | 17330       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | -0.22297163 |\n",
      "|    std                  | 9.44        |\n",
      "|    value_loss           | 17.6        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5225208.41\n",
      "total_reward: 4225208.41\n",
      "total_cost: 70371.46\n",
      "total_trades: 54548\n",
      "Sharpe: 0.911\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 4825         |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018022421 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 17340        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    reward               | 1.6265345    |\n",
      "|    std                  | 9.44         |\n",
      "|    value_loss           | 56.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 271          |\n",
      "|    time_elapsed         | 4842         |\n",
      "|    total_timesteps      | 555008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018652924 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 17350        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -0.1081873   |\n",
      "|    std                  | 9.45         |\n",
      "|    value_loss           | 65.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 4860         |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027062665 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 17360        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | -2.7352178   |\n",
      "|    std                  | 9.45         |\n",
      "|    value_loss           | 40.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 4877         |\n",
      "|    total_timesteps      | 559104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049528903 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.4         |\n",
      "|    n_updates            | 17370        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    reward               | -0.44713554  |\n",
      "|    std                  | 9.46         |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 4894        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000542306 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    reward               | -10.436986  |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 54.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 4912         |\n",
      "|    total_timesteps      | 563200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034573972 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 17390        |\n",
      "|    policy_gradient_loss | -0.000808    |\n",
      "|    reward               | 0.54791677   |\n",
      "|    std                  | 9.46         |\n",
      "|    value_loss           | 48.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 4930        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005555807 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | 3.530447    |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 33          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 4947        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002855935 |\n",
      "|    clip_fraction        | 0.00562     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 17410       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    reward               | 0.23706268  |\n",
      "|    std                  | 9.5         |\n",
      "|    value_loss           | 48.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 4965         |\n",
      "|    total_timesteps      | 569344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059183277 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 17420        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | 4.9173055    |\n",
      "|    std                  | 9.51         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 4982        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009040475 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 17430       |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    reward               | 0.47421014  |\n",
      "|    std                  | 9.52        |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 280          |\n",
      "|    time_elapsed         | 5000         |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074221883 |\n",
      "|    clip_fraction        | 0.0517       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.1         |\n",
      "|    n_updates            | 17440        |\n",
      "|    policy_gradient_loss | -0.00762     |\n",
      "|    reward               | 1.475227     |\n",
      "|    std                  | 9.52         |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 281          |\n",
      "|    time_elapsed         | 5017         |\n",
      "|    total_timesteps      | 575488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015365832 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.8         |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | 6.4512234    |\n",
      "|    std                  | 9.52         |\n",
      "|    value_loss           | 69.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 282          |\n",
      "|    time_elapsed         | 5034         |\n",
      "|    total_timesteps      | 577536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052927416 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 17460        |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | -1.9485049   |\n",
      "|    std                  | 9.53         |\n",
      "|    value_loss           | 57           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 5052        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00372094  |\n",
      "|    clip_fraction        | 0.0082      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | -0.30433097 |\n",
      "|    std                  | 9.53        |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6085788.78\n",
      "total_reward: 5085788.78\n",
      "total_cost: 91839.17\n",
      "total_trades: 56483\n",
      "Sharpe: 0.979\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 284          |\n",
      "|    time_elapsed         | 5070         |\n",
      "|    total_timesteps      | 581632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017234852 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 17480        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 1.2417583    |\n",
      "|    std                  | 9.55         |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 285          |\n",
      "|    time_elapsed         | 5087         |\n",
      "|    total_timesteps      | 583680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012814698 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.328        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.5         |\n",
      "|    n_updates            | 17490        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    reward               | -1.0380341   |\n",
      "|    std                  | 9.55         |\n",
      "|    value_loss           | 83.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 5105        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006956308 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | -1.5894336  |\n",
      "|    std                  | 9.56        |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 5123        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001253969 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 17510       |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    reward               | -0.22644885 |\n",
      "|    std                  | 9.56        |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 5140         |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047492897 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 17520        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | 4.880861     |\n",
      "|    std                  | 9.56         |\n",
      "|    value_loss           | 61.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 5158        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008072401 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | 2.8302035   |\n",
      "|    std                  | 9.59        |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 5175        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005683521 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 17540       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 1.8287237   |\n",
      "|    std                  | 9.61        |\n",
      "|    value_loss           | 43          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 5193        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007420199 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 17550       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    reward               | 0.08117282  |\n",
      "|    std                  | 9.63        |\n",
      "|    value_loss           | 71.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 5210        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006542584 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.5        |\n",
      "|    n_updates            | 17560       |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    reward               | 1.6278194   |\n",
      "|    std                  | 9.63        |\n",
      "|    value_loss           | 72.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 5229        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012477973 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.28        |\n",
      "|    n_updates            | 17570       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 1.778572    |\n",
      "|    std                  | 9.63        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 5247         |\n",
      "|    total_timesteps      | 602112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026903707 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 17580        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -0.6810732   |\n",
      "|    std                  | 9.64         |\n",
      "|    value_loss           | 50.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 5265         |\n",
      "|    total_timesteps      | 604160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034790887 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.2         |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | 1.585327     |\n",
      "|    std                  | 9.65         |\n",
      "|    value_loss           | 59.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 5282        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009173459 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 17600       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -3.6456478  |\n",
      "|    std                  | 9.66        |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 5301        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003146896 |\n",
      "|    clip_fraction        | 0.00508     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    reward               | -0.25222617 |\n",
      "|    std                  | 9.67        |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 298          |\n",
      "|    time_elapsed         | 5318         |\n",
      "|    total_timesteps      | 610304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014653247 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 17620        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -3.7501655   |\n",
      "|    std                  | 9.68         |\n",
      "|    value_loss           | 71.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4821644.94\n",
      "total_reward: 3821644.94\n",
      "total_cost: 88916.25\n",
      "total_trades: 55637\n",
      "Sharpe: 0.884\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 5336         |\n",
      "|    total_timesteps      | 612352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022711775 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 17630        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | 0.2796409    |\n",
      "|    std                  | 9.68         |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 5354        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010049038 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    reward               | 0.99359834  |\n",
      "|    std                  | 9.68        |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 301          |\n",
      "|    time_elapsed         | 5372         |\n",
      "|    total_timesteps      | 616448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027359119 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 17650        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 0.48140624   |\n",
      "|    std                  | 9.69         |\n",
      "|    value_loss           | 61.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 302          |\n",
      "|    time_elapsed         | 5390         |\n",
      "|    total_timesteps      | 618496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028722417 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 17660        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    reward               | -7.3526473   |\n",
      "|    std                  | 9.69         |\n",
      "|    value_loss           | 76           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 5408        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013073487 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 17670       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -3.1085112  |\n",
      "|    std                  | 9.69        |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 5425        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003859025 |\n",
      "|    clip_fraction        | 0.00522     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    reward               | -0.47488037 |\n",
      "|    std                  | 9.69        |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 5443         |\n",
      "|    total_timesteps      | 624640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038119243 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.7         |\n",
      "|    n_updates            | 17690        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | -0.33457845  |\n",
      "|    std                  | 9.7          |\n",
      "|    value_loss           | 65.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 306          |\n",
      "|    time_elapsed         | 5461         |\n",
      "|    total_timesteps      | 626688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072909947 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 17700        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    reward               | -1.482459    |\n",
      "|    std                  | 9.7          |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 5479        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009379817 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.13441974 |\n",
      "|    std                  | 9.7         |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 308          |\n",
      "|    time_elapsed         | 5497         |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033377353 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 17720        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | -0.010091667 |\n",
      "|    std                  | 9.71         |\n",
      "|    value_loss           | 48.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 5515        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005865974 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 17730       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | 1.6606678   |\n",
      "|    std                  | 9.72        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 5533        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008597523 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.75        |\n",
      "|    n_updates            | 17740       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    reward               | 0.6100902   |\n",
      "|    std                  | 9.73        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 5550        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001385508 |\n",
      "|    clip_fraction        | 0.000488    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    reward               | -0.02340285 |\n",
      "|    std                  | 9.73        |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 5568         |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024237586 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 17760        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 0.96501094   |\n",
      "|    std                  | 9.74         |\n",
      "|    value_loss           | 52           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5415011.41\n",
      "total_reward: 4415011.41\n",
      "total_cost: 84771.56\n",
      "total_trades: 55550\n",
      "Sharpe: 0.949\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 5586        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008368904 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 17770       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | -8.716169   |\n",
      "|    std                  | 9.75        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 5604         |\n",
      "|    total_timesteps      | 643072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070089134 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 17780        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    reward               | -0.25050336  |\n",
      "|    std                  | 9.78         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 315        |\n",
      "|    time_elapsed         | 5622       |\n",
      "|    total_timesteps      | 645120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00794763 |\n",
      "|    clip_fraction        | 0.0273     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19.1       |\n",
      "|    n_updates            | 17790      |\n",
      "|    policy_gradient_loss | -0.0047    |\n",
      "|    reward               | -5.3319902 |\n",
      "|    std                  | 9.79       |\n",
      "|    value_loss           | 48.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 316        |\n",
      "|    time_elapsed         | 5640       |\n",
      "|    total_timesteps      | 647168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00447259 |\n",
      "|    clip_fraction        | 0.0101     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 31.3       |\n",
      "|    n_updates            | 17800      |\n",
      "|    policy_gradient_loss | -0.00628   |\n",
      "|    reward               | -1.5636668 |\n",
      "|    std                  | 9.79       |\n",
      "|    value_loss           | 54.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 5657        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012803698 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.64        |\n",
      "|    n_updates            | 17810       |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    reward               | 0.89695126  |\n",
      "|    std                  | 9.82        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 318          |\n",
      "|    time_elapsed         | 5675         |\n",
      "|    total_timesteps      | 651264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035021035 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 17820        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | 4.2078204    |\n",
      "|    std                  | 9.83         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 319          |\n",
      "|    time_elapsed         | 5692         |\n",
      "|    total_timesteps      | 653312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022845333 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 17830        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 0.28397286   |\n",
      "|    std                  | 9.84         |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 320          |\n",
      "|    time_elapsed         | 5710         |\n",
      "|    total_timesteps      | 655360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057468107 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24           |\n",
      "|    n_updates            | 17840        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | -6.0538254   |\n",
      "|    std                  | 9.84         |\n",
      "|    value_loss           | 45.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 5728        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007169693 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | 1.4885802   |\n",
      "|    std                  | 9.86        |\n",
      "|    value_loss           | 66.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 5746         |\n",
      "|    total_timesteps      | 659456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044639446 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 17860        |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    reward               | 2.83622      |\n",
      "|    std                  | 9.87         |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 323          |\n",
      "|    time_elapsed         | 5764         |\n",
      "|    total_timesteps      | 661504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048681498 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.1         |\n",
      "|    n_updates            | 17870        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | -2.6415918   |\n",
      "|    std                  | 9.89         |\n",
      "|    value_loss           | 82.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 324          |\n",
      "|    time_elapsed         | 5782         |\n",
      "|    total_timesteps      | 663552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017851831 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 17880        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -1.3211378   |\n",
      "|    std                  | 9.89         |\n",
      "|    value_loss           | 70.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 325          |\n",
      "|    time_elapsed         | 5800         |\n",
      "|    total_timesteps      | 665600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055933977 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.6         |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | -0.00773     |\n",
      "|    reward               | 0.54780287   |\n",
      "|    std                  | 9.9          |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 5817        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007412537 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.3        |\n",
      "|    n_updates            | 17900       |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | 2.0038805   |\n",
      "|    std                  | 9.93        |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6223394.66\n",
      "total_reward: 5223394.66\n",
      "total_cost: 103065.02\n",
      "total_trades: 56694\n",
      "Sharpe: 0.987\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 114       |\n",
      "|    iterations           | 327       |\n",
      "|    time_elapsed         | 5835      |\n",
      "|    total_timesteps      | 669696    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0085669 |\n",
      "|    clip_fraction        | 0.0424    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -107      |\n",
      "|    explained_variance   | 0.345     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 13.6      |\n",
      "|    n_updates            | 17910     |\n",
      "|    policy_gradient_loss | -0.0092   |\n",
      "|    reward               | 1.5405774 |\n",
      "|    std                  | 9.95      |\n",
      "|    value_loss           | 33.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 5852        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002332651 |\n",
      "|    clip_fraction        | 0.00225     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.5        |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    reward               | 0.15571506  |\n",
      "|    std                  | 9.95        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 5870         |\n",
      "|    total_timesteps      | 673792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026291185 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.3         |\n",
      "|    n_updates            | 17930        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -3.1907456   |\n",
      "|    std                  | 9.96         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 5888        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003709742 |\n",
      "|    clip_fraction        | 0.00415     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    reward               | -2.4850702  |\n",
      "|    std                  | 9.96        |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 5906        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007316501 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | -0.30604672 |\n",
      "|    std                  | 9.98        |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 5924         |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033295322 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 17960        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | -0.56676376  |\n",
      "|    std                  | 9.99         |\n",
      "|    value_loss           | 78           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 333           |\n",
      "|    time_elapsed         | 5942          |\n",
      "|    total_timesteps      | 681984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011595542 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -107          |\n",
      "|    explained_variance   | 0.551         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.8          |\n",
      "|    n_updates            | 17970         |\n",
      "|    policy_gradient_loss | -0.000756     |\n",
      "|    reward               | 4.9032536     |\n",
      "|    std                  | 9.99          |\n",
      "|    value_loss           | 89.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 5960        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009957217 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | -0.20845589 |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 5977         |\n",
      "|    total_timesteps      | 686080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075704996 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.9         |\n",
      "|    n_updates            | 17990        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    reward               | -0.34249592  |\n",
      "|    std                  | 10           |\n",
      "|    value_loss           | 233          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 336          |\n",
      "|    time_elapsed         | 5995         |\n",
      "|    total_timesteps      | 688128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033512511 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 151          |\n",
      "|    n_updates            | 18000        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | -3.1926496   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 267          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 337        |\n",
      "|    time_elapsed         | 6013       |\n",
      "|    total_timesteps      | 690176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00209981 |\n",
      "|    clip_fraction        | 0.000977   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.274      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 18010      |\n",
      "|    policy_gradient_loss | -0.00231   |\n",
      "|    reward               | 0.82580674 |\n",
      "|    std                  | 10.1       |\n",
      "|    value_loss           | 47.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 6031        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008978433 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 18020       |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    reward               | 0.06716446  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 339          |\n",
      "|    time_elapsed         | 6049         |\n",
      "|    total_timesteps      | 694272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067135706 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 18030        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    reward               | -7.3741364   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 340          |\n",
      "|    time_elapsed         | 6066         |\n",
      "|    total_timesteps      | 696320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001272553 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.7         |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | -0.000682    |\n",
      "|    reward               | 3.857486     |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 99.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6493073.82\n",
      "total_reward: 5493073.82\n",
      "total_cost: 98512.96\n",
      "total_trades: 56847\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 6084        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010816709 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -0.60263693 |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 342          |\n",
      "|    time_elapsed         | 6101         |\n",
      "|    total_timesteps      | 700416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032090854 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.7         |\n",
      "|    n_updates            | 18060        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 0.4916923    |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 343           |\n",
      "|    time_elapsed         | 6119          |\n",
      "|    total_timesteps      | 702464        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087769155 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -108          |\n",
      "|    explained_variance   | 0.409         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24.6          |\n",
      "|    n_updates            | 18070         |\n",
      "|    policy_gradient_loss | -0.00305      |\n",
      "|    reward               | -0.896966     |\n",
      "|    std                  | 10.1          |\n",
      "|    value_loss           | 147           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 344        |\n",
      "|    time_elapsed         | 6137       |\n",
      "|    total_timesteps      | 704512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00248671 |\n",
      "|    clip_fraction        | 0.000928   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.389      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 21.7       |\n",
      "|    n_updates            | 18080      |\n",
      "|    policy_gradient_loss | -0.00306   |\n",
      "|    reward               | 9.472846   |\n",
      "|    std                  | 10.1       |\n",
      "|    value_loss           | 60.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 6155        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005960986 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 18090       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    reward               | 0.91914487  |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 6172        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011292761 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 18100       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    reward               | 2.5430648   |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 347          |\n",
      "|    time_elapsed         | 6190         |\n",
      "|    total_timesteps      | 710656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030564913 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.3         |\n",
      "|    n_updates            | 18110        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | -0.8245409   |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 6207        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005904072 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    reward               | -0.29351205 |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 349           |\n",
      "|    time_elapsed         | 6225          |\n",
      "|    total_timesteps      | 714752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054968044 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -108          |\n",
      "|    explained_variance   | 0.37          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 81.5          |\n",
      "|    n_updates            | 18130         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | 0.86456996    |\n",
      "|    std                  | 10.2          |\n",
      "|    value_loss           | 212           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 350          |\n",
      "|    time_elapsed         | 6242         |\n",
      "|    total_timesteps      | 716800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028641578 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.312        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 18140        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | 1.9033711    |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 257          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 351          |\n",
      "|    time_elapsed         | 6260         |\n",
      "|    total_timesteps      | 718848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105658285 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18           |\n",
      "|    n_updates            | 18150        |\n",
      "|    policy_gradient_loss | -0.0079      |\n",
      "|    reward               | 0.31883743   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 38           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 352          |\n",
      "|    time_elapsed         | 6277         |\n",
      "|    total_timesteps      | 720896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038164598 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.2         |\n",
      "|    n_updates            | 18160        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | -1.9884247   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 353          |\n",
      "|    time_elapsed         | 6294         |\n",
      "|    total_timesteps      | 722944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013309132 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 18170        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | 2.4786       |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 6312         |\n",
      "|    total_timesteps      | 724992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025717346 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.3         |\n",
      "|    n_updates            | 18180        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -5.4667015   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6674323.42\n",
      "total_reward: 5674323.42\n",
      "total_cost: 96985.21\n",
      "total_trades: 55703\n",
      "Sharpe: 0.928\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 6330         |\n",
      "|    total_timesteps      | 727040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077868183 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.5         |\n",
      "|    n_updates            | 18190        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    reward               | -0.06616824  |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 356          |\n",
      "|    time_elapsed         | 6347         |\n",
      "|    total_timesteps      | 729088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038953414 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.5         |\n",
      "|    n_updates            | 18200        |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    reward               | -0.9169804   |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 357          |\n",
      "|    time_elapsed         | 6365         |\n",
      "|    total_timesteps      | 731136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033614319 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.0548       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 338          |\n",
      "|    n_updates            | 18210        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 3.2436144    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 537          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 6382        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010441622 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 18220       |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    reward               | 0.18836941  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 6399        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005541853 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 18230       |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    reward               | -2.0806506  |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 360          |\n",
      "|    time_elapsed         | 6417         |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052631004 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.285        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 183          |\n",
      "|    n_updates            | 18240        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    reward               | 5.4685235    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 293          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 361          |\n",
      "|    time_elapsed         | 6435         |\n",
      "|    total_timesteps      | 739328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058999057 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 18250        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 1.1961259    |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 69.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 362          |\n",
      "|    time_elapsed         | 6452         |\n",
      "|    total_timesteps      | 741376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042947074 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.1         |\n",
      "|    n_updates            | 18260        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | -1.1860528   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 123          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 6470         |\n",
      "|    total_timesteps      | 743424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055314275 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 185          |\n",
      "|    n_updates            | 18270        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    reward               | -69.390434   |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 336          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 6487        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007747383 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 78.3        |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    reward               | -4.9343443  |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 6505         |\n",
      "|    total_timesteps      | 747520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051632095 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.9         |\n",
      "|    n_updates            | 18290        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | 1.6202099    |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 366          |\n",
      "|    time_elapsed         | 6522         |\n",
      "|    total_timesteps      | 749568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031229141 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 18300        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | 1.7881708    |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 310          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 367          |\n",
      "|    time_elapsed         | 6540         |\n",
      "|    total_timesteps      | 751616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024842476 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -108         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 213          |\n",
      "|    n_updates            | 18310        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | 5.122671     |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 317          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 6557        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009750307 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 18320       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | 0.64275473  |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 70.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7850234.79\n",
      "total_reward: 6850234.79\n",
      "total_cost: 102810.42\n",
      "total_trades: 56065\n",
      "Sharpe: 0.951\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 369          |\n",
      "|    time_elapsed         | 6576         |\n",
      "|    total_timesteps      | 755712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035309715 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97           |\n",
      "|    n_updates            | 18330        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -1.0443598   |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 223          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 370          |\n",
      "|    time_elapsed         | 6593         |\n",
      "|    total_timesteps      | 757760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008508763 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 18340        |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    reward               | 8.306203     |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 289          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 371          |\n",
      "|    time_elapsed         | 6611         |\n",
      "|    total_timesteps      | 759808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026787426 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.9         |\n",
      "|    n_updates            | 18350        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | -7.552997    |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 6629        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00610693  |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    reward               | -0.12977561 |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 6647        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006538911 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 18370       |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | -0.8303808  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 272         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 374          |\n",
      "|    time_elapsed         | 6664         |\n",
      "|    total_timesteps      | 765952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010744245 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 18380        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 3.827294     |\n",
      "|    std                  | 10.5         |\n",
      "|    value_loss           | 253          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 6682        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009477491 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 18390       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    reward               | 1.4771585   |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 6701        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004773443 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 18400       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    reward               | 0.99991924  |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 6718        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000623662 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 18410       |\n",
      "|    policy_gradient_loss | -0.000879   |\n",
      "|    reward               | 0.6143709   |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 315         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 378          |\n",
      "|    time_elapsed         | 6736         |\n",
      "|    total_timesteps      | 774144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035989447 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.287        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61           |\n",
      "|    n_updates            | 18420        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | 2.7152596    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 6754        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007550915 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 18430       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    reward               | -3.085158   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 380          |\n",
      "|    time_elapsed         | 6771         |\n",
      "|    total_timesteps      | 778240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013967925 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 18440        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | 0.44971794   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 307          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 381          |\n",
      "|    time_elapsed         | 6789         |\n",
      "|    total_timesteps      | 780288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037853434 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 18450        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | -2.53772     |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 414          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 6807         |\n",
      "|    total_timesteps      | 782336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068463907 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.9         |\n",
      "|    n_updates            | 18460        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | 2.9935343    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 42.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7479687.33\n",
      "total_reward: 6479687.33\n",
      "total_cost: 108536.25\n",
      "total_trades: 56174\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 383          |\n",
      "|    time_elapsed         | 6825         |\n",
      "|    total_timesteps      | 784384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018806055 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 141          |\n",
      "|    n_updates            | 18470        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 1.1027309    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 384          |\n",
      "|    time_elapsed         | 6842         |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036197812 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 231          |\n",
      "|    n_updates            | 18480        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | 1.9522897    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 276          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 6860         |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028888572 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 18490        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 0.6245675    |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 77.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 386          |\n",
      "|    time_elapsed         | 6878         |\n",
      "|    total_timesteps      | 790528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045110136 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 0.87755525   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 387          |\n",
      "|    time_elapsed         | 6896         |\n",
      "|    total_timesteps      | 792576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016777924 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 18510        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    reward               | -2.8474743   |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 230          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 6913        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009781487 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 18520       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    reward               | 1.0821958   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 6931        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010016176 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | 1.5665991   |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 390        |\n",
      "|    time_elapsed         | 6949       |\n",
      "|    total_timesteps      | 798720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00534713 |\n",
      "|    clip_fraction        | 0.0167     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -109       |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 18540      |\n",
      "|    policy_gradient_loss | -0.00569   |\n",
      "|    reward               | 1.2976389  |\n",
      "|    std                  | 10.7       |\n",
      "|    value_loss           | 197        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 391         |\n",
      "|    time_elapsed         | 6966        |\n",
      "|    total_timesteps      | 800768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003936606 |\n",
      "|    clip_fraction        | 0.00908     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.2        |\n",
      "|    n_updates            | 18550       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    reward               | 7.1009946   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 6984        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010582596 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 18560       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    reward               | -1.6020045  |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 393          |\n",
      "|    time_elapsed         | 7002         |\n",
      "|    total_timesteps      | 804864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017046435 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 18570        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -0.62106156  |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 7019        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008147014 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 201         |\n",
      "|    n_updates            | 18580       |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    reward               | 4.2122993   |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 395          |\n",
      "|    time_elapsed         | 7037         |\n",
      "|    total_timesteps      | 808960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036014463 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -109         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.9         |\n",
      "|    n_updates            | 18590        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 1.2239894    |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 7054        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008692911 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 1.0971751   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8204343.86\n",
      "total_reward: 7204343.86\n",
      "total_cost: 111119.87\n",
      "total_trades: 55927\n",
      "Sharpe: 0.977\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 397          |\n",
      "|    time_elapsed         | 7072         |\n",
      "|    total_timesteps      | 813056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020073545 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 200          |\n",
      "|    n_updates            | 18610        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -0.6095334   |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 288          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 398          |\n",
      "|    time_elapsed         | 7090         |\n",
      "|    total_timesteps      | 815104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016003816 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 18620        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -8.214785    |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 334          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 7108        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008728393 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 18630       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    reward               | -3.0819976  |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 49.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 7125        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003314956 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 18640       |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | -0.53112084 |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 293         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 7143        |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001229486 |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 18650       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    reward               | -8.316663   |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 402        |\n",
      "|    time_elapsed         | 7160       |\n",
      "|    total_timesteps      | 823296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00423196 |\n",
      "|    clip_fraction        | 0.0106     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 61.8       |\n",
      "|    n_updates            | 18660      |\n",
      "|    policy_gradient_loss | -0.00513   |\n",
      "|    reward               | 2.953339   |\n",
      "|    std                  | 10.8       |\n",
      "|    value_loss           | 122        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 403          |\n",
      "|    time_elapsed         | 7177         |\n",
      "|    total_timesteps      | 825344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063880812 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 18670        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    reward               | 0.58637124   |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 404          |\n",
      "|    time_elapsed         | 7195         |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055776057 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.8         |\n",
      "|    n_updates            | 18680        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    reward               | 4.1135097    |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 313          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 405          |\n",
      "|    time_elapsed         | 7213         |\n",
      "|    total_timesteps      | 829440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038718393 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 185          |\n",
      "|    n_updates            | 18690        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | 0.112872206  |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 361          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 7230        |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009195225 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 18700       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    reward               | 0.08068167  |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 42.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 407          |\n",
      "|    time_elapsed         | 7248         |\n",
      "|    total_timesteps      | 833536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037431233 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 168          |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | 2.774164     |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 301          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 408          |\n",
      "|    time_elapsed         | 7265         |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011104814 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 187          |\n",
      "|    n_updates            | 18720        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | 7.490363     |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 318          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 409          |\n",
      "|    time_elapsed         | 7283         |\n",
      "|    total_timesteps      | 837632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097959945 |\n",
      "|    clip_fraction        | 0.061        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.8         |\n",
      "|    n_updates            | 18730        |\n",
      "|    policy_gradient_loss | -0.00882     |\n",
      "|    reward               | -6.166203    |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 90.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 7302        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003912813 |\n",
      "|    clip_fraction        | 0.00957     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 169         |\n",
      "|    n_updates            | 18740       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    reward               | 1.2821494   |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 411          |\n",
      "|    time_elapsed         | 7320         |\n",
      "|    total_timesteps      | 841728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020402502 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 18750        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 6.869758     |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 290          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8000881.75\n",
      "total_reward: 7000881.75\n",
      "total_cost: 103707.62\n",
      "total_trades: 55627\n",
      "Sharpe: 0.946\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 7338        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003729287 |\n",
      "|    clip_fraction        | 0.00684     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 84.4        |\n",
      "|    n_updates            | 18760       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    reward               | -0.33734265 |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 7356        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009871278 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | -1.8916484  |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 414          |\n",
      "|    time_elapsed         | 7374         |\n",
      "|    total_timesteps      | 847872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046190266 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | -1.0087174   |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 300          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 415          |\n",
      "|    time_elapsed         | 7392         |\n",
      "|    total_timesteps      | 849920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026831594 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 18790        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | -4.1403737   |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 304          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 7410        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008279538 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 18800       |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | -4.7898607  |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 50.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 7427         |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043492774 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 199          |\n",
      "|    n_updates            | 18810        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    reward               | -0.20262724  |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 250          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 418          |\n",
      "|    time_elapsed         | 7445         |\n",
      "|    total_timesteps      | 856064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037755393 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 18820        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    reward               | 10.677054    |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 250          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 7463        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004484115 |\n",
      "|    clip_fraction        | 0.00957     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 18830       |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | -7.108855   |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 7481        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005799327 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 0.07069407  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 7499        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004834911 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 95.8        |\n",
      "|    n_updates            | 18850       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    reward               | -0.63181657 |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 422          |\n",
      "|    time_elapsed         | 7517         |\n",
      "|    total_timesteps      | 864256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016294125 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.8         |\n",
      "|    n_updates            | 18860        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | 0.6210854    |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 325          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 7535        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011716045 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 0.23903517  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 7553        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002023549 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 18880       |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    reward               | -1.2166973  |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 322         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 425          |\n",
      "|    time_elapsed         | 7571         |\n",
      "|    total_timesteps      | 870400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023627195 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 18890        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -10.163668   |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7915534.23\n",
      "total_reward: 6915534.23\n",
      "total_cost: 101570.38\n",
      "total_trades: 55043\n",
      "Sharpe: 0.957\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 7589        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009734964 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.8        |\n",
      "|    n_updates            | 18900       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 1.9140221   |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 7607         |\n",
      "|    total_timesteps      | 874496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053387466 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.5         |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    reward               | 0.5116662    |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 217          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 428          |\n",
      "|    time_elapsed         | 7625         |\n",
      "|    total_timesteps      | 876544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044117696 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.358        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 287          |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    reward               | -12.921616   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 475          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 429          |\n",
      "|    time_elapsed         | 7642         |\n",
      "|    total_timesteps      | 878592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019234837 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 18930        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -3.5245476   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 7660        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010898415 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 18940       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | -0.33414176 |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 57.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 431          |\n",
      "|    time_elapsed         | 7678         |\n",
      "|    total_timesteps      | 882688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024574902 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90           |\n",
      "|    n_updates            | 18950        |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    reward               | -1.4307501   |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 305          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 432           |\n",
      "|    time_elapsed         | 7696          |\n",
      "|    total_timesteps      | 884736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022739684 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -111          |\n",
      "|    explained_variance   | 0.499         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 203           |\n",
      "|    n_updates            | 18960         |\n",
      "|    policy_gradient_loss | -0.000433     |\n",
      "|    reward               | 1.7801049     |\n",
      "|    std                  | 11.1          |\n",
      "|    value_loss           | 333           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 433        |\n",
      "|    time_elapsed         | 7713       |\n",
      "|    total_timesteps      | 886784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00850022 |\n",
      "|    clip_fraction        | 0.0568     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.502      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 49.5       |\n",
      "|    n_updates            | 18970      |\n",
      "|    policy_gradient_loss | -0.00795   |\n",
      "|    reward               | -3.5757728 |\n",
      "|    std                  | 11.2       |\n",
      "|    value_loss           | 71.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 7731        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002313232 |\n",
      "|    clip_fraction        | 0.00347     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.4        |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 1.8594377   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 246         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 435        |\n",
      "|    time_elapsed         | 7749       |\n",
      "|    total_timesteps      | 890880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00143202 |\n",
      "|    clip_fraction        | 0.00112    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.639      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 217        |\n",
      "|    n_updates            | 18990      |\n",
      "|    policy_gradient_loss | -0.00336   |\n",
      "|    reward               | -9.077139  |\n",
      "|    std                  | 11.2       |\n",
      "|    value_loss           | 303        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 436          |\n",
      "|    time_elapsed         | 7766         |\n",
      "|    total_timesteps      | 892928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009882532 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43           |\n",
      "|    n_updates            | 19000        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 8.606285     |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 192          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 7784        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009326069 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.1        |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    reward               | -3.0145786  |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 438          |\n",
      "|    time_elapsed         | 7802         |\n",
      "|    total_timesteps      | 897024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023168598 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 19020        |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    reward               | 0.95991826   |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 293          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 439          |\n",
      "|    time_elapsed         | 7820         |\n",
      "|    total_timesteps      | 899072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009466858 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 19030        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 7.325008     |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 348          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8124669.75\n",
      "total_reward: 7124669.75\n",
      "total_cost: 109497.66\n",
      "total_trades: 55941\n",
      "Sharpe: 0.954\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 7838        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009189731 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 19040       |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    reward               | 1.3411437   |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 52.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 7855        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001849486 |\n",
      "|    clip_fraction        | 0.0043      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 19050       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | -1.1431584  |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 442          |\n",
      "|    time_elapsed         | 7873         |\n",
      "|    total_timesteps      | 905216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023560743 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | -1.471955    |\n",
      "|    std                  | 11.2         |\n",
      "|    value_loss           | 362          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 7890         |\n",
      "|    total_timesteps      | 907264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040853275 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.9         |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 1.7785324    |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 7908        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009733619 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    reward               | -0.57574517 |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 7926        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004284944 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 19090       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -0.73136747 |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 7943        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002645794 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 19100       |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | 4.7629323   |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 356         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 7961        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010744319 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 19110       |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    reward               | 0.40580422  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 7979        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002779014 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 19120       |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 0.59053475  |\n",
      "|    std                  | 11.3        |\n",
      "|    value_loss           | 314         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 449          |\n",
      "|    time_elapsed         | 7997         |\n",
      "|    total_timesteps      | 919552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014894359 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 19130        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 6.1703644    |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 358          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 8014        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003149293 |\n",
      "|    clip_fraction        | 0.00337     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    reward               | 1.287897    |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 8032        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004322493 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 19150       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    reward               | -0.34569463 |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 192         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 8049        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002017583 |\n",
      "|    clip_fraction        | 0.00112     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 19160       |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | -32.451393  |\n",
      "|    std                  | 11.4        |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 8067         |\n",
      "|    total_timesteps      | 927744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021578686 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.321        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 169          |\n",
      "|    n_updates            | 19170        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | 9.871798     |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 272          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7667952.78\n",
      "total_reward: 6667952.78\n",
      "total_cost: 102669.59\n",
      "total_trades: 54958\n",
      "Sharpe: 0.958\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 8085        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011472887 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 57          |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    reward               | -0.6417566  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 69.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 455          |\n",
      "|    time_elapsed         | 8102         |\n",
      "|    total_timesteps      | 931840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047723106 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 19190        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    reward               | 1.2706473    |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 258          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 456          |\n",
      "|    time_elapsed         | 8120         |\n",
      "|    total_timesteps      | 933888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004518576 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 19200        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | -4.108532    |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 254          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 8137        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009192528 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 19210       |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | -1.4676187  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 62          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 8155        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002079385 |\n",
      "|    clip_fraction        | 0.00146     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | -5.0085974  |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 459          |\n",
      "|    time_elapsed         | 8173         |\n",
      "|    total_timesteps      | 940032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014633575 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 19230        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 8.28732      |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 276          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 8191         |\n",
      "|    total_timesteps      | 942080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045261383 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.2         |\n",
      "|    n_updates            | 19240        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | -9.555585    |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 461          |\n",
      "|    time_elapsed         | 8209         |\n",
      "|    total_timesteps      | 944128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082230745 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 19250        |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    reward               | 0.836273     |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 462          |\n",
      "|    time_elapsed         | 8226         |\n",
      "|    total_timesteps      | 946176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013253932 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.4         |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | -0.38535166  |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 285          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 8244         |\n",
      "|    total_timesteps      | 948224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015446736 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 19270        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | -2.410492    |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 286          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 8262        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011441503 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 19280       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -1.8560565  |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 35.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 465          |\n",
      "|    time_elapsed         | 8280         |\n",
      "|    total_timesteps      | 952320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013836926 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 19290        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | -0.34299424  |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 232          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 466          |\n",
      "|    time_elapsed         | 8297         |\n",
      "|    total_timesteps      | 954368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014131577 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.8         |\n",
      "|    n_updates            | 19300        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -3.2965717   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 467          |\n",
      "|    time_elapsed         | 8315         |\n",
      "|    total_timesteps      | 956416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022465799 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 19310        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | 1.5471345    |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 88.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6226887.38\n",
      "total_reward: 5226887.38\n",
      "total_cost: 88831.19\n",
      "total_trades: 53968\n",
      "Sharpe: 0.902\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 468          |\n",
      "|    time_elapsed         | 8332         |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062492182 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 19320        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | -0.0936175   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 469        |\n",
      "|    time_elapsed         | 8350       |\n",
      "|    total_timesteps      | 960512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00248769 |\n",
      "|    clip_fraction        | 0.00225    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -112       |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 72.2       |\n",
      "|    n_updates            | 19330      |\n",
      "|    policy_gradient_loss | -0.00325   |\n",
      "|    reward               | -0.6214575 |\n",
      "|    std                  | 11.7       |\n",
      "|    value_loss           | 144        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 8368         |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069892537 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93           |\n",
      "|    n_updates            | 19340        |\n",
      "|    policy_gradient_loss | -0.00762     |\n",
      "|    reward               | -1.7197337   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 273          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 8385        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009818307 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 19350       |\n",
      "|    policy_gradient_loss | -0.0085     |\n",
      "|    reward               | -0.87377864 |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 30.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 472          |\n",
      "|    time_elapsed         | 8403         |\n",
      "|    total_timesteps      | 966656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017971346 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 19360        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -0.74448067  |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 8421         |\n",
      "|    total_timesteps      | 968704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013042506 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 19370        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | -1.2281659   |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 254          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 474          |\n",
      "|    time_elapsed         | 8438         |\n",
      "|    total_timesteps      | 970752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072955177 |\n",
      "|    clip_fraction        | 0.0356       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 19380        |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    reward               | 6.5906863    |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 80.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 475          |\n",
      "|    time_elapsed         | 8456         |\n",
      "|    total_timesteps      | 972800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020301684 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 19390        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | 0.034828216  |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 220          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 476          |\n",
      "|    time_elapsed         | 8473         |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014961859 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 19400        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | -0.94299227  |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 252          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 477          |\n",
      "|    time_elapsed         | 8491         |\n",
      "|    total_timesteps      | 976896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022332175 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.3         |\n",
      "|    n_updates            | 19410        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    reward               | -4.9827504   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 8509        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009067247 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 86.1        |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 1.1733608   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 479          |\n",
      "|    time_elapsed         | 8526         |\n",
      "|    total_timesteps      | 980992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018862562 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 87.9         |\n",
      "|    n_updates            | 19430        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    reward               | -2.5870936   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 247          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 8544        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001937429 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 89.3        |\n",
      "|    n_updates            | 19440       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    reward               | -3.719399   |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 481          |\n",
      "|    time_elapsed         | 8561         |\n",
      "|    total_timesteps      | 985088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040754923 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 19450        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    reward               | -0.110270314 |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 59.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6183243.62\n",
      "total_reward: 5183243.62\n",
      "total_cost: 99112.44\n",
      "total_trades: 54550\n",
      "Sharpe: 0.886\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 482          |\n",
      "|    time_elapsed         | 8579         |\n",
      "|    total_timesteps      | 987136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019756039 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.6         |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 0.94464594   |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 8597        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008128984 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 19470       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    reward               | -20.665197  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 484          |\n",
      "|    time_elapsed         | 8614         |\n",
      "|    total_timesteps      | 991232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011973896 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.32         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.2         |\n",
      "|    n_updates            | 19480        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | 2.1270983    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 8632        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007982569 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 79.4        |\n",
      "|    n_updates            | 19490       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    reward               | -0.5124512  |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 486          |\n",
      "|    time_elapsed         | 8649         |\n",
      "|    total_timesteps      | 995328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023146519 |\n",
      "|    clip_fraction        | 0.00894      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 19500        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 1.0781089    |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 487          |\n",
      "|    time_elapsed         | 8667         |\n",
      "|    total_timesteps      | 997376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022734026 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -112         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.3         |\n",
      "|    n_updates            | 19510        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | 7.941495     |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 263          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 8685        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011748025 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 19520       |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    reward               | 0.026191097 |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 27.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 489          |\n",
      "|    time_elapsed         | 8703         |\n",
      "|    total_timesteps      | 1001472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022474367 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -0.28683206  |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 490          |\n",
      "|    time_elapsed         | 8720         |\n",
      "|    total_timesteps      | 1003520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026233667 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 19540        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.5305842    |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 232          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 8738        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008465072 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 19550       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    reward               | 6.0920463   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 81          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 8756        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004269019 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.8        |\n",
      "|    n_updates            | 19560       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 1.4934398   |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 115           |\n",
      "|    iterations           | 493           |\n",
      "|    time_elapsed         | 8774          |\n",
      "|    total_timesteps      | 1009664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.002812068   |\n",
      "|    clip_fraction        | 0.00239       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -113          |\n",
      "|    explained_variance   | 0.577         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 38.5          |\n",
      "|    n_updates            | 19570         |\n",
      "|    policy_gradient_loss | -0.00269      |\n",
      "|    reward               | 0.00069412094 |\n",
      "|    std                  | 12            |\n",
      "|    value_loss           | 144           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 494          |\n",
      "|    time_elapsed         | 8792         |\n",
      "|    total_timesteps      | 1011712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006721562 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.4         |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | -0.7288175   |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 8810        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012412773 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 19590       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | -0.13671122 |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6993869.31\n",
      "total_reward: 5993869.31\n",
      "total_cost: 122079.44\n",
      "total_trades: 56539\n",
      "Sharpe: 0.983\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 496          |\n",
      "|    time_elapsed         | 8828         |\n",
      "|    total_timesteps      | 1015808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025929757 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.4         |\n",
      "|    n_updates            | 19600        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | 0.2863634    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 286          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 8846         |\n",
      "|    total_timesteps      | 1017856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040469626 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.8         |\n",
      "|    n_updates            | 19610        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | 0.48377016   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 498          |\n",
      "|    time_elapsed         | 8864         |\n",
      "|    total_timesteps      | 1019904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036568139 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 19620        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 1.734751     |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 60.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 499          |\n",
      "|    time_elapsed         | 8882         |\n",
      "|    total_timesteps      | 1021952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041325986 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.7         |\n",
      "|    n_updates            | 19630        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | -0.1643637   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 500          |\n",
      "|    time_elapsed         | 8900         |\n",
      "|    total_timesteps      | 1024000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044457684 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.3         |\n",
      "|    n_updates            | 19640        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | -3.952896    |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 501          |\n",
      "|    time_elapsed         | 8918         |\n",
      "|    total_timesteps      | 1026048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031616334 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.4         |\n",
      "|    n_updates            | 19650        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    reward               | -1.7533532   |\n",
      "|    std                  | 12.1         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 502          |\n",
      "|    time_elapsed         | 8937         |\n",
      "|    total_timesteps      | 1028096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076487013 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.4         |\n",
      "|    n_updates            | 19660        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | -0.46826586  |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 75.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 503          |\n",
      "|    time_elapsed         | 8954         |\n",
      "|    total_timesteps      | 1030144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033818176 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42           |\n",
      "|    n_updates            | 19670        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    reward               | 1.055446     |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 504          |\n",
      "|    time_elapsed         | 8972         |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018574193 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | -8.848943    |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 8991        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012217661 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 19690       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.3976449  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 506        |\n",
      "|    time_elapsed         | 9009       |\n",
      "|    total_timesteps      | 1036288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0064033  |\n",
      "|    clip_fraction        | 0.0358     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.526      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 53.8       |\n",
      "|    n_updates            | 19700      |\n",
      "|    policy_gradient_loss | -0.00899   |\n",
      "|    reward               | 0.94176733 |\n",
      "|    std                  | 12.3       |\n",
      "|    value_loss           | 166        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 9027         |\n",
      "|    total_timesteps      | 1038336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021686899 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.4         |\n",
      "|    n_updates            | 19710        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    reward               | 4.673558     |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 115        |\n",
      "|    iterations           | 508        |\n",
      "|    time_elapsed         | 9045       |\n",
      "|    total_timesteps      | 1040384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00645085 |\n",
      "|    clip_fraction        | 0.0226     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.277      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 34.7       |\n",
      "|    n_updates            | 19720      |\n",
      "|    policy_gradient_loss | -0.0056    |\n",
      "|    reward               | 2.5510817  |\n",
      "|    std                  | 12.3       |\n",
      "|    value_loss           | 67.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 115          |\n",
      "|    iterations           | 509          |\n",
      "|    time_elapsed         | 9063         |\n",
      "|    total_timesteps      | 1042432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064317314 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 19730        |\n",
      "|    policy_gradient_loss | -0.00812     |\n",
      "|    reward               | -1.4318866   |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 87.7         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6117863.23\n",
      "total_reward: 5117863.23\n",
      "total_cost: 98052.08\n",
      "total_trades: 54821\n",
      "Sharpe: 0.923\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 9082        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007023866 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.6        |\n",
      "|    n_updates            | 19740       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    reward               | 0.14023846  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 115         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 9099        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004363223 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 19750       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | -0.46690282 |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 512          |\n",
      "|    time_elapsed         | 9162         |\n",
      "|    total_timesteps      | 1048576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114579145 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 19760        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    reward               | -0.65988624  |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 9180        |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004160233 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 19770       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    reward               | -0.3896097  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 9197         |\n",
      "|    total_timesteps      | 1052672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016469628 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.1         |\n",
      "|    n_updates            | 19780        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 4.7688913    |\n",
      "|    std                  | 12.3         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 9215        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006651738 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 19790       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | -1.2292948  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 57.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 9232        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006293766 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 19800       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | -2.4063013  |\n",
      "|    std                  | 12.3        |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 9250        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004441507 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 19810       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -2.5722387  |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 99.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 518          |\n",
      "|    time_elapsed         | 9268         |\n",
      "|    total_timesteps      | 1060864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028597168 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | -0.07259144  |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 519          |\n",
      "|    time_elapsed         | 9286         |\n",
      "|    total_timesteps      | 1062912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089310445 |\n",
      "|    clip_fraction        | 0.0658       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.56         |\n",
      "|    n_updates            | 19830        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    reward               | 0.4525499    |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 24.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 520          |\n",
      "|    time_elapsed         | 9304         |\n",
      "|    total_timesteps      | 1064960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024734298 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.3         |\n",
      "|    n_updates            | 19840        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -0.1482463   |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 521          |\n",
      "|    time_elapsed         | 9322         |\n",
      "|    total_timesteps      | 1067008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012119771 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.8         |\n",
      "|    n_updates            | 19850        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | -3.870638    |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 9340        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010143025 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 19860       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | -0.5054542  |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 44          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 9358        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004207329 |\n",
      "|    clip_fraction        | 0.00522     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.6        |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | 2.0833054   |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 76.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 524          |\n",
      "|    time_elapsed         | 9376         |\n",
      "|    total_timesteps      | 1073152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039179605 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 19880        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -1.5504775   |\n",
      "|    std                  | 12.4         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6061798.52\n",
      "total_reward: 5061798.52\n",
      "total_cost: 93013.17\n",
      "total_trades: 54722\n",
      "Sharpe: 0.920\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 525          |\n",
      "|    time_elapsed         | 9395         |\n",
      "|    total_timesteps      | 1075200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031384572 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 19890        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 2.6178832    |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 78.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 9413        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008193968 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.9        |\n",
      "|    n_updates            | 19900       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | -0.1309883  |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 57.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 527          |\n",
      "|    time_elapsed         | 9431         |\n",
      "|    total_timesteps      | 1079296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016962552 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.8         |\n",
      "|    n_updates            | 19910        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | -1.6753033   |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 528          |\n",
      "|    time_elapsed         | 9449         |\n",
      "|    total_timesteps      | 1081344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042939447 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.8         |\n",
      "|    n_updates            | 19920        |\n",
      "|    policy_gradient_loss | -0.00817     |\n",
      "|    reward               | 0.68915457   |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 9467        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011012579 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 0.52245677  |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 30          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 530          |\n",
      "|    time_elapsed         | 9485         |\n",
      "|    total_timesteps      | 1085440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021173013 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 19940        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    reward               | -0.54663783  |\n",
      "|    std                  | 12.5         |\n",
      "|    value_loss           | 86.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 9503        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003937222 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 19950       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    reward               | -4.643262   |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 9521        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002612613 |\n",
      "|    clip_fraction        | 0.000879    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 19960       |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | 2.5678165   |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 9539        |\n",
      "|    total_timesteps      | 1091584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008299248 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 19970       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    reward               | -0.9412388  |\n",
      "|    std                  | 12.5        |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 534           |\n",
      "|    time_elapsed         | 9557          |\n",
      "|    total_timesteps      | 1093632       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079626305 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.584         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.3          |\n",
      "|    n_updates            | 19980         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    reward               | -0.22428992   |\n",
      "|    std                  | 12.6          |\n",
      "|    value_loss           | 154           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 535          |\n",
      "|    time_elapsed         | 9574         |\n",
      "|    total_timesteps      | 1095680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010377571 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 19990        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 5.202022     |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 201          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 536        |\n",
      "|    time_elapsed         | 9592       |\n",
      "|    total_timesteps      | 1097728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0108943  |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -114       |\n",
      "|    explained_variance   | 0.511      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 20000      |\n",
      "|    policy_gradient_loss | -0.00836   |\n",
      "|    reward               | 0.67657644 |\n",
      "|    std                  | 12.6       |\n",
      "|    value_loss           | 22.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 537          |\n",
      "|    time_elapsed         | 9610         |\n",
      "|    total_timesteps      | 1099776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028204946 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 20010        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | -0.8912711   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 94.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 538          |\n",
      "|    time_elapsed         | 9628         |\n",
      "|    total_timesteps      | 1101824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013686873 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 20020        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    reward               | -1.9501781   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6209471.47\n",
      "total_reward: 5209471.47\n",
      "total_cost: 103359.35\n",
      "total_trades: 55618\n",
      "Sharpe: 0.948\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 9646         |\n",
      "|    total_timesteps      | 1103872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048363185 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    reward               | 0.46377718   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 58.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 9664        |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002655222 |\n",
      "|    clip_fraction        | 0.00254     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.2        |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    reward               | 0.7661515   |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 541          |\n",
      "|    time_elapsed         | 9682         |\n",
      "|    total_timesteps      | 1107968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011665882 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70           |\n",
      "|    n_updates            | 20050        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | -9.6859455   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 542          |\n",
      "|    time_elapsed         | 9700         |\n",
      "|    total_timesteps      | 1110016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016478677 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.2         |\n",
      "|    n_updates            | 20060        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 8.594759     |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 9718        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008937654 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.4610463  |\n",
      "|    std                  | 12.6        |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 544          |\n",
      "|    time_elapsed         | 9735         |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017236415 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.3         |\n",
      "|    n_updates            | 20080        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | -0.61733735  |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 545          |\n",
      "|    time_elapsed         | 9752         |\n",
      "|    total_timesteps      | 1116160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015047821 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.1         |\n",
      "|    n_updates            | 20090        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 6.737869     |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 546          |\n",
      "|    time_elapsed         | 9770         |\n",
      "|    total_timesteps      | 1118208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088293785 |\n",
      "|    clip_fraction        | 0.0528       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 20100        |\n",
      "|    policy_gradient_loss | -0.00959     |\n",
      "|    reward               | -3.4213555   |\n",
      "|    std                  | 12.6         |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 547          |\n",
      "|    time_elapsed         | 9787         |\n",
      "|    total_timesteps      | 1120256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016259527 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.8         |\n",
      "|    n_updates            | 20110        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | 3.1686661    |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 9804        |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002497476 |\n",
      "|    clip_fraction        | 0.00234     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 71.4        |\n",
      "|    n_updates            | 20120       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    reward               | -2.0556211  |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 9822        |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005740253 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 20130       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | -7.0787063  |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 97.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 9840        |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006131124 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 20140       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    reward               | -0.46688813 |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 9857         |\n",
      "|    total_timesteps      | 1128448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017466663 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -114         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 20150        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | -0.31057706  |\n",
      "|    std                  | 12.7         |\n",
      "|    value_loss           | 259          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 552           |\n",
      "|    time_elapsed         | 9875          |\n",
      "|    total_timesteps      | 1130496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028762393 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -114          |\n",
      "|    explained_variance   | 0.569         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 137           |\n",
      "|    n_updates            | 20160         |\n",
      "|    policy_gradient_loss | -0.00113      |\n",
      "|    reward               | 4.6387444     |\n",
      "|    std                  | 12.7          |\n",
      "|    value_loss           | 263           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7353089.84\n",
      "total_reward: 6353089.84\n",
      "total_cost: 116925.47\n",
      "total_trades: 56893\n",
      "Sharpe: 0.967\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 9893        |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008613172 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 20170       |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    reward               | -0.55149853 |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 38.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 9911        |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001613043 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 20180       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 0.47016522  |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 555          |\n",
      "|    time_elapsed         | 9929         |\n",
      "|    total_timesteps      | 1136640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011506323 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | -4.0508056   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 556          |\n",
      "|    time_elapsed         | 9947         |\n",
      "|    total_timesteps      | 1138688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035945955 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.5         |\n",
      "|    n_updates            | 20200        |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | -2.2966948   |\n",
      "|    std                  | 12.8         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 9966        |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007362344 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 83.2        |\n",
      "|    n_updates            | 20210       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    reward               | 0.31668216  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 558          |\n",
      "|    time_elapsed         | 9985         |\n",
      "|    total_timesteps      | 1142784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048090275 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 98.3         |\n",
      "|    n_updates            | 20220        |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    reward               | -0.20173979  |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 188          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 10004       |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001690226 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 20230       |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    reward               | 0.22370201  |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 10022       |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010035579 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 20240       |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    reward               | 1.2824954   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 561          |\n",
      "|    time_elapsed         | 10041        |\n",
      "|    total_timesteps      | 1148928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013871805 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 20250        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    reward               | -0.044285093 |\n",
      "|    std                  | 12.9         |\n",
      "|    value_loss           | 245          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 10060       |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002129598 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 20260       |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    reward               | -2.878101   |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 10078       |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00278223  |\n",
      "|    clip_fraction        | 0.00195     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 20270       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    reward               | -0.13348861 |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 84          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 564          |\n",
      "|    time_elapsed         | 10097        |\n",
      "|    total_timesteps      | 1155072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015141924 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.2         |\n",
      "|    n_updates            | 20280        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | 0.7975712    |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 10115        |\n",
      "|    total_timesteps      | 1157120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026950059 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 20290        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -54.839306   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 327          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 566           |\n",
      "|    time_elapsed         | 10133         |\n",
      "|    total_timesteps      | 1159168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075509213 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.411         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 64.2          |\n",
      "|    n_updates            | 20300         |\n",
      "|    policy_gradient_loss | -0.00245      |\n",
      "|    reward               | -1.9272938    |\n",
      "|    std                  | 13            |\n",
      "|    value_loss           | 164           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8522578.72\n",
      "total_reward: 7522578.72\n",
      "total_cost: 113390.34\n",
      "total_trades: 56357\n",
      "Sharpe: 0.998\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 10151       |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005740683 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 91.4        |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    reward               | -5.9169836  |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 568           |\n",
      "|    time_elapsed         | 10169         |\n",
      "|    total_timesteps      | 1163264       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0021259652  |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -115          |\n",
      "|    explained_variance   | 0.472         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 149           |\n",
      "|    n_updates            | 20320         |\n",
      "|    policy_gradient_loss | -0.00456      |\n",
      "|    reward               | -0.0153292045 |\n",
      "|    std                  | 13            |\n",
      "|    value_loss           | 357           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 569          |\n",
      "|    time_elapsed         | 10187        |\n",
      "|    total_timesteps      | 1165312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063662156 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 20330        |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    reward               | -14.063877   |\n",
      "|    std                  | 13           |\n",
      "|    value_loss           | 249          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 570        |\n",
      "|    time_elapsed         | 10205      |\n",
      "|    total_timesteps      | 1167360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01032092 |\n",
      "|    clip_fraction        | 0.0701     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.8       |\n",
      "|    n_updates            | 20340      |\n",
      "|    policy_gradient_loss | -0.00891   |\n",
      "|    reward               | 1.9691564  |\n",
      "|    std                  | 13.1       |\n",
      "|    value_loss           | 50.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 571          |\n",
      "|    time_elapsed         | 10224        |\n",
      "|    total_timesteps      | 1169408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041838116 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.3         |\n",
      "|    n_updates            | 20350        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    reward               | 0.58313173   |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 572          |\n",
      "|    time_elapsed         | 10242        |\n",
      "|    total_timesteps      | 1171456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012079948 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.3         |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -12.63126    |\n",
      "|    std                  | 13.1         |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 10260       |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007846609 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 20370       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    reward               | 0.13926396  |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 10278       |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003980197 |\n",
      "|    clip_fraction        | 0.00693     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 20380       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | -1.2617661  |\n",
      "|    std                  | 13.1        |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 575          |\n",
      "|    time_elapsed         | 10296        |\n",
      "|    total_timesteps      | 1177600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020663412 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | -0.030572018 |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 10315        |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015763256 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -115         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.7         |\n",
      "|    n_updates            | 20400        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 3.4522474    |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 279          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 10333       |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007069845 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.2        |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | -2.2154443  |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 578          |\n",
      "|    time_elapsed         | 10351        |\n",
      "|    total_timesteps      | 1183744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032175712 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 20420        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    reward               | -0.31907538  |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 579          |\n",
      "|    time_elapsed         | 10369        |\n",
      "|    total_timesteps      | 1185792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020778724 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 20430        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | 4.529737     |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 284          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 580          |\n",
      "|    time_elapsed         | 10387        |\n",
      "|    total_timesteps      | 1187840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034771403 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91           |\n",
      "|    n_updates            | 20440        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 0.78293586   |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7432653.16\n",
      "total_reward: 6432653.16\n",
      "total_cost: 139624.96\n",
      "total_trades: 58381\n",
      "Sharpe: 0.965\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 581        |\n",
      "|    time_elapsed         | 10406      |\n",
      "|    total_timesteps      | 1189888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00668189 |\n",
      "|    clip_fraction        | 0.0242     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -116       |\n",
      "|    explained_variance   | 0.659      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 174        |\n",
      "|    n_updates            | 20450      |\n",
      "|    policy_gradient_loss | -0.00741   |\n",
      "|    reward               | 2.4742723  |\n",
      "|    std                  | 13.3       |\n",
      "|    value_loss           | 169        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 582          |\n",
      "|    time_elapsed         | 10424        |\n",
      "|    total_timesteps      | 1191936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047259466 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 20460        |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | -0.050674915 |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 583          |\n",
      "|    time_elapsed         | 10442        |\n",
      "|    total_timesteps      | 1193984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035505649 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 20470        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | 1.9864305    |\n",
      "|    std                  | 13.3         |\n",
      "|    value_loss           | 285          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 10460       |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011083839 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 20480       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 0.38029298  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 10479       |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001231172 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 20490       |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    reward               | 0.59116894  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 586           |\n",
      "|    time_elapsed         | 10497         |\n",
      "|    total_timesteps      | 1200128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096840353 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.479         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 48.3          |\n",
      "|    n_updates            | 20500         |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    reward               | -4.0857015    |\n",
      "|    std                  | 13.3          |\n",
      "|    value_loss           | 263           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 10515       |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008797899 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.5        |\n",
      "|    n_updates            | 20510       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    reward               | -0.6457195  |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 588          |\n",
      "|    time_elapsed         | 10534        |\n",
      "|    total_timesteps      | 1204224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031744614 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 133          |\n",
      "|    n_updates            | 20520        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    reward               | 0.3183011    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 230          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 10553       |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001622584 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 20530       |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | -2.57882    |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 10571        |\n",
      "|    total_timesteps      | 1208320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022966582 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.4         |\n",
      "|    n_updates            | 20540        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 1.9100599    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 591         |\n",
      "|    time_elapsed         | 10589       |\n",
      "|    total_timesteps      | 1210368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008754256 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 20550       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 1.0519964   |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 592          |\n",
      "|    time_elapsed         | 10607        |\n",
      "|    total_timesteps      | 1212416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045896303 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    reward               | 0.10382518   |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 593          |\n",
      "|    time_elapsed         | 10625        |\n",
      "|    total_timesteps      | 1214464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016972413 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 20570        |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | 5.3669453    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 245          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 594          |\n",
      "|    time_elapsed         | 10644        |\n",
      "|    total_timesteps      | 1216512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071598166 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 20580        |\n",
      "|    policy_gradient_loss | -0.00861     |\n",
      "|    reward               | -3.3014271   |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 74.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8466794.52\n",
      "total_reward: 7466794.52\n",
      "total_cost: 133191.15\n",
      "total_trades: 58086\n",
      "Sharpe: 0.982\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 595          |\n",
      "|    time_elapsed         | 10662        |\n",
      "|    total_timesteps      | 1218560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017481861 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 20590        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -4.295546    |\n",
      "|    std                  | 13.4         |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 114           |\n",
      "|    iterations           | 596           |\n",
      "|    time_elapsed         | 10682         |\n",
      "|    total_timesteps      | 1220608       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017688362 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -116          |\n",
      "|    explained_variance   | 0.66          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 152           |\n",
      "|    n_updates            | 20600         |\n",
      "|    policy_gradient_loss | -0.000735     |\n",
      "|    reward               | 6.166554      |\n",
      "|    std                  | 13.4          |\n",
      "|    value_loss           | 302           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 597          |\n",
      "|    time_elapsed         | 10700        |\n",
      "|    total_timesteps      | 1222656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027107985 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.3         |\n",
      "|    n_updates            | 20610        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 0.8846214    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 598          |\n",
      "|    time_elapsed         | 10718        |\n",
      "|    total_timesteps      | 1224704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055207787 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 95.3         |\n",
      "|    n_updates            | 20620        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    reward               | 1.0742254    |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 599          |\n",
      "|    time_elapsed         | 10736        |\n",
      "|    total_timesteps      | 1226752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038208994 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 20630        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | 0.69005996   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 263          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 10754        |\n",
      "|    total_timesteps      | 1228800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017058514 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.7         |\n",
      "|    n_updates            | 20640        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | -0.9952234   |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 220          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 10772       |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011305781 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 20650       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -3.950715   |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 602          |\n",
      "|    time_elapsed         | 10790        |\n",
      "|    total_timesteps      | 1232896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028019873 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 20660        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 1.3884121    |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 603          |\n",
      "|    time_elapsed         | 10808        |\n",
      "|    total_timesteps      | 1234944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014802868 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.2         |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 1.5001824    |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 604         |\n",
      "|    time_elapsed         | 10827       |\n",
      "|    total_timesteps      | 1236992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004679705 |\n",
      "|    clip_fraction        | 0.00845     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 20680       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | 6.4762435   |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 80.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 605          |\n",
      "|    time_elapsed         | 10845        |\n",
      "|    total_timesteps      | 1239040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066087907 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.6         |\n",
      "|    n_updates            | 20690        |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    reward               | 0.28773654   |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 606          |\n",
      "|    time_elapsed         | 10863        |\n",
      "|    total_timesteps      | 1241088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029662438 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.3         |\n",
      "|    n_updates            | 20700        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | -5.5738373   |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 10881       |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003268613 |\n",
      "|    clip_fraction        | 0.00508     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 77.4        |\n",
      "|    n_updates            | 20710       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | 3.1371586   |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 608          |\n",
      "|    time_elapsed         | 10899        |\n",
      "|    total_timesteps      | 1245184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076650004 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 20720        |\n",
      "|    policy_gradient_loss | -0.00905     |\n",
      "|    reward               | 0.7480997    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7593130.40\n",
      "total_reward: 6593130.40\n",
      "total_cost: 131479.35\n",
      "total_trades: 57724\n",
      "Sharpe: 1.017\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 609          |\n",
      "|    time_elapsed         | 10917        |\n",
      "|    total_timesteps      | 1247232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029733889 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.7         |\n",
      "|    n_updates            | 20730        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    reward               | -1.0611697   |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 10935        |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072446433 |\n",
      "|    clip_fraction        | 0.0356       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 183          |\n",
      "|    n_updates            | 20740        |\n",
      "|    policy_gradient_loss | -0.00883     |\n",
      "|    reward               | 2.2158113    |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 247          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 10954       |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012163393 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 20750       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 2.9393117   |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 612          |\n",
      "|    time_elapsed         | 10972        |\n",
      "|    total_timesteps      | 1253376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035156785 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.6         |\n",
      "|    n_updates            | 20760        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | 2.4314513    |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 613          |\n",
      "|    time_elapsed         | 10991        |\n",
      "|    total_timesteps      | 1255424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019394173 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 20770        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 1.0294489    |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 11009       |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002201133 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 20780       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | -0.86174697 |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 86.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 11028       |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007596283 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 20790       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | 0.49864328  |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 11046       |\n",
      "|    total_timesteps      | 1261568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003130542 |\n",
      "|    clip_fraction        | 0.00537     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 20800       |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 0.87783587  |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 97.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 617          |\n",
      "|    time_elapsed         | 11064        |\n",
      "|    total_timesteps      | 1263616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038128137 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.9         |\n",
      "|    n_updates            | 20810        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    reward               | 3.9740539    |\n",
      "|    std                  | 13.9         |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 11082       |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007655984 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | -0.0796     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.23        |\n",
      "|    n_updates            | 20820       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    reward               | 1.0741595   |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 619          |\n",
      "|    time_elapsed         | 11101        |\n",
      "|    total_timesteps      | 1267712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032220893 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.6         |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | 0.3860026    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 84.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 620          |\n",
      "|    time_elapsed         | 11119        |\n",
      "|    total_timesteps      | 1269760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060475357 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 20840        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | 0.5008138    |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 11138       |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008276602 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 20850       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | 2.7609537   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 11156       |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008186522 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 20860       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    reward               | 1.4322008   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 76.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6644991.92\n",
      "total_reward: 5644991.92\n",
      "total_cost: 129814.98\n",
      "total_trades: 57118\n",
      "Sharpe: 0.985\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 623          |\n",
      "|    time_elapsed         | 11174        |\n",
      "|    total_timesteps      | 1275904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044062613 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.2         |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    reward               | 0.62104255   |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 624          |\n",
      "|    time_elapsed         | 11193        |\n",
      "|    total_timesteps      | 1277952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020060034 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.6         |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 0.7515391    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 625         |\n",
      "|    time_elapsed         | 11211       |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010308304 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 20890       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | 5.7704287   |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 626          |\n",
      "|    time_elapsed         | 11229        |\n",
      "|    total_timesteps      | 1282048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036532027 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -117         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 114          |\n",
      "|    n_updates            | 20900        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -0.8022356   |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 11248        |\n",
      "|    total_timesteps      | 1284096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018730457 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.3         |\n",
      "|    n_updates            | 20910        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    reward               | 4.4708843    |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 628          |\n",
      "|    time_elapsed         | 11266        |\n",
      "|    total_timesteps      | 1286144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024952416 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 20920        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 4.383087     |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 84.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 629          |\n",
      "|    time_elapsed         | 11285        |\n",
      "|    total_timesteps      | 1288192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031402318 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.6         |\n",
      "|    n_updates            | 20930        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | -0.52248484  |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 630          |\n",
      "|    time_elapsed         | 11303        |\n",
      "|    total_timesteps      | 1290240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027668122 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 20940        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 13.648506    |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 631          |\n",
      "|    time_elapsed         | 11322        |\n",
      "|    total_timesteps      | 1292288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005561255 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 20950        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | 0.70458543   |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 11340       |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009440603 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 20960       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | -2.1760132  |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 633          |\n",
      "|    time_elapsed         | 11359        |\n",
      "|    total_timesteps      | 1296384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035756347 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    reward               | -0.2788121   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 304          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 11377       |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001736511 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 20980       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    reward               | -2.7195237  |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 635         |\n",
      "|    time_elapsed         | 11395       |\n",
      "|    total_timesteps      | 1300480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004864524 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 20990       |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    reward               | 6.435116    |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 76.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 636          |\n",
      "|    time_elapsed         | 11414        |\n",
      "|    total_timesteps      | 1302528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012217353 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 21000        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 1.4831718    |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 174          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 637          |\n",
      "|    time_elapsed         | 11432        |\n",
      "|    total_timesteps      | 1304576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016853819 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.3         |\n",
      "|    n_updates            | 21010        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    reward               | -5.3972216   |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7918741.26\n",
      "total_reward: 6918741.26\n",
      "total_cost: 131372.48\n",
      "total_trades: 57552\n",
      "Sharpe: 0.993\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 11452       |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004306727 |\n",
      "|    clip_fraction        | 0.00698     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 21020       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    reward               | 1.4725322   |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 11470       |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003977457 |\n",
      "|    clip_fraction        | 0.00708     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.6        |\n",
      "|    n_updates            | 21030       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | -0.76827466 |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 640          |\n",
      "|    time_elapsed         | 11489        |\n",
      "|    total_timesteps      | 1310720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036913103 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.4         |\n",
      "|    n_updates            | 21040        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | 1.009251     |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 114        |\n",
      "|    iterations           | 641        |\n",
      "|    time_elapsed         | 11507      |\n",
      "|    total_timesteps      | 1312768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00177341 |\n",
      "|    clip_fraction        | 0.000537   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.623      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 69.3       |\n",
      "|    n_updates            | 21050      |\n",
      "|    policy_gradient_loss | -0.00241   |\n",
      "|    reward               | -1.5353861 |\n",
      "|    std                  | 14.4       |\n",
      "|    value_loss           | 163        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 11526       |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009363817 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 21060       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    reward               | 1.5097805   |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 643          |\n",
      "|    time_elapsed         | 11545        |\n",
      "|    total_timesteps      | 1316864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024814326 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 21070        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | -0.414452    |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 644          |\n",
      "|    time_elapsed         | 11563        |\n",
      "|    total_timesteps      | 1318912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024601647 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.2         |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 4.5483713    |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 645          |\n",
      "|    time_elapsed         | 11582        |\n",
      "|    total_timesteps      | 1320960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026573734 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.2         |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | -4.667748    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 90.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 646          |\n",
      "|    time_elapsed         | 11600        |\n",
      "|    total_timesteps      | 1323008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039841514 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.1         |\n",
      "|    n_updates            | 21100        |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    reward               | 0.7055502    |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 11618       |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001521555 |\n",
      "|    clip_fraction        | 0.00142     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 21110       |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    reward               | 1.2743264   |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 648          |\n",
      "|    time_elapsed         | 11639        |\n",
      "|    total_timesteps      | 1327104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013108695 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.5         |\n",
      "|    n_updates            | 21120        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -1.0207922   |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 248          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 11657       |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008934317 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 21130       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -2.668249   |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 30.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 650          |\n",
      "|    time_elapsed         | 11676        |\n",
      "|    total_timesteps      | 1331200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013878389 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.2         |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | 1.0563536    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 185          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 651          |\n",
      "|    time_elapsed         | 11695        |\n",
      "|    total_timesteps      | 1333248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011104994 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 21150        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | -2.4012396   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6555370.89\n",
      "total_reward: 5555370.89\n",
      "total_cost: 130383.60\n",
      "total_trades: 57856\n",
      "Sharpe: 0.943\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 11713       |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006124343 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 21160       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | 0.61722106  |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 653          |\n",
      "|    time_elapsed         | 11732        |\n",
      "|    total_timesteps      | 1337344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028791574 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 21170        |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 1.8464636    |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 11750       |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002099602 |\n",
      "|    clip_fraction        | 0.00586     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 21180       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 30.690943   |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 655          |\n",
      "|    time_elapsed         | 11768        |\n",
      "|    total_timesteps      | 1341440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021222522 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.1         |\n",
      "|    n_updates            | 21190        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -5.1154885   |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 11787       |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010742223 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 21200       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | -0.8892523  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 657          |\n",
      "|    time_elapsed         | 11805        |\n",
      "|    total_timesteps      | 1345536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018555545 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    reward               | 0.02251324   |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 658          |\n",
      "|    time_elapsed         | 11824        |\n",
      "|    total_timesteps      | 1347584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018169319 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 21220        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -6.9841094   |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 11842       |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007252791 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 21230       |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    reward               | -2.1630113  |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 54.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 11861       |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001746985 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 54.7        |\n",
      "|    n_updates            | 21240       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    reward               | -0.53359026 |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 661           |\n",
      "|    time_elapsed         | 11879         |\n",
      "|    total_timesteps      | 1353728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078077975 |\n",
      "|    clip_fraction        | 0.00142       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.483         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 69.7          |\n",
      "|    n_updates            | 21250         |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    reward               | -9.189155     |\n",
      "|    std                  | 14.7          |\n",
      "|    value_loss           | 199           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 662          |\n",
      "|    time_elapsed         | 11898        |\n",
      "|    total_timesteps      | 1355776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014273288 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.6         |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | 0.06605334   |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 663          |\n",
      "|    time_elapsed         | 11916        |\n",
      "|    total_timesteps      | 1357824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073267245 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.6         |\n",
      "|    n_updates            | 21270        |\n",
      "|    policy_gradient_loss | -0.00929     |\n",
      "|    reward               | -0.80242383  |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 664          |\n",
      "|    time_elapsed         | 11934        |\n",
      "|    total_timesteps      | 1359872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032862206 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.1         |\n",
      "|    n_updates            | 21280        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    reward               | 0.2597114    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 665           |\n",
      "|    time_elapsed         | 11953         |\n",
      "|    total_timesteps      | 1361920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067426206 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.491         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 71.8          |\n",
      "|    n_updates            | 21290         |\n",
      "|    policy_gradient_loss | -0.00206      |\n",
      "|    reward               | -1.8436533    |\n",
      "|    std                  | 14.8          |\n",
      "|    value_loss           | 216           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7429707.21\n",
      "total_reward: 6429707.21\n",
      "total_cost: 143304.21\n",
      "total_trades: 58750\n",
      "Sharpe: 0.956\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 11971       |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010960239 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 21300       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | 0.4207121   |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 37.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 667          |\n",
      "|    time_elapsed         | 11989        |\n",
      "|    total_timesteps      | 1366016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010569629 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.6         |\n",
      "|    n_updates            | 21310        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | 0.6889555    |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 668          |\n",
      "|    time_elapsed         | 12007        |\n",
      "|    total_timesteps      | 1368064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017369156 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.7         |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | 1.5860721    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 669          |\n",
      "|    time_elapsed         | 12026        |\n",
      "|    total_timesteps      | 1370112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034819383 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.9         |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | 0.92609674   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 75.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 670          |\n",
      "|    time_elapsed         | 12044        |\n",
      "|    total_timesteps      | 1372160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064092204 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.8         |\n",
      "|    n_updates            | 21340        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    reward               | -0.17590562  |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 671          |\n",
      "|    time_elapsed         | 12062        |\n",
      "|    total_timesteps      | 1374208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010507845 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.2         |\n",
      "|    n_updates            | 21350        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | -0.2782846   |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 672           |\n",
      "|    time_elapsed         | 12081         |\n",
      "|    total_timesteps      | 1376256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096088747 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.509         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 113           |\n",
      "|    n_updates            | 21360         |\n",
      "|    policy_gradient_loss | -0.00249      |\n",
      "|    reward               | 1.8822134     |\n",
      "|    std                  | 14.9          |\n",
      "|    value_loss           | 203           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 12099       |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008286236 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 21370       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    reward               | 0.04926272  |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 674          |\n",
      "|    time_elapsed         | 12117        |\n",
      "|    total_timesteps      | 1380352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015653111 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 21380        |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    reward               | 1.4098879    |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 12135        |\n",
      "|    total_timesteps      | 1382400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010051029 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    reward               | 8.344594     |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 12154       |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006776125 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 21400       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | -4.8617587  |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 63.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 677          |\n",
      "|    time_elapsed         | 12172        |\n",
      "|    total_timesteps      | 1386496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011446434 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.9         |\n",
      "|    n_updates            | 21410        |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    reward               | -0.015593727 |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 678          |\n",
      "|    time_elapsed         | 12190        |\n",
      "|    total_timesteps      | 1388544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009008211 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.7         |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | 2.4665327    |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 679          |\n",
      "|    time_elapsed         | 12209        |\n",
      "|    total_timesteps      | 1390592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013516272 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.2         |\n",
      "|    n_updates            | 21430        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | -0.7855582   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6527889.42\n",
      "total_reward: 5527889.42\n",
      "total_cost: 145048.08\n",
      "total_trades: 58914\n",
      "Sharpe: 0.902\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 680          |\n",
      "|    time_elapsed         | 12227        |\n",
      "|    total_timesteps      | 1392640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058571594 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 21440        |\n",
      "|    policy_gradient_loss | -0.00852     |\n",
      "|    reward               | -1.4744892   |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 201          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 681           |\n",
      "|    time_elapsed         | 12245         |\n",
      "|    total_timesteps      | 1394688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096670596 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -119          |\n",
      "|    explained_variance   | 0.685         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 90.6          |\n",
      "|    n_updates            | 21450         |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    reward               | 0.7739192     |\n",
      "|    std                  | 15.1          |\n",
      "|    value_loss           | 158           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 682          |\n",
      "|    time_elapsed         | 12264        |\n",
      "|    total_timesteps      | 1396736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013028318 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 91.8         |\n",
      "|    n_updates            | 21460        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | -1.5791134   |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 206          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 12282       |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008427432 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 21470       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    reward               | 3.0493593   |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 684          |\n",
      "|    time_elapsed         | 12300        |\n",
      "|    total_timesteps      | 1400832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031750412 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.5         |\n",
      "|    n_updates            | 21480        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | 0.5528406    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 12318       |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001988368 |\n",
      "|    clip_fraction        | 0.00181     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 21490       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | -4.242906   |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 686          |\n",
      "|    time_elapsed         | 12336        |\n",
      "|    total_timesteps      | 1404928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007168461 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.2         |\n",
      "|    n_updates            | 21500        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | 3.8176985    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 687          |\n",
      "|    time_elapsed         | 12354        |\n",
      "|    total_timesteps      | 1406976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049010618 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.5         |\n",
      "|    n_updates            | 21510        |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    reward               | 0.8781554    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 688          |\n",
      "|    time_elapsed         | 12373        |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024279826 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.4         |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 1.1380372    |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 689          |\n",
      "|    time_elapsed         | 12391        |\n",
      "|    total_timesteps      | 1411072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016149292 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -119         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 21530        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    reward               | -0.6767584   |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 266          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 12410       |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008814277 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 21540       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    reward               | -0.42729893 |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 12428       |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001841305 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 68.5        |\n",
      "|    n_updates            | 21550       |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | 0.6728369   |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 692          |\n",
      "|    time_elapsed         | 12447        |\n",
      "|    total_timesteps      | 1417216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024203854 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    reward               | 0.5176769    |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 146          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 12465       |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007372055 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 21570       |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    reward               | 1.6818386   |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 59          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7237794.68\n",
      "total_reward: 6237794.68\n",
      "total_cost: 137889.28\n",
      "total_trades: 57185\n",
      "Sharpe: 0.963\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 694          |\n",
      "|    time_elapsed         | 12483        |\n",
      "|    total_timesteps      | 1421312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046012513 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.7         |\n",
      "|    n_updates            | 21580        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | 0.17507488   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 695          |\n",
      "|    time_elapsed         | 12501        |\n",
      "|    total_timesteps      | 1423360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013102728 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.2         |\n",
      "|    n_updates            | 21590        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | 0.043979492  |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 696          |\n",
      "|    time_elapsed         | 12520        |\n",
      "|    total_timesteps      | 1425408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009073592 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.9         |\n",
      "|    n_updates            | 21600        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | -1.1617277   |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 12538       |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009926733 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 21610       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -1.7146859  |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 698          |\n",
      "|    time_elapsed         | 12557        |\n",
      "|    total_timesteps      | 1429504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012274836 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.4         |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    reward               | 0.049944412  |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 699           |\n",
      "|    time_elapsed         | 12575         |\n",
      "|    total_timesteps      | 1431552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069604826 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -120          |\n",
      "|    explained_variance   | 0.587         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 41.9          |\n",
      "|    n_updates            | 21630         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    reward               | 0.72788495    |\n",
      "|    std                  | 15.3          |\n",
      "|    value_loss           | 181           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 700          |\n",
      "|    time_elapsed         | 12594        |\n",
      "|    total_timesteps      | 1433600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072431555 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 21640        |\n",
      "|    policy_gradient_loss | -0.00869     |\n",
      "|    reward               | 0.06356603   |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 53.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 701          |\n",
      "|    time_elapsed         | 12612        |\n",
      "|    total_timesteps      | 1435648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021794697 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 92.5         |\n",
      "|    n_updates            | 21650        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    reward               | -3.4196298   |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 702          |\n",
      "|    time_elapsed         | 12631        |\n",
      "|    total_timesteps      | 1437696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017416799 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.9         |\n",
      "|    n_updates            | 21660        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 3.5579681    |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 703          |\n",
      "|    time_elapsed         | 12649        |\n",
      "|    total_timesteps      | 1439744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014023762 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.1         |\n",
      "|    n_updates            | 21670        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 0.77835804   |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 704          |\n",
      "|    time_elapsed         | 12668        |\n",
      "|    total_timesteps      | 1441792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059901867 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.8         |\n",
      "|    n_updates            | 21680        |\n",
      "|    policy_gradient_loss | -0.00842     |\n",
      "|    reward               | -0.06839576  |\n",
      "|    std                  | 15.4         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 12687        |\n",
      "|    total_timesteps      | 1443840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018277738 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.9         |\n",
      "|    n_updates            | 21690        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | 0.28210986   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 706          |\n",
      "|    time_elapsed         | 12705        |\n",
      "|    total_timesteps      | 1445888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030831576 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.3         |\n",
      "|    n_updates            | 21700        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | -1.4138147   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 707          |\n",
      "|    time_elapsed         | 12723        |\n",
      "|    total_timesteps      | 1447936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073344535 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 21710        |\n",
      "|    policy_gradient_loss | -0.0092      |\n",
      "|    reward               | 1.7337215    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7197865.90\n",
      "total_reward: 6197865.90\n",
      "total_cost: 145402.84\n",
      "total_trades: 58103\n",
      "Sharpe: 0.971\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 708          |\n",
      "|    time_elapsed         | 12742        |\n",
      "|    total_timesteps      | 1449984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018297848 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.4         |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    reward               | 0.38496986   |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 709          |\n",
      "|    time_elapsed         | 12760        |\n",
      "|    total_timesteps      | 1452032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024422235 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.6         |\n",
      "|    n_updates            | 21730        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | 3.0563676    |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 710          |\n",
      "|    time_elapsed         | 12782        |\n",
      "|    total_timesteps      | 1454080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052594882 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.8         |\n",
      "|    n_updates            | 21740        |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    reward               | 3.202191     |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 711          |\n",
      "|    time_elapsed         | 12800        |\n",
      "|    total_timesteps      | 1456128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049606077 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.6         |\n",
      "|    n_updates            | 21750        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | -1.9799762   |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 12818        |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019438006 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.7         |\n",
      "|    n_updates            | 21760        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | -0.16477892  |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 713          |\n",
      "|    time_elapsed         | 12837        |\n",
      "|    total_timesteps      | 1460224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009130208 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -120         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68           |\n",
      "|    n_updates            | 21770        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -1.0791382   |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 12855       |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009978227 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -120        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.3        |\n",
      "|    n_updates            | 21780       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.24752517 |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 12874        |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018453951 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.6         |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | 1.2321515    |\n",
      "|    std                  | 15.7         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 12892       |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002666541 |\n",
      "|    clip_fraction        | 0.00811     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 21800       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    reward               | -8.31639    |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 12910       |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005423869 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 21810       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | 1.8317971   |\n",
      "|    std                  | 15.7        |\n",
      "|    value_loss           | 59.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 718          |\n",
      "|    time_elapsed         | 12929        |\n",
      "|    total_timesteps      | 1470464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038519083 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.1         |\n",
      "|    n_updates            | 21820        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | -1.1438669   |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 88.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 719          |\n",
      "|    time_elapsed         | 12947        |\n",
      "|    total_timesteps      | 1472512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038524542 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.8         |\n",
      "|    n_updates            | 21830        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    reward               | 11.283516    |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 720          |\n",
      "|    time_elapsed         | 12966        |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019326732 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.245        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.1         |\n",
      "|    n_updates            | 21840        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 2.5943933    |\n",
      "|    std                  | 15.8         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 12985       |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010348695 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.19        |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 2.4165335   |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5347073.92\n",
      "total_reward: 4347073.92\n",
      "total_cost: 164643.88\n",
      "total_trades: 58858\n",
      "Sharpe: 0.905\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 722          |\n",
      "|    time_elapsed         | 13003        |\n",
      "|    total_timesteps      | 1478656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035213495 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.2         |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | -2.181914    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 723         |\n",
      "|    time_elapsed         | 13022       |\n",
      "|    total_timesteps      | 1480704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002881574 |\n",
      "|    clip_fraction        | 0.00288     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 21870       |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | -1.8888711  |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 92.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 724          |\n",
      "|    time_elapsed         | 13040        |\n",
      "|    total_timesteps      | 1482752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056625265 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.3         |\n",
      "|    n_updates            | 21880        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | 4.1843247    |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 33.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 725          |\n",
      "|    time_elapsed         | 13059        |\n",
      "|    total_timesteps      | 1484800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059948764 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 21890        |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    reward               | 0.97414374   |\n",
      "|    std                  | 15.9         |\n",
      "|    value_loss           | 63.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 13078       |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002412417 |\n",
      "|    clip_fraction        | 0.00381     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.7        |\n",
      "|    n_updates            | 21900       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | -22.530767  |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 13097       |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002728446 |\n",
      "|    clip_fraction        | 0.00811     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 21910       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    reward               | -1.8489382  |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 13116       |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004158113 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 21920       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    reward               | -0.07309238 |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 53.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 729          |\n",
      "|    time_elapsed         | 13134        |\n",
      "|    total_timesteps      | 1492992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022388545 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 21930        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | -0.74461997  |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 13153       |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003362815 |\n",
      "|    clip_fraction        | 0.00835     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 21940       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    reward               | -1.7137384  |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 13171       |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009809351 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 21950       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 1.3514358   |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 732          |\n",
      "|    time_elapsed         | 13189        |\n",
      "|    total_timesteps      | 1499136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015397338 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.655        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 21960        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | -0.40301377  |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 98.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 733          |\n",
      "|    time_elapsed         | 13208        |\n",
      "|    total_timesteps      | 1501184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023394907 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.8         |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | -2.642633    |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 96.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 734          |\n",
      "|    time_elapsed         | 13226        |\n",
      "|    total_timesteps      | 1503232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018193852 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 21980        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -5.8873234   |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 58.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 735          |\n",
      "|    time_elapsed         | 13245        |\n",
      "|    total_timesteps      | 1505280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061576217 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 21990        |\n",
      "|    policy_gradient_loss | -0.0087      |\n",
      "|    reward               | -0.28269225  |\n",
      "|    std                  | 16           |\n",
      "|    value_loss           | 39.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5891764.00\n",
      "total_reward: 4891764.00\n",
      "total_cost: 214659.10\n",
      "total_trades: 61597\n",
      "Sharpe: 0.886\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 13264       |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003935659 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -121        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 22000       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | -0.65404385 |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 13282        |\n",
      "|    total_timesteps      | 1509376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017951177 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.3         |\n",
      "|    n_updates            | 22010        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 0.018920286  |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 132          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 738          |\n",
      "|    time_elapsed         | 13301        |\n",
      "|    total_timesteps      | 1511424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102114985 |\n",
      "|    clip_fraction        | 0.0929       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.46         |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    reward               | -0.25395423  |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 15.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 739          |\n",
      "|    time_elapsed         | 13319        |\n",
      "|    total_timesteps      | 1513472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027606483 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.9         |\n",
      "|    n_updates            | 22030        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    reward               | -0.39069527  |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 92.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 13338        |\n",
      "|    total_timesteps      | 1515520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020640464 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -121         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 22040        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 1.5142254    |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 741        |\n",
      "|    time_elapsed         | 13356      |\n",
      "|    total_timesteps      | 1517568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00664304 |\n",
      "|    clip_fraction        | 0.0162     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | 0.594      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 22050      |\n",
      "|    policy_gradient_loss | -0.00467   |\n",
      "|    reward               | 0.22337274 |\n",
      "|    std                  | 16.3       |\n",
      "|    value_loss           | 27.3       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 13374       |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004434065 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 22060       |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | 0.67078716  |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 743          |\n",
      "|    time_elapsed         | 13393        |\n",
      "|    total_timesteps      | 1521664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039232727 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 22070        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | -12.287625   |\n",
      "|    std                  | 16.3         |\n",
      "|    value_loss           | 68.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 13412       |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004082002 |\n",
      "|    clip_fraction        | 0.0082      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 22080       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    reward               | 0.5521136   |\n",
      "|    std                  | 16.3        |\n",
      "|    value_loss           | 63.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 13430       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010355752 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.84        |\n",
      "|    n_updates            | 22090       |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | -0.20154418 |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 13449       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003753305 |\n",
      "|    clip_fraction        | 0.00708     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 22100       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | -0.5262285  |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 13467       |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004388907 |\n",
      "|    clip_fraction        | 0.00552     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 22110       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | 2.808893    |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 42.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 748          |\n",
      "|    time_elapsed         | 13485        |\n",
      "|    total_timesteps      | 1531904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051475647 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.02         |\n",
      "|    n_updates            | 22120        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | 1.1603808    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 29.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 749          |\n",
      "|    time_elapsed         | 13504        |\n",
      "|    total_timesteps      | 1533952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038943368 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -3.4046159   |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 80.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 750          |\n",
      "|    time_elapsed         | 13523        |\n",
      "|    total_timesteps      | 1536000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010120714 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.4         |\n",
      "|    n_updates            | 22140        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | 5.5973554    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6228022.29\n",
      "total_reward: 5228022.29\n",
      "total_cost: 180450.58\n",
      "total_trades: 59673\n",
      "Sharpe: 0.942\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 751          |\n",
      "|    time_elapsed         | 13542        |\n",
      "|    total_timesteps      | 1538048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020365987 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 22150        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | -0.56288254  |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 70.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 752          |\n",
      "|    time_elapsed         | 13561        |\n",
      "|    total_timesteps      | 1540096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036085993 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.5         |\n",
      "|    n_updates            | 22160        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    reward               | 0.7112202    |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 71           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 13579       |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001138923 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 22170       |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | 0.22184141  |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 754          |\n",
      "|    time_elapsed         | 13597        |\n",
      "|    total_timesteps      | 1544192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025963648 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.9         |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    reward               | 0.64300925   |\n",
      "|    std                  | 16.5         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 755        |\n",
      "|    time_elapsed         | 13616      |\n",
      "|    total_timesteps      | 1546240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01026275 |\n",
      "|    clip_fraction        | 0.0968     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -122       |\n",
      "|    explained_variance   | 0.72       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.1       |\n",
      "|    n_updates            | 22190      |\n",
      "|    policy_gradient_loss | -0.00926   |\n",
      "|    reward               | 0.56739014 |\n",
      "|    std                  | 16.5       |\n",
      "|    value_loss           | 18.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 13635       |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002320652 |\n",
      "|    clip_fraction        | 0.002       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 22200       |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -0.44833452 |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 13654       |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000633413 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 62.5        |\n",
      "|    n_updates            | 22210       |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    reward               | 3.6653638   |\n",
      "|    std                  | 16.5        |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 13673       |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002159885 |\n",
      "|    clip_fraction        | 0.0022      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 22220       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    reward               | 0.48090804  |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 81.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 759          |\n",
      "|    time_elapsed         | 13691        |\n",
      "|    total_timesteps      | 1554432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017304402 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.1         |\n",
      "|    n_updates            | 22230        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | -0.32221192  |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 94.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 13710       |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002084834 |\n",
      "|    clip_fraction        | 0.00308     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.6        |\n",
      "|    n_updates            | 22240       |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | 0.15519328  |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 761          |\n",
      "|    time_elapsed         | 13729        |\n",
      "|    total_timesteps      | 1558528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009213654 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.9         |\n",
      "|    n_updates            | 22250        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    reward               | -0.17814118  |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 13748       |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008332047 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 22260       |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    reward               | 6.150878    |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 763           |\n",
      "|    time_elapsed         | 13766         |\n",
      "|    total_timesteps      | 1562624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079756137 |\n",
      "|    clip_fraction        | 0.00176       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.618         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55            |\n",
      "|    n_updates            | 22270         |\n",
      "|    policy_gradient_loss | -0.00118      |\n",
      "|    reward               | -2.188682     |\n",
      "|    std                  | 16.7          |\n",
      "|    value_loss           | 133           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 764           |\n",
      "|    time_elapsed         | 13785         |\n",
      "|    total_timesteps      | 1564672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064453983 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.609         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 60.6          |\n",
      "|    n_updates            | 22280         |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    reward               | 0.8365782     |\n",
      "|    std                  | 16.7          |\n",
      "|    value_loss           | 164           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6293998.10\n",
      "total_reward: 5293998.10\n",
      "total_cost: 188588.29\n",
      "total_trades: 60707\n",
      "Sharpe: 0.890\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 13803       |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004543605 |\n",
      "|    clip_fraction        | 0.00957     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -122        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.6        |\n",
      "|    n_updates            | 22290       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    reward               | -0.26603565 |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 766           |\n",
      "|    time_elapsed         | 13822         |\n",
      "|    total_timesteps      | 1568768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.002793876   |\n",
      "|    clip_fraction        | 0.00522       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -122          |\n",
      "|    explained_variance   | 0.552         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 86.7          |\n",
      "|    n_updates            | 22300         |\n",
      "|    policy_gradient_loss | -0.00394      |\n",
      "|    reward               | -0.0048295828 |\n",
      "|    std                  | 16.8          |\n",
      "|    value_loss           | 107           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 767          |\n",
      "|    time_elapsed         | 13840        |\n",
      "|    total_timesteps      | 1570816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008700142 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.2         |\n",
      "|    n_updates            | 22310        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | 31.37352     |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 768          |\n",
      "|    time_elapsed         | 13859        |\n",
      "|    total_timesteps      | 1572864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019984236 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -122         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.2         |\n",
      "|    n_updates            | 22320        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 0.48784384   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 13877       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005519559 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.1        |\n",
      "|    n_updates            | 22330       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -0.20436864 |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 770          |\n",
      "|    time_elapsed         | 13896        |\n",
      "|    total_timesteps      | 1576960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021077418 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 22340        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    reward               | 0.32034576   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 771          |\n",
      "|    time_elapsed         | 13914        |\n",
      "|    total_timesteps      | 1579008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010207703 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63           |\n",
      "|    n_updates            | 22350        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -5.1611657   |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 13933       |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008252987 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 22360       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    reward               | -0.75244653 |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 773          |\n",
      "|    time_elapsed         | 13951        |\n",
      "|    total_timesteps      | 1583104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021724608 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.8         |\n",
      "|    n_updates            | 22370        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -0.8785683   |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 13969       |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000857464 |\n",
      "|    clip_fraction        | 0.00083     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 75.8        |\n",
      "|    n_updates            | 22380       |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    reward               | 9.610608    |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 775          |\n",
      "|    time_elapsed         | 13988        |\n",
      "|    total_timesteps      | 1587200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059550926 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.5         |\n",
      "|    n_updates            | 22390        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | -0.53248286  |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 97.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 776          |\n",
      "|    time_elapsed         | 14006        |\n",
      "|    total_timesteps      | 1589248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028374055 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.2         |\n",
      "|    n_updates            | 22400        |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    reward               | -1.0878483   |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 777          |\n",
      "|    time_elapsed         | 14024        |\n",
      "|    total_timesteps      | 1591296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037271476 |\n",
      "|    clip_fraction        | 0.00864      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 22410        |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    reward               | 1.1979932    |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 778          |\n",
      "|    time_elapsed         | 14043        |\n",
      "|    total_timesteps      | 1593344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029730708 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 95.6         |\n",
      "|    n_updates            | 22420        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    reward               | 0.13559426   |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5809391.28\n",
      "total_reward: 4809391.28\n",
      "total_cost: 224435.33\n",
      "total_trades: 62712\n",
      "Sharpe: 0.852\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 14062       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008822824 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 22430       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -1.8303349  |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 14081       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001915232 |\n",
      "|    clip_fraction        | 0.00215     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.5        |\n",
      "|    n_updates            | 22440       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | 1.5243633   |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 781          |\n",
      "|    time_elapsed         | 14100        |\n",
      "|    total_timesteps      | 1599488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041978057 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.2         |\n",
      "|    n_updates            | 22450        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    reward               | -5.1421027   |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 782          |\n",
      "|    time_elapsed         | 14118        |\n",
      "|    total_timesteps      | 1601536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054430687 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 22460        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | -3.6360974   |\n",
      "|    std                  | 17           |\n",
      "|    value_loss           | 56.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 783          |\n",
      "|    time_elapsed         | 14137        |\n",
      "|    total_timesteps      | 1603584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036731302 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 22470        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 0.41809544   |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 92.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 14155       |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003603442 |\n",
      "|    clip_fraction        | 0.00728     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 22480       |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    reward               | 0.84151596  |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 785          |\n",
      "|    time_elapsed         | 14173        |\n",
      "|    total_timesteps      | 1607680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013647593 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 22490        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | 2.707851     |\n",
      "|    std                  | 17.1         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 14192       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008664664 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.81        |\n",
      "|    n_updates            | 22500       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | 0.269993    |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 787          |\n",
      "|    time_elapsed         | 14210        |\n",
      "|    total_timesteps      | 1611776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014326927 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.9         |\n",
      "|    n_updates            | 22510        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | -1.0233622   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 14229        |\n",
      "|    total_timesteps      | 1613824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006091991 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.9         |\n",
      "|    n_updates            | 22520        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    reward               | 0.54265064   |\n",
      "|    std                  | 17.2         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 14247       |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008146514 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 22530       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | -1.781168   |\n",
      "|    std                  | 17.2        |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 790          |\n",
      "|    time_elapsed         | 14267        |\n",
      "|    total_timesteps      | 1617920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028103832 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 22540        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    reward               | 0.8544643    |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 92.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 791          |\n",
      "|    time_elapsed         | 14285        |\n",
      "|    total_timesteps      | 1619968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020929114 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.6         |\n",
      "|    n_updates            | 22550        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -0.25307655  |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 135          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 792          |\n",
      "|    time_elapsed         | 14304        |\n",
      "|    total_timesteps      | 1622016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042816317 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 22560        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | 2.0587852    |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 71.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5102863.92\n",
      "total_reward: 4102863.92\n",
      "total_cost: 252205.78\n",
      "total_trades: 64455\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 14323       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007098736 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -123        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | 1.5684537   |\n",
      "|    std                  | 17.3        |\n",
      "|    value_loss           | 59.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 794          |\n",
      "|    time_elapsed         | 14341        |\n",
      "|    total_timesteps      | 1626112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017408936 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.5         |\n",
      "|    n_updates            | 22580        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    reward               | 0.22047605   |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 14359        |\n",
      "|    total_timesteps      | 1628160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007513654 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -123         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.4         |\n",
      "|    n_updates            | 22590        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    reward               | -0.70037407  |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 796         |\n",
      "|    time_elapsed         | 14378       |\n",
      "|    total_timesteps      | 1630208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007370648 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 22600       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -0.57815206 |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 797        |\n",
      "|    time_elapsed         | 14396      |\n",
      "|    total_timesteps      | 1632256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0009446  |\n",
      "|    clip_fraction        | 0.000684   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -124       |\n",
      "|    explained_variance   | 0.65       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 155        |\n",
      "|    n_updates            | 22610      |\n",
      "|    policy_gradient_loss | -0.00246   |\n",
      "|    reward               | 0.29096675 |\n",
      "|    std                  | 17.4       |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 798           |\n",
      "|    time_elapsed         | 14415         |\n",
      "|    total_timesteps      | 1634304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051496155 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.637         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 81.1          |\n",
      "|    n_updates            | 22620         |\n",
      "|    policy_gradient_loss | -0.00223      |\n",
      "|    reward               | -2.8808956    |\n",
      "|    std                  | 17.4          |\n",
      "|    value_loss           | 155           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 799          |\n",
      "|    time_elapsed         | 14433        |\n",
      "|    total_timesteps      | 1636352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023053996 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.629        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.1         |\n",
      "|    n_updates            | 22630        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | -1.2531521   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 78           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 800          |\n",
      "|    time_elapsed         | 14452        |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064145075 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.8         |\n",
      "|    n_updates            | 22640        |\n",
      "|    policy_gradient_loss | -0.00874     |\n",
      "|    reward               | -1.2324765   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 89.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 801          |\n",
      "|    time_elapsed         | 14470        |\n",
      "|    total_timesteps      | 1640448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012697409 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.6         |\n",
      "|    n_updates            | 22650        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -1.4739035   |\n",
      "|    std                  | 17.4         |\n",
      "|    value_loss           | 138          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 802          |\n",
      "|    time_elapsed         | 14488        |\n",
      "|    total_timesteps      | 1642496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012046691 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.5         |\n",
      "|    n_updates            | 22660        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 4.6041746    |\n",
      "|    std                  | 17.5         |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 14507       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009100033 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 22670       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | 1.1223007   |\n",
      "|    std                  | 17.5        |\n",
      "|    value_loss           | 30.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 804        |\n",
      "|    time_elapsed         | 14525      |\n",
      "|    total_timesteps      | 1646592    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00318281 |\n",
      "|    clip_fraction        | 0.00635    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -124       |\n",
      "|    explained_variance   | 0.55       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 128        |\n",
      "|    n_updates            | 22680      |\n",
      "|    policy_gradient_loss | -0.0057    |\n",
      "|    reward               | 0.577543   |\n",
      "|    std                  | 17.5       |\n",
      "|    value_loss           | 160        |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 805           |\n",
      "|    time_elapsed         | 14543         |\n",
      "|    total_timesteps      | 1648640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082885893 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.524         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 94.1          |\n",
      "|    n_updates            | 22690         |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    reward               | 0.83118415    |\n",
      "|    std                  | 17.5          |\n",
      "|    value_loss           | 154           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 806          |\n",
      "|    time_elapsed         | 14562        |\n",
      "|    total_timesteps      | 1650688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045369593 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 22700        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | 7.163254     |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6221660.61\n",
      "total_reward: 5221660.61\n",
      "total_cost: 220543.14\n",
      "total_trades: 63191\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 807          |\n",
      "|    time_elapsed         | 14581        |\n",
      "|    total_timesteps      | 1652736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037048138 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 57.6         |\n",
      "|    n_updates            | 22710        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    reward               | 0.9347433    |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 808          |\n",
      "|    time_elapsed         | 14600        |\n",
      "|    total_timesteps      | 1654784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010180189 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.6         |\n",
      "|    n_updates            | 22720        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | -3.1479871   |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 809          |\n",
      "|    time_elapsed         | 14619        |\n",
      "|    total_timesteps      | 1656832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024692584 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.3         |\n",
      "|    n_updates            | 22730        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    reward               | 2.6219144    |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 237          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 810        |\n",
      "|    time_elapsed         | 14638      |\n",
      "|    total_timesteps      | 1658880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00987531 |\n",
      "|    clip_fraction        | 0.0615     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -124       |\n",
      "|    explained_variance   | 0.479      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 13.4       |\n",
      "|    n_updates            | 22740      |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    reward               | 0.5933426  |\n",
      "|    std                  | 17.7       |\n",
      "|    value_loss           | 28.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 811          |\n",
      "|    time_elapsed         | 14657        |\n",
      "|    total_timesteps      | 1660928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006244486 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 96.7         |\n",
      "|    n_updates            | 22750        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | -0.7713392   |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 812          |\n",
      "|    time_elapsed         | 14675        |\n",
      "|    total_timesteps      | 1662976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013524375 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.4         |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | 4.178955     |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 813          |\n",
      "|    time_elapsed         | 14693        |\n",
      "|    total_timesteps      | 1665024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067785806 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 22770        |\n",
      "|    policy_gradient_loss | -0.00772     |\n",
      "|    reward               | 2.8524144    |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 38.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 814          |\n",
      "|    time_elapsed         | 14713        |\n",
      "|    total_timesteps      | 1667072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015204884 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 22780        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    reward               | 3.819994     |\n",
      "|    std                  | 17.7         |\n",
      "|    value_loss           | 97.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 815          |\n",
      "|    time_elapsed         | 14731        |\n",
      "|    total_timesteps      | 1669120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015856654 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.7         |\n",
      "|    n_updates            | 22790        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | 5.276372     |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 99           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 816        |\n",
      "|    time_elapsed         | 14750      |\n",
      "|    total_timesteps      | 1671168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00639202 |\n",
      "|    clip_fraction        | 0.011      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -124       |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.6       |\n",
      "|    n_updates            | 22800      |\n",
      "|    policy_gradient_loss | -0.00726   |\n",
      "|    reward               | 0.9088506  |\n",
      "|    std                  | 17.8       |\n",
      "|    value_loss           | 92.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 817          |\n",
      "|    time_elapsed         | 14768        |\n",
      "|    total_timesteps      | 1673216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034090842 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 22810        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | -0.8977253   |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 94.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 14787       |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001210959 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66.4        |\n",
      "|    n_updates            | 22820       |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | 0.6192772   |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 819          |\n",
      "|    time_elapsed         | 14805        |\n",
      "|    total_timesteps      | 1677312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030716672 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.4         |\n",
      "|    n_updates            | 22830        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    reward               | -3.092919    |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 14824       |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007729684 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -124        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 22840       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    reward               | 0.5340357   |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 30.9        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5687901.14\n",
      "total_reward: 4687901.14\n",
      "total_cost: 216316.89\n",
      "total_trades: 61878\n",
      "Sharpe: 0.815\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 821           |\n",
      "|    time_elapsed         | 14842         |\n",
      "|    total_timesteps      | 1681408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091878825 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -124          |\n",
      "|    explained_variance   | 0.537         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.7          |\n",
      "|    n_updates            | 22850         |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    reward               | -0.43410608   |\n",
      "|    std                  | 17.9          |\n",
      "|    value_loss           | 123           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 822          |\n",
      "|    time_elapsed         | 14861        |\n",
      "|    total_timesteps      | 1683456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005786739 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -124         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.6         |\n",
      "|    n_updates            | 22860        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | 1.418296     |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 823          |\n",
      "|    time_elapsed         | 14879        |\n",
      "|    total_timesteps      | 1685504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021148198 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.2         |\n",
      "|    n_updates            | 22870        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -0.59027845  |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 65.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 824          |\n",
      "|    time_elapsed         | 14898        |\n",
      "|    total_timesteps      | 1687552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033929457 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 22880        |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    reward               | 2.114521     |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 91.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 825          |\n",
      "|    time_elapsed         | 14919        |\n",
      "|    total_timesteps      | 1689600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011720385 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.3         |\n",
      "|    n_updates            | 22890        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | -0.5901736   |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 826          |\n",
      "|    time_elapsed         | 14937        |\n",
      "|    total_timesteps      | 1691648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016591098 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35           |\n",
      "|    n_updates            | 22900        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 2.1644692    |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 14957       |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009528796 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.31        |\n",
      "|    n_updates            | 22910       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 2.0141678   |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 828          |\n",
      "|    time_elapsed         | 14975        |\n",
      "|    total_timesteps      | 1695744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009705419 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 46.3         |\n",
      "|    n_updates            | 22920        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | -0.2717037   |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 829           |\n",
      "|    time_elapsed         | 14994         |\n",
      "|    total_timesteps      | 1697792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022693138 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.535         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.3          |\n",
      "|    n_updates            | 22930         |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    reward               | 11.129349     |\n",
      "|    std                  | 18.1          |\n",
      "|    value_loss           | 163           |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 830        |\n",
      "|    time_elapsed         | 15013      |\n",
      "|    total_timesteps      | 1699840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00520868 |\n",
      "|    clip_fraction        | 0.0165     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -125       |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 22940      |\n",
      "|    policy_gradient_loss | -0.004     |\n",
      "|    reward               | -1.7900896 |\n",
      "|    std                  | 18.2       |\n",
      "|    value_loss           | 52.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 831          |\n",
      "|    time_elapsed         | 15031        |\n",
      "|    total_timesteps      | 1701888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027978143 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 22950        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    reward               | 2.532811     |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 86           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 832          |\n",
      "|    time_elapsed         | 15050        |\n",
      "|    total_timesteps      | 1703936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020550238 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58           |\n",
      "|    n_updates            | 22960        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | 7.2892833    |\n",
      "|    std                  | 18.2         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 833          |\n",
      "|    time_elapsed         | 15068        |\n",
      "|    total_timesteps      | 1705984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029258728 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.3         |\n",
      "|    n_updates            | 22970        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    reward               | -0.71345407  |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 15087       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007851444 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.06        |\n",
      "|    n_updates            | 22980       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    reward               | -4.3769383  |\n",
      "|    std                  | 18.3        |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6490875.12\n",
      "total_reward: 5490875.12\n",
      "total_cost: 236074.62\n",
      "total_trades: 62660\n",
      "Sharpe: 0.891\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 835          |\n",
      "|    time_elapsed         | 15106        |\n",
      "|    total_timesteps      | 1710080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016164173 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 95.4         |\n",
      "|    n_updates            | 22990        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | 0.47519252   |\n",
      "|    std                  | 18.3         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 836           |\n",
      "|    time_elapsed         | 15126         |\n",
      "|    total_timesteps      | 1712128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082307355 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -125          |\n",
      "|    explained_variance   | 0.461         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 70.2          |\n",
      "|    n_updates            | 23000         |\n",
      "|    policy_gradient_loss | -0.0022       |\n",
      "|    reward               | -0.77840537   |\n",
      "|    std                  | 18.3          |\n",
      "|    value_loss           | 168           |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 113       |\n",
      "|    iterations           | 837       |\n",
      "|    time_elapsed         | 15144     |\n",
      "|    total_timesteps      | 1714176   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0082286 |\n",
      "|    clip_fraction        | 0.0338    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -125      |\n",
      "|    explained_variance   | 0.611     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 16.4      |\n",
      "|    n_updates            | 23010     |\n",
      "|    policy_gradient_loss | -0.00889  |\n",
      "|    reward               | 5.1486344 |\n",
      "|    std                  | 18.4      |\n",
      "|    value_loss           | 38.8      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 838          |\n",
      "|    time_elapsed         | 15163        |\n",
      "|    total_timesteps      | 1716224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025686699 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | 3.30449      |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 839          |\n",
      "|    time_elapsed         | 15181        |\n",
      "|    total_timesteps      | 1718272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031780738 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.6         |\n",
      "|    n_updates            | 23030        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | 5.2584786    |\n",
      "|    std                  | 18.4         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 840          |\n",
      "|    time_elapsed         | 15200        |\n",
      "|    total_timesteps      | 1720320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034210375 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.4         |\n",
      "|    n_updates            | 23040        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 1.6048739    |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 55.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 841          |\n",
      "|    time_elapsed         | 15218        |\n",
      "|    total_timesteps      | 1722368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058831587 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 23050        |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    reward               | -1.2621386   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 67.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 842          |\n",
      "|    time_elapsed         | 15236        |\n",
      "|    total_timesteps      | 1724416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009102613 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 23060        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -2.1720748   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 843          |\n",
      "|    time_elapsed         | 15255        |\n",
      "|    total_timesteps      | 1726464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018641409 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.2         |\n",
      "|    n_updates            | 23070        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 0.33980826   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 265          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 15273       |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008012829 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -125        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 23080       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    reward               | 0.5846205   |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 845          |\n",
      "|    time_elapsed         | 15291        |\n",
      "|    total_timesteps      | 1730560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011734318 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.7         |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -1.7848486   |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 846          |\n",
      "|    time_elapsed         | 15310        |\n",
      "|    total_timesteps      | 1732608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012351518 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -125         |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.5         |\n",
      "|    n_updates            | 23100        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | -2.964881    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 847        |\n",
      "|    time_elapsed         | 15328      |\n",
      "|    total_timesteps      | 1734656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00451376 |\n",
      "|    clip_fraction        | 0.0109     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -125       |\n",
      "|    explained_variance   | 0.613      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 23110      |\n",
      "|    policy_gradient_loss | -0.00422   |\n",
      "|    reward               | 3.7064378  |\n",
      "|    std                  | 18.6       |\n",
      "|    value_loss           | 53         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 848          |\n",
      "|    time_elapsed         | 15347        |\n",
      "|    total_timesteps      | 1736704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036495868 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50           |\n",
      "|    n_updates            | 23120        |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    reward               | 2.277711     |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 78.3         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5167616.41\n",
      "total_reward: 4167616.41\n",
      "total_cost: 251706.85\n",
      "total_trades: 64054\n",
      "Sharpe: 0.780\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 849          |\n",
      "|    time_elapsed         | 15365        |\n",
      "|    total_timesteps      | 1738752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013728716 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.6         |\n",
      "|    n_updates            | 23130        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -0.8146862   |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 850          |\n",
      "|    time_elapsed         | 15384        |\n",
      "|    total_timesteps      | 1740800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018948598 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.5         |\n",
      "|    n_updates            | 23140        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | -5.280125    |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 15403       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008173078 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 23150       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 0.483687    |\n",
      "|    std                  | 18.7        |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 852          |\n",
      "|    time_elapsed         | 15421        |\n",
      "|    total_timesteps      | 1744896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010696175 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 74.9         |\n",
      "|    n_updates            | 23160        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -1.755504    |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 15440       |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003912725 |\n",
      "|    clip_fraction        | 0.00718     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 23170       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    reward               | -17.061209  |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 15459       |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005085365 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 23180       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 0.48692998  |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 855          |\n",
      "|    time_elapsed         | 15477        |\n",
      "|    total_timesteps      | 1751040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027173164 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.1         |\n",
      "|    n_updates            | 23190        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | 0.22923864   |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 92.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 856          |\n",
      "|    time_elapsed         | 15496        |\n",
      "|    total_timesteps      | 1753088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015289556 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 23200        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 20.142433    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 857          |\n",
      "|    time_elapsed         | 15514        |\n",
      "|    total_timesteps      | 1755136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016945502 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.6         |\n",
      "|    n_updates            | 23210        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    reward               | 3.0410602    |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 15532       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006433131 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.88        |\n",
      "|    n_updates            | 23220       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    reward               | 1.429083    |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 15552       |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004178502 |\n",
      "|    clip_fraction        | 0.00845     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.2        |\n",
      "|    n_updates            | 23230       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -0.39619505 |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 860          |\n",
      "|    time_elapsed         | 15570        |\n",
      "|    total_timesteps      | 1761280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014044198 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.7         |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | 3.755786     |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 144          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 861          |\n",
      "|    time_elapsed         | 15589        |\n",
      "|    total_timesteps      | 1763328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069468254 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 23250        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    reward               | 0.57686603   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 50.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 15608       |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002342621 |\n",
      "|    clip_fraction        | 0.00171     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -126        |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 72.9        |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | -3.3344316  |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 863          |\n",
      "|    time_elapsed         | 15626        |\n",
      "|    total_timesteps      | 1767424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032204576 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.3         |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | -1.7601486   |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 256          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6004894.52\n",
      "total_reward: 5004894.52\n",
      "total_cost: 223494.06\n",
      "total_trades: 62173\n",
      "Sharpe: 0.845\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 864          |\n",
      "|    time_elapsed         | 15645        |\n",
      "|    total_timesteps      | 1769472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053781755 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.4         |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    reward               | 1.0642265    |\n",
      "|    std                  | 19.1         |\n",
      "|    value_loss           | 66.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 865          |\n",
      "|    time_elapsed         | 15663        |\n",
      "|    total_timesteps      | 1771520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040683183 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.3         |\n",
      "|    n_updates            | 23290        |\n",
      "|    policy_gradient_loss | -0.00751     |\n",
      "|    reward               | -1.1680648   |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 98.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 866          |\n",
      "|    time_elapsed         | 15682        |\n",
      "|    total_timesteps      | 1773568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009706637 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 23300        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 0.5346717    |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 867           |\n",
      "|    time_elapsed         | 15700         |\n",
      "|    total_timesteps      | 1775616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041154772 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -126          |\n",
      "|    explained_variance   | 0.56          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 64            |\n",
      "|    n_updates            | 23310         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | -0.45265633   |\n",
      "|    std                  | 19.2          |\n",
      "|    value_loss           | 123           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 868          |\n",
      "|    time_elapsed         | 15719        |\n",
      "|    total_timesteps      | 1777664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055251196 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -126         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 23320        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    reward               | 0.8460592    |\n",
      "|    std                  | 19.2         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 869          |\n",
      "|    time_elapsed         | 15737        |\n",
      "|    total_timesteps      | 1779712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050568897 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 116          |\n",
      "|    n_updates            | 23330        |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    reward               | -0.003815383 |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 231          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 870          |\n",
      "|    time_elapsed         | 15755        |\n",
      "|    total_timesteps      | 1781760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021123094 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.1         |\n",
      "|    n_updates            | 23340        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    reward               | 1.1341437    |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 15774       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003396499 |\n",
      "|    clip_fraction        | 0.00361     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.2        |\n",
      "|    n_updates            | 23350       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    reward               | 1.7667649   |\n",
      "|    std                  | 19.3        |\n",
      "|    value_loss           | 79.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 872          |\n",
      "|    time_elapsed         | 15792        |\n",
      "|    total_timesteps      | 1785856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026380566 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 23360        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | 0.959971     |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 15810       |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002552357 |\n",
      "|    clip_fraction        | 0.00405     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 23370       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | -1.1118884  |\n",
      "|    std                  | 19.4        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 874           |\n",
      "|    time_elapsed         | 15829         |\n",
      "|    total_timesteps      | 1789952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073413027 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -127          |\n",
      "|    explained_variance   | 0.531         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 90.2          |\n",
      "|    n_updates            | 23380         |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    reward               | 0.6177308     |\n",
      "|    std                  | 19.4          |\n",
      "|    value_loss           | 179           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 875          |\n",
      "|    time_elapsed         | 15847        |\n",
      "|    total_timesteps      | 1792000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074163685 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.00884     |\n",
      "|    reward               | 1.7205368    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 26.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 876          |\n",
      "|    time_elapsed         | 15865        |\n",
      "|    total_timesteps      | 1794048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035941342 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.2         |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.00741     |\n",
      "|    reward               | 1.3463652    |\n",
      "|    std                  | 19.5         |\n",
      "|    value_loss           | 228          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 877         |\n",
      "|    time_elapsed         | 15884       |\n",
      "|    total_timesteps      | 1796096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001029283 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.6        |\n",
      "|    n_updates            | 23410       |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    reward               | 3.887875    |\n",
      "|    std                  | 19.6        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6026399.28\n",
      "total_reward: 5026399.28\n",
      "total_cost: 206202.14\n",
      "total_trades: 61477\n",
      "Sharpe: 0.829\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 15902       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007717493 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 23420       |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | -4.315621   |\n",
      "|    std                  | 19.6        |\n",
      "|    value_loss           | 49.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 879          |\n",
      "|    time_elapsed         | 15920        |\n",
      "|    total_timesteps      | 1800192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032313922 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 142          |\n",
      "|    n_updates            | 23430        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    reward               | 0.6476784    |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 880          |\n",
      "|    time_elapsed         | 15938        |\n",
      "|    total_timesteps      | 1802240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023194384 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 98.8         |\n",
      "|    n_updates            | 23440        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    reward               | 8.837092     |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 268          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 881          |\n",
      "|    time_elapsed         | 15957        |\n",
      "|    total_timesteps      | 1804288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041746255 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.32         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.1         |\n",
      "|    n_updates            | 23450        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -0.97528714  |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 882          |\n",
      "|    time_elapsed         | 15975        |\n",
      "|    total_timesteps      | 1806336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028515428 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 23460        |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    reward               | -1.6822557   |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 883          |\n",
      "|    time_elapsed         | 15993        |\n",
      "|    total_timesteps      | 1808384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020141467 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.4         |\n",
      "|    n_updates            | 23470        |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | 0.57127714   |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 213          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 884          |\n",
      "|    time_elapsed         | 16011        |\n",
      "|    total_timesteps      | 1810432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018863593 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 223          |\n",
      "|    n_updates            | 23480        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 8.055816     |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 290          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 16030       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004758957 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 23490       |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    reward               | 3.30721     |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 16048       |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004273452 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -127        |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.9        |\n",
      "|    n_updates            | 23500       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    reward               | -2.5459955  |\n",
      "|    std                  | 19.9        |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 887          |\n",
      "|    time_elapsed         | 16066        |\n",
      "|    total_timesteps      | 1816576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010529442 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    reward               | 8.871564     |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 888          |\n",
      "|    time_elapsed         | 16085        |\n",
      "|    total_timesteps      | 1818624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069940584 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -127         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.8         |\n",
      "|    n_updates            | 23520        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    reward               | 3.586449     |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 88.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 889          |\n",
      "|    time_elapsed         | 16103        |\n",
      "|    total_timesteps      | 1820672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014393363 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.9         |\n",
      "|    n_updates            | 23530        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -0.08140381  |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 890          |\n",
      "|    time_elapsed         | 16121        |\n",
      "|    total_timesteps      | 1822720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032961606 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 120          |\n",
      "|    n_updates            | 23540        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | -0.47868302  |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 269          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 891          |\n",
      "|    time_elapsed         | 16139        |\n",
      "|    total_timesteps      | 1824768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032084866 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 95           |\n",
      "|    n_updates            | 23550        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | 4.488828     |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7065963.04\n",
      "total_reward: 6065963.04\n",
      "total_cost: 175391.84\n",
      "total_trades: 59766\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 892        |\n",
      "|    time_elapsed         | 16158      |\n",
      "|    total_timesteps      | 1826816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00862134 |\n",
      "|    clip_fraction        | 0.0414     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -128       |\n",
      "|    explained_variance   | 0.477      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 12.8       |\n",
      "|    n_updates            | 23560      |\n",
      "|    policy_gradient_loss | -0.00867   |\n",
      "|    reward               | 3.6773667  |\n",
      "|    std                  | 20.1       |\n",
      "|    value_loss           | 36.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 16177       |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004328426 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 23570       |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    reward               | 0.014172158 |\n",
      "|    std                  | 20.1        |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 894          |\n",
      "|    time_elapsed         | 16195        |\n",
      "|    total_timesteps      | 1830912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024992675 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.3         |\n",
      "|    n_updates            | 23580        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | 2.5664291    |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 194          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 895          |\n",
      "|    time_elapsed         | 16214        |\n",
      "|    total_timesteps      | 1832960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050007296 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 23590        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | -2.1223052   |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 73.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 896          |\n",
      "|    time_elapsed         | 16232        |\n",
      "|    total_timesteps      | 1835008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010171696 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.3         |\n",
      "|    n_updates            | 23600        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | -0.735608    |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 85           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 897          |\n",
      "|    time_elapsed         | 16250        |\n",
      "|    total_timesteps      | 1837056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020330437 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 23610        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | -14.653663   |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 262          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 898          |\n",
      "|    time_elapsed         | 16271        |\n",
      "|    total_timesteps      | 1839104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038148784 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.7         |\n",
      "|    n_updates            | 23620        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | -1.4367805   |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 899         |\n",
      "|    time_elapsed         | 16290       |\n",
      "|    total_timesteps      | 1841152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062869 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.09        |\n",
      "|    n_updates            | 23630       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | -2.282301   |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 900          |\n",
      "|    time_elapsed         | 16308        |\n",
      "|    total_timesteps      | 1843200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015792804 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.3         |\n",
      "|    n_updates            | 23640        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 0.7275349    |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 113           |\n",
      "|    iterations           | 901           |\n",
      "|    time_elapsed         | 16326         |\n",
      "|    total_timesteps      | 1845248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090622937 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.587         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 56.5          |\n",
      "|    n_updates            | 23650         |\n",
      "|    policy_gradient_loss | -0.00268      |\n",
      "|    reward               | -4.4433784    |\n",
      "|    std                  | 20.3          |\n",
      "|    value_loss           | 153           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 16345       |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004879169 |\n",
      "|    clip_fraction        | 0.00991     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 23660       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    reward               | -2.2978454  |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 65.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 903          |\n",
      "|    time_elapsed         | 16363        |\n",
      "|    total_timesteps      | 1849344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029042903 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 23670        |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    reward               | -0.46310765  |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 220          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 904          |\n",
      "|    time_elapsed         | 16382        |\n",
      "|    total_timesteps      | 1851392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018834801 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.4         |\n",
      "|    n_updates            | 23680        |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    reward               | -2.0470426   |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 249          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 16400        |\n",
      "|    total_timesteps      | 1853440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018819929 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 23690        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    reward               | -3.1341512   |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 94.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6136660.17\n",
      "total_reward: 5136660.17\n",
      "total_cost: 208196.85\n",
      "total_trades: 61374\n",
      "Sharpe: 0.837\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 906          |\n",
      "|    time_elapsed         | 16418        |\n",
      "|    total_timesteps      | 1855488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038694823 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    reward               | 2.9309983    |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 75.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 907          |\n",
      "|    time_elapsed         | 16437        |\n",
      "|    total_timesteps      | 1857536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007039823 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -128         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.1         |\n",
      "|    n_updates            | 23710        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 0.6517       |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 113        |\n",
      "|    iterations           | 908        |\n",
      "|    time_elapsed         | 16455      |\n",
      "|    total_timesteps      | 1859584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00067021 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -128       |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 132        |\n",
      "|    n_updates            | 23720      |\n",
      "|    policy_gradient_loss | -0.00168   |\n",
      "|    reward               | 5.6775036  |\n",
      "|    std                  | 20.5       |\n",
      "|    value_loss           | 200        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 909         |\n",
      "|    time_elapsed         | 16474       |\n",
      "|    total_timesteps      | 1861632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003305452 |\n",
      "|    clip_fraction        | 0.00264     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | -0.0295     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 23730       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    reward               | -1.0481043  |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 16493       |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003534276 |\n",
      "|    clip_fraction        | 0.00679     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 23740       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    reward               | -1.749891   |\n",
      "|    std                  | 20.5        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 911           |\n",
      "|    time_elapsed         | 16511         |\n",
      "|    total_timesteps      | 1865728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039455135 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -128          |\n",
      "|    explained_variance   | 0.586         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 82.1          |\n",
      "|    n_updates            | 23750         |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | -1.8005391    |\n",
      "|    std                  | 20.5          |\n",
      "|    value_loss           | 162           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 16530       |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004142235 |\n",
      "|    clip_fraction        | 0.00737     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 23760       |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    reward               | 6.641624    |\n",
      "|    std                  | 20.6        |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 16548       |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002714311 |\n",
      "|    clip_fraction        | 0.00288     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -128        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 23770       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    reward               | 1.7722445   |\n",
      "|    std                  | 20.7        |\n",
      "|    value_loss           | 91.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 914          |\n",
      "|    time_elapsed         | 16567        |\n",
      "|    total_timesteps      | 1871872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008851938 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.7         |\n",
      "|    n_updates            | 23780        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | 0.51372474   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 16585        |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007806975 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86.6         |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | -4.6484904   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 916          |\n",
      "|    time_elapsed         | 16604        |\n",
      "|    total_timesteps      | 1875968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046561747 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 23800        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | -0.7660465   |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 36.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 917          |\n",
      "|    time_elapsed         | 16622        |\n",
      "|    total_timesteps      | 1878016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030178048 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.5         |\n",
      "|    n_updates            | 23810        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    reward               | -0.29926705  |\n",
      "|    std                  | 20.7         |\n",
      "|    value_loss           | 231          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 918          |\n",
      "|    time_elapsed         | 16641        |\n",
      "|    total_timesteps      | 1880064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011636475 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 65.1         |\n",
      "|    n_updates            | 23820        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 4.532173     |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 919          |\n",
      "|    time_elapsed         | 16659        |\n",
      "|    total_timesteps      | 1882112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046054823 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 23830        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    reward               | -0.76377815  |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 66.4         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4818231.36\n",
      "total_reward: 3818231.36\n",
      "total_cost: 221060.98\n",
      "total_trades: 63242\n",
      "Sharpe: 0.755\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 920          |\n",
      "|    time_elapsed         | 16678        |\n",
      "|    total_timesteps      | 1884160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026047186 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 23840        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    reward               | 0.82972795   |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 921          |\n",
      "|    time_elapsed         | 16696        |\n",
      "|    total_timesteps      | 1886208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025346717 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.2         |\n",
      "|    n_updates            | 23850        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    reward               | 6.065325     |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 922           |\n",
      "|    time_elapsed         | 16715         |\n",
      "|    total_timesteps      | 1888256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058521784 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.607         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32            |\n",
      "|    n_updates            | 23860         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | -0.898053     |\n",
      "|    std                  | 20.9          |\n",
      "|    value_loss           | 138           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 923          |\n",
      "|    time_elapsed         | 16733        |\n",
      "|    total_timesteps      | 1890304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078099864 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 23870        |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    reward               | 1.0796931    |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 924          |\n",
      "|    time_elapsed         | 16752        |\n",
      "|    total_timesteps      | 1892352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012903338 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62           |\n",
      "|    n_updates            | 23880        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | -2.1885247   |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 925          |\n",
      "|    time_elapsed         | 16770        |\n",
      "|    total_timesteps      | 1894400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008640298 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.8         |\n",
      "|    n_updates            | 23890        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | -1.6380724   |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 16788       |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005045364 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -129        |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 23900       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    reward               | 1.2638327   |\n",
      "|    std                  | 21          |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 16807        |\n",
      "|    total_timesteps      | 1898496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015237625 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.6         |\n",
      "|    n_updates            | 23910        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 2.499312     |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 928           |\n",
      "|    time_elapsed         | 16825         |\n",
      "|    total_timesteps      | 1900544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041391308 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.577         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 59.7          |\n",
      "|    n_updates            | 23920         |\n",
      "|    policy_gradient_loss | -0.00163      |\n",
      "|    reward               | 4.1666965     |\n",
      "|    std                  | 21            |\n",
      "|    value_loss           | 126           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 929          |\n",
      "|    time_elapsed         | 16844        |\n",
      "|    total_timesteps      | 1902592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018469435 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 23930        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    reward               | 6.8652697    |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 73.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 930          |\n",
      "|    time_elapsed         | 16862        |\n",
      "|    total_timesteps      | 1904640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027058925 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.4         |\n",
      "|    n_updates            | 23940        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 0.16225678   |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 90.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 931           |\n",
      "|    time_elapsed         | 16881         |\n",
      "|    total_timesteps      | 1906688       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028081395 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -129          |\n",
      "|    explained_variance   | 0.572         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 56.6          |\n",
      "|    n_updates            | 23950         |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    reward               | -0.49218938   |\n",
      "|    std                  | 21.1          |\n",
      "|    value_loss           | 151           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 932        |\n",
      "|    time_elapsed         | 16899      |\n",
      "|    total_timesteps      | 1908736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00112522 |\n",
      "|    clip_fraction        | 0.000195   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -129       |\n",
      "|    explained_variance   | 0.393      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 46.2       |\n",
      "|    n_updates            | 23960      |\n",
      "|    policy_gradient_loss | -0.00293   |\n",
      "|    reward               | 2.5314765  |\n",
      "|    std                  | 21.1       |\n",
      "|    value_loss           | 125        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 933          |\n",
      "|    time_elapsed         | 16918        |\n",
      "|    total_timesteps      | 1910784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079172505 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 23970        |\n",
      "|    policy_gradient_loss | -0.0097      |\n",
      "|    reward               | -1.792067    |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 26           |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4987511.37\n",
      "total_reward: 3987511.37\n",
      "total_cost: 214238.80\n",
      "total_trades: 62324\n",
      "Sharpe: 0.771\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 934          |\n",
      "|    time_elapsed         | 16937        |\n",
      "|    total_timesteps      | 1912832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011391382 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.1         |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | 0.57927847   |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 16955        |\n",
      "|    total_timesteps      | 1914880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001522227 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.3         |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.000708    |\n",
      "|    reward               | 2.79715      |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 936          |\n",
      "|    time_elapsed         | 16974        |\n",
      "|    total_timesteps      | 1916928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017690423 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 24000        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    reward               | -2.4242814   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 60.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 937        |\n",
      "|    time_elapsed         | 16992      |\n",
      "|    total_timesteps      | 1918976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00392959 |\n",
      "|    clip_fraction        | 0.00688    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -129       |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 37         |\n",
      "|    n_updates            | 24010      |\n",
      "|    policy_gradient_loss | -0.00804   |\n",
      "|    reward               | -0.5192927 |\n",
      "|    std                  | 21.3       |\n",
      "|    value_loss           | 89.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 938          |\n",
      "|    time_elapsed         | 17011        |\n",
      "|    total_timesteps      | 1921024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010643604 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.618        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.6         |\n",
      "|    n_updates            | 24020        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 0.04978106   |\n",
      "|    std                  | 21.3         |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 939          |\n",
      "|    time_elapsed         | 17029        |\n",
      "|    total_timesteps      | 1923072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005687128 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -129         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.4         |\n",
      "|    n_updates            | 24030        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | -1.3000674   |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 940          |\n",
      "|    time_elapsed         | 17047        |\n",
      "|    total_timesteps      | 1925120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007866654  |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.6          |\n",
      "|    n_updates            | 24040        |\n",
      "|    policy_gradient_loss | -0.00951     |\n",
      "|    reward               | -0.079021506 |\n",
      "|    std                  | 21.4         |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 941          |\n",
      "|    time_elapsed         | 17066        |\n",
      "|    total_timesteps      | 1927168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018348349 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88           |\n",
      "|    n_updates            | 24050        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    reward               | 0.035813395  |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 942          |\n",
      "|    time_elapsed         | 17084        |\n",
      "|    total_timesteps      | 1929216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006853293 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.7         |\n",
      "|    n_updates            | 24060        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    reward               | 4.918083     |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 943          |\n",
      "|    time_elapsed         | 17103        |\n",
      "|    total_timesteps      | 1931264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029312302 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 24070        |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    reward               | 1.2291647    |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 53.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 17121       |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003002327 |\n",
      "|    clip_fraction        | 0.00405     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 24080       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    reward               | 1.1860814   |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 86          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 945          |\n",
      "|    time_elapsed         | 17140        |\n",
      "|    total_timesteps      | 1935360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012611594 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 90.1         |\n",
      "|    n_updates            | 24090        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 18.579424    |\n",
      "|    std                  | 21.5         |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 17158       |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002168972 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.6        |\n",
      "|    n_updates            | 24100       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -0.72767925 |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 213         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 17177       |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007333101 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 24110       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -0.56527174 |\n",
      "|    std                  | 21.5        |\n",
      "|    value_loss           | 45.2        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5918580.99\n",
      "total_reward: 4918580.99\n",
      "total_cost: 249712.58\n",
      "total_trades: 64389\n",
      "Sharpe: 0.833\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 948          |\n",
      "|    time_elapsed         | 17195        |\n",
      "|    total_timesteps      | 1941504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014248069 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.3         |\n",
      "|    n_updates            | 24120        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | 0.50909615   |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 157          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 949          |\n",
      "|    time_elapsed         | 17214        |\n",
      "|    total_timesteps      | 1943552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006153486 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84           |\n",
      "|    n_updates            | 24130        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -5.5441146   |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 950          |\n",
      "|    time_elapsed         | 17232        |\n",
      "|    total_timesteps      | 1945600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071386164 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    reward               | 0.67975974   |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 17250       |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001257574 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 24150       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | 2.2890582   |\n",
      "|    std                  | 21.7        |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 952          |\n",
      "|    time_elapsed         | 17269        |\n",
      "|    total_timesteps      | 1949696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011038234 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.6         |\n",
      "|    n_updates            | 24160        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | 2.9041822    |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 953          |\n",
      "|    time_elapsed         | 17287        |\n",
      "|    total_timesteps      | 1951744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016755966 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 24170        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    reward               | 1.6266816    |\n",
      "|    std                  | 21.7         |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 17306       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002232579 |\n",
      "|    clip_fraction        | 0.00361     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | 1.8084544   |\n",
      "|    std                  | 21.7        |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 955          |\n",
      "|    time_elapsed         | 17324        |\n",
      "|    total_timesteps      | 1955840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009667736 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 24190        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | 0.7564729    |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 956           |\n",
      "|    time_elapsed         | 17342         |\n",
      "|    total_timesteps      | 1957888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051962654 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -130          |\n",
      "|    explained_variance   | 0.648         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 77.3          |\n",
      "|    n_updates            | 24200         |\n",
      "|    policy_gradient_loss | -0.00266      |\n",
      "|    reward               | 2.888467      |\n",
      "|    std                  | 21.8          |\n",
      "|    value_loss           | 140           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 957          |\n",
      "|    time_elapsed         | 17361        |\n",
      "|    total_timesteps      | 1959936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065836096 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.5          |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    reward               | 0.25254318   |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 958          |\n",
      "|    time_elapsed         | 17379        |\n",
      "|    total_timesteps      | 1961984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024812755 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.4         |\n",
      "|    n_updates            | 24220        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -0.6745754   |\n",
      "|    std                  | 21.8         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 17397       |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000148956 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.1        |\n",
      "|    n_updates            | 24230       |\n",
      "|    policy_gradient_loss | -0.000688   |\n",
      "|    reward               | -3.114866   |\n",
      "|    std                  | 21.9        |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 17416       |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001717384 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 24240       |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 0.5948208   |\n",
      "|    std                  | 21.9        |\n",
      "|    value_loss           | 62.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 17435       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003925491 |\n",
      "|    clip_fraction        | 0.0083      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 24250       |\n",
      "|    policy_gradient_loss | -0.00723    |\n",
      "|    reward               | -0.3989942  |\n",
      "|    std                  | 21.9        |\n",
      "|    value_loss           | 84.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6192675.97\n",
      "total_reward: 5192675.97\n",
      "total_cost: 219655.54\n",
      "total_trades: 62123\n",
      "Sharpe: 0.843\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 962          |\n",
      "|    time_elapsed         | 17453        |\n",
      "|    total_timesteps      | 1970176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011488479 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.3         |\n",
      "|    n_updates            | 24260        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | -0.06371372  |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 963          |\n",
      "|    time_elapsed         | 17471        |\n",
      "|    total_timesteps      | 1972224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010092275 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -130         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.7         |\n",
      "|    n_updates            | 24270        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | 2.9851196    |\n",
      "|    std                  | 22           |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 17490       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008637099 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -130        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 24280       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    reward               | 0.8756509   |\n",
      "|    std                  | 22.1        |\n",
      "|    value_loss           | 37          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 965           |\n",
      "|    time_elapsed         | 17508         |\n",
      "|    total_timesteps      | 1976320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063593825 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.422         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 96.2          |\n",
      "|    n_updates            | 24290         |\n",
      "|    policy_gradient_loss | -0.00137      |\n",
      "|    reward               | -0.22451104   |\n",
      "|    std                  | 22.1          |\n",
      "|    value_loss           | 220           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 966          |\n",
      "|    time_elapsed         | 17526        |\n",
      "|    total_timesteps      | 1978368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020234971 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.9         |\n",
      "|    n_updates            | 24300        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | -1.6003476   |\n",
      "|    std                  | 22.1         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 967          |\n",
      "|    time_elapsed         | 17545        |\n",
      "|    total_timesteps      | 1980416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018172979 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.7         |\n",
      "|    n_updates            | 24310        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -5.331393    |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 64.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 968          |\n",
      "|    time_elapsed         | 17563        |\n",
      "|    total_timesteps      | 1982464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020830543 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 85.1         |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    reward               | 0.35944936   |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 969          |\n",
      "|    time_elapsed         | 17581        |\n",
      "|    total_timesteps      | 1984512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017098166 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 24330        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -16.377329   |\n",
      "|    std                  | 22.2         |\n",
      "|    value_loss           | 270          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 970          |\n",
      "|    time_elapsed         | 17599        |\n",
      "|    total_timesteps      | 1986560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013923334 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.5         |\n",
      "|    n_updates            | 24340        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 1.4764391    |\n",
      "|    std                  | 22.3         |\n",
      "|    value_loss           | 93.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 971        |\n",
      "|    time_elapsed         | 17617      |\n",
      "|    total_timesteps      | 1988608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00357441 |\n",
      "|    clip_fraction        | 0.00669    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -131       |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 23.8       |\n",
      "|    n_updates            | 24350      |\n",
      "|    policy_gradient_loss | -0.00474   |\n",
      "|    reward               | -3.0292354 |\n",
      "|    std                  | 22.3       |\n",
      "|    value_loss           | 79.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 972          |\n",
      "|    time_elapsed         | 17636        |\n",
      "|    total_timesteps      | 1990656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013447927 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    reward               | 1.0205165    |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 253          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 973          |\n",
      "|    time_elapsed         | 17654        |\n",
      "|    total_timesteps      | 1992704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011908729 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 24370        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | -7.7019105   |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 297          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 974          |\n",
      "|    time_elapsed         | 17672        |\n",
      "|    total_timesteps      | 1994752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027743017 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 24380        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    reward               | -0.015686465 |\n",
      "|    std                  | 22.4         |\n",
      "|    value_loss           | 51.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 975          |\n",
      "|    time_elapsed         | 17691        |\n",
      "|    total_timesteps      | 1996800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017280709 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.2         |\n",
      "|    n_updates            | 24390        |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    reward               | -0.4238853   |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 976          |\n",
      "|    time_elapsed         | 17709        |\n",
      "|    total_timesteps      | 1998848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009588819 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.3         |\n",
      "|    n_updates            | 24400        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | -9.478822    |\n",
      "|    std                  | 22.5         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6387264.48\n",
      "total_reward: 5387264.48\n",
      "total_cost: 188644.00\n",
      "total_trades: 60956\n",
      "Sharpe: 0.852\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 977         |\n",
      "|    time_elapsed         | 17728       |\n",
      "|    total_timesteps      | 2000896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001965701 |\n",
      "|    clip_fraction        | 0.000439    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 24410       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | 1.4983047   |\n",
      "|    std                  | 22.5        |\n",
      "|    value_loss           | 68.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 978          |\n",
      "|    time_elapsed         | 17746        |\n",
      "|    total_timesteps      | 2002944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015076117 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.9         |\n",
      "|    n_updates            | 24420        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    reward               | 1.3865762    |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 96.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 979          |\n",
      "|    time_elapsed         | 17764        |\n",
      "|    total_timesteps      | 2004992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010362304 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.9         |\n",
      "|    n_updates            | 24430        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | -0.2632932   |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 182          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 980           |\n",
      "|    time_elapsed         | 17783         |\n",
      "|    total_timesteps      | 2007040       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061149197 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.558         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.6          |\n",
      "|    n_updates            | 24440         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | -2.8044713    |\n",
      "|    std                  | 22.6          |\n",
      "|    value_loss           | 156           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 981          |\n",
      "|    time_elapsed         | 17801        |\n",
      "|    total_timesteps      | 2009088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050191707 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 24450        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | 1.4426396    |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 982          |\n",
      "|    time_elapsed         | 17820        |\n",
      "|    total_timesteps      | 2011136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011253889 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 24460        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | -0.22397694  |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 208          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 983          |\n",
      "|    time_elapsed         | 17838        |\n",
      "|    total_timesteps      | 2013184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010995005 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.4         |\n",
      "|    n_updates            | 24470        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -1.010963    |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 984          |\n",
      "|    time_elapsed         | 17856        |\n",
      "|    total_timesteps      | 2015232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018350936 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41           |\n",
      "|    n_updates            | 24480        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 0.5747594    |\n",
      "|    std                  | 22.6         |\n",
      "|    value_loss           | 72.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 985          |\n",
      "|    time_elapsed         | 17875        |\n",
      "|    total_timesteps      | 2017280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022831662 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 75.7         |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    reward               | -1.5979548   |\n",
      "|    std                  | 22.7         |\n",
      "|    value_loss           | 97.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 986           |\n",
      "|    time_elapsed         | 17893         |\n",
      "|    total_timesteps      | 2019328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073282927 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.669         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 113           |\n",
      "|    n_updates            | 24500         |\n",
      "|    policy_gradient_loss | -0.00245      |\n",
      "|    reward               | -0.04592629   |\n",
      "|    std                  | 22.7          |\n",
      "|    value_loss           | 162           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 987           |\n",
      "|    time_elapsed         | 17911         |\n",
      "|    total_timesteps      | 2021376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016663515 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -131          |\n",
      "|    explained_variance   | 0.562         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 71.6          |\n",
      "|    n_updates            | 24510         |\n",
      "|    policy_gradient_loss | -0.000553     |\n",
      "|    reward               | -0.72004217   |\n",
      "|    std                  | 22.7          |\n",
      "|    value_loss           | 224           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 17930       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008652991 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 24520       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    reward               | -1.707826   |\n",
      "|    std                  | 22.8        |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 989          |\n",
      "|    time_elapsed         | 17949        |\n",
      "|    total_timesteps      | 2025472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009449128 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 83.2         |\n",
      "|    n_updates            | 24530        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | 0.39850464   |\n",
      "|    std                  | 22.8         |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 990          |\n",
      "|    time_elapsed         | 17970        |\n",
      "|    total_timesteps      | 2027520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008972165 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -131         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 177          |\n",
      "|    n_updates            | 24540        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | -2.6408942   |\n",
      "|    std                  | 22.8         |\n",
      "|    value_loss           | 317          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6711947.02\n",
      "total_reward: 5711947.02\n",
      "total_cost: 201997.20\n",
      "total_trades: 61074\n",
      "Sharpe: 0.871\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 17988       |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002188807 |\n",
      "|    clip_fraction        | 0.000586    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -131        |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 24550       |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | 2.5733113   |\n",
      "|    std                  | 22.9        |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 992         |\n",
      "|    time_elapsed         | 18007       |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001330808 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 24560       |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    reward               | -1.7011671  |\n",
      "|    std                  | 22.9        |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 993          |\n",
      "|    time_elapsed         | 18025        |\n",
      "|    total_timesteps      | 2033664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003334061 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.7         |\n",
      "|    n_updates            | 24570        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | 10.940247    |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 145          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 994          |\n",
      "|    time_elapsed         | 18044        |\n",
      "|    total_timesteps      | 2035712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018259591 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.6         |\n",
      "|    n_updates            | 24580        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | -3.1630666   |\n",
      "|    std                  | 22.9         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 18063       |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002956275 |\n",
      "|    clip_fraction        | 0.00576     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43.4        |\n",
      "|    n_updates            | 24590       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    reward               | -1.7963988  |\n",
      "|    std                  | 23          |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 996          |\n",
      "|    time_elapsed         | 18083        |\n",
      "|    total_timesteps      | 2039808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002458301 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 61.7         |\n",
      "|    n_updates            | 24600        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | 0.065168455  |\n",
      "|    std                  | 23           |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 997         |\n",
      "|    time_elapsed         | 18101       |\n",
      "|    total_timesteps      | 2041856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000744394 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 96.8        |\n",
      "|    n_updates            | 24610       |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    reward               | -26.3268    |\n",
      "|    std                  | 23          |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 18120       |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006927707 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 24620       |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    reward               | -2.0883265  |\n",
      "|    std                  | 23.1        |\n",
      "|    value_loss           | 37.3        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 999           |\n",
      "|    time_elapsed         | 18138         |\n",
      "|    total_timesteps      | 2045952       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031759444 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.705         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 82            |\n",
      "|    n_updates            | 24630         |\n",
      "|    policy_gradient_loss | -0.000878     |\n",
      "|    reward               | -1.6401061    |\n",
      "|    std                  | 23.1          |\n",
      "|    value_loss           | 175           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1000         |\n",
      "|    time_elapsed         | 18157        |\n",
      "|    total_timesteps      | 2048000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006519816 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 217          |\n",
      "|    n_updates            | 24640        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | 1.0544214    |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1001         |\n",
      "|    time_elapsed         | 18176        |\n",
      "|    total_timesteps      | 2050048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033957753 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.1         |\n",
      "|    n_updates            | 24650        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    reward               | -3.0132146   |\n",
      "|    std                  | 23.1         |\n",
      "|    value_loss           | 79.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1002         |\n",
      "|    time_elapsed         | 18195        |\n",
      "|    total_timesteps      | 2052096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026251785 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.4         |\n",
      "|    n_updates            | 24660        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    reward               | 0.5167374    |\n",
      "|    std                  | 23.2         |\n",
      "|    value_loss           | 84.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1003          |\n",
      "|    time_elapsed         | 18213         |\n",
      "|    total_timesteps      | 2054144       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072157744 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.676         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 117           |\n",
      "|    n_updates            | 24670         |\n",
      "|    policy_gradient_loss | -0.00243      |\n",
      "|    reward               | -0.36499867   |\n",
      "|    std                  | 23.2          |\n",
      "|    value_loss           | 195           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1004          |\n",
      "|    time_elapsed         | 18231         |\n",
      "|    total_timesteps      | 2056192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052296254 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.676         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 48.7          |\n",
      "|    n_updates            | 24680         |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    reward               | 4.6026406     |\n",
      "|    std                  | 23.2          |\n",
      "|    value_loss           | 135           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6316743.27\n",
      "total_reward: 5316743.27\n",
      "total_cost: 216908.14\n",
      "total_trades: 62488\n",
      "Sharpe: 0.869\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 18250       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006378779 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 24690       |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    reward               | 0.6821176   |\n",
      "|    std                  | 23.3        |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1006         |\n",
      "|    time_elapsed         | 18268        |\n",
      "|    total_timesteps      | 2060288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006433575 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.6         |\n",
      "|    n_updates            | 24700        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | -1.0033171   |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 18287        |\n",
      "|    total_timesteps      | 2062336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005752202 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.5         |\n",
      "|    n_updates            | 24710        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    reward               | 2.3600078    |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1008         |\n",
      "|    time_elapsed         | 18305        |\n",
      "|    total_timesteps      | 2064384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015246004 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.2         |\n",
      "|    n_updates            | 24720        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -0.18718562  |\n",
      "|    std                  | 23.3         |\n",
      "|    value_loss           | 79.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1009         |\n",
      "|    time_elapsed         | 18324        |\n",
      "|    total_timesteps      | 2066432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019879248 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 24730        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    reward               | -1.0652635   |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1010         |\n",
      "|    time_elapsed         | 18343        |\n",
      "|    total_timesteps      | 2068480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016406949 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.2         |\n",
      "|    n_updates            | 24740        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | -6.0152626   |\n",
      "|    std                  | 23.4         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1011          |\n",
      "|    time_elapsed         | 18362         |\n",
      "|    total_timesteps      | 2070528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022550055 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.465         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.8          |\n",
      "|    n_updates            | 24750         |\n",
      "|    policy_gradient_loss | -0.00113      |\n",
      "|    reward               | -1.8484557    |\n",
      "|    std                  | 23.4          |\n",
      "|    value_loss           | 163           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 18381       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011181473 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -132        |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 24760       |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    reward               | -2.5155208  |\n",
      "|    std                  | 23.5        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1013          |\n",
      "|    time_elapsed         | 18399         |\n",
      "|    total_timesteps      | 2074624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047774173 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.467         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 40.9          |\n",
      "|    n_updates            | 24770         |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    reward               | -1.4710007    |\n",
      "|    std                  | 23.6          |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1014          |\n",
      "|    time_elapsed         | 18418         |\n",
      "|    total_timesteps      | 2076672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060903974 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -132          |\n",
      "|    explained_variance   | 0.368         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 94.2          |\n",
      "|    n_updates            | 24780         |\n",
      "|    policy_gradient_loss | -0.00197      |\n",
      "|    reward               | -0.8580798    |\n",
      "|    std                  | 23.6          |\n",
      "|    value_loss           | 271           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1015         |\n",
      "|    time_elapsed         | 18436        |\n",
      "|    total_timesteps      | 2078720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030694213 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -132         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 24790        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | -1.082253    |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1016         |\n",
      "|    time_elapsed         | 18455        |\n",
      "|    total_timesteps      | 2080768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011164135 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.6         |\n",
      "|    n_updates            | 24800        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -0.7408842   |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 93.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1017         |\n",
      "|    time_elapsed         | 18473        |\n",
      "|    total_timesteps      | 2082816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007071184 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79           |\n",
      "|    n_updates            | 24810        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | 3.1555681    |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 230          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1018         |\n",
      "|    time_elapsed         | 18492        |\n",
      "|    total_timesteps      | 2084864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004353483 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.3         |\n",
      "|    n_updates            | 24820        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    reward               | -1.0541127   |\n",
      "|    std                  | 23.7         |\n",
      "|    value_loss           | 81.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6469672.95\n",
      "total_reward: 5469672.95\n",
      "total_cost: 246176.92\n",
      "total_trades: 64067\n",
      "Sharpe: 0.883\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1019         |\n",
      "|    time_elapsed         | 18510        |\n",
      "|    total_timesteps      | 2086912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014316775 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 24830        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 0.09603245   |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 82.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1020         |\n",
      "|    time_elapsed         | 18529        |\n",
      "|    total_timesteps      | 2088960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014778979 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.2         |\n",
      "|    n_updates            | 24840        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | 0.045648053  |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1021          |\n",
      "|    time_elapsed         | 18547         |\n",
      "|    total_timesteps      | 2091008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088363886 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.497         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 81.2          |\n",
      "|    n_updates            | 24850         |\n",
      "|    policy_gradient_loss | -0.00276      |\n",
      "|    reward               | -0.39040932   |\n",
      "|    std                  | 23.8          |\n",
      "|    value_loss           | 221           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 18566       |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006492176 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 24860       |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    reward               | 5.123297    |\n",
      "|    std                  | 23.8        |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1023          |\n",
      "|    time_elapsed         | 18584         |\n",
      "|    total_timesteps      | 2095104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038695819 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.583         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.8          |\n",
      "|    n_updates            | 24870         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 0.086026244   |\n",
      "|    std                  | 23.8          |\n",
      "|    value_loss           | 156           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1024         |\n",
      "|    time_elapsed         | 18603        |\n",
      "|    total_timesteps      | 2097152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012659854 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 88.1         |\n",
      "|    n_updates            | 24880        |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    reward               | -0.57114446  |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 202          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1025          |\n",
      "|    time_elapsed         | 18622         |\n",
      "|    total_timesteps      | 2099200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038634683 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.297         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.4          |\n",
      "|    n_updates            | 24890         |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    reward               | 7.067807      |\n",
      "|    std                  | 23.8          |\n",
      "|    value_loss           | 81.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1026         |\n",
      "|    time_elapsed         | 18640        |\n",
      "|    total_timesteps      | 2101248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013827784 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.4         |\n",
      "|    n_updates            | 24900        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 0.15391949   |\n",
      "|    std                  | 23.8         |\n",
      "|    value_loss           | 99.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 18658       |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001507041 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 24910       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | 0.7257422   |\n",
      "|    std                  | 23.9        |\n",
      "|    value_loss           | 298         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1028         |\n",
      "|    time_elapsed         | 18677        |\n",
      "|    total_timesteps      | 2105344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012658136 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.7         |\n",
      "|    n_updates            | 24920        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | -8.753096    |\n",
      "|    std                  | 23.9         |\n",
      "|    value_loss           | 210          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 1029       |\n",
      "|    time_elapsed         | 18695      |\n",
      "|    total_timesteps      | 2107392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00743962 |\n",
      "|    clip_fraction        | 0.0275     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -133       |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.97       |\n",
      "|    n_updates            | 24930      |\n",
      "|    policy_gradient_loss | -0.00477   |\n",
      "|    reward               | -0.7555019 |\n",
      "|    std                  | 23.9       |\n",
      "|    value_loss           | 24.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1030         |\n",
      "|    time_elapsed         | 18713        |\n",
      "|    total_timesteps      | 2109440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040221307 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.7         |\n",
      "|    n_updates            | 24940        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    reward               | 0.5207008    |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1031          |\n",
      "|    time_elapsed         | 18732         |\n",
      "|    total_timesteps      | 2111488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031685748 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.63          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 93.6          |\n",
      "|    n_updates            | 24950         |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    reward               | -1.0804282    |\n",
      "|    std                  | 24            |\n",
      "|    value_loss           | 177           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1032         |\n",
      "|    time_elapsed         | 18750        |\n",
      "|    total_timesteps      | 2113536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013101092 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.316        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 24960        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -0.8103102   |\n",
      "|    std                  | 24           |\n",
      "|    value_loss           | 76.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5265777.47\n",
      "total_reward: 4265777.47\n",
      "total_cost: 302031.23\n",
      "total_trades: 67956\n",
      "Sharpe: 0.803\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1033         |\n",
      "|    time_elapsed         | 18769        |\n",
      "|    total_timesteps      | 2115584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015947302 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.8         |\n",
      "|    n_updates            | 24970        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 1.8232945    |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 97.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1034         |\n",
      "|    time_elapsed         | 18787        |\n",
      "|    total_timesteps      | 2117632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010557934 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.3         |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    reward               | 8.899195     |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1035          |\n",
      "|    time_elapsed         | 18806         |\n",
      "|    total_timesteps      | 2119680       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046781875 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.654         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 89            |\n",
      "|    n_updates            | 24990         |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    reward               | -1.8041046    |\n",
      "|    std                  | 24.1          |\n",
      "|    value_loss           | 120           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1036         |\n",
      "|    time_elapsed         | 18824        |\n",
      "|    total_timesteps      | 2121728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030232472 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 25000        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    reward               | 0.5311277    |\n",
      "|    std                  | 24.1         |\n",
      "|    value_loss           | 38.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1037         |\n",
      "|    time_elapsed         | 18843        |\n",
      "|    total_timesteps      | 2123776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021326612 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 97.1         |\n",
      "|    n_updates            | 25010        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 0.44768065   |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1038         |\n",
      "|    time_elapsed         | 18861        |\n",
      "|    total_timesteps      | 2125824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015991214 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 25020        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    reward               | -7.4549046   |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1039         |\n",
      "|    time_elapsed         | 18880        |\n",
      "|    total_timesteps      | 2127872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042857556 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 25030        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    reward               | -1.1600696   |\n",
      "|    std                  | 24.2         |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1040         |\n",
      "|    time_elapsed         | 18898        |\n",
      "|    total_timesteps      | 2129920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021518457 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 25040        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -1.6284423   |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 156          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1041         |\n",
      "|    time_elapsed         | 18917        |\n",
      "|    total_timesteps      | 2131968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009326199 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.3         |\n",
      "|    n_updates            | 25050        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -5.013733    |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1042         |\n",
      "|    time_elapsed         | 18935        |\n",
      "|    total_timesteps      | 2134016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019123806 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 25060        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 2.7126384    |\n",
      "|    std                  | 24.3         |\n",
      "|    value_loss           | 56.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 18954       |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002354178 |\n",
      "|    clip_fraction        | 0.00254     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 48.8        |\n",
      "|    n_updates            | 25070       |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | 0.5333675   |\n",
      "|    std                  | 24.4        |\n",
      "|    value_loss           | 66          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 18972       |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001437389 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -133        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 90.8        |\n",
      "|    n_updates            | 25080       |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    reward               | 1.1906382   |\n",
      "|    std                  | 24.4        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1045         |\n",
      "|    time_elapsed         | 18991        |\n",
      "|    total_timesteps      | 2140160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014172487 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.2         |\n",
      "|    n_updates            | 25090        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    reward               | 5.6611114    |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 207          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1046         |\n",
      "|    time_elapsed         | 19009        |\n",
      "|    total_timesteps      | 2142208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055375425 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.98         |\n",
      "|    n_updates            | 25100        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    reward               | -2.4600663   |\n",
      "|    std                  | 24.4         |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5828981.90\n",
      "total_reward: 4828981.90\n",
      "total_cost: 260346.16\n",
      "total_trades: 64740\n",
      "Sharpe: 0.849\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1047         |\n",
      "|    time_elapsed         | 19027        |\n",
      "|    total_timesteps      | 2144256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012671765 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 25110        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | -2.6290898   |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1048          |\n",
      "|    time_elapsed         | 19046         |\n",
      "|    total_timesteps      | 2146304       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057770504 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -133          |\n",
      "|    explained_variance   | 0.487         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 70.7          |\n",
      "|    n_updates            | 25120         |\n",
      "|    policy_gradient_loss | -0.00198      |\n",
      "|    reward               | -2.2304688    |\n",
      "|    std                  | 24.5          |\n",
      "|    value_loss           | 153           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1049         |\n",
      "|    time_elapsed         | 19064        |\n",
      "|    total_timesteps      | 2148352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015975753 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -133         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.5         |\n",
      "|    n_updates            | 25130        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    reward               | -5.378357    |\n",
      "|    std                  | 24.5         |\n",
      "|    value_loss           | 77.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1050        |\n",
      "|    time_elapsed         | 19083       |\n",
      "|    total_timesteps      | 2150400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001568513 |\n",
      "|    clip_fraction        | 0.00176     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 25140       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    reward               | -0.9291947  |\n",
      "|    std                  | 24.5        |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1051         |\n",
      "|    time_elapsed         | 19101        |\n",
      "|    total_timesteps      | 2152448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016775017 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.7         |\n",
      "|    n_updates            | 25150        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    reward               | 0.24164368   |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1052         |\n",
      "|    time_elapsed         | 19120        |\n",
      "|    total_timesteps      | 2154496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005966977 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.5         |\n",
      "|    n_updates            | 25160        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | 1.8709297    |\n",
      "|    std                  | 24.6         |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1053         |\n",
      "|    time_elapsed         | 19138        |\n",
      "|    total_timesteps      | 2156544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060154796 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17           |\n",
      "|    n_updates            | 25170        |\n",
      "|    policy_gradient_loss | -0.00859     |\n",
      "|    reward               | -0.09031372  |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 37.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1054         |\n",
      "|    time_elapsed         | 19156        |\n",
      "|    total_timesteps      | 2158592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030459443 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 25180        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    reward               | -0.16083004  |\n",
      "|    std                  | 24.7         |\n",
      "|    value_loss           | 263          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1055          |\n",
      "|    time_elapsed         | 19175         |\n",
      "|    total_timesteps      | 2160640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090713776 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.509         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 121           |\n",
      "|    n_updates            | 25190         |\n",
      "|    policy_gradient_loss | -0.00276      |\n",
      "|    reward               | 7.4333906     |\n",
      "|    std                  | 24.7          |\n",
      "|    value_loss           | 230           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 19193       |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005261666 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 25200       |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    reward               | -1.1616279  |\n",
      "|    std                  | 24.7        |\n",
      "|    value_loss           | 71.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1057         |\n",
      "|    time_elapsed         | 19212        |\n",
      "|    total_timesteps      | 2164736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022456315 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 131          |\n",
      "|    n_updates            | 25210        |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | -0.5278084   |\n",
      "|    std                  | 24.8         |\n",
      "|    value_loss           | 155          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 19230       |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000507668 |\n",
      "|    clip_fraction        | 0.00137     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 25220       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    reward               | -53.28511   |\n",
      "|    std                  | 24.8        |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1059          |\n",
      "|    time_elapsed         | 19249         |\n",
      "|    total_timesteps      | 2168832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033729404 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.14          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.2          |\n",
      "|    n_updates            | 25230         |\n",
      "|    policy_gradient_loss | -0.00166      |\n",
      "|    reward               | 1.8680091     |\n",
      "|    std                  | 24.8          |\n",
      "|    value_loss           | 276           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1060         |\n",
      "|    time_elapsed         | 19267        |\n",
      "|    total_timesteps      | 2170880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045120902 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 25240        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    reward               | -0.38059253  |\n",
      "|    std                  | 24.9         |\n",
      "|    value_loss           | 74.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6871148.30\n",
      "total_reward: 5871148.30\n",
      "total_cost: 260522.41\n",
      "total_trades: 64767\n",
      "Sharpe: 0.926\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 19285       |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002149995 |\n",
      "|    clip_fraction        | 0.00151     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -134        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 25250       |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | 0.08503256  |\n",
      "|    std                  | 25          |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1062          |\n",
      "|    time_elapsed         | 19304         |\n",
      "|    total_timesteps      | 2174976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061081426 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.484         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 72.4          |\n",
      "|    n_updates            | 25260         |\n",
      "|    policy_gradient_loss | -0.00236      |\n",
      "|    reward               | -1.7691718    |\n",
      "|    std                  | 25            |\n",
      "|    value_loss           | 197           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1063         |\n",
      "|    time_elapsed         | 19322        |\n",
      "|    total_timesteps      | 2177024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056699766 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.7         |\n",
      "|    n_updates            | 25270        |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    reward               | -1.5602123   |\n",
      "|    std                  | 25.1         |\n",
      "|    value_loss           | 53.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1064         |\n",
      "|    time_elapsed         | 19340        |\n",
      "|    total_timesteps      | 2179072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015368022 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.546        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55           |\n",
      "|    n_updates            | 25280        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -0.8671035   |\n",
      "|    std                  | 25.1         |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1065          |\n",
      "|    time_elapsed         | 19359         |\n",
      "|    total_timesteps      | 2181120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064286066 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.502         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 150           |\n",
      "|    n_updates            | 25290         |\n",
      "|    policy_gradient_loss | -0.0026       |\n",
      "|    reward               | 2.9329002     |\n",
      "|    std                  | 25.2          |\n",
      "|    value_loss           | 252           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1066         |\n",
      "|    time_elapsed         | 19377        |\n",
      "|    total_timesteps      | 2183168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027221288 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.3         |\n",
      "|    n_updates            | 25300        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    reward               | 0.95030177   |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1067         |\n",
      "|    time_elapsed         | 19395        |\n",
      "|    total_timesteps      | 2185216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020761786 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.1         |\n",
      "|    n_updates            | 25310        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    reward               | 0.119733796  |\n",
      "|    std                  | 25.2         |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1068         |\n",
      "|    time_elapsed         | 19414        |\n",
      "|    total_timesteps      | 2187264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022617728 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -134         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 25320        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    reward               | -1.8323641   |\n",
      "|    std                  | 25.3         |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1069          |\n",
      "|    time_elapsed         | 19432         |\n",
      "|    total_timesteps      | 2189312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032587894 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -134          |\n",
      "|    explained_variance   | 0.541         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 160           |\n",
      "|    n_updates            | 25330         |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    reward               | 0.27253616    |\n",
      "|    std                  | 25.3          |\n",
      "|    value_loss           | 274           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1070        |\n",
      "|    time_elapsed         | 19450       |\n",
      "|    total_timesteps      | 2191360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011761232 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 25340       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 1.0357065   |\n",
      "|    std                  | 25.5        |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1071         |\n",
      "|    time_elapsed         | 19469        |\n",
      "|    total_timesteps      | 2193408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010224726 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.9         |\n",
      "|    n_updates            | 25350        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 0.05315286   |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1072         |\n",
      "|    time_elapsed         | 19487        |\n",
      "|    total_timesteps      | 2195456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005483321 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 76.5         |\n",
      "|    n_updates            | 25360        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    reward               | 2.8537724    |\n",
      "|    std                  | 25.5         |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1073         |\n",
      "|    time_elapsed         | 19505        |\n",
      "|    total_timesteps      | 2197504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012856381 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 25370        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -0.5684219   |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 69.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1074         |\n",
      "|    time_elapsed         | 19524        |\n",
      "|    total_timesteps      | 2199552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031775972 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51           |\n",
      "|    n_updates            | 25380        |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    reward               | -0.06744767  |\n",
      "|    std                  | 25.6         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6825861.17\n",
      "total_reward: 5825861.17\n",
      "total_cost: 274414.73\n",
      "total_trades: 65444\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1075         |\n",
      "|    time_elapsed         | 19543        |\n",
      "|    total_timesteps      | 2201600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013762331 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 47.9         |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | 0.2761258    |\n",
      "|    std                  | 25.7         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1076          |\n",
      "|    time_elapsed         | 19561         |\n",
      "|    total_timesteps      | 2203648       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036900272 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.529         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 115           |\n",
      "|    n_updates            | 25400         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | -0.35810864   |\n",
      "|    std                  | 25.7          |\n",
      "|    value_loss           | 207           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 19580       |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004077081 |\n",
      "|    clip_fraction        | 0.00625     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -135        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 25410       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | -1.2871517  |\n",
      "|    std                  | 25.8        |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1078         |\n",
      "|    time_elapsed         | 19598        |\n",
      "|    total_timesteps      | 2207744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023418465 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 25420        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 0.84824044   |\n",
      "|    std                  | 25.8         |\n",
      "|    value_loss           | 223          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1079          |\n",
      "|    time_elapsed         | 19616         |\n",
      "|    total_timesteps      | 2209792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029851394 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -135          |\n",
      "|    explained_variance   | 0.576         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 88            |\n",
      "|    n_updates            | 25430         |\n",
      "|    policy_gradient_loss | -0.00116      |\n",
      "|    reward               | 3.7170312     |\n",
      "|    std                  | 25.8          |\n",
      "|    value_loss           | 199           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1080         |\n",
      "|    time_elapsed         | 19634        |\n",
      "|    total_timesteps      | 2211840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038317065 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.4         |\n",
      "|    n_updates            | 25440        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    reward               | -6.3443117   |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 52.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1081         |\n",
      "|    time_elapsed         | 19653        |\n",
      "|    total_timesteps      | 2213888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022507866 |\n",
      "|    clip_fraction        | 0.004        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.5         |\n",
      "|    n_updates            | 25450        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -1.1161048   |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1082         |\n",
      "|    time_elapsed         | 19671        |\n",
      "|    total_timesteps      | 2215936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010638173 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 170          |\n",
      "|    n_updates            | 25460        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 7.8816495    |\n",
      "|    std                  | 26           |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1083         |\n",
      "|    time_elapsed         | 19690        |\n",
      "|    total_timesteps      | 2217984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010756473 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.4         |\n",
      "|    n_updates            | 25470        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    reward               | -6.957461    |\n",
      "|    std                  | 26.1         |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1084         |\n",
      "|    time_elapsed         | 19708        |\n",
      "|    total_timesteps      | 2220032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024296562 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.4         |\n",
      "|    n_updates            | 25480        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | -0.5752133   |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1085         |\n",
      "|    time_elapsed         | 19726        |\n",
      "|    total_timesteps      | 2222080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013232231 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -135         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 95.9         |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    reward               | 0.19837093   |\n",
      "|    std                  | 26.2         |\n",
      "|    value_loss           | 263          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1086          |\n",
      "|    time_elapsed         | 19745         |\n",
      "|    total_timesteps      | 2224128       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096809433 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.421         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 101           |\n",
      "|    n_updates            | 25500         |\n",
      "|    policy_gradient_loss | -0.00351      |\n",
      "|    reward               | -6.6729674    |\n",
      "|    std                  | 26.3          |\n",
      "|    value_loss           | 204           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1087         |\n",
      "|    time_elapsed         | 19764        |\n",
      "|    total_timesteps      | 2226176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029827207 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 25510        |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | 3.9357088    |\n",
      "|    std                  | 26.3         |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1088         |\n",
      "|    time_elapsed         | 19783        |\n",
      "|    total_timesteps      | 2228224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035790007 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38           |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    reward               | -2.6894298   |\n",
      "|    std                  | 26.4         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1089        |\n",
      "|    time_elapsed         | 19801       |\n",
      "|    total_timesteps      | 2230272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001010612 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 25530       |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    reward               | -2.3168972  |\n",
      "|    std                  | 26.4        |\n",
      "|    value_loss           | 321         |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6331821.33\n",
      "total_reward: 5331821.33\n",
      "total_cost: 255159.20\n",
      "total_trades: 63961\n",
      "Sharpe: 0.843\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1090          |\n",
      "|    time_elapsed         | 19820         |\n",
      "|    total_timesteps      | 2232320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027167372 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.471         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.8          |\n",
      "|    n_updates            | 25540         |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    reward               | -0.9457543    |\n",
      "|    std                  | 26.4          |\n",
      "|    value_loss           | 100           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1091         |\n",
      "|    time_elapsed         | 19839        |\n",
      "|    total_timesteps      | 2234368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030201068 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.1         |\n",
      "|    n_updates            | 25550        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    reward               | 0.8225625    |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 93.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1092         |\n",
      "|    time_elapsed         | 19857        |\n",
      "|    total_timesteps      | 2236416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024769618 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.6         |\n",
      "|    n_updates            | 25560        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    reward               | -1.403324    |\n",
      "|    std                  | 26.5         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1093         |\n",
      "|    time_elapsed         | 19876        |\n",
      "|    total_timesteps      | 2238464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022024114 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 159          |\n",
      "|    n_updates            | 25570        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    reward               | -2.3470438   |\n",
      "|    std                  | 26.6         |\n",
      "|    value_loss           | 304          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1094         |\n",
      "|    time_elapsed         | 19894        |\n",
      "|    total_timesteps      | 2240512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057160775 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 25580        |\n",
      "|    policy_gradient_loss | -0.00872     |\n",
      "|    reward               | 2.0566428    |\n",
      "|    std                  | 26.7         |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 19912       |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0035192   |\n",
      "|    clip_fraction        | 0.00562     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 25590       |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    reward               | -0.33115608 |\n",
      "|    std                  | 26.7        |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1096         |\n",
      "|    time_elapsed         | 19931        |\n",
      "|    total_timesteps      | 2244608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015532803 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.2         |\n",
      "|    n_updates            | 25600        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | -1.7690678   |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1097         |\n",
      "|    time_elapsed         | 19949        |\n",
      "|    total_timesteps      | 2246656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019558687 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.1         |\n",
      "|    n_updates            | 25610        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | 0.17267235   |\n",
      "|    std                  | 26.8         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1098         |\n",
      "|    time_elapsed         | 19967        |\n",
      "|    total_timesteps      | 2248704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026964268 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 133          |\n",
      "|    n_updates            | 25620        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    reward               | -1.4106191   |\n",
      "|    std                  | 26.9         |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1099         |\n",
      "|    time_elapsed         | 19989        |\n",
      "|    total_timesteps      | 2250752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023337582 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 109          |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    reward               | 15.066786    |\n",
      "|    std                  | 27           |\n",
      "|    value_loss           | 207          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1100          |\n",
      "|    time_elapsed         | 20008         |\n",
      "|    total_timesteps      | 2252800       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069512165 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.424         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 59.1          |\n",
      "|    n_updates            | 25640         |\n",
      "|    policy_gradient_loss | -0.00246      |\n",
      "|    reward               | 3.5244672     |\n",
      "|    std                  | 27.1          |\n",
      "|    value_loss           | 253           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 20027       |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005149433 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -136        |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 25650       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    reward               | 3.9537234   |\n",
      "|    std                  | 27.1        |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1102         |\n",
      "|    time_elapsed         | 20045        |\n",
      "|    total_timesteps      | 2256896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014600095 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67.4         |\n",
      "|    n_updates            | 25660        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    reward               | -0.06574616  |\n",
      "|    std                  | 27.1         |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1103          |\n",
      "|    time_elapsed         | 20063         |\n",
      "|    total_timesteps      | 2258944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090303575 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -136          |\n",
      "|    explained_variance   | 0.618         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 91            |\n",
      "|    n_updates            | 25670         |\n",
      "|    policy_gradient_loss | -0.00356      |\n",
      "|    reward               | -0.598527     |\n",
      "|    std                  | 27.1          |\n",
      "|    value_loss           | 163           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6617569.47\n",
      "total_reward: 5617569.47\n",
      "total_cost: 247304.41\n",
      "total_trades: 63883\n",
      "Sharpe: 0.881\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1104         |\n",
      "|    time_elapsed         | 20082        |\n",
      "|    total_timesteps      | 2260992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033917767 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -136         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 25680        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    reward               | 4.415806     |\n",
      "|    std                  | 27.2         |\n",
      "|    value_loss           | 52.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1105         |\n",
      "|    time_elapsed         | 20100        |\n",
      "|    total_timesteps      | 2263040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016012824 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.6         |\n",
      "|    n_updates            | 25690        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -3.0210195   |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1106         |\n",
      "|    time_elapsed         | 20119        |\n",
      "|    total_timesteps      | 2265088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010335918 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.2         |\n",
      "|    n_updates            | 25700        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | -5.822968    |\n",
      "|    std                  | 27.3         |\n",
      "|    value_loss           | 149          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1107         |\n",
      "|    time_elapsed         | 20137        |\n",
      "|    total_timesteps      | 2267136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026219373 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45           |\n",
      "|    n_updates            | 25710        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    reward               | 1.257595     |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1108         |\n",
      "|    time_elapsed         | 20156        |\n",
      "|    total_timesteps      | 2269184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025966398 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.3         |\n",
      "|    n_updates            | 25720        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    reward               | 0.7618174    |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1109         |\n",
      "|    time_elapsed         | 20174        |\n",
      "|    total_timesteps      | 2271232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006935928 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 25730        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    reward               | 0.22133571   |\n",
      "|    std                  | 27.4         |\n",
      "|    value_loss           | 205          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1110         |\n",
      "|    time_elapsed         | 20193        |\n",
      "|    total_timesteps      | 2273280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013040544 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 80.6         |\n",
      "|    n_updates            | 25740        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 9.511568     |\n",
      "|    std                  | 27.5         |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1111        |\n",
      "|    time_elapsed         | 20211       |\n",
      "|    total_timesteps      | 2275328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003473434 |\n",
      "|    clip_fraction        | 0.00728     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -137        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 25750       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    reward               | -4.4878335  |\n",
      "|    std                  | 27.5        |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1112         |\n",
      "|    time_elapsed         | 20230        |\n",
      "|    total_timesteps      | 2277376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018149789 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36           |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    reward               | 0.34028077   |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 183          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1113         |\n",
      "|    time_elapsed         | 20248        |\n",
      "|    total_timesteps      | 2279424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008101321 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 126          |\n",
      "|    n_updates            | 25770        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | 8.960813     |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1114         |\n",
      "|    time_elapsed         | 20266        |\n",
      "|    total_timesteps      | 2281472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020978646 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 25780        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 0.4380645    |\n",
      "|    std                  | 27.6         |\n",
      "|    value_loss           | 89.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1115         |\n",
      "|    time_elapsed         | 20285        |\n",
      "|    total_timesteps      | 2283520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038352816 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.1         |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -0.00787     |\n",
      "|    reward               | 0.24396916   |\n",
      "|    std                  | 27.7         |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1116          |\n",
      "|    time_elapsed         | 20303         |\n",
      "|    total_timesteps      | 2285568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047626637 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -137          |\n",
      "|    explained_variance   | 0.496         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 48.1          |\n",
      "|    n_updates            | 25800         |\n",
      "|    policy_gradient_loss | -0.00168      |\n",
      "|    reward               | 0.9699695     |\n",
      "|    std                  | 27.7          |\n",
      "|    value_loss           | 175           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1117         |\n",
      "|    time_elapsed         | 20322        |\n",
      "|    total_timesteps      | 2287616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002633357 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.1         |\n",
      "|    n_updates            | 25810        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    reward               | 1.5457641    |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6158207.10\n",
      "total_reward: 5158207.10\n",
      "total_cost: 273727.15\n",
      "total_trades: 65470\n",
      "Sharpe: 0.841\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1118         |\n",
      "|    time_elapsed         | 20340        |\n",
      "|    total_timesteps      | 2289664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062770657 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.09         |\n",
      "|    n_updates            | 25820        |\n",
      "|    policy_gradient_loss | -0.00838     |\n",
      "|    reward               | -1.6808041   |\n",
      "|    std                  | 27.8         |\n",
      "|    value_loss           | 29.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1119         |\n",
      "|    time_elapsed         | 20359        |\n",
      "|    total_timesteps      | 2291712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012146224 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.8         |\n",
      "|    n_updates            | 25830        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 0.44284594   |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1120         |\n",
      "|    time_elapsed         | 20377        |\n",
      "|    total_timesteps      | 2293760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007965414 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 25840        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -0.66147745  |\n",
      "|    std                  | 27.9         |\n",
      "|    value_loss           | 280          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1121         |\n",
      "|    time_elapsed         | 20399        |\n",
      "|    total_timesteps      | 2295808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026418301 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 25850        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | -2.850955    |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 69.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1122         |\n",
      "|    time_elapsed         | 20418        |\n",
      "|    total_timesteps      | 2297856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007439023 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -0.5920829   |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 91.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1123         |\n",
      "|    time_elapsed         | 20436        |\n",
      "|    total_timesteps      | 2299904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006409843 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.8         |\n",
      "|    n_updates            | 25870        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 16.718967    |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1124         |\n",
      "|    time_elapsed         | 20454        |\n",
      "|    total_timesteps      | 2301952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004527932 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52.5         |\n",
      "|    n_updates            | 25880        |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    reward               | -0.93900895  |\n",
      "|    std                  | 28           |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1125         |\n",
      "|    time_elapsed         | 20473        |\n",
      "|    total_timesteps      | 2304000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059877653 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -137         |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 25890        |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    reward               | 0.41499695   |\n",
      "|    std                  | 28.1         |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1126          |\n",
      "|    time_elapsed         | 20491         |\n",
      "|    total_timesteps      | 2306048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073724927 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.645         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 79.1          |\n",
      "|    n_updates            | 25900         |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    reward               | 0.47929245    |\n",
      "|    std                  | 28.1          |\n",
      "|    value_loss           | 156           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1127          |\n",
      "|    time_elapsed         | 20510         |\n",
      "|    total_timesteps      | 2308096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038042714 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 79.3          |\n",
      "|    n_updates            | 25910         |\n",
      "|    policy_gradient_loss | -0.00192      |\n",
      "|    reward               | 3.2866907     |\n",
      "|    std                  | 28.2          |\n",
      "|    value_loss           | 164           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1128         |\n",
      "|    time_elapsed         | 20528        |\n",
      "|    total_timesteps      | 2310144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029665274 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 25920        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    reward               | 0.32215545   |\n",
      "|    std                  | 28.2         |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1129          |\n",
      "|    time_elapsed         | 20546         |\n",
      "|    total_timesteps      | 2312192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088099565 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.6          |\n",
      "|    n_updates            | 25930         |\n",
      "|    policy_gradient_loss | -0.00286      |\n",
      "|    reward               | -3.7800984    |\n",
      "|    std                  | 28.3          |\n",
      "|    value_loss           | 130           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1130          |\n",
      "|    time_elapsed         | 20565         |\n",
      "|    total_timesteps      | 2314240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023052128 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.661         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 60.7          |\n",
      "|    n_updates            | 25940         |\n",
      "|    policy_gradient_loss | -0.00131      |\n",
      "|    reward               | -2.8305864    |\n",
      "|    std                  | 28.3          |\n",
      "|    value_loss           | 189           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1131         |\n",
      "|    time_elapsed         | 20583        |\n",
      "|    total_timesteps      | 2316288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003813561 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.4         |\n",
      "|    n_updates            | 25950        |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    reward               | -0.7441192   |\n",
      "|    std                  | 28.3         |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6858276.28\n",
      "total_reward: 5858276.28\n",
      "total_cost: 252628.59\n",
      "total_trades: 63643\n",
      "Sharpe: 0.895\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1132         |\n",
      "|    time_elapsed         | 20602        |\n",
      "|    total_timesteps      | 2318336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024034535 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58           |\n",
      "|    n_updates            | 25960        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 5.24222      |\n",
      "|    std                  | 28.4         |\n",
      "|    value_loss           | 80.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1133        |\n",
      "|    time_elapsed         | 20620       |\n",
      "|    total_timesteps      | 2320384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000790805 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 25970       |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    reward               | 0.6564245   |\n",
      "|    std                  | 28.4        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1134          |\n",
      "|    time_elapsed         | 20638         |\n",
      "|    total_timesteps      | 2322432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027480518 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.651         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 148           |\n",
      "|    n_updates            | 25980         |\n",
      "|    policy_gradient_loss | -0.00159      |\n",
      "|    reward               | 11.033215     |\n",
      "|    std                  | 28.4          |\n",
      "|    value_loss           | 192           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1135         |\n",
      "|    time_elapsed         | 20656        |\n",
      "|    total_timesteps      | 2324480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063598608 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.67         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 25990        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    reward               | -1.0451088   |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 32           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1136          |\n",
      "|    time_elapsed         | 20675         |\n",
      "|    total_timesteps      | 2326528       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040946904 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.706         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 77.9          |\n",
      "|    n_updates            | 26000         |\n",
      "|    policy_gradient_loss | -0.00202      |\n",
      "|    reward               | 0.8171329     |\n",
      "|    std                  | 28.5          |\n",
      "|    value_loss           | 144           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1137          |\n",
      "|    time_elapsed         | 20693         |\n",
      "|    total_timesteps      | 2328576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031138153 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.741         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 80.7          |\n",
      "|    n_updates            | 26010         |\n",
      "|    policy_gradient_loss | -0.000951     |\n",
      "|    reward               | -1.5681497    |\n",
      "|    std                  | 28.5          |\n",
      "|    value_loss           | 137           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1138         |\n",
      "|    time_elapsed         | 20712        |\n",
      "|    total_timesteps      | 2330624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005143295 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41           |\n",
      "|    n_updates            | 26020        |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    reward               | 2.452184     |\n",
      "|    std                  | 28.6         |\n",
      "|    value_loss           | 83.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1139         |\n",
      "|    time_elapsed         | 20731        |\n",
      "|    total_timesteps      | 2332672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014868829 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33           |\n",
      "|    n_updates            | 26030        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    reward               | 1.1784838    |\n",
      "|    std                  | 28.5         |\n",
      "|    value_loss           | 74.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1140          |\n",
      "|    time_elapsed         | 20750         |\n",
      "|    total_timesteps      | 2334720       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048615094 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.724         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 86.8          |\n",
      "|    n_updates            | 26040         |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    reward               | -1.8484461    |\n",
      "|    std                  | 28.6          |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1141          |\n",
      "|    time_elapsed         | 20768         |\n",
      "|    total_timesteps      | 2336768       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044274522 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.712         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 80.2          |\n",
      "|    n_updates            | 26050         |\n",
      "|    policy_gradient_loss | -0.00207      |\n",
      "|    reward               | 4.6236835     |\n",
      "|    std                  | 28.6          |\n",
      "|    value_loss           | 132           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1142         |\n",
      "|    time_elapsed         | 20786        |\n",
      "|    total_timesteps      | 2338816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029715179 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | -0.19392793  |\n",
      "|    std                  | 28.7         |\n",
      "|    value_loss           | 42.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1143         |\n",
      "|    time_elapsed         | 20804        |\n",
      "|    total_timesteps      | 2340864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009356362 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 84.3         |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | 0.26817003   |\n",
      "|    std                  | 28.8         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1144          |\n",
      "|    time_elapsed         | 20823         |\n",
      "|    total_timesteps      | 2342912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044753353 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.618         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 138           |\n",
      "|    n_updates            | 26080         |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    reward               | -1.1489224    |\n",
      "|    std                  | 28.8          |\n",
      "|    value_loss           | 179           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1145         |\n",
      "|    time_elapsed         | 20842        |\n",
      "|    total_timesteps      | 2344960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015853386 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.9         |\n",
      "|    n_updates            | 26090        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | -0.36717942  |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 87.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7324644.93\n",
      "total_reward: 6324644.93\n",
      "total_cost: 221804.41\n",
      "total_trades: 62318\n",
      "Sharpe: 0.901\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1146         |\n",
      "|    time_elapsed         | 20860        |\n",
      "|    total_timesteps      | 2347008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011442482 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 0.34449443   |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1147         |\n",
      "|    time_elapsed         | 20879        |\n",
      "|    total_timesteps      | 2349056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007196439 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.3         |\n",
      "|    n_updates            | 26110        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    reward               | 33.10155     |\n",
      "|    std                  | 28.9         |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1148          |\n",
      "|    time_elapsed         | 20897         |\n",
      "|    total_timesteps      | 2351104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023090324 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -138          |\n",
      "|    explained_variance   | 0.673         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55.2          |\n",
      "|    n_updates            | 26120         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | 0.5850432     |\n",
      "|    std                  | 28.9          |\n",
      "|    value_loss           | 166           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 20916       |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004655773 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -138        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 26130       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    reward               | 0.34159288  |\n",
      "|    std                  | 29.1        |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1150         |\n",
      "|    time_elapsed         | 20935        |\n",
      "|    total_timesteps      | 2355200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004495663 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -138         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 73.5         |\n",
      "|    n_updates            | 26140        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    reward               | 0.32111865   |\n",
      "|    std                  | 29.1         |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1151          |\n",
      "|    time_elapsed         | 20954         |\n",
      "|    total_timesteps      | 2357248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068470417 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.644         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 50.1          |\n",
      "|    n_updates            | 26150         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    reward               | -4.3650765    |\n",
      "|    std                  | 29.2          |\n",
      "|    value_loss           | 149           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1152         |\n",
      "|    time_elapsed         | 20973        |\n",
      "|    total_timesteps      | 2359296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018716576 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.1         |\n",
      "|    n_updates            | 26160        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | 4.6752133    |\n",
      "|    std                  | 29.2         |\n",
      "|    value_loss           | 55.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1153          |\n",
      "|    time_elapsed         | 20992         |\n",
      "|    total_timesteps      | 2361344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073606253 |\n",
      "|    clip_fraction        | 0.000928      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.724         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.6          |\n",
      "|    n_updates            | 26170         |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    reward               | -6.7689075    |\n",
      "|    std                  | 29.2          |\n",
      "|    value_loss           | 105           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1154         |\n",
      "|    time_elapsed         | 21011        |\n",
      "|    total_timesteps      | 2363392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002064957 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60           |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -0.000865    |\n",
      "|    reward               | -3.032581    |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1155         |\n",
      "|    time_elapsed         | 21030        |\n",
      "|    total_timesteps      | 2365440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008338769 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 56.1         |\n",
      "|    n_updates            | 26190        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | -1.2140648   |\n",
      "|    std                  | 29.3         |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 21048       |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003674772 |\n",
      "|    clip_fraction        | 0.00552     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 26200       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 0.14294785  |\n",
      "|    std                  | 29.4        |\n",
      "|    value_loss           | 72.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1157         |\n",
      "|    time_elapsed         | 21067        |\n",
      "|    total_timesteps      | 2369536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011962566 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 26210        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    reward               | 0.6649796    |\n",
      "|    std                  | 29.4         |\n",
      "|    value_loss           | 247          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1158          |\n",
      "|    time_elapsed         | 21086         |\n",
      "|    total_timesteps      | 2371584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052780146 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.49          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 129           |\n",
      "|    n_updates            | 26220         |\n",
      "|    policy_gradient_loss | -0.00247      |\n",
      "|    reward               | 3.4243019     |\n",
      "|    std                  | 29.4          |\n",
      "|    value_loss           | 241           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1159         |\n",
      "|    time_elapsed         | 21105        |\n",
      "|    total_timesteps      | 2373632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032848972 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 26230        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    reward               | 2.6102319    |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 36.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7517002.45\n",
      "total_reward: 6517002.45\n",
      "total_cost: 254972.45\n",
      "total_trades: 64332\n",
      "Sharpe: 0.929\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1160         |\n",
      "|    time_elapsed         | 21124        |\n",
      "|    total_timesteps      | 2375680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007195751 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 69.3         |\n",
      "|    n_updates            | 26240        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | 0.3228191    |\n",
      "|    std                  | 29.5         |\n",
      "|    value_loss           | 143          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1161         |\n",
      "|    time_elapsed         | 21142        |\n",
      "|    total_timesteps      | 2377728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007316793 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 165          |\n",
      "|    n_updates            | 26250        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | 2.1804008    |\n",
      "|    std                  | 29.6         |\n",
      "|    value_loss           | 205          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1162         |\n",
      "|    time_elapsed         | 21161        |\n",
      "|    total_timesteps      | 2379776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013620446 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.516        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 26260        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    reward               | 3.611263     |\n",
      "|    std                  | 29.7         |\n",
      "|    value_loss           | 87.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1163         |\n",
      "|    time_elapsed         | 21179        |\n",
      "|    total_timesteps      | 2381824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047777044 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 26270        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    reward               | -0.6448208   |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 89.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 21197        |\n",
      "|    total_timesteps      | 2383872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003564601 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 68.6         |\n",
      "|    n_updates            | 26280        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    reward               | -0.5006      |\n",
      "|    std                  | 29.8         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1165          |\n",
      "|    time_elapsed         | 21216         |\n",
      "|    total_timesteps      | 2385920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8978574e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.264         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 85.4          |\n",
      "|    n_updates            | 26290         |\n",
      "|    policy_gradient_loss | -0.000664     |\n",
      "|    reward               | 3.7918699     |\n",
      "|    std                  | 29.8          |\n",
      "|    value_loss           | 295           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1166         |\n",
      "|    time_elapsed         | 21235        |\n",
      "|    total_timesteps      | 2387968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071219774 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.53         |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    reward               | -1.7028663   |\n",
      "|    std                  | 30           |\n",
      "|    value_loss           | 27.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1167          |\n",
      "|    time_elapsed         | 21253         |\n",
      "|    total_timesteps      | 2390016       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047235476 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.689         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.8          |\n",
      "|    n_updates            | 26310         |\n",
      "|    policy_gradient_loss | -0.00195      |\n",
      "|    reward               | -0.827291     |\n",
      "|    std                  | 30            |\n",
      "|    value_loss           | 126           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1168          |\n",
      "|    time_elapsed         | 21272         |\n",
      "|    total_timesteps      | 2392064       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032978845 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.738         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 60.9          |\n",
      "|    n_updates            | 26320         |\n",
      "|    policy_gradient_loss | -0.002        |\n",
      "|    reward               | -1.5868909    |\n",
      "|    std                  | 30            |\n",
      "|    value_loss           | 120           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1169         |\n",
      "|    time_elapsed         | 21290        |\n",
      "|    total_timesteps      | 2394112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019916943 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 26330        |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | 2.03997      |\n",
      "|    std                  | 30           |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1170         |\n",
      "|    time_elapsed         | 21309        |\n",
      "|    total_timesteps      | 2396160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008042563 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.4         |\n",
      "|    n_updates            | 26340        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 1.3526846    |\n",
      "|    std                  | 30           |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1171          |\n",
      "|    time_elapsed         | 21327         |\n",
      "|    total_timesteps      | 2398208       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022490334 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.708         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 42.3          |\n",
      "|    n_updates            | 26350         |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    reward               | -5.7989383    |\n",
      "|    std                  | 30            |\n",
      "|    value_loss           | 156           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1172          |\n",
      "|    time_elapsed         | 21346         |\n",
      "|    total_timesteps      | 2400256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036830633 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.68          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 66            |\n",
      "|    n_updates            | 26360         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    reward               | -1.0069733    |\n",
      "|    std                  | 30            |\n",
      "|    value_loss           | 108           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1173         |\n",
      "|    time_elapsed         | 21365        |\n",
      "|    total_timesteps      | 2402304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019485375 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -139         |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 26370        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | 3.3288593    |\n",
      "|    std                  | 30.1         |\n",
      "|    value_loss           | 65.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6775381.18\n",
      "total_reward: 5775381.18\n",
      "total_cost: 264599.61\n",
      "total_trades: 64660\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 21383       |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00085868  |\n",
      "|    clip_fraction        | 0.00127     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -139        |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.1        |\n",
      "|    n_updates            | 26380       |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    reward               | -0.63467246 |\n",
      "|    std                  | 30.1        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1175          |\n",
      "|    time_elapsed         | 21402         |\n",
      "|    total_timesteps      | 2406400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052258745 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -139          |\n",
      "|    explained_variance   | 0.745         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 87.8          |\n",
      "|    n_updates            | 26390         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | -5.01586      |\n",
      "|    std                  | 30.2          |\n",
      "|    value_loss           | 135           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1176         |\n",
      "|    time_elapsed         | 21420        |\n",
      "|    total_timesteps      | 2408448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029994661 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 26400        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    reward               | 3.6453588    |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 41.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1177         |\n",
      "|    time_elapsed         | 21439        |\n",
      "|    total_timesteps      | 2410496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012121638 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.716        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.7         |\n",
      "|    n_updates            | 26410        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 0.052200567  |\n",
      "|    std                  | 30.3         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 21457        |\n",
      "|    total_timesteps      | 2412544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008407973 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 22.655092    |\n",
      "|    std                  | 30.4         |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1179          |\n",
      "|    time_elapsed         | 21476         |\n",
      "|    total_timesteps      | 2414592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089349155 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.644         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.2          |\n",
      "|    n_updates            | 26430         |\n",
      "|    policy_gradient_loss | -0.0025       |\n",
      "|    reward               | 3.5373373     |\n",
      "|    std                  | 30.4          |\n",
      "|    value_loss           | 87.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1180         |\n",
      "|    time_elapsed         | 21494        |\n",
      "|    total_timesteps      | 2416640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038783725 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 26440        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    reward               | 1.0139365    |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1181         |\n",
      "|    time_elapsed         | 21513        |\n",
      "|    total_timesteps      | 2418688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003593733 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63           |\n",
      "|    n_updates            | 26450        |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    reward               | 0.23919652   |\n",
      "|    std                  | 30.5         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1182          |\n",
      "|    time_elapsed         | 21531         |\n",
      "|    total_timesteps      | 2420736       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071417773 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.636         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53.4          |\n",
      "|    n_updates            | 26460         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | 3.387286      |\n",
      "|    std                  | 30.5          |\n",
      "|    value_loss           | 149           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1183         |\n",
      "|    time_elapsed         | 21549        |\n",
      "|    total_timesteps      | 2422784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050391736 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.5         |\n",
      "|    n_updates            | 26470        |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    reward               | -3.317021    |\n",
      "|    std                  | 30.6         |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1184         |\n",
      "|    time_elapsed         | 21568        |\n",
      "|    total_timesteps      | 2424832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007233352 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 26480        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    reward               | -0.20973395  |\n",
      "|    std                  | 30.6         |\n",
      "|    value_loss           | 97.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1185          |\n",
      "|    time_elapsed         | 21586         |\n",
      "|    total_timesteps      | 2426880       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047327252 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.476         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 108           |\n",
      "|    n_updates            | 26490         |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | -1.9127061    |\n",
      "|    std                  | 30.7          |\n",
      "|    value_loss           | 187           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1186          |\n",
      "|    time_elapsed         | 21605         |\n",
      "|    total_timesteps      | 2428928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043882357 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.64          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.5          |\n",
      "|    n_updates            | 26500         |\n",
      "|    policy_gradient_loss | -0.00154      |\n",
      "|    reward               | -1.5284269    |\n",
      "|    std                  | 30.7          |\n",
      "|    value_loss           | 62.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1187         |\n",
      "|    time_elapsed         | 21623        |\n",
      "|    total_timesteps      | 2430976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012856369 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.2         |\n",
      "|    n_updates            | 26510        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | -1.0313108   |\n",
      "|    std                  | 30.8         |\n",
      "|    value_loss           | 88.9         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7000727.19\n",
      "total_reward: 6000727.19\n",
      "total_cost: 264395.54\n",
      "total_trades: 64895\n",
      "Sharpe: 0.897\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1188          |\n",
      "|    time_elapsed         | 21642         |\n",
      "|    total_timesteps      | 2433024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052891974 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.686         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 142           |\n",
      "|    n_updates            | 26520         |\n",
      "|    policy_gradient_loss | -0.00233      |\n",
      "|    reward               | -0.5661934    |\n",
      "|    std                  | 30.8          |\n",
      "|    value_loss           | 192           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1189          |\n",
      "|    time_elapsed         | 21660         |\n",
      "|    total_timesteps      | 2435072       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028291758 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.702         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 47.1          |\n",
      "|    n_updates            | 26530         |\n",
      "|    policy_gradient_loss | -0.00142      |\n",
      "|    reward               | -1.027967     |\n",
      "|    std                  | 30.8          |\n",
      "|    value_loss           | 160           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1190         |\n",
      "|    time_elapsed         | 21679        |\n",
      "|    total_timesteps      | 2437120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037610154 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 26540        |\n",
      "|    policy_gradient_loss | -0.00813     |\n",
      "|    reward               | 2.2378457    |\n",
      "|    std                  | 30.8         |\n",
      "|    value_loss           | 45.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1191         |\n",
      "|    time_elapsed         | 21697        |\n",
      "|    total_timesteps      | 2439168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012801039 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.2         |\n",
      "|    n_updates            | 26550        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -1.7298476   |\n",
      "|    std                  | 30.9         |\n",
      "|    value_loss           | 189          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1192         |\n",
      "|    time_elapsed         | 21716        |\n",
      "|    total_timesteps      | 2441216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013077991 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.2         |\n",
      "|    n_updates            | 26560        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -0.045053605 |\n",
      "|    std                  | 31           |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1193         |\n",
      "|    time_elapsed         | 21734        |\n",
      "|    total_timesteps      | 2443264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009917396 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 26570        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | 3.4890156    |\n",
      "|    std                  | 31           |\n",
      "|    value_loss           | 66.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1194         |\n",
      "|    time_elapsed         | 21753        |\n",
      "|    total_timesteps      | 2445312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070153824 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -140         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54           |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    reward               | 0.45515886   |\n",
      "|    std                  | 31.2         |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1195          |\n",
      "|    time_elapsed         | 21771         |\n",
      "|    total_timesteps      | 2447360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012552415 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.607         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 124           |\n",
      "|    n_updates            | 26590         |\n",
      "|    policy_gradient_loss | -0.000951     |\n",
      "|    reward               | -2.4461784    |\n",
      "|    std                  | 31.2          |\n",
      "|    value_loss           | 216           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1196          |\n",
      "|    time_elapsed         | 21789         |\n",
      "|    total_timesteps      | 2449408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020197601 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -140          |\n",
      "|    explained_variance   | 0.655         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 58.6          |\n",
      "|    n_updates            | 26600         |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    reward               | 0.40140343    |\n",
      "|    std                  | 31.2          |\n",
      "|    value_loss           | 102           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 21808       |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0016878   |\n",
      "|    clip_fraction        | 0.00181     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 26610       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -0.25546136 |\n",
      "|    std                  | 31.3        |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1198         |\n",
      "|    time_elapsed         | 21827        |\n",
      "|    total_timesteps      | 2453504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006009201 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 79.9         |\n",
      "|    n_updates            | 26620        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    reward               | -0.24345562  |\n",
      "|    std                  | 31.3         |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1199          |\n",
      "|    time_elapsed         | 21845         |\n",
      "|    total_timesteps      | 2455552       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028180843 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.399         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 94.4          |\n",
      "|    n_updates            | 26630         |\n",
      "|    policy_gradient_loss | -0.00138      |\n",
      "|    reward               | -29.92789     |\n",
      "|    std                  | 31.4          |\n",
      "|    value_loss           | 344           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1200         |\n",
      "|    time_elapsed         | 21864        |\n",
      "|    total_timesteps      | 2457600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027647158 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 26640        |\n",
      "|    policy_gradient_loss | -0.00715     |\n",
      "|    reward               | 2.3952427    |\n",
      "|    std                  | 31.5         |\n",
      "|    value_loss           | 57.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1201         |\n",
      "|    time_elapsed         | 21882        |\n",
      "|    total_timesteps      | 2459648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003886326 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 58.8         |\n",
      "|    n_updates            | 26650        |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    reward               | 0.88695675   |\n",
      "|    std                  | 31.5         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1202         |\n",
      "|    time_elapsed         | 21901        |\n",
      "|    total_timesteps      | 2461696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007050275 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89.9         |\n",
      "|    n_updates            | 26660        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    reward               | -3.4519548   |\n",
      "|    std                  | 31.5         |\n",
      "|    value_loss           | 166          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7154707.22\n",
      "total_reward: 6154707.22\n",
      "total_cost: 240326.29\n",
      "total_trades: 63211\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1203         |\n",
      "|    time_elapsed         | 21920        |\n",
      "|    total_timesteps      | 2463744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008058977 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 26670        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | 3.4808424    |\n",
      "|    std                  | 31.6         |\n",
      "|    value_loss           | 93.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1204         |\n",
      "|    time_elapsed         | 21939        |\n",
      "|    total_timesteps      | 2465792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018617988 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.2         |\n",
      "|    n_updates            | 26680        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | 0.923229     |\n",
      "|    std                  | 31.6         |\n",
      "|    value_loss           | 98.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1205         |\n",
      "|    time_elapsed         | 21957        |\n",
      "|    total_timesteps      | 2467840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013149944 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.6         |\n",
      "|    n_updates            | 26690        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    reward               | 0.06542416   |\n",
      "|    std                  | 31.7         |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1206          |\n",
      "|    time_elapsed         | 21975         |\n",
      "|    total_timesteps      | 2469888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042184864 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.601         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 60.5          |\n",
      "|    n_updates            | 26700         |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    reward               | 0.73760694    |\n",
      "|    std                  | 31.7          |\n",
      "|    value_loss           | 166           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1207         |\n",
      "|    time_elapsed         | 21995        |\n",
      "|    total_timesteps      | 2471936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020317938 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 26710        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | 0.7051683    |\n",
      "|    std                  | 31.8         |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1208         |\n",
      "|    time_elapsed         | 22014        |\n",
      "|    total_timesteps      | 2473984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016651902 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78.9         |\n",
      "|    n_updates            | 26720        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | -1.8985326   |\n",
      "|    std                  | 31.8         |\n",
      "|    value_loss           | 194          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1209          |\n",
      "|    time_elapsed         | 22033         |\n",
      "|    total_timesteps      | 2476032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025479856 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.672         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 62.6          |\n",
      "|    n_updates            | 26730         |\n",
      "|    policy_gradient_loss | -0.00152      |\n",
      "|    reward               | -8.100241     |\n",
      "|    std                  | 31.9          |\n",
      "|    value_loss           | 155           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1210         |\n",
      "|    time_elapsed         | 22051        |\n",
      "|    total_timesteps      | 2478080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019404382 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 26740        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | -4.637226    |\n",
      "|    std                  | 31.9         |\n",
      "|    value_loss           | 74.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 22069       |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004381736 |\n",
      "|    clip_fraction        | 0.00874     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 26750       |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | 1.1891323   |\n",
      "|    std                  | 32          |\n",
      "|    value_loss           | 75.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1212          |\n",
      "|    time_elapsed         | 22088         |\n",
      "|    total_timesteps      | 2482176       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023725757 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.581         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 145           |\n",
      "|    n_updates            | 26760         |\n",
      "|    policy_gradient_loss | -0.00122      |\n",
      "|    reward               | 17.394203     |\n",
      "|    std                  | 32            |\n",
      "|    value_loss           | 229           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1213          |\n",
      "|    time_elapsed         | 22106         |\n",
      "|    total_timesteps      | 2484224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021778909 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.67          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 110           |\n",
      "|    n_updates            | 26770         |\n",
      "|    policy_gradient_loss | -0.00113      |\n",
      "|    reward               | 2.6235213     |\n",
      "|    std                  | 32            |\n",
      "|    value_loss           | 194           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1214         |\n",
      "|    time_elapsed         | 22125        |\n",
      "|    total_timesteps      | 2486272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017041453 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.312        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 26780        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 4.216737     |\n",
      "|    std                  | 32.1         |\n",
      "|    value_loss           | 68.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1215          |\n",
      "|    time_elapsed         | 22144         |\n",
      "|    total_timesteps      | 2488320       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063640706 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.663         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 79.6          |\n",
      "|    n_updates            | 26790         |\n",
      "|    policy_gradient_loss | -0.00217      |\n",
      "|    reward               | -0.30183664   |\n",
      "|    std                  | 32.1          |\n",
      "|    value_loss           | 177           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1216          |\n",
      "|    time_elapsed         | 22162         |\n",
      "|    total_timesteps      | 2490368       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034996998 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.564         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 149           |\n",
      "|    n_updates            | 26800         |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    reward               | -0.12682855   |\n",
      "|    std                  | 32.1          |\n",
      "|    value_loss           | 189           |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6758967.18\n",
      "total_reward: 5758967.18\n",
      "total_cost: 251432.95\n",
      "total_trades: 63320\n",
      "Sharpe: 0.948\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 22180       |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002687756 |\n",
      "|    clip_fraction        | 0.00249     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -141        |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 26810       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 3.0951183   |\n",
      "|    std                  | 32.2        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1218         |\n",
      "|    time_elapsed         | 22199        |\n",
      "|    total_timesteps      | 2494464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020563668 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.1         |\n",
      "|    n_updates            | 26820        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    reward               | 2.8904433    |\n",
      "|    std                  | 32.2         |\n",
      "|    value_loss           | 91.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1219          |\n",
      "|    time_elapsed         | 22217         |\n",
      "|    total_timesteps      | 2496512       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095382944 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -141          |\n",
      "|    explained_variance   | 0.692         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 74.9          |\n",
      "|    n_updates            | 26830         |\n",
      "|    policy_gradient_loss | -0.00341      |\n",
      "|    reward               | -5.7684145    |\n",
      "|    std                  | 32.3          |\n",
      "|    value_loss           | 118           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1220         |\n",
      "|    time_elapsed         | 22236        |\n",
      "|    total_timesteps      | 2498560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005506809 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -141         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.3         |\n",
      "|    n_updates            | 26840        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | 1.03076      |\n",
      "|    std                  | 32.3         |\n",
      "|    value_loss           | 70.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 22254       |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002420062 |\n",
      "|    clip_fraction        | 0.0021      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 26850       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    reward               | -2.251213   |\n",
      "|    std                  | 32.4        |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1222         |\n",
      "|    time_elapsed         | 22273        |\n",
      "|    total_timesteps      | 2502656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010729288 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.6         |\n",
      "|    n_updates            | 26860        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | 0.117619745  |\n",
      "|    std                  | 32.4         |\n",
      "|    value_loss           | 122          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1223          |\n",
      "|    time_elapsed         | 22291         |\n",
      "|    total_timesteps      | 2504704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018635212 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.696         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.8          |\n",
      "|    n_updates            | 26870         |\n",
      "|    policy_gradient_loss | -0.000928     |\n",
      "|    reward               | 1.431016      |\n",
      "|    std                  | 32.4          |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1224         |\n",
      "|    time_elapsed         | 22310        |\n",
      "|    total_timesteps      | 2506752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021836204 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 26880        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    reward               | -0.6498812   |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 53.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1225         |\n",
      "|    time_elapsed         | 22329        |\n",
      "|    total_timesteps      | 2508800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019969454 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.9         |\n",
      "|    n_updates            | 26890        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 0.276351     |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1226         |\n",
      "|    time_elapsed         | 22347        |\n",
      "|    total_timesteps      | 2510848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006647149 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.7          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 63.9         |\n",
      "|    n_updates            | 26900        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | -3.9510505   |\n",
      "|    std                  | 32.5         |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1227         |\n",
      "|    time_elapsed         | 22365        |\n",
      "|    total_timesteps      | 2512896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017063057 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32           |\n",
      "|    n_updates            | 26910        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | 1.3890456    |\n",
      "|    std                  | 32.6         |\n",
      "|    value_loss           | 66.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 22383       |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001090313 |\n",
      "|    clip_fraction        | 0.00342     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.5        |\n",
      "|    n_updates            | 26920       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    reward               | 2.1014843   |\n",
      "|    std                  | 32.6        |\n",
      "|    value_loss           | 78.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1229         |\n",
      "|    time_elapsed         | 22402        |\n",
      "|    total_timesteps      | 2516992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009973553 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 26930        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    reward               | 0.19353391   |\n",
      "|    std                  | 32.7         |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1230         |\n",
      "|    time_elapsed         | 22420        |\n",
      "|    total_timesteps      | 2519040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003100399 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 89           |\n",
      "|    n_updates            | 26940        |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    reward               | -3.2570255   |\n",
      "|    std                  | 32.7         |\n",
      "|    value_loss           | 166          |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7521536.48\n",
      "total_reward: 6521536.48\n",
      "total_cost: 250272.70\n",
      "total_trades: 64053\n",
      "Sharpe: 0.949\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1231         |\n",
      "|    time_elapsed         | 22439        |\n",
      "|    total_timesteps      | 2521088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020491248 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.8         |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 1.6565535    |\n",
      "|    std                  | 32.8         |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1232         |\n",
      "|    time_elapsed         | 22458        |\n",
      "|    total_timesteps      | 2523136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005917281 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 81.7         |\n",
      "|    n_updates            | 26960        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 0.28974837   |\n",
      "|    std                  | 32.8         |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1233         |\n",
      "|    time_elapsed         | 22476        |\n",
      "|    total_timesteps      | 2525184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005672355 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 70.8         |\n",
      "|    n_updates            | 26970        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    reward               | -9.1828      |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1234         |\n",
      "|    time_elapsed         | 22495        |\n",
      "|    total_timesteps      | 2527232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013979961 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 26980        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 0.30052054   |\n",
      "|    std                  | 32.9         |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1235         |\n",
      "|    time_elapsed         | 22513        |\n",
      "|    total_timesteps      | 2529280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026112418 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -142         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 26990        |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    reward               | -0.67073196  |\n",
      "|    std                  | 33           |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1236        |\n",
      "|    time_elapsed         | 22531       |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001371441 |\n",
      "|    clip_fraction        | 0.0042      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 56.7        |\n",
      "|    n_updates            | 27000       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    reward               | 26.079279   |\n",
      "|    std                  | 33.1        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1237          |\n",
      "|    time_elapsed         | 22550         |\n",
      "|    total_timesteps      | 2533376       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046449894 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.536         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 94.5          |\n",
      "|    n_updates            | 27010         |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    reward               | 5.229753      |\n",
      "|    std                  | 33.1          |\n",
      "|    value_loss           | 185           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 22568       |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005271474 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 27020       |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    reward               | -2.5925167  |\n",
      "|    std                  | 33.3        |\n",
      "|    value_loss           | 49.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1239          |\n",
      "|    time_elapsed         | 22587         |\n",
      "|    total_timesteps      | 2537472       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057344994 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.72          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 56.1          |\n",
      "|    n_updates            | 27030         |\n",
      "|    policy_gradient_loss | -0.00228      |\n",
      "|    reward               | 0.1928529     |\n",
      "|    std                  | 33.3          |\n",
      "|    value_loss           | 131           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1240          |\n",
      "|    time_elapsed         | 22605         |\n",
      "|    total_timesteps      | 2539520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025366782 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.743         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 83.9          |\n",
      "|    n_updates            | 27040         |\n",
      "|    policy_gradient_loss | -0.0013       |\n",
      "|    reward               | -4.3239264    |\n",
      "|    std                  | 33.4          |\n",
      "|    value_loss           | 150           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1241          |\n",
      "|    time_elapsed         | 22624         |\n",
      "|    total_timesteps      | 2541568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045256305 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -142          |\n",
      "|    explained_variance   | 0.526         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.1          |\n",
      "|    n_updates            | 27050         |\n",
      "|    policy_gradient_loss | -0.0018       |\n",
      "|    reward               | 6.286042      |\n",
      "|    std                  | 33.4          |\n",
      "|    value_loss           | 74.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 22642       |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002242559 |\n",
      "|    clip_fraction        | 0.00137     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -142        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 27060       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    reward               | 1.8681636   |\n",
      "|    std                  | 33.5        |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1243          |\n",
      "|    time_elapsed         | 22661         |\n",
      "|    total_timesteps      | 2545664       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054020155 |\n",
      "|    clip_fraction        | 0.000977      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.665         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 37.7          |\n",
      "|    n_updates            | 27070         |\n",
      "|    policy_gradient_loss | -0.00189      |\n",
      "|    reward               | 1.6044713     |\n",
      "|    std                  | 33.5          |\n",
      "|    value_loss           | 117           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 22679       |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002018591 |\n",
      "|    clip_fraction        | 0.000635    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 27080       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    reward               | -1.1971654  |\n",
      "|    std                  | 33.6        |\n",
      "|    value_loss           | 63.5        |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 1920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7201365.60\n",
      "total_reward: 6201365.60\n",
      "total_cost: 223673.65\n",
      "total_trades: 62091\n",
      "Sharpe: 0.966\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1245         |\n",
      "|    time_elapsed         | 22698        |\n",
      "|    total_timesteps      | 2549760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030357786 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 27090        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    reward               | 1.291468     |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 56.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1246         |\n",
      "|    time_elapsed         | 22716        |\n",
      "|    total_timesteps      | 2551808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005075459 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 43.5         |\n",
      "|    n_updates            | 27100        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | -0.9189725   |\n",
      "|    std                  | 33.7         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1247          |\n",
      "|    time_elapsed         | 22735         |\n",
      "|    total_timesteps      | 2553856       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039176852 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.719         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 99.9          |\n",
      "|    n_updates            | 27110         |\n",
      "|    policy_gradient_loss | -0.00206      |\n",
      "|    reward               | -2.139232     |\n",
      "|    std                  | 33.7          |\n",
      "|    value_loss           | 125           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 22753       |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004612094 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 27120       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    reward               | -1.4220989  |\n",
      "|    std                  | 33.7        |\n",
      "|    value_loss           | 37.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1249         |\n",
      "|    time_elapsed         | 22771        |\n",
      "|    total_timesteps      | 2557952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005897147 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 86           |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | -0.06709231  |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1250         |\n",
      "|    time_elapsed         | 22790        |\n",
      "|    total_timesteps      | 2560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003710475 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 66.4         |\n",
      "|    n_updates            | 27140        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | -0.7682487   |\n",
      "|    std                  | 33.8         |\n",
      "|    value_loss           | 136          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1251          |\n",
      "|    time_elapsed         | 22808         |\n",
      "|    total_timesteps      | 2562048       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055667316 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.647         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.3          |\n",
      "|    n_updates            | 27150         |\n",
      "|    policy_gradient_loss | -0.00215      |\n",
      "|    reward               | 9.081548      |\n",
      "|    std                  | 33.9          |\n",
      "|    value_loss           | 81.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1252         |\n",
      "|    time_elapsed         | 22827        |\n",
      "|    total_timesteps      | 2564096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019036025 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.9         |\n",
      "|    n_updates            | 27160        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 4.2440934    |\n",
      "|    std                  | 33.9         |\n",
      "|    value_loss           | 71.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1253         |\n",
      "|    time_elapsed         | 22845        |\n",
      "|    total_timesteps      | 2566144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011588875 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 67           |\n",
      "|    n_updates            | 27170        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -0.4260628   |\n",
      "|    std                  | 34           |\n",
      "|    value_loss           | 160          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1254          |\n",
      "|    time_elapsed         | 22864         |\n",
      "|    total_timesteps      | 2568192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031217246 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.641         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 66.3          |\n",
      "|    n_updates            | 27180         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    reward               | 1.6879146     |\n",
      "|    std                  | 34            |\n",
      "|    value_loss           | 150           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 22882       |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005012379 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -143        |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.92        |\n",
      "|    n_updates            | 27190       |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    reward               | 0.78447896  |\n",
      "|    std                  | 34.2        |\n",
      "|    value_loss           | 27.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1256         |\n",
      "|    time_elapsed         | 22901        |\n",
      "|    total_timesteps      | 2572288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018821601 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.6         |\n",
      "|    n_updates            | 27200        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | -0.17149168  |\n",
      "|    std                  | 34.3         |\n",
      "|    value_loss           | 91           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1257          |\n",
      "|    time_elapsed         | 22920         |\n",
      "|    total_timesteps      | 2574336       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063484325 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.0744        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 181           |\n",
      "|    n_updates            | 27210         |\n",
      "|    policy_gradient_loss | -0.00265      |\n",
      "|    reward               | -4.9184875    |\n",
      "|    std                  | 34.3          |\n",
      "|    value_loss           | 304           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1258         |\n",
      "|    time_elapsed         | 22938        |\n",
      "|    total_timesteps      | 2576384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038017454 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 27220        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | 3.3340013    |\n",
      "|    std                  | 34.4         |\n",
      "|    value_loss           | 52.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6133644.78\n",
      "total_reward: 5133644.78\n",
      "total_cost: 230271.34\n",
      "total_trades: 63339\n",
      "Sharpe: 0.868\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1259         |\n",
      "|    time_elapsed         | 22957        |\n",
      "|    total_timesteps      | 2578432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011714578 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.7         |\n",
      "|    n_updates            | 27230        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    reward               | 0.41540518   |\n",
      "|    std                  | 34.5         |\n",
      "|    value_loss           | 79.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1260          |\n",
      "|    time_elapsed         | 22975         |\n",
      "|    total_timesteps      | 2580480       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018410356 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -143          |\n",
      "|    explained_variance   | 0.681         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 75.2          |\n",
      "|    n_updates            | 27240         |\n",
      "|    policy_gradient_loss | -0.000862     |\n",
      "|    reward               | 39.106953     |\n",
      "|    std                  | 34.6          |\n",
      "|    value_loss           | 146           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1261         |\n",
      "|    time_elapsed         | 22993        |\n",
      "|    total_timesteps      | 2582528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002723054 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 27250        |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    reward               | -5.403795    |\n",
      "|    std                  | 34.6         |\n",
      "|    value_loss           | 97.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1262         |\n",
      "|    time_elapsed         | 23012        |\n",
      "|    total_timesteps      | 2584576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022656461 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -143         |\n",
      "|    explained_variance   | 0.671        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 27260        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | 3.9133987    |\n",
      "|    std                  | 34.7         |\n",
      "|    value_loss           | 44.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1263          |\n",
      "|    time_elapsed         | 23030         |\n",
      "|    total_timesteps      | 2586624       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050206843 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.694         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.6          |\n",
      "|    n_updates            | 27270         |\n",
      "|    policy_gradient_loss | -0.00246      |\n",
      "|    reward               | 0.6120272     |\n",
      "|    std                  | 34.7          |\n",
      "|    value_loss           | 112           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1264          |\n",
      "|    time_elapsed         | 23048         |\n",
      "|    total_timesteps      | 2588672       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022926251 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.672         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 37.7          |\n",
      "|    n_updates            | 27280         |\n",
      "|    policy_gradient_loss | -0.00108      |\n",
      "|    reward               | -11.386224    |\n",
      "|    std                  | 34.7          |\n",
      "|    value_loss           | 113           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1265         |\n",
      "|    time_elapsed         | 23067        |\n",
      "|    total_timesteps      | 2590720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018352909 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.2         |\n",
      "|    n_updates            | 27290        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -3.4704945   |\n",
      "|    std                  | 34.8         |\n",
      "|    value_loss           | 41.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1266         |\n",
      "|    time_elapsed         | 23085        |\n",
      "|    total_timesteps      | 2592768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016371099 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.9         |\n",
      "|    n_updates            | 27300        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 1.5197877    |\n",
      "|    std                  | 34.9         |\n",
      "|    value_loss           | 73.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1267          |\n",
      "|    time_elapsed         | 23103         |\n",
      "|    total_timesteps      | 2594816       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039207458 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.751         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43.5          |\n",
      "|    n_updates            | 27310         |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    reward               | 5.05488       |\n",
      "|    std                  | 35            |\n",
      "|    value_loss           | 116           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1268          |\n",
      "|    time_elapsed         | 23122         |\n",
      "|    total_timesteps      | 2596864       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021426636 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.677         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.3          |\n",
      "|    n_updates            | 27320         |\n",
      "|    policy_gradient_loss | -0.00127      |\n",
      "|    reward               | 2.380705      |\n",
      "|    std                  | 35            |\n",
      "|    value_loss           | 75            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1269         |\n",
      "|    time_elapsed         | 23140        |\n",
      "|    total_timesteps      | 2598912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018240798 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.712        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.3         |\n",
      "|    n_updates            | 27330        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | -2.7849028   |\n",
      "|    std                  | 35.1         |\n",
      "|    value_loss           | 61.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1270          |\n",
      "|    time_elapsed         | 23158         |\n",
      "|    total_timesteps      | 2600960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087202707 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.769         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 55            |\n",
      "|    n_updates            | 27340         |\n",
      "|    policy_gradient_loss | -0.00363      |\n",
      "|    reward               | 1.5665833     |\n",
      "|    std                  | 35.1          |\n",
      "|    value_loss           | 126           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1271          |\n",
      "|    time_elapsed         | 23177         |\n",
      "|    total_timesteps      | 2603008       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022558952 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.704         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.5          |\n",
      "|    n_updates            | 27350         |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | 0.92374855    |\n",
      "|    std                  | 35.2          |\n",
      "|    value_loss           | 107           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1272         |\n",
      "|    time_elapsed         | 23195        |\n",
      "|    total_timesteps      | 2605056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038396965 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 27360        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 0.94311935   |\n",
      "|    std                  | 35.4         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6332851.26\n",
      "total_reward: 5332851.26\n",
      "total_cost: 181080.90\n",
      "total_trades: 59968\n",
      "Sharpe: 0.964\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1273          |\n",
      "|    time_elapsed         | 23213         |\n",
      "|    total_timesteps      | 2607104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075192924 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.733         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.5          |\n",
      "|    n_updates            | 27370         |\n",
      "|    policy_gradient_loss | -0.00256      |\n",
      "|    reward               | 0.95818645    |\n",
      "|    std                  | 35.4          |\n",
      "|    value_loss           | 85.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1274          |\n",
      "|    time_elapsed         | 23232         |\n",
      "|    total_timesteps      | 2609152       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042197012 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.778         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 40.3          |\n",
      "|    n_updates            | 27380         |\n",
      "|    policy_gradient_loss | -0.00137      |\n",
      "|    reward               | 0.5216107     |\n",
      "|    std                  | 35.5          |\n",
      "|    value_loss           | 83.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1275         |\n",
      "|    time_elapsed         | 23250        |\n",
      "|    total_timesteps      | 2611200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015187375 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 27390        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 0.11104064   |\n",
      "|    std                  | 35.6         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1276         |\n",
      "|    time_elapsed         | 23269        |\n",
      "|    total_timesteps      | 2613248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022558966 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 27400        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | 2.646461     |\n",
      "|    std                  | 35.6         |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1277         |\n",
      "|    time_elapsed         | 23287        |\n",
      "|    total_timesteps      | 2615296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007982999 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.8         |\n",
      "|    n_updates            | 27410        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | 0.6778557    |\n",
      "|    std                  | 35.7         |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1278         |\n",
      "|    time_elapsed         | 23305        |\n",
      "|    total_timesteps      | 2617344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007045709 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.4         |\n",
      "|    n_updates            | 27420        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 1.5102544    |\n",
      "|    std                  | 35.7         |\n",
      "|    value_loss           | 89.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 23323       |\n",
      "|    total_timesteps      | 2619392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004228334 |\n",
      "|    clip_fraction        | 0.00771     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -144        |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 27430       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    reward               | 1.7167776   |\n",
      "|    std                  | 35.7        |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1280         |\n",
      "|    time_elapsed         | 23342        |\n",
      "|    total_timesteps      | 2621440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005175717 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 60.6         |\n",
      "|    n_updates            | 27440        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | 0.16369012   |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 66.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1281          |\n",
      "|    time_elapsed         | 23360         |\n",
      "|    total_timesteps      | 2623488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051266386 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -144          |\n",
      "|    explained_variance   | 0.601         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.6          |\n",
      "|    n_updates            | 27450         |\n",
      "|    policy_gradient_loss | -0.00196      |\n",
      "|    reward               | 2.5975556     |\n",
      "|    std                  | 35.8          |\n",
      "|    value_loss           | 72.3          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1282         |\n",
      "|    time_elapsed         | 23378        |\n",
      "|    total_timesteps      | 2625536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021419115 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 27460        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 0.2451002    |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1283         |\n",
      "|    time_elapsed         | 23397        |\n",
      "|    total_timesteps      | 2627584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008878977 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 27470        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -2.7079358   |\n",
      "|    std                  | 35.8         |\n",
      "|    value_loss           | 44.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1284         |\n",
      "|    time_elapsed         | 23415        |\n",
      "|    total_timesteps      | 2629632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004465622 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 27480        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | -12.001939   |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 66.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1285         |\n",
      "|    time_elapsed         | 23433        |\n",
      "|    total_timesteps      | 2631680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003602576 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -144         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.6         |\n",
      "|    n_updates            | 27490        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    reward               | 2.0679936    |\n",
      "|    std                  | 35.9         |\n",
      "|    value_loss           | 75.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1286         |\n",
      "|    time_elapsed         | 23451        |\n",
      "|    total_timesteps      | 2633728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038788551 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 27500        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    reward               | 2.412626     |\n",
      "|    std                  | 36           |\n",
      "|    value_loss           | 32.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5874245.02\n",
      "total_reward: 4874245.02\n",
      "total_cost: 151636.44\n",
      "total_trades: 57907\n",
      "Sharpe: 0.955\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1287         |\n",
      "|    time_elapsed         | 23469        |\n",
      "|    total_timesteps      | 2635776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007116654 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.8         |\n",
      "|    n_updates            | 27510        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | -0.3525969   |\n",
      "|    std                  | 36.1         |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1288          |\n",
      "|    time_elapsed         | 23488         |\n",
      "|    total_timesteps      | 2637824       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060256827 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.516         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.1          |\n",
      "|    n_updates            | 27520         |\n",
      "|    policy_gradient_loss | -0.00208      |\n",
      "|    reward               | 4.0768256     |\n",
      "|    std                  | 36.1          |\n",
      "|    value_loss           | 69            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1289         |\n",
      "|    time_elapsed         | 23506        |\n",
      "|    total_timesteps      | 2639872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017491631 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 27530        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    reward               | -7.557007    |\n",
      "|    std                  | 36.2         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1290         |\n",
      "|    time_elapsed         | 23525        |\n",
      "|    total_timesteps      | 2641920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011102846 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.3         |\n",
      "|    n_updates            | 27540        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -0.047960218 |\n",
      "|    std                  | 36.2         |\n",
      "|    value_loss           | 50.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1291         |\n",
      "|    time_elapsed         | 23543        |\n",
      "|    total_timesteps      | 2643968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012524128 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    reward               | -0.11052845  |\n",
      "|    std                  | 36.3         |\n",
      "|    value_loss           | 89.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1292         |\n",
      "|    time_elapsed         | 23561        |\n",
      "|    total_timesteps      | 2646016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007115751 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 44.7         |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -0.21678819  |\n",
      "|    std                  | 36.3         |\n",
      "|    value_loss           | 60           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1293         |\n",
      "|    time_elapsed         | 23579        |\n",
      "|    total_timesteps      | 2648064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014419522 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 27570        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | -2.1039925   |\n",
      "|    std                  | 36.3         |\n",
      "|    value_loss           | 41.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1294         |\n",
      "|    time_elapsed         | 23598        |\n",
      "|    total_timesteps      | 2650112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011057721 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 27580        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    reward               | 0.22572058   |\n",
      "|    std                  | 36.4         |\n",
      "|    value_loss           | 62.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1295         |\n",
      "|    time_elapsed         | 23616        |\n",
      "|    total_timesteps      | 2652160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007007705 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.4         |\n",
      "|    n_updates            | 27590        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | -3.7849662   |\n",
      "|    std                  | 36.4         |\n",
      "|    value_loss           | 94.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1296         |\n",
      "|    time_elapsed         | 23634        |\n",
      "|    total_timesteps      | 2654208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024042134 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.61         |\n",
      "|    n_updates            | 27600        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    reward               | -2.1208181   |\n",
      "|    std                  | 36.5         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1297         |\n",
      "|    time_elapsed         | 23653        |\n",
      "|    total_timesteps      | 2656256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006931373 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 27610        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | 2.948679     |\n",
      "|    std                  | 36.5         |\n",
      "|    value_loss           | 55.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1298         |\n",
      "|    time_elapsed         | 23671        |\n",
      "|    total_timesteps      | 2658304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009607108 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.4         |\n",
      "|    n_updates            | 27620        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 1.9243531    |\n",
      "|    std                  | 36.6         |\n",
      "|    value_loss           | 59.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1299         |\n",
      "|    time_elapsed         | 23689        |\n",
      "|    total_timesteps      | 2660352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023262168 |\n",
      "|    clip_fraction        | 0.00132      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 27630        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | -1.4384116   |\n",
      "|    std                  | 36.7         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1300          |\n",
      "|    time_elapsed         | 23707         |\n",
      "|    total_timesteps      | 2662400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094644347 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.664         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.5          |\n",
      "|    n_updates            | 27640         |\n",
      "|    policy_gradient_loss | -0.0038       |\n",
      "|    reward               | -0.60219693   |\n",
      "|    std                  | 36.7          |\n",
      "|    value_loss           | 60.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1301          |\n",
      "|    time_elapsed         | 23725         |\n",
      "|    total_timesteps      | 2664448       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033361904 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.605         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.6          |\n",
      "|    n_updates            | 27650         |\n",
      "|    policy_gradient_loss | -0.00193      |\n",
      "|    reward               | -4.9282107    |\n",
      "|    std                  | 36.7          |\n",
      "|    value_loss           | 68            |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 1960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5124547.53\n",
      "total_reward: 4124547.53\n",
      "total_cost: 170654.81\n",
      "total_trades: 59476\n",
      "Sharpe: 0.905\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1302         |\n",
      "|    time_elapsed         | 23743        |\n",
      "|    total_timesteps      | 2666496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003612028 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.554        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 27660        |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    reward               | 3.61164      |\n",
      "|    std                  | 36.7         |\n",
      "|    value_loss           | 72.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1303         |\n",
      "|    time_elapsed         | 23762        |\n",
      "|    total_timesteps      | 2668544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050092377 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.4          |\n",
      "|    n_updates            | 27670        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    reward               | -2.3170729   |\n",
      "|    std                  | 36.9         |\n",
      "|    value_loss           | 21.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1304         |\n",
      "|    time_elapsed         | 23780        |\n",
      "|    total_timesteps      | 2670592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006623021 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.9         |\n",
      "|    n_updates            | 27680        |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    reward               | -1.6060904   |\n",
      "|    std                  | 36.9         |\n",
      "|    value_loss           | 61.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1305          |\n",
      "|    time_elapsed         | 23798         |\n",
      "|    total_timesteps      | 2672640       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038987768 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -145          |\n",
      "|    explained_variance   | 0.645         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 44.1          |\n",
      "|    n_updates            | 27690         |\n",
      "|    policy_gradient_loss | -0.00178      |\n",
      "|    reward               | -0.48230717   |\n",
      "|    std                  | 36.9          |\n",
      "|    value_loss           | 70.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1306         |\n",
      "|    time_elapsed         | 23816        |\n",
      "|    total_timesteps      | 2674688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032447467 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.5         |\n",
      "|    n_updates            | 27700        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    reward               | -0.49475953  |\n",
      "|    std                  | 37.1         |\n",
      "|    value_loss           | 49.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1307         |\n",
      "|    time_elapsed         | 23834        |\n",
      "|    total_timesteps      | 2676736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015328724 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 27710        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    reward               | 2.4754443    |\n",
      "|    std                  | 37.2         |\n",
      "|    value_loss           | 79.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1308         |\n",
      "|    time_elapsed         | 23852        |\n",
      "|    total_timesteps      | 2678784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016098825 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -145         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 27720        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    reward               | -3.1308968   |\n",
      "|    std                  | 37.2         |\n",
      "|    value_loss           | 72           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1309          |\n",
      "|    time_elapsed         | 23871         |\n",
      "|    total_timesteps      | 2680832       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082047726 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.575         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 24.7          |\n",
      "|    n_updates            | 27730         |\n",
      "|    policy_gradient_loss | -0.00267      |\n",
      "|    reward               | 0.92203057    |\n",
      "|    std                  | 37.2          |\n",
      "|    value_loss           | 68.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1310         |\n",
      "|    time_elapsed         | 23889        |\n",
      "|    total_timesteps      | 2682880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037881224 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 27740        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    reward               | 0.77066237   |\n",
      "|    std                  | 37.4         |\n",
      "|    value_loss           | 39.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1311          |\n",
      "|    time_elapsed         | 23908         |\n",
      "|    total_timesteps      | 2684928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053142407 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.669         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 17.4          |\n",
      "|    n_updates            | 27750         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | -0.54053205   |\n",
      "|    std                  | 37.4          |\n",
      "|    value_loss           | 62.5          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1312        |\n",
      "|    time_elapsed         | 23926       |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001132847 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 27760       |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | 5.7907157   |\n",
      "|    std                  | 37.4        |\n",
      "|    value_loss           | 70.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1313         |\n",
      "|    time_elapsed         | 23944        |\n",
      "|    total_timesteps      | 2689024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015300829 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 27770        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | 2.0371706    |\n",
      "|    std                  | 37.5         |\n",
      "|    value_loss           | 31.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1314         |\n",
      "|    time_elapsed         | 23963        |\n",
      "|    total_timesteps      | 2691072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012933089 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.5         |\n",
      "|    n_updates            | 27780        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | 1.2351639    |\n",
      "|    std                  | 37.5         |\n",
      "|    value_loss           | 74.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 23981        |\n",
      "|    total_timesteps      | 2693120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007692808 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.7         |\n",
      "|    n_updates            | 27790        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 1.3623064    |\n",
      "|    std                  | 37.5         |\n",
      "|    value_loss           | 76.1         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 1970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5846784.19\n",
      "total_reward: 4846784.19\n",
      "total_cost: 166048.58\n",
      "total_trades: 58862\n",
      "Sharpe: 0.951\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1316         |\n",
      "|    time_elapsed         | 24000        |\n",
      "|    total_timesteps      | 2695168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009158801 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.9         |\n",
      "|    n_updates            | 27800        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -5.7565875   |\n",
      "|    std                  | 37.6         |\n",
      "|    value_loss           | 58.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 24018       |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003168122 |\n",
      "|    clip_fraction        | 0.00498     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 27810       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    reward               | -0.37916836 |\n",
      "|    std                  | 37.7        |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1318         |\n",
      "|    time_elapsed         | 24036        |\n",
      "|    total_timesteps      | 2699264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010159204 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 27820        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -0.45547208  |\n",
      "|    std                  | 37.8         |\n",
      "|    value_loss           | 56.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1319          |\n",
      "|    time_elapsed         | 24055         |\n",
      "|    total_timesteps      | 2701312       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065672246 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.631         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.8          |\n",
      "|    n_updates            | 27830         |\n",
      "|    policy_gradient_loss | -0.00218      |\n",
      "|    reward               | -5.3881946    |\n",
      "|    std                  | 37.8          |\n",
      "|    value_loss           | 69.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 24073       |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002371605 |\n",
      "|    clip_fraction        | 0.00186     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 27840       |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    reward               | -0.7086936  |\n",
      "|    std                  | 37.8        |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1321          |\n",
      "|    time_elapsed         | 24091         |\n",
      "|    total_timesteps      | 2705408       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074155984 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.701         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.2          |\n",
      "|    n_updates            | 27850         |\n",
      "|    policy_gradient_loss | -0.00151      |\n",
      "|    reward               | 1.2852632     |\n",
      "|    std                  | 37.9          |\n",
      "|    value_loss           | 68.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1322         |\n",
      "|    time_elapsed         | 24110        |\n",
      "|    total_timesteps      | 2707456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005732301 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.4         |\n",
      "|    n_updates            | 27860        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | -0.37129363  |\n",
      "|    std                  | 37.9         |\n",
      "|    value_loss           | 69.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1323         |\n",
      "|    time_elapsed         | 24128        |\n",
      "|    total_timesteps      | 2709504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012680523 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 27870        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 0.2031016    |\n",
      "|    std                  | 38           |\n",
      "|    value_loss           | 45.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 24147       |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000783893 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 27880       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    reward               | -0.3564539  |\n",
      "|    std                  | 38          |\n",
      "|    value_loss           | 57.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1325         |\n",
      "|    time_elapsed         | 24165        |\n",
      "|    total_timesteps      | 2713600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018023625 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 27890        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    reward               | -3.8288596   |\n",
      "|    std                  | 38           |\n",
      "|    value_loss           | 57.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1326        |\n",
      "|    time_elapsed         | 24184       |\n",
      "|    total_timesteps      | 2715648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000454223 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.3        |\n",
      "|    n_updates            | 27900       |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    reward               | -0.51127034 |\n",
      "|    std                  | 38          |\n",
      "|    value_loss           | 68          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1327         |\n",
      "|    time_elapsed         | 24202        |\n",
      "|    total_timesteps      | 2717696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051071076 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.37         |\n",
      "|    n_updates            | 27910        |\n",
      "|    policy_gradient_loss | -0.00806     |\n",
      "|    reward               | 2.7784085    |\n",
      "|    std                  | 38.1         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1328         |\n",
      "|    time_elapsed         | 24220        |\n",
      "|    total_timesteps      | 2719744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007954417 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.9         |\n",
      "|    n_updates            | 27920        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    reward               | 0.818075     |\n",
      "|    std                  | 38.1         |\n",
      "|    value_loss           | 60.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1329          |\n",
      "|    time_elapsed         | 24239         |\n",
      "|    total_timesteps      | 2721792       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033928148 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.656         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 50.3          |\n",
      "|    n_updates            | 27930         |\n",
      "|    policy_gradient_loss | -0.00158      |\n",
      "|    reward               | 2.7027035     |\n",
      "|    std                  | 38.1          |\n",
      "|    value_loss           | 98            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6664073.78\n",
      "total_reward: 5664073.78\n",
      "total_cost: 180073.22\n",
      "total_trades: 59702\n",
      "Sharpe: 1.001\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1330         |\n",
      "|    time_elapsed         | 24257        |\n",
      "|    total_timesteps      | 2723840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011383703 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.8         |\n",
      "|    n_updates            | 27940        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | -1.6745399   |\n",
      "|    std                  | 38.2         |\n",
      "|    value_loss           | 42.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1331         |\n",
      "|    time_elapsed         | 24276        |\n",
      "|    total_timesteps      | 2725888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008531463 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 42.3         |\n",
      "|    n_updates            | 27950        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    reward               | 0.04841424   |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 76.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1332          |\n",
      "|    time_elapsed         | 24294         |\n",
      "|    total_timesteps      | 2727936       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064527686 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.756         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46            |\n",
      "|    n_updates            | 27960         |\n",
      "|    policy_gradient_loss | -0.00199      |\n",
      "|    reward               | 3.3499193     |\n",
      "|    std                  | 38.3          |\n",
      "|    value_loss           | 91.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1333         |\n",
      "|    time_elapsed         | 24313        |\n",
      "|    total_timesteps      | 2729984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007505161 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 27970        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | 1.5067271    |\n",
      "|    std                  | 38.3         |\n",
      "|    value_loss           | 62.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 24331       |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003131926 |\n",
      "|    clip_fraction        | 0.00591     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -146        |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 27980       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | -0.7415288  |\n",
      "|    std                  | 38.4        |\n",
      "|    value_loss           | 29.5        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1335          |\n",
      "|    time_elapsed         | 24350         |\n",
      "|    total_timesteps      | 2734080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055349746 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -146          |\n",
      "|    explained_variance   | 0.657         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 29.6          |\n",
      "|    n_updates            | 27990         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | -0.096636355  |\n",
      "|    std                  | 38.5          |\n",
      "|    value_loss           | 66.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1336         |\n",
      "|    time_elapsed         | 24368        |\n",
      "|    total_timesteps      | 2736128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012299377 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -146         |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.7         |\n",
      "|    n_updates            | 28000        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 3.3917167    |\n",
      "|    std                  | 38.6         |\n",
      "|    value_loss           | 67.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1337         |\n",
      "|    time_elapsed         | 24386        |\n",
      "|    total_timesteps      | 2738176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040157856 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 28010        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    reward               | -0.8822799   |\n",
      "|    std                  | 38.6         |\n",
      "|    value_loss           | 24.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1338          |\n",
      "|    time_elapsed         | 24405         |\n",
      "|    total_timesteps      | 2740224       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040497922 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.525         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.9          |\n",
      "|    n_updates            | 28020         |\n",
      "|    policy_gradient_loss | -0.00177      |\n",
      "|    reward               | -1.2432096    |\n",
      "|    std                  | 38.6          |\n",
      "|    value_loss           | 58.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1339          |\n",
      "|    time_elapsed         | 24423         |\n",
      "|    total_timesteps      | 2742272       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074988196 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.468         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34            |\n",
      "|    n_updates            | 28030         |\n",
      "|    policy_gradient_loss | -0.00258      |\n",
      "|    reward               | 0.9302248     |\n",
      "|    std                  | 38.7          |\n",
      "|    value_loss           | 64.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1340         |\n",
      "|    time_elapsed         | 24442        |\n",
      "|    total_timesteps      | 2744320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021216087 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.6         |\n",
      "|    n_updates            | 28040        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    reward               | 1.8064024    |\n",
      "|    std                  | 38.7         |\n",
      "|    value_loss           | 35.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1341         |\n",
      "|    time_elapsed         | 24460        |\n",
      "|    total_timesteps      | 2746368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025311757 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 28050        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | 3.1782618    |\n",
      "|    std                  | 38.9         |\n",
      "|    value_loss           | 38.9         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1342         |\n",
      "|    time_elapsed         | 24479        |\n",
      "|    total_timesteps      | 2748416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020929906 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.3         |\n",
      "|    n_updates            | 28060        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    reward               | 0.52662575   |\n",
      "|    std                  | 39.1         |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1343          |\n",
      "|    time_elapsed         | 24497         |\n",
      "|    total_timesteps      | 2750464       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096824544 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.506         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.8          |\n",
      "|    n_updates            | 28070         |\n",
      "|    policy_gradient_loss | -0.00216      |\n",
      "|    reward               | -2.1679173    |\n",
      "|    std                  | 39.1          |\n",
      "|    value_loss           | 58.4          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 1990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5497918.08\n",
      "total_reward: 4497918.08\n",
      "total_cost: 175451.17\n",
      "total_trades: 60179\n",
      "Sharpe: 0.915\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1344         |\n",
      "|    time_elapsed         | 24515        |\n",
      "|    total_timesteps      | 2752512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033646675 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.29         |\n",
      "|    n_updates            | 28080        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -1.042194    |\n",
      "|    std                  | 39           |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1345         |\n",
      "|    time_elapsed         | 24533        |\n",
      "|    total_timesteps      | 2754560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012484206 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 28090        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | 0.2522749    |\n",
      "|    std                  | 39           |\n",
      "|    value_loss           | 60.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1346         |\n",
      "|    time_elapsed         | 24552        |\n",
      "|    total_timesteps      | 2756608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005981182 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 28100        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | -8.780872    |\n",
      "|    std                  | 39.1         |\n",
      "|    value_loss           | 51.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1347        |\n",
      "|    time_elapsed         | 24571       |\n",
      "|    total_timesteps      | 2758656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001110073 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 28110       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | 1.0791982   |\n",
      "|    std                  | 39.1        |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1348         |\n",
      "|    time_elapsed         | 24589        |\n",
      "|    total_timesteps      | 2760704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015241152 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.2         |\n",
      "|    n_updates            | 28120        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 0.67586184   |\n",
      "|    std                  | 39.2         |\n",
      "|    value_loss           | 46.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1349         |\n",
      "|    time_elapsed         | 24607        |\n",
      "|    total_timesteps      | 2762752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012972271 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 28130        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | -2.678938    |\n",
      "|    std                  | 39.2         |\n",
      "|    value_loss           | 74.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1350         |\n",
      "|    time_elapsed         | 24626        |\n",
      "|    total_timesteps      | 2764800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009696955 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 28140        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | -1.7017367   |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 54.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1351         |\n",
      "|    time_elapsed         | 24644        |\n",
      "|    total_timesteps      | 2766848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001933971  |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.71         |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 0.0150324525 |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1352         |\n",
      "|    time_elapsed         | 24663        |\n",
      "|    total_timesteps      | 2768896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016329263 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.593        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 20.7         |\n",
      "|    n_updates            | 28160        |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    reward               | 0.24944074   |\n",
      "|    std                  | 39.3         |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1353          |\n",
      "|    time_elapsed         | 24682         |\n",
      "|    total_timesteps      | 2770944       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060640473 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.427         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.4          |\n",
      "|    n_updates            | 28170         |\n",
      "|    policy_gradient_loss | -0.00188      |\n",
      "|    reward               | 2.230121      |\n",
      "|    std                  | 39.4          |\n",
      "|    value_loss           | 75            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1354         |\n",
      "|    time_elapsed         | 24701        |\n",
      "|    total_timesteps      | 2772992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015873216 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 28180        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.49715775   |\n",
      "|    std                  | 39.4         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1355         |\n",
      "|    time_elapsed         | 24719        |\n",
      "|    total_timesteps      | 2775040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029043152 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 28190        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    reward               | -0.5682787   |\n",
      "|    std                  | 39.5         |\n",
      "|    value_loss           | 34.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1356          |\n",
      "|    time_elapsed         | 24738         |\n",
      "|    total_timesteps      | 2777088       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071601185 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -147          |\n",
      "|    explained_variance   | 0.65          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.2          |\n",
      "|    n_updates            | 28200         |\n",
      "|    policy_gradient_loss | -0.00241      |\n",
      "|    reward               | 1.731333      |\n",
      "|    std                  | 39.5          |\n",
      "|    value_loss           | 54.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1357         |\n",
      "|    time_elapsed         | 24756        |\n",
      "|    total_timesteps      | 2779136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004187505 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 28210        |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    reward               | -2.9450648   |\n",
      "|    std                  | 39.6         |\n",
      "|    value_loss           | 54.8         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5519538.35\n",
      "total_reward: 4519538.35\n",
      "total_cost: 178501.46\n",
      "total_trades: 59307\n",
      "Sharpe: 0.897\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1358         |\n",
      "|    time_elapsed         | 24775        |\n",
      "|    total_timesteps      | 2781184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021376666 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10           |\n",
      "|    n_updates            | 28220        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | -0.11219548  |\n",
      "|    std                  | 39.6         |\n",
      "|    value_loss           | 33.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1359         |\n",
      "|    time_elapsed         | 24793        |\n",
      "|    total_timesteps      | 2783232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011804873 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.1         |\n",
      "|    n_updates            | 28230        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | -0.15529934  |\n",
      "|    std                  | 39.7         |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1360         |\n",
      "|    time_elapsed         | 24811        |\n",
      "|    total_timesteps      | 2785280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011131798 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 28240        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    reward               | 0.5083467    |\n",
      "|    std                  | 39.7         |\n",
      "|    value_loss           | 89.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 24829       |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002420642 |\n",
      "|    clip_fraction        | 0.00225     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.93        |\n",
      "|    n_updates            | 28250       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    reward               | -2.5559542  |\n",
      "|    std                  | 39.7        |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1362         |\n",
      "|    time_elapsed         | 24847        |\n",
      "|    total_timesteps      | 2789376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015915806 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | 1.5939981    |\n",
      "|    std                  | 39.8         |\n",
      "|    value_loss           | 46.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1363        |\n",
      "|    time_elapsed         | 24866       |\n",
      "|    total_timesteps      | 2791424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000629795 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -147        |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 28270       |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    reward               | 0.3480878   |\n",
      "|    std                  | 39.8        |\n",
      "|    value_loss           | 60.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1364         |\n",
      "|    time_elapsed         | 24884        |\n",
      "|    total_timesteps      | 2793472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014311838 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -147         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 28280        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    reward               | -2.5728133   |\n",
      "|    std                  | 39.9         |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1365         |\n",
      "|    time_elapsed         | 24902        |\n",
      "|    total_timesteps      | 2795520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017845146 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.88         |\n",
      "|    n_updates            | 28290        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    reward               | -1.1358489   |\n",
      "|    std                  | 40           |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1366          |\n",
      "|    time_elapsed         | 24921         |\n",
      "|    total_timesteps      | 2797568       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068069005 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.676         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.5          |\n",
      "|    n_updates            | 28300         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | -0.6799935    |\n",
      "|    std                  | 40.1          |\n",
      "|    value_loss           | 66.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1367          |\n",
      "|    time_elapsed         | 24939         |\n",
      "|    total_timesteps      | 2799616       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037932687 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.667         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 26.9          |\n",
      "|    n_updates            | 28310         |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    reward               | 2.1000319     |\n",
      "|    std                  | 40.1          |\n",
      "|    value_loss           | 76            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1368        |\n",
      "|    time_elapsed         | 24958       |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002917049 |\n",
      "|    clip_fraction        | 0.00459     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.43        |\n",
      "|    n_updates            | 28320       |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    reward               | -0.47222695 |\n",
      "|    std                  | 40.1        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1369          |\n",
      "|    time_elapsed         | 24976         |\n",
      "|    total_timesteps      | 2803712       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039182152 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.481         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 38.6          |\n",
      "|    n_updates            | 28330         |\n",
      "|    policy_gradient_loss | -0.0014       |\n",
      "|    reward               | -0.5436464    |\n",
      "|    std                  | 40.2          |\n",
      "|    value_loss           | 51.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1370          |\n",
      "|    time_elapsed         | 24995         |\n",
      "|    total_timesteps      | 2805760       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0004708811  |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.64          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.7          |\n",
      "|    n_updates            | 28340         |\n",
      "|    policy_gradient_loss | -0.00241      |\n",
      "|    reward               | -0.0073296404 |\n",
      "|    std                  | 40.2          |\n",
      "|    value_loss           | 70.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1371         |\n",
      "|    time_elapsed         | 25014        |\n",
      "|    total_timesteps      | 2807808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007145086 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 28350        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | -1.525186    |\n",
      "|    std                  | 40.3         |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2892, episode: 2010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6181873.49\n",
      "total_reward: 5181873.49\n",
      "total_cost: 155723.32\n",
      "total_trades: 58454\n",
      "Sharpe: 0.977\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1372         |\n",
      "|    time_elapsed         | 25032        |\n",
      "|    total_timesteps      | 2809856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010814623 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 28360        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -1.4284639   |\n",
      "|    std                  | 40.3         |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1373         |\n",
      "|    time_elapsed         | 25051        |\n",
      "|    total_timesteps      | 2811904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005042517 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.723        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 28370        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 2.9357593    |\n",
      "|    std                  | 40.4         |\n",
      "|    value_loss           | 75.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 25069       |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001026239 |\n",
      "|    clip_fraction        | 4.88e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | -0.134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 28380       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | -2.7431984  |\n",
      "|    std                  | 40.4        |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1375         |\n",
      "|    time_elapsed         | 25088        |\n",
      "|    total_timesteps      | 2816000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030228575 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 28390        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    reward               | -3.4208891   |\n",
      "|    std                  | 40.5         |\n",
      "|    value_loss           | 33.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1376         |\n",
      "|    time_elapsed         | 25106        |\n",
      "|    total_timesteps      | 2818048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017616546 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 28400        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | 0.35702327   |\n",
      "|    std                  | 40.6         |\n",
      "|    value_loss           | 62.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1377          |\n",
      "|    time_elapsed         | 25125         |\n",
      "|    total_timesteps      | 2820096       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052585534 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.665         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 53.8          |\n",
      "|    n_updates            | 28410         |\n",
      "|    policy_gradient_loss | -0.00284      |\n",
      "|    reward               | -2.538441     |\n",
      "|    std                  | 40.6          |\n",
      "|    value_loss           | 77            |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 112         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 25143       |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000987398 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.83        |\n",
      "|    n_updates            | 28420       |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    reward               | -2.1091666  |\n",
      "|    std                  | 40.6        |\n",
      "|    value_loss           | 32.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1379          |\n",
      "|    time_elapsed         | 25162         |\n",
      "|    total_timesteps      | 2824192       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00059664034 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.638         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 20.8          |\n",
      "|    n_updates            | 28430         |\n",
      "|    policy_gradient_loss | -0.0023       |\n",
      "|    reward               | -1.7356787    |\n",
      "|    std                  | 40.7          |\n",
      "|    value_loss           | 57.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1380         |\n",
      "|    time_elapsed         | 25180        |\n",
      "|    total_timesteps      | 2826240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008685244 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 28440        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | 17.752634    |\n",
      "|    std                  | 40.7         |\n",
      "|    value_loss           | 75.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1381          |\n",
      "|    time_elapsed         | 25198         |\n",
      "|    total_timesteps      | 2828288       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075616484 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.516         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 19.4          |\n",
      "|    n_updates            | 28450         |\n",
      "|    policy_gradient_loss | -0.00275      |\n",
      "|    reward               | -4.142916     |\n",
      "|    std                  | 40.8          |\n",
      "|    value_loss           | 41.7          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1382         |\n",
      "|    time_elapsed         | 25217        |\n",
      "|    total_timesteps      | 2830336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042030895 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.88         |\n",
      "|    n_updates            | 28460        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | -0.6589547   |\n",
      "|    std                  | 40.9         |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 112          |\n",
      "|    iterations           | 1383         |\n",
      "|    time_elapsed         | 25235        |\n",
      "|    total_timesteps      | 2832384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010327704 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 49.1         |\n",
      "|    n_updates            | 28470        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | 0.7725231    |\n",
      "|    std                  | 40.9         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 112           |\n",
      "|    iterations           | 1384          |\n",
      "|    time_elapsed         | 25253         |\n",
      "|    total_timesteps      | 2834432       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053778675 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.485         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 28.3          |\n",
      "|    n_updates            | 28480         |\n",
      "|    policy_gradient_loss | -0.00148      |\n",
      "|    reward               | 1.0180724     |\n",
      "|    std                  | 41            |\n",
      "|    value_loss           | 60.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 25326       |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002854222 |\n",
      "|    clip_fraction        | 0.00278     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.17        |\n",
      "|    n_updates            | 28490       |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | -0.25791264 |\n",
      "|    std                  | 41          |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5185475.74\n",
      "total_reward: 4185475.74\n",
      "total_cost: 150160.57\n",
      "total_trades: 57353\n",
      "Sharpe: 0.891\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1386         |\n",
      "|    time_elapsed         | 25345        |\n",
      "|    total_timesteps      | 2838528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012814868 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.8         |\n",
      "|    n_updates            | 28500        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | 0.043626685  |\n",
      "|    std                  | 41.1         |\n",
      "|    value_loss           | 56.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1387          |\n",
      "|    time_elapsed         | 25363         |\n",
      "|    total_timesteps      | 2840576       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036777958 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -148          |\n",
      "|    explained_variance   | 0.653         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 18.9          |\n",
      "|    n_updates            | 28510         |\n",
      "|    policy_gradient_loss | -0.00155      |\n",
      "|    reward               | -0.7860537    |\n",
      "|    std                  | 41.1          |\n",
      "|    value_loss           | 52.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1388         |\n",
      "|    time_elapsed         | 25381        |\n",
      "|    total_timesteps      | 2842624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010501489 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38.7         |\n",
      "|    n_updates            | 28520        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | 0.7388392    |\n",
      "|    std                  | 41.2         |\n",
      "|    value_loss           | 71.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1389         |\n",
      "|    time_elapsed         | 25399        |\n",
      "|    total_timesteps      | 2844672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023209518 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55           |\n",
      "|    n_updates            | 28530        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | 1.8526074    |\n",
      "|    std                  | 41.3         |\n",
      "|    value_loss           | 71           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1390        |\n",
      "|    time_elapsed         | 25417       |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000787286 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -148        |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 28540       |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    reward               | -0.344411   |\n",
      "|    std                  | 41.3        |\n",
      "|    value_loss           | 52.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1391         |\n",
      "|    time_elapsed         | 25436        |\n",
      "|    total_timesteps      | 2848768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006196285 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 28550        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | -1.0396818   |\n",
      "|    std                  | 41.3         |\n",
      "|    value_loss           | 67.8         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1392         |\n",
      "|    time_elapsed         | 25454        |\n",
      "|    total_timesteps      | 2850816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027943763 |\n",
      "|    clip_fraction        | 0.00444      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -148         |\n",
      "|    explained_variance   | 0.595        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.14         |\n",
      "|    n_updates            | 28560        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 3.1917527    |\n",
      "|    std                  | 41.4         |\n",
      "|    value_loss           | 15.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1393        |\n",
      "|    time_elapsed         | 25473       |\n",
      "|    total_timesteps      | 2852864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002273278 |\n",
      "|    clip_fraction        | 0.00249     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 28570       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    reward               | 0.2888574   |\n",
      "|    std                  | 41.5        |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1394         |\n",
      "|    time_elapsed         | 25491        |\n",
      "|    total_timesteps      | 2854912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007442038 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.2         |\n",
      "|    n_updates            | 28580        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    reward               | 0.19644873   |\n",
      "|    std                  | 41.5         |\n",
      "|    value_loss           | 60.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1395         |\n",
      "|    time_elapsed         | 25509        |\n",
      "|    total_timesteps      | 2856960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023790565 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.7         |\n",
      "|    n_updates            | 28590        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | 2.8769956    |\n",
      "|    std                  | 41.5         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1396         |\n",
      "|    time_elapsed         | 25528        |\n",
      "|    total_timesteps      | 2859008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016768803 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.3         |\n",
      "|    n_updates            | 28600        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | -0.9738405   |\n",
      "|    std                  | 41.6         |\n",
      "|    value_loss           | 75.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1397         |\n",
      "|    time_elapsed         | 25546        |\n",
      "|    total_timesteps      | 2861056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007058993 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22           |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    reward               | 1.6275737    |\n",
      "|    std                  | 41.6         |\n",
      "|    value_loss           | 60.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1398          |\n",
      "|    time_elapsed         | 25564         |\n",
      "|    total_timesteps      | 2863104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029335593 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.612         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 21.5          |\n",
      "|    n_updates            | 28620         |\n",
      "|    policy_gradient_loss | -0.00121      |\n",
      "|    reward               | 1.466346      |\n",
      "|    std                  | 41.6          |\n",
      "|    value_loss           | 44.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 25582       |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002184329 |\n",
      "|    clip_fraction        | 0.00181     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 28630       |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | 0.32627332  |\n",
      "|    std                  | 41.7        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "day: 2892, episode: 2030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5965326.80\n",
      "total_reward: 4965326.80\n",
      "total_cost: 157170.01\n",
      "total_trades: 57928\n",
      "Sharpe: 0.947\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1400          |\n",
      "|    time_elapsed         | 25601         |\n",
      "|    total_timesteps      | 2867200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037028248 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.629         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.9          |\n",
      "|    n_updates            | 28640         |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    reward               | 0.94428366    |\n",
      "|    std                  | 41.8          |\n",
      "|    value_loss           | 60.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1401          |\n",
      "|    time_elapsed         | 25619         |\n",
      "|    total_timesteps      | 2869248       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018433426 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.611         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 49.2          |\n",
      "|    n_updates            | 28650         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    reward               | -3.677512     |\n",
      "|    std                  | 41.8          |\n",
      "|    value_loss           | 73.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1402         |\n",
      "|    time_elapsed         | 25638        |\n",
      "|    total_timesteps      | 2871296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027889968 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.583        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.63         |\n",
      "|    n_updates            | 28660        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | -1.4645724   |\n",
      "|    std                  | 41.9         |\n",
      "|    value_loss           | 30.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1403          |\n",
      "|    time_elapsed         | 25656         |\n",
      "|    total_timesteps      | 2873344       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046112953 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.636         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 57.5          |\n",
      "|    n_updates            | 28670         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | -0.84964025   |\n",
      "|    std                  | 41.9          |\n",
      "|    value_loss           | 73.2          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1404          |\n",
      "|    time_elapsed         | 25675         |\n",
      "|    total_timesteps      | 2875392       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095174654 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.63          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 36.2          |\n",
      "|    n_updates            | 28680         |\n",
      "|    policy_gradient_loss | -0.00332      |\n",
      "|    reward               | -1.8095291    |\n",
      "|    std                  | 42            |\n",
      "|    value_loss           | 63.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1405         |\n",
      "|    time_elapsed         | 25693        |\n",
      "|    total_timesteps      | 2877440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007775137 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.54         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.2         |\n",
      "|    n_updates            | 28690        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    reward               | 2.7847474    |\n",
      "|    std                  | 42           |\n",
      "|    value_loss           | 62.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1406        |\n",
      "|    time_elapsed         | 25712       |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002176781 |\n",
      "|    clip_fraction        | 0.00239     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -149        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.66        |\n",
      "|    n_updates            | 28700       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    reward               | 1.881246    |\n",
      "|    std                  | 42.1        |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1407          |\n",
      "|    time_elapsed         | 25730         |\n",
      "|    total_timesteps      | 2881536       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089579914 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.276         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 15.3          |\n",
      "|    n_updates            | 28710         |\n",
      "|    policy_gradient_loss | -0.00248      |\n",
      "|    reward               | 0.15420663    |\n",
      "|    std                  | 42.2          |\n",
      "|    value_loss           | 60.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1408          |\n",
      "|    time_elapsed         | 25748         |\n",
      "|    total_timesteps      | 2883584       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061723765 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.393         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 31.7          |\n",
      "|    n_updates            | 28720         |\n",
      "|    policy_gradient_loss | -0.00217      |\n",
      "|    reward               | 3.629932      |\n",
      "|    std                  | 42.3          |\n",
      "|    value_loss           | 72.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1409         |\n",
      "|    time_elapsed         | 25767        |\n",
      "|    total_timesteps      | 2885632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037071914 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.27         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 28730        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    reward               | 1.7335299    |\n",
      "|    std                  | 42.5         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1410         |\n",
      "|    time_elapsed         | 25785        |\n",
      "|    total_timesteps      | 2887680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010394433 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 64.3         |\n",
      "|    n_updates            | 28740        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -0.6037456   |\n",
      "|    std                  | 42.6         |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1411          |\n",
      "|    time_elapsed         | 25804         |\n",
      "|    total_timesteps      | 2889728       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00078592065 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -149          |\n",
      "|    explained_variance   | 0.593         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32.5          |\n",
      "|    n_updates            | 28750         |\n",
      "|    policy_gradient_loss | -0.0022       |\n",
      "|    reward               | 0.9700249     |\n",
      "|    std                  | 42.7          |\n",
      "|    value_loss           | 81            |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1412         |\n",
      "|    time_elapsed         | 25822        |\n",
      "|    total_timesteps      | 2891776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008815101 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 28760        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    reward               | -3.3568568   |\n",
      "|    std                  | 42.7         |\n",
      "|    value_loss           | 46.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1413         |\n",
      "|    time_elapsed         | 25841        |\n",
      "|    total_timesteps      | 2893824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016020283 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 28770        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    reward               | 1.0201496    |\n",
      "|    std                  | 42.8         |\n",
      "|    value_loss           | 56.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1414         |\n",
      "|    time_elapsed         | 25859        |\n",
      "|    total_timesteps      | 2895872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004791372 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -149         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 28780        |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    reward               | 10.47039     |\n",
      "|    std                  | 42.8         |\n",
      "|    value_loss           | 72.5         |\n",
      "------------------------------------------\n",
      "day: 2892, episode: 2040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6864994.44\n",
      "total_reward: 5864994.44\n",
      "total_cost: 164304.70\n",
      "total_trades: 58045\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1415          |\n",
      "|    time_elapsed         | 25877         |\n",
      "|    total_timesteps      | 2897920       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015253277 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.509         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 63.2          |\n",
      "|    n_updates            | 28790         |\n",
      "|    policy_gradient_loss | -0.00092      |\n",
      "|    reward               | 4.4015        |\n",
      "|    std                  | 42.9          |\n",
      "|    value_loss           | 123           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1416         |\n",
      "|    time_elapsed         | 25896        |\n",
      "|    total_timesteps      | 2899968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022912761 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.79         |\n",
      "|    n_updates            | 28800        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | -0.19259703  |\n",
      "|    std                  | 42.9         |\n",
      "|    value_loss           | 29.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1417         |\n",
      "|    time_elapsed         | 25914        |\n",
      "|    total_timesteps      | 2902016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007229642 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 72.7         |\n",
      "|    n_updates            | 28810        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | -4.3214054   |\n",
      "|    std                  | 43           |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1418         |\n",
      "|    time_elapsed         | 25932        |\n",
      "|    total_timesteps      | 2904064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010275498 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.7         |\n",
      "|    n_updates            | 28820        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | 1.8357605    |\n",
      "|    std                  | 43.1         |\n",
      "|    value_loss           | 79.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1419         |\n",
      "|    time_elapsed         | 25951        |\n",
      "|    total_timesteps      | 2906112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018243999 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 28830        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 0.32959265   |\n",
      "|    std                  | 43.2         |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1420          |\n",
      "|    time_elapsed         | 25969         |\n",
      "|    total_timesteps      | 2908160       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050475163 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.652         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.4          |\n",
      "|    n_updates            | 28840         |\n",
      "|    policy_gradient_loss | -0.0014       |\n",
      "|    reward               | 0.9137959     |\n",
      "|    std                  | 43.2          |\n",
      "|    value_loss           | 57.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1421         |\n",
      "|    time_elapsed         | 25988        |\n",
      "|    total_timesteps      | 2910208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022393125 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.647        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 28850        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | -0.5219481   |\n",
      "|    std                  | 43.4         |\n",
      "|    value_loss           | 69           |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1422          |\n",
      "|    time_elapsed         | 26006         |\n",
      "|    total_timesteps      | 2912256       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073216896 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.636         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 35.7          |\n",
      "|    n_updates            | 28860         |\n",
      "|    policy_gradient_loss | -0.003        |\n",
      "|    reward               | 0.7854604     |\n",
      "|    std                  | 43.4          |\n",
      "|    value_loss           | 73.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1423         |\n",
      "|    time_elapsed         | 26025        |\n",
      "|    total_timesteps      | 2914304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034395375 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.7         |\n",
      "|    n_updates            | 28870        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    reward               | 0.052311406  |\n",
      "|    std                  | 43.6         |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1424         |\n",
      "|    time_elapsed         | 26043        |\n",
      "|    total_timesteps      | 2916352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008997305 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 28880        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 2.0738568    |\n",
      "|    std                  | 43.6         |\n",
      "|    value_loss           | 78.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1425          |\n",
      "|    time_elapsed         | 26062         |\n",
      "|    total_timesteps      | 2918400       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010558078 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.494         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 73.1          |\n",
      "|    n_updates            | 28890         |\n",
      "|    policy_gradient_loss | -0.000761     |\n",
      "|    reward               | 4.886037      |\n",
      "|    std                  | 43.6          |\n",
      "|    value_loss           | 147           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1426         |\n",
      "|    time_elapsed         | 26080        |\n",
      "|    total_timesteps      | 2920448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016500868 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 28900        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -0.10641167  |\n",
      "|    std                  | 43.7         |\n",
      "|    value_loss           | 32.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1427          |\n",
      "|    time_elapsed         | 26099         |\n",
      "|    total_timesteps      | 2922496       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068371254 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.649         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 27.5          |\n",
      "|    n_updates            | 28910         |\n",
      "|    policy_gradient_loss | -0.00288      |\n",
      "|    reward               | 1.1600156     |\n",
      "|    std                  | 43.8          |\n",
      "|    value_loss           | 67.9          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1428          |\n",
      "|    time_elapsed         | 26118         |\n",
      "|    total_timesteps      | 2924544       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054392335 |\n",
      "|    clip_fraction        | 0.000684      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.692         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 44.7          |\n",
      "|    n_updates            | 28920         |\n",
      "|    policy_gradient_loss | -0.00236      |\n",
      "|    reward               | 3.9873133     |\n",
      "|    std                  | 43.8          |\n",
      "|    value_loss           | 84.6          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6838851.32\n",
      "total_reward: 5838851.32\n",
      "total_cost: 157374.73\n",
      "total_trades: 57894\n",
      "Sharpe: 0.984\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1429          |\n",
      "|    time_elapsed         | 26136         |\n",
      "|    total_timesteps      | 2926592       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034110344 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.629         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32.1          |\n",
      "|    n_updates            | 28930         |\n",
      "|    policy_gradient_loss | -0.00195      |\n",
      "|    reward               | -11.1175165   |\n",
      "|    std                  | 43.8          |\n",
      "|    value_loss           | 55.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1430         |\n",
      "|    time_elapsed         | 26155        |\n",
      "|    total_timesteps      | 2928640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025183628 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 28940        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | 0.6077084    |\n",
      "|    std                  | 43.7         |\n",
      "|    value_loss           | 55.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1431         |\n",
      "|    time_elapsed         | 26173        |\n",
      "|    total_timesteps      | 2930688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016125261 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 28950        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | -0.04662041  |\n",
      "|    std                  | 43.8         |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1432         |\n",
      "|    time_elapsed         | 26192        |\n",
      "|    total_timesteps      | 2932736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005772329 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.8         |\n",
      "|    n_updates            | 28960        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -2.399197    |\n",
      "|    std                  | 43.9         |\n",
      "|    value_loss           | 97.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1433         |\n",
      "|    time_elapsed         | 26210        |\n",
      "|    total_timesteps      | 2934784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042034327 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    reward               | 1.772374     |\n",
      "|    std                  | 44.1         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1434         |\n",
      "|    time_elapsed         | 26229        |\n",
      "|    total_timesteps      | 2936832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010881156 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 28980        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 0.9515841    |\n",
      "|    std                  | 44.1         |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1435         |\n",
      "|    time_elapsed         | 26247        |\n",
      "|    total_timesteps      | 2938880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004075933 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 45.7         |\n",
      "|    n_updates            | 28990        |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | -3.2701025   |\n",
      "|    std                  | 44.1         |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1436         |\n",
      "|    time_elapsed         | 26266        |\n",
      "|    total_timesteps      | 2940928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003826523 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 35.5         |\n",
      "|    n_updates            | 29000        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    reward               | 3.621628     |\n",
      "|    std                  | 44.2         |\n",
      "|    value_loss           | 54.5         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1437          |\n",
      "|    time_elapsed         | 26284         |\n",
      "|    total_timesteps      | 2942976       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094767415 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.654         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 25.2          |\n",
      "|    n_updates            | 29010         |\n",
      "|    policy_gradient_loss | -0.00341      |\n",
      "|    reward               | 0.75329113    |\n",
      "|    std                  | 44.2          |\n",
      "|    value_loss           | 59.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1438          |\n",
      "|    time_elapsed         | 26303         |\n",
      "|    total_timesteps      | 2945024       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047057515 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.662         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 59.2          |\n",
      "|    n_updates            | 29020         |\n",
      "|    policy_gradient_loss | -0.0018       |\n",
      "|    reward               | -6.5241914    |\n",
      "|    std                  | 44.2          |\n",
      "|    value_loss           | 85.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 26321       |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000579525 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -150        |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 29030       |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    reward               | -0.47600952 |\n",
      "|    std                  | 44.3        |\n",
      "|    value_loss           | 68.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1440         |\n",
      "|    time_elapsed         | 26340        |\n",
      "|    total_timesteps      | 2949120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019222327 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.38         |\n",
      "|    n_updates            | 29040        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    reward               | 3.188902     |\n",
      "|    std                  | 44.3         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1441          |\n",
      "|    time_elapsed         | 26358         |\n",
      "|    total_timesteps      | 2951168       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043384946 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.661         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 34.8          |\n",
      "|    n_updates            | 29050         |\n",
      "|    policy_gradient_loss | -0.00191      |\n",
      "|    reward               | 0.75635386    |\n",
      "|    std                  | 44.3          |\n",
      "|    value_loss           | 74.2          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1442          |\n",
      "|    time_elapsed         | 26377         |\n",
      "|    total_timesteps      | 2953216       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00059187703 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -150          |\n",
      "|    explained_variance   | 0.594         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 32.5          |\n",
      "|    n_updates            | 29060         |\n",
      "|    policy_gradient_loss | -0.00198      |\n",
      "|    reward               | 3.3604274     |\n",
      "|    std                  | 44.3          |\n",
      "|    value_loss           | 64.9          |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6478473.89\n",
      "total_reward: 5478473.89\n",
      "total_cost: 149028.78\n",
      "total_trades: 56525\n",
      "Sharpe: 0.973\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1443         |\n",
      "|    time_elapsed         | 26395        |\n",
      "|    total_timesteps      | 2955264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014143783 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -150         |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 29070        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    reward               | -4.196563    |\n",
      "|    std                  | 44.4         |\n",
      "|    value_loss           | 43.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1444         |\n",
      "|    time_elapsed         | 26413        |\n",
      "|    total_timesteps      | 2957312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005823539 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.8         |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 3.0866122    |\n",
      "|    std                  | 44.4         |\n",
      "|    value_loss           | 63.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1445         |\n",
      "|    time_elapsed         | 26432        |\n",
      "|    total_timesteps      | 2959360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005749741 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | 2.829602     |\n",
      "|    std                  | 44.5         |\n",
      "|    value_loss           | 82.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1446         |\n",
      "|    time_elapsed         | 26450        |\n",
      "|    total_timesteps      | 2961408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006150962 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 38           |\n",
      "|    n_updates            | 29100        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 1.2571299    |\n",
      "|    std                  | 44.5         |\n",
      "|    value_loss           | 78.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1447         |\n",
      "|    time_elapsed         | 26468        |\n",
      "|    total_timesteps      | 2963456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028884055 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.4         |\n",
      "|    n_updates            | 29110        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 0.3591504    |\n",
      "|    std                  | 44.6         |\n",
      "|    value_loss           | 46.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1448          |\n",
      "|    time_elapsed         | 26487         |\n",
      "|    total_timesteps      | 2965504       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041519888 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.693         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 43            |\n",
      "|    n_updates            | 29120         |\n",
      "|    policy_gradient_loss | -0.00161      |\n",
      "|    reward               | 0.491411      |\n",
      "|    std                  | 44.6          |\n",
      "|    value_loss           | 97.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1449         |\n",
      "|    time_elapsed         | 26505        |\n",
      "|    total_timesteps      | 2967552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006311425 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 29130        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | -3.1582208   |\n",
      "|    std                  | 44.7         |\n",
      "|    value_loss           | 81.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1450         |\n",
      "|    time_elapsed         | 26523        |\n",
      "|    total_timesteps      | 2969600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015758976 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.2         |\n",
      "|    n_updates            | 29140        |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | 1.4729781    |\n",
      "|    std                  | 44.7         |\n",
      "|    value_loss           | 26.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1451         |\n",
      "|    time_elapsed         | 26542        |\n",
      "|    total_timesteps      | 2971648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021553668 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 34.9         |\n",
      "|    n_updates            | 29150        |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    reward               | 1.7199212    |\n",
      "|    std                  | 44.8         |\n",
      "|    value_loss           | 58.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1452         |\n",
      "|    time_elapsed         | 26561        |\n",
      "|    total_timesteps      | 2973696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010023052 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.1         |\n",
      "|    n_updates            | 29160        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 5.3582215    |\n",
      "|    std                  | 44.9         |\n",
      "|    value_loss           | 60.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1453         |\n",
      "|    time_elapsed         | 26580        |\n",
      "|    total_timesteps      | 2975744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010832879 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 22.8         |\n",
      "|    n_updates            | 29170        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | 1.578927     |\n",
      "|    std                  | 45           |\n",
      "|    value_loss           | 45.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1454         |\n",
      "|    time_elapsed         | 26598        |\n",
      "|    total_timesteps      | 2977792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012564013 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.1         |\n",
      "|    n_updates            | 29180        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -0.14740796  |\n",
      "|    std                  | 45.1         |\n",
      "|    value_loss           | 50           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1455         |\n",
      "|    time_elapsed         | 26617        |\n",
      "|    total_timesteps      | 2979840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003019673 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.5         |\n",
      "|    n_updates            | 29190        |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    reward               | 1.9374313    |\n",
      "|    std                  | 45.2         |\n",
      "|    value_loss           | 75.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1456          |\n",
      "|    time_elapsed         | 26635         |\n",
      "|    total_timesteps      | 2981888       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081552216 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.54          |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 30            |\n",
      "|    n_updates            | 29200         |\n",
      "|    policy_gradient_loss | -0.0029       |\n",
      "|    reward               | 1.3666172     |\n",
      "|    std                  | 45.2          |\n",
      "|    value_loss           | 59            |\n",
      "-------------------------------------------\n",
      "day: 2892, episode: 2070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7043803.91\n",
      "total_reward: 6043803.91\n",
      "total_cost: 148852.64\n",
      "total_trades: 57595\n",
      "Sharpe: 1.005\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1457         |\n",
      "|    time_elapsed         | 26653        |\n",
      "|    total_timesteps      | 2983936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054079285 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 29210        |\n",
      "|    policy_gradient_loss | -0.00749     |\n",
      "|    reward               | 0.360088     |\n",
      "|    std                  | 45.4         |\n",
      "|    value_loss           | 31.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1458         |\n",
      "|    time_elapsed         | 26672        |\n",
      "|    total_timesteps      | 2985984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019102589 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.307        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.8         |\n",
      "|    n_updates            | 29220        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 1.8649116    |\n",
      "|    std                  | 45.5         |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 111           |\n",
      "|    iterations           | 1459          |\n",
      "|    time_elapsed         | 26690         |\n",
      "|    total_timesteps      | 2988032       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044762105 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -151          |\n",
      "|    explained_variance   | 0.442         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 23.6          |\n",
      "|    n_updates            | 29230         |\n",
      "|    policy_gradient_loss | -0.00208      |\n",
      "|    reward               | 0.4282479     |\n",
      "|    std                  | 45.5          |\n",
      "|    value_loss           | 73.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1460         |\n",
      "|    time_elapsed         | 26709        |\n",
      "|    total_timesteps      | 2990080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005183081 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.203        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 29240        |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    reward               | -2.350746    |\n",
      "|    std                  | 45.6         |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1461         |\n",
      "|    time_elapsed         | 26727        |\n",
      "|    total_timesteps      | 2992128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021470205 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 29250        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 1.9203005    |\n",
      "|    std                  | 45.7         |\n",
      "|    value_loss           | 42.4         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1462         |\n",
      "|    time_elapsed         | 26745        |\n",
      "|    total_timesteps      | 2994176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023576529 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 71.2         |\n",
      "|    n_updates            | 29260        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 11.938088    |\n",
      "|    std                  | 45.8         |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1463         |\n",
      "|    time_elapsed         | 26764        |\n",
      "|    total_timesteps      | 2996224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009965939 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -151         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 51.8         |\n",
      "|    n_updates            | 29270        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    reward               | 0.39619717   |\n",
      "|    std                  | 45.9         |\n",
      "|    value_loss           | 82.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 111          |\n",
      "|    iterations           | 1464         |\n",
      "|    time_elapsed         | 26782        |\n",
      "|    total_timesteps      | 2998272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026244093 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -152         |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.9         |\n",
      "|    n_updates            | 29280        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    reward               | 0.5749521    |\n",
      "|    std                  | 46.1         |\n",
      "|    value_loss           | 42           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 1465        |\n",
      "|    time_elapsed         | 26800       |\n",
      "|    total_timesteps      | 3000320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002411804 |\n",
      "|    clip_fraction        | 0.00142     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -152        |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 29290       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 1.5991069   |\n",
      "|    std                  | 46.2        |\n",
      "|    value_loss           | 93.9        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo2.load('41')\n",
    "print('load')\n",
    "trained_ppo2 = agent_con.train_model(model=model_ppo2, \n",
    "                             tb_log_name=\"4\",\n",
    "                             total_timesteps=3000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwOhVjqRkCdM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "K8RSdKCckJyH"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23766/4244563930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_sac = agent.train_model(model=model_sac, \n\u001b[1;32m      2\u001b[0m                              \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                              total_timesteps=60000)\n\u001b[0m",
      "\u001b[0;32m/data3/zj/FinRL/finrl/agents/stablebaselines3/models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, tb_log_name, total_timesteps)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorboardCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         )\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m# Special case when the user passes `gradient_steps=0`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgradient_steps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Select action according to policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0mnext_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# Compute the next Q values: min over all critics targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnext_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/sac/policies.py\u001b[0m in \u001b[0;36maction_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_dist_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# return action and associated log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mlog_prob_from_params\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mactions_from_params\u001b[0;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactions_from_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Update the proba distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_actions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SquashedDiagGaussianDistribution\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSquashedDiagGaussianDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/finrl/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2020-07-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])\n",
    "\n",
    "trained_ppo2.save('42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "VHZMBpSqh1jG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       18.824245\n",
       "std         8.489311\n",
       "min         9.140000\n",
       "25%        13.330000\n",
       "50%        16.139999\n",
       "75%        21.309999\n",
       "max        82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "BDkszkMloRWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.40400183105453"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "AL7hs7svnNWT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2893.000000\n",
       "mean       34.574233\n",
       "std        43.787150\n",
       "min         0.000000\n",
       "25%        14.966105\n",
       "50%        24.124290\n",
       "75%        39.162080\n",
       "max       652.505555\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "N78hfHckoqJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.45132359815483"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "cIqoV0GSI52v"
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "W_XNgGsBMeVw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121800</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>91.839996</td>\n",
       "      <td>90.977501</td>\n",
       "      <td>89.904610</td>\n",
       "      <td>110737200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.014605</td>\n",
       "      <td>92.699324</td>\n",
       "      <td>80.179949</td>\n",
       "      <td>62.807159</td>\n",
       "      <td>107.491902</td>\n",
       "      <td>29.730532</td>\n",
       "      <td>83.933769</td>\n",
       "      <td>77.717544</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121801</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>256.230011</td>\n",
       "      <td>232.580002</td>\n",
       "      <td>240.153946</td>\n",
       "      <td>6575800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.636393</td>\n",
       "      <td>232.397416</td>\n",
       "      <td>200.212956</td>\n",
       "      <td>61.279633</td>\n",
       "      <td>271.386127</td>\n",
       "      <td>46.806139</td>\n",
       "      <td>214.858665</td>\n",
       "      <td>215.931664</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121802</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>AXP</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>96.959999</td>\n",
       "      <td>93.639999</td>\n",
       "      <td>92.086380</td>\n",
       "      <td>3301000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>110.423947</td>\n",
       "      <td>87.759330</td>\n",
       "      <td>48.504818</td>\n",
       "      <td>-66.328694</td>\n",
       "      <td>3.142448</td>\n",
       "      <td>97.244637</td>\n",
       "      <td>90.695524</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121803</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>BA</td>\n",
       "      <td>185.880005</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>180.039993</td>\n",
       "      <td>180.320007</td>\n",
       "      <td>49036700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.443193</td>\n",
       "      <td>220.721139</td>\n",
       "      <td>160.932863</td>\n",
       "      <td>50.925771</td>\n",
       "      <td>24.220608</td>\n",
       "      <td>15.932920</td>\n",
       "      <td>176.472335</td>\n",
       "      <td>155.614168</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121804</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>CAT</td>\n",
       "      <td>129.380005</td>\n",
       "      <td>129.399994</td>\n",
       "      <td>125.879997</td>\n",
       "      <td>120.651634</td>\n",
       "      <td>2807800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.272629</td>\n",
       "      <td>130.624281</td>\n",
       "      <td>113.353126</td>\n",
       "      <td>52.865420</td>\n",
       "      <td>35.597291</td>\n",
       "      <td>14.457404</td>\n",
       "      <td>119.412836</td>\n",
       "      <td>113.646674</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>53.068037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date   tic        open        high         low  \\\n",
       "0      121800  2020-07-01  AAPL   91.279999   91.839996   90.977501   \n",
       "0      121801  2020-07-01  AMGN  235.520004  256.230011  232.580002   \n",
       "0      121802  2020-07-01   AXP   95.250000   96.959999   93.639999   \n",
       "0      121803  2020-07-01    BA  185.880005  190.610001  180.039993   \n",
       "0      121804  2020-07-01   CAT  129.380005  129.399994  125.879997   \n",
       "\n",
       "        close       volume  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
       "0   89.904610  110737200.0  2.0  3.014605   92.699324   80.179949  62.807159   \n",
       "0  240.153946    6575800.0  2.0  3.636393  232.397416  200.212956  61.279633   \n",
       "0   92.086380    3301000.0  2.0 -0.389162  110.423947   87.759330  48.504818   \n",
       "0  180.320007   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   \n",
       "0  120.651634    2807800.0  2.0  1.272629  130.624281  113.353126  52.865420   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0  107.491902  29.730532     83.933769     77.717544  28.620001   53.068037  \n",
       "0  271.386127  46.806139    214.858665    215.931664  28.620001   53.068037  \n",
       "0  -66.328694   3.142448     97.244637     90.695524  28.620001   53.068037  \n",
       "0   24.220608  15.932920    176.472335    155.614168  28.620001   53.068037  \n",
       "0   35.597291  14.457404    119.412836    113.646674  28.620001   53.068037  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_ppo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53156/536458364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     environment = e_trade_gym)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df_account_value, df_actions = DRLAgent.DRL_prediction(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_ppo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     environment = e_trade_gym)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_ppo' is not defined"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERxw3KqLkcP4"
   },
   "outputs": [],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yRkNguY5yvp"
   },
   "outputs": [],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFlK5hNbWVFk"
   },
   "outputs": [],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nzkr9yv-AdV_"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkV-LB66iwhD"
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg1kvfemrrQH"
   },
   "outputs": [],
   "source": [
    "df_account_value.loc[0,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tt1bzL5OrsTa"
   },
   "outputs": [],
   "source": [
    "df_account_value.loc[len(df_account_value)-1,'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKRGftSS7pNM"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "BzBaE63H3RLc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_sac, \n",
    "#     environment = e_trade_gym)\n",
    "df_account_value2, df_actions2 = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo2, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "ZYeOjax-7H_5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.344855\n",
      "Cumulative returns     0.484456\n",
      "Annual volatility      0.141697\n",
      "Sharpe ratio           2.169263\n",
      "Calmar ratio           4.269411\n",
      "Stability              0.944391\n",
      "Max drawdown          -0.080773\n",
      "Omega ratio            1.434521\n",
      "Sortino ratio          3.211075\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.046391\n",
      "Daily value at risk   -0.016632\n",
      "dtype: float64\n",
      "==============Get Baseline Stats===========\n",
      "Annual return          0.269722\n",
      "Cumulative returns     0.374922\n",
      "Annual volatility      0.139083\n",
      "Sharpe ratio           1.792302\n",
      "Calmar ratio           3.020136\n",
      "Stability              0.919220\n",
      "Max drawdown          -0.089308\n",
      "Omega ratio            1.347571\n",
      "Sortino ratio          2.655481\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.052781\n",
      "Daily value at risk   -0.016534\n",
      "dtype: float64\n",
      "==============Compare to DJIA===========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-28</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>34.485%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>48.446%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>14.17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-8.077%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-1.663%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.08</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.93</td>\n",
       "      <td>2021-08-16</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>2021-10-19</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.48</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.74</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.50</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.12%</td>\n",
       "      <td>-3.72%</td>\n",
       "      <td>2.35%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value2)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'2.csv')\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value2.loc[0,'date'],\n",
    "        end = df_account_value2.loc[len(df_account_value2)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value2, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = df_account_value2.loc[0,'date'],\n",
    "             baseline_end = df_account_value2.loc[len(df_account_value2)-1,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uy5_PTmOh1hj",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_StockTrading_NeurIPS_2018.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
